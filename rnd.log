nohup: ignoring input
/root/BoredDoomGuy/env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/BoredDoomGuy/env/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: Currently logged in as: mjsong2021 (minjunes) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run e5hi10t4
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /root/BoredDoomGuy/wandb/run-20251019_232842-e5hi10t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-river-119
wandb: ‚≠êÔ∏è View project at https://wandb.ai/minjunes/doom-idm-curiosity
wandb: üöÄ View run at https://wandb.ai/minjunes/doom-idm-curiosity/runs/e5hi10t4
/root/BoredDoomGuy/icm_rnd.py:419: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)
  Image.fromarray(rgb_curr, mode='RGB').save(f'{save_frame_dir}/frame_{i:04d}_current.png')
Using device: cpu
Using 30 worker threads

=== Iteration 1/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 16.45s
EPOCH 1 took 18.39s
update_step :  1
reward/intrinsic_batch_mean :  0.05185218081816479
reward/extrinsic_batch_mean :  0.0031777777777777776
loss/policy :  -0.0005310489090554642
loss/rnd :  0.001135435527458233
loss/value :  0.22153204690777895
loss/value_i :  0.05109938925880036
loss/value_e :  0.17043265677762753
loss/entropy :  2.483627084529761
reward/intrinsic_running :  0.526446857823786
reward/extrinsic_running :  0.0031777777777777776
reward/intrinsic_std_running :  0.11137740150069643
reward/extrinsic_std_running :  0.18487506759237152
reward/intrinsic_batch_std :  0.0010243783762326247
reward/intrinsic_batch_max :  0.058197833597660065
reward/intrinsic_batch_min :  0.04906843602657318
reward/total_batch :  0.027514979297971285
time/iteration_time :  94.73927330970764
time/fps :  2849.9268631431855
data/episodes_collected :  60
data/frames_collected :  270000
Timer 94.7s | FPS: 2850
Policy Loss: -0.0005, Value Loss: 0.2215, Entropy: 2.4836
RND Loss: 0.0011
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.466, max=0.523, sum=31424.9
Extrinsic raw: Œº=0.0031777777777777776

=== Iteration 2/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.39s
EPOCH 1 took 18.52s
update_step :  2
reward/intrinsic_batch_mean :  0.00012030486159352155
reward/extrinsic_batch_mean :  0.002777777777777778
loss/policy :  2.2520060156239197e-05
loss/rnd :  1.9111848346118208e-05
loss/value :  0.16527614042614447
loss/value_i :  0.003309305035861943
loss/value_e :  0.16196683523329822
loss/entropy :  2.4840281587658506
reward/intrinsic_running :  0.2647122293208
reward/extrinsic_running :  0.002777777777777778
reward/intrinsic_std_running :  0.27332988942382613
reward/extrinsic_std_running :  0.17237896093444668
reward/intrinsic_batch_std :  0.00013415854369128264
reward/intrinsic_batch_max :  0.004226543474942446
reward/intrinsic_batch_min :  2.9350318072829396e-05
reward/total_batch :  0.0014490413196856498
time/iteration_time :  110.08966326713562
time/fps :  2452.54633348126
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2453
Policy Loss: 0.0000, Value Loss: 0.1653, Entropy: 2.4840
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.015, sum=29.7
Extrinsic raw: Œº=0.002777777777777778

=== Iteration 3/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 18.72s
update_step :  3
reward/intrinsic_batch_mean :  5.4747879315457086e-05
reward/extrinsic_batch_mean :  0.0020148148148148148
loss/policy :  -0.0003127975488138018
loss/rnd :  1.102320587079069e-05
loss/value :  0.10867859084497798
loss/value_i :  0.0026450489584187217
loss/value_e :  0.1060335420523629
loss/entropy :  2.483979759794293
reward/intrinsic_running :  0.17689448839917404
reward/extrinsic_running :  0.0020148148148148148
reward/intrinsic_std_running :  0.2554023552472604
reward/extrinsic_std_running :  0.14940504157219037
reward/intrinsic_batch_std :  7.034208793450641e-05
reward/intrinsic_batch_max :  0.0014420845545828342
reward/intrinsic_batch_min :  1.191046612802893e-05
reward/total_batch :  0.001034781347065136
time/iteration_time :  110.7502818107605
time/fps :  2437.917047121832
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2438
Policy Loss: -0.0003, Value Loss: 0.1087, Entropy: 2.4840
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.006, sum=14.5
Extrinsic raw: Œº=0.0020148148148148148

=== Iteration 4/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.60s
EPOCH 1 took 19.96s
update_step :  4
reward/intrinsic_batch_mean :  4.5608037946631495e-05
reward/extrinsic_batch_mean :  0.003459259259259259
loss/policy :  -0.0003054787344863695
loss/rnd :  9.496217816459565e-06
loss/value :  0.18663252585313536
loss/value_i :  0.0018637819995285208
loss/value_e :  0.18476874403881305
loss/entropy :  2.4835718111558394
reward/intrinsic_running :  0.13290877929433123
reward/extrinsic_running :  0.003459259259259259
reward/intrinsic_std_running :  0.2339382230321626
reward/extrinsic_std_running :  0.19273632969587357
reward/intrinsic_batch_std :  4.0733006002095825e-05
reward/intrinsic_batch_max :  0.0005642608739435673
reward/intrinsic_batch_min :  6.5929284573940095e-06
reward/total_batch :  0.0017524336486029453
time/iteration_time :  111.05513858795166
time/fps :  2431.224736045597
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0003, Value Loss: 0.1866, Entropy: 2.4836
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=13.2
Extrinsic raw: Œº=0.003459259259259259

=== Iteration 5/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.31s
EPOCH 1 took 19.25s
update_step :  5
reward/intrinsic_batch_mean :  3.8906200322836176e-05
reward/extrinsic_batch_mean :  0.0026666666666666666
loss/policy :  -0.00042646880540291244
loss/rnd :  7.863729203536147e-06
loss/value :  0.1472309801840421
loss/value_i :  0.001173024176916277
loss/value_e :  0.14605795580780867
loss/entropy :  2.4827063914501304
reward/intrinsic_running :  0.10647938053981786
reward/extrinsic_running :  0.0026666666666666666
reward/intrinsic_std_running :  0.21581417124019053
reward/extrinsic_std_running :  0.17254178237941872
reward/intrinsic_batch_std :  2.8641461666697525e-05
reward/intrinsic_batch_max :  0.0004196729278191924
reward/intrinsic_batch_min :  3.847220341413049e-06
reward/total_batch :  0.0013527864334947513
time/iteration_time :  109.7834746837616
time/fps :  2459.3865404401936
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.8s | FPS: 2459
Policy Loss: -0.0004, Value Loss: 0.1472, Entropy: 2.4827
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=12.2
Extrinsic raw: Œº=0.0026666666666666666

=== Iteration 6/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.26s
update_step :  6
reward/intrinsic_batch_mean :  3.513498861329599e-05
reward/extrinsic_batch_mean :  0.004088888888888889
loss/policy :  -0.00011170029095162384
loss/rnd :  6.718840316380286e-06
loss/value :  0.23169654122356212
loss/value_i :  0.0008335752332420794
loss/value_e :  0.23086296608953766
loss/entropy :  2.483149918642911
reward/intrinsic_running :  0.08883982483021637
reward/extrinsic_running :  0.004088888888888889
reward/intrinsic_std_running :  0.20092017293356637
reward/extrinsic_std_running :  0.21120014964454112
reward/intrinsic_batch_std :  2.4573592265540742e-05
reward/intrinsic_batch_max :  0.00037133583100512624
reward/intrinsic_batch_min :  3.876937171298778e-06
reward/total_batch :  0.002062011938751093
time/iteration_time :  110.83959627151489
time/fps :  2435.952575455098
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2436
Policy Loss: -0.0001, Value Loss: 0.2317, Entropy: 2.4831
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=11.8
Extrinsic raw: Œº=0.004088888888888889

=== Iteration 7/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.35s
EPOCH 1 took 19.40s
update_step :  7
reward/intrinsic_batch_mean :  3.493936450671484e-05
reward/extrinsic_batch_mean :  0.004392592592592593
loss/policy :  -2.3263873475970644e-06
loss/rnd :  6.29518409699482e-06
loss/value :  0.2671644589440389
loss/value_i :  0.0004982504421301807
loss/value_e :  0.2666662087043126
loss/entropy :  2.483318137400078
reward/intrinsic_running :  0.07623474990204329
reward/extrinsic_running :  0.004392592592592593
reward/intrinsic_std_running :  0.18856105233473416
reward/extrinsic_std_running :  0.2180875663851495
reward/intrinsic_batch_std :  2.6181966655106287e-05
reward/intrinsic_batch_max :  0.00041116279317066073
reward/intrinsic_batch_min :  3.952903625759063e-06
reward/total_batch :  0.002213765978549654
time/iteration_time :  112.03216671943665
time/fps :  2410.0221204876266
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0000, Value Loss: 0.2672, Entropy: 2.4833
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=12.5
Extrinsic raw: Œº=0.004392592592592593

=== Iteration 8/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 18.60s
update_step :  8
reward/intrinsic_batch_mean :  3.4673529587571806e-05
reward/extrinsic_batch_mean :  0.004111111111111111
loss/policy :  -0.0003886643724840586
loss/rnd :  5.9501422983334065e-06
loss/value :  0.25835197712435864
loss/value_i :  0.00038219964092907804
loss/value_e :  0.2579697779182232
loss/entropy :  2.4826861908941558
reward/intrinsic_running :  0.06677629388598023
reward/extrinsic_running :  0.004111111111111111
reward/intrinsic_std_running :  0.17814912488680917
reward/extrinsic_std_running :  0.2111734118598817
reward/intrinsic_batch_std :  2.661966974375903e-05
reward/intrinsic_batch_max :  0.0003918822330888361
reward/intrinsic_batch_min :  4.051887572131818e-06
reward/total_batch :  0.0020728923203493415
time/iteration_time :  110.38449835777283
time/fps :  2445.9956245385943
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: -0.0004, Value Loss: 0.2584, Entropy: 2.4827
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=13.1
Extrinsic raw: Œº=0.004111111111111111

=== Iteration 9/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.01s
EPOCH 1 took 18.98s
update_step :  9
reward/intrinsic_batch_mean :  3.2576536168050585e-05
reward/extrinsic_batch_mean :  0.003933333333333333
loss/policy :  -0.00029998439387065554
loss/rnd :  5.325560199377254e-06
loss/value :  0.23753746915044208
loss/value_i :  0.0002918876202646502
loss/value_e :  0.23724558181834943
loss/entropy :  2.4822864640842783
reward/intrinsic_running :  0.059412469650618686
reward/extrinsic_running :  0.003933333333333333
reward/intrinsic_std_running :  0.1692470911748713
reward/extrinsic_std_running :  0.20389560509676952
reward/intrinsic_batch_std :  2.246720850847549e-05
reward/intrinsic_batch_max :  0.0003418932610657066
reward/intrinsic_batch_min :  4.66224400952342e-06
reward/total_batch :  0.0019829549347506917
time/iteration_time :  111.7067813873291
time/fps :  2417.042158468511
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: -0.0003, Value Loss: 0.2375, Entropy: 2.4823
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=13.0
Extrinsic raw: Œº=0.003933333333333333

=== Iteration 10/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.21s
update_step :  10
reward/intrinsic_batch_mean :  3.363493896191627e-05
reward/extrinsic_batch_mean :  0.002585185185185185
loss/policy :  -0.0003039610102970266
loss/rnd :  5.301420342772017e-06
loss/value :  0.1883149960953178
loss/value_i :  0.00022338256751412922
loss/value_e :  0.1880916138038491
loss/entropy :  2.481469974373326
reward/intrinsic_running :  0.053520894480226594
reward/extrinsic_running :  0.002585185185185185
reward/intrinsic_std_running :  0.16153180285524837
reward/extrinsic_std_running :  0.16809604332202852
reward/intrinsic_batch_std :  2.6201640776856735e-05
reward/intrinsic_batch_max :  0.0003595917369239032
reward/intrinsic_batch_min :  4.227358203934273e-06
reward/total_batch :  0.0013094100620735507
time/iteration_time :  110.66588687896729
time/fps :  2439.776227477332
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2440
Policy Loss: -0.0003, Value Loss: 0.1883, Entropy: 2.4815
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=14.1
Extrinsic raw: Œº=0.002585185185185185

=== Iteration 11/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.71s
update_step :  11
reward/intrinsic_batch_mean :  3.409218215429064e-05
reward/extrinsic_batch_mean :  0.004614814814814815
loss/policy :  -0.00036046840074105245
loss/rnd :  5.075308997744067e-06
loss/value :  0.2840056751262058
loss/value_i :  0.0001560368514081788
loss/value_e :  0.28384963693943893
loss/entropy :  2.4798743724823
reward/intrinsic_running :  0.048698974373319714
reward/extrinsic_running :  0.004614814814814815
reward/intrinsic_std_running :  0.15476753710187643
reward/extrinsic_std_running :  0.22136989273645785
reward/intrinsic_batch_std :  2.574858586246606e-05
reward/intrinsic_batch_max :  0.00033447908936068416
reward/intrinsic_batch_min :  3.1391643915412715e-06
reward/total_batch :  0.0023244534984845524
time/iteration_time :  111.0013861656189
time/fps :  2432.4020566477275
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0004, Value Loss: 0.2840, Entropy: 2.4799
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=14.9
Extrinsic raw: Œº=0.004614814814814815

=== Iteration 12/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.87s
EPOCH 1 took 20.23s
update_step :  12
reward/intrinsic_batch_mean :  3.331242665529283e-05
reward/extrinsic_batch_mean :  0.004888888888888889
loss/policy :  -0.00036374055410057986
loss/rnd :  4.861332296389843e-06
loss/value :  0.3299933337804043
loss/value_i :  0.00013283068906413533
loss/value_e :  0.32986050257177063
loss/entropy :  2.4794763760133223
reward/intrinsic_running :  0.044678340625329195
reward/extrinsic_running :  0.004888888888888889
reward/intrinsic_std_running :  0.14877745701624281
reward/extrinsic_std_running :  0.22798267207275227
reward/intrinsic_batch_std :  2.494089255982634e-05
reward/intrinsic_batch_max :  0.00043069597450084984
reward/intrinsic_batch_min :  2.678792952792719e-06
reward/total_batch :  0.0024611006577720906
time/iteration_time :  112.83330464363098
time/fps :  2392.910505038908
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: -0.0004, Value Loss: 0.3300, Entropy: 2.4795
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=15.1
Extrinsic raw: Œº=0.004888888888888889

=== Iteration 13/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.21s
update_step :  13
reward/intrinsic_batch_mean :  3.361589401823342e-05
reward/extrinsic_batch_mean :  0.0042
loss/policy :  -0.00015642772919046834
loss/rnd :  4.745555605206226e-06
loss/value :  0.30436403552691144
loss/value_i :  0.00010060777375739153
loss/value_e :  0.30426342830513464
loss/entropy :  2.4798328840371333
reward/intrinsic_running :  0.04127556634092727
reward/extrinsic_running :  0.0042
reward/intrinsic_std_running :  0.14342597389629527
reward/extrinsic_std_running :  0.21471977603896247
reward/intrinsic_batch_std :  2.5716218927197804e-05
reward/intrinsic_batch_max :  0.0003611822903621942
reward/intrinsic_batch_min :  3.7595573303406127e-06
reward/total_batch :  0.0021168079470091166
time/iteration_time :  111.3011908531189
time/fps :  2425.8500554258358
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: -0.0002, Value Loss: 0.3044, Entropy: 2.4798
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=15.8
Extrinsic raw: Œº=0.0042

=== Iteration 14/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.55s
EPOCH 1 took 19.20s
update_step :  14
reward/intrinsic_batch_mean :  3.514270439370901e-05
reward/extrinsic_batch_mean :  0.004814814814814815
loss/policy :  -0.00042094962543959616
loss/rnd :  4.800701486656732e-06
loss/value :  0.3287339930733045
loss/value_i :  8.960298333532234e-05
loss/value_e :  0.3286443917137204
loss/entropy :  2.479902299967679
reward/intrinsic_running :  0.03835905697247103
reward/extrinsic_running :  0.004814814814814815
reward/intrinsic_std_running :  0.13860820355194556
reward/extrinsic_std_running :  0.22806546120650548
reward/intrinsic_batch_std :  2.7498178090919016e-05
reward/intrinsic_batch_max :  0.0003211770090274513
reward/intrinsic_batch_min :  3.3905153031810187e-06
reward/total_batch :  0.0024249787596042622
time/iteration_time :  111.8884527683258
time/fps :  2413.117648154963
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0004, Value Loss: 0.3287, Entropy: 2.4799
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=17.1
Extrinsic raw: Œº=0.004814814814814815

=== Iteration 15/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.21s
EPOCH 1 took 18.59s
update_step :  15
reward/intrinsic_batch_mean :  3.4001118077971854e-05
reward/extrinsic_batch_mean :  0.0036148148148148146
loss/policy :  -0.0005783052408580922
loss/rnd :  4.552773554788666e-06
loss/value :  0.285905913421602
loss/value_i :  4.454968739358292e-05
loss/value_e :  0.28586136346513574
loss/entropy :  2.4807476274894946
reward/intrinsic_running :  0.03582952230809151
reward/extrinsic_running :  0.0036148148148148146
reward/intrinsic_std_running :  0.1342423226944982
reward/extrinsic_std_running :  0.19652982000422128
reward/intrinsic_batch_std :  2.6235905276915573e-05
reward/intrinsic_batch_max :  0.0003379677655175328
reward/intrinsic_batch_min :  3.068174009968061e-06
reward/total_batch :  0.0018244079664463933
time/iteration_time :  110.26911091804504
time/fps :  2448.55515522086
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.3s | FPS: 2449
Policy Loss: -0.0006, Value Loss: 0.2859, Entropy: 2.4807
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=17.1
Extrinsic raw: Œº=0.0036148148148148146

=== Iteration 16/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.89s
EPOCH 1 took 18.86s
update_step :  16
reward/intrinsic_batch_mean :  3.2343266255941636e-05
reward/extrinsic_batch_mean :  0.005629629629629629
loss/policy :  -0.000400285554915723
loss/rnd :  4.153926531878162e-06
loss/value :  0.34108534387566825
loss/value_i :  3.790597877399925e-05
loss/value_e :  0.3410474375793428
loss/entropy :  2.4802073601520425
reward/intrinsic_running :  0.03361405729560428
reward/extrinsic_running :  0.005629629629629629
reward/intrinsic_std_running :  0.13026248358927095
reward/extrinsic_std_running :  0.24367132510338715
reward/intrinsic_batch_std :  2.1946758990723413e-05
reward/intrinsic_batch_max :  0.0002840885135810822
reward/intrinsic_batch_min :  3.137843123113271e-06
reward/total_batch :  0.0028309864479427855
time/iteration_time :  112.06803631782532
time/fps :  2409.250745094517
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: -0.0004, Value Loss: 0.3411, Entropy: 2.4802
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.002, sum=16.8
Extrinsic raw: Œº=0.005629629629629629

=== Iteration 17/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.80s
update_step :  17
reward/intrinsic_batch_mean :  3.606814707429159e-05
reward/extrinsic_batch_mean :  0.004488888888888889
loss/policy :  -0.0005273807090072131
loss/rnd :  4.870027472255363e-06
loss/value :  0.3351371985944835
loss/value_i :  3.222874875064008e-05
loss/value_e :  0.33510497076944873
loss/entropy :  2.4798193339145547
reward/intrinsic_running :  0.03166092580240743
reward/extrinsic_running :  0.004488888888888889
reward/intrinsic_std_running :  0.12661444253499782
reward/extrinsic_std_running :  0.2179751894364966
reward/intrinsic_batch_std :  2.918348573494048e-05
reward/intrinsic_batch_max :  0.00033794884802773595
reward/intrinsic_batch_min :  3.81917561753653e-06
reward/total_batch :  0.00226247851798159
time/iteration_time :  112.37213587760925
time/fps :  2402.7308717712017
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: -0.0005, Value Loss: 0.3351, Entropy: 2.4798
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=19.2
Extrinsic raw: Œº=0.004488888888888889

=== Iteration 18/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.96s
EPOCH 1 took 19.50s
update_step :  18
reward/intrinsic_batch_mean :  4.048767789778746e-05
reward/extrinsic_batch_mean :  0.0029407407407407407
loss/policy :  -0.0004089738270550063
loss/rnd :  4.0996860455131605e-06
loss/value :  0.21093764246413202
loss/value_i :  2.332821592669158e-05
loss/value_e :  0.21091431447050787
loss/entropy :  2.480631131114382
reward/intrinsic_running :  0.02992739913782279
reward/extrinsic_running :  0.0029407407407407407
reward/intrinsic_std_running :  0.12325454382052975
reward/extrinsic_std_running :  0.18095083281308105
reward/intrinsic_batch_std :  2.520423922933025e-05
reward/intrinsic_batch_max :  0.0003450406948104501
reward/intrinsic_batch_min :  8.048243216762785e-06
reward/total_batch :  0.001490614209319264
time/iteration_time :  111.76546812057495
time/fps :  2415.772998049078
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: -0.0004, Value Loss: 0.2109, Entropy: 2.4806
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=22.2
Extrinsic raw: Œº=0.0029407407407407407

=== Iteration 19/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.88s
EPOCH 1 took 20.29s
update_step :  19
reward/intrinsic_batch_mean :  3.282292918101693e-05
reward/extrinsic_batch_mean :  0.0036962962962962965
loss/policy :  -0.000251599851198438
loss/rnd :  3.9086197292900495e-06
loss/value :  0.28290603603377484
loss/value_i :  3.260857250676384e-05
loss/value_e :  0.28287342664870346
loss/entropy :  2.4788000366904517
reward/intrinsic_running :  0.028371198796487612
reward/extrinsic_running :  0.0036962962962962965
reward/intrinsic_std_running :  0.12014871253677484
reward/extrinsic_std_running :  0.1999751011936078
reward/intrinsic_batch_std :  2.2405133051347463e-05
reward/intrinsic_batch_max :  0.00030152779072523117
reward/intrinsic_batch_min :  3.1995141398510896e-06
reward/total_batch :  0.0018645596127386567
time/iteration_time :  113.3372278213501
time/fps :  2382.2710788867407
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2382
Policy Loss: -0.0003, Value Loss: 0.2829, Entropy: 2.4788
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=18.4
Extrinsic raw: Œº=0.0036962962962962965

=== Iteration 20/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.45s
EPOCH 1 took 18.89s
update_step :  20
reward/intrinsic_batch_mean :  3.326022497802586e-05
reward/extrinsic_batch_mean :  0.003674074074074074
loss/policy :  -0.00034044401642555994
loss/rnd :  3.872784280688255e-06
loss/value :  0.34340163455768064
loss/value_i :  2.9263090558136657e-05
loss/value_e :  0.3433723709348476
loss/entropy :  2.47753948876352
reward/intrinsic_running :  0.026970405237998783
reward/extrinsic_running :  0.003674074074074074
reward/intrinsic_std_running :  0.11726555657415048
reward/extrinsic_std_running :  0.20037331195211905
reward/intrinsic_batch_std :  2.2593891783969063e-05
reward/intrinsic_batch_max :  0.00032763744820840657
reward/intrinsic_batch_min :  3.057035428355448e-06
reward/total_batch :  0.00185366714952605
time/iteration_time :  109.6301851272583
time/fps :  2462.825358605251
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.6s | FPS: 2463
Policy Loss: -0.0003, Value Loss: 0.3434, Entropy: 2.4775
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=19.1
Extrinsic raw: Œº=0.003674074074074074

=== Iteration 21/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 18.65s
update_step :  21
reward/intrinsic_batch_mean :  3.5796159824746646e-05
reward/extrinsic_batch_mean :  0.00297037037037037
loss/policy :  -0.00015762527596741688
loss/rnd :  4.027822748839478e-06
loss/value :  0.24636741908210696
loss/value_i :  2.1746996949470045e-05
loss/value_e :  0.24634567219199557
loss/entropy :  2.47877980001045
reward/intrinsic_running :  0.025703955960804263
reward/extrinsic_running :  0.00297037037037037
reward/intrinsic_std_running :  0.11457953690420683
reward/extrinsic_std_running :  0.18090940809394035
reward/intrinsic_batch_std :  2.6112891438193912e-05
reward/intrinsic_batch_max :  0.0004003657668363303
reward/intrinsic_batch_min :  3.6584669942385517e-06
reward/total_batch :  0.0015030832650975584
time/iteration_time :  111.70919275283813
time/fps :  2416.9899839611926
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: -0.0002, Value Loss: 0.2464, Entropy: 2.4788
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=21.1
Extrinsic raw: Œº=0.00297037037037037

=== Iteration 22/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.62s
EPOCH 1 took 18.84s
update_step :  22
reward/intrinsic_batch_mean :  3.4885189985575214e-05
reward/extrinsic_batch_mean :  0.003488888888888889
loss/policy :  -0.0006912181870024087
loss/rnd :  3.914511963061655e-06
loss/value :  0.2767906518596591
loss/value_i :  2.6025984824986097e-05
loss/value_e :  0.2767646263043086
loss/entropy :  2.479607759100018
reward/intrinsic_running :  0.024551745070605875
reward/extrinsic_running :  0.003488888888888889
reward/intrinsic_std_running :  0.1120696307948121
reward/extrinsic_std_running :  0.19669221554073
reward/intrinsic_batch_std :  2.5835721300639252e-05
reward/intrinsic_batch_max :  0.0003980566398240626
reward/intrinsic_batch_min :  3.7139755022508325e-06
reward/total_batch :  0.001761887039437232
time/iteration_time :  111.39231276512146
time/fps :  2423.8656447443914
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0007, Value Loss: 0.2768, Entropy: 2.4796
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=21.0
Extrinsic raw: Œº=0.003488888888888889

=== Iteration 23/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 18.50s
update_step :  23
reward/intrinsic_batch_mean :  3.452040874845571e-05
reward/extrinsic_batch_mean :  0.004051851851851852
loss/policy :  -0.0003676526367516172
loss/rnd :  3.682689425383587e-06
loss/value :  0.30993259043404553
loss/value_i :  2.339692246371697e-05
loss/value_e :  0.3099091958367463
loss/entropy :  2.47971654660774
reward/intrinsic_running :  0.023499271260254046
reward/extrinsic_running :  0.004051851851851852
reward/intrinsic_std_running :  0.10971737721199687
reward/extrinsic_std_running :  0.20753016089656906
reward/intrinsic_batch_std :  2.3535475219561813e-05
reward/intrinsic_batch_max :  0.00036576605634763837
reward/intrinsic_batch_min :  3.791513108808431e-06
reward/total_batch :  0.0020431861303001537
time/iteration_time :  111.42375206947327
time/fps :  2423.1817272824705
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: -0.0004, Value Loss: 0.3099, Entropy: 2.4797
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=21.2
Extrinsic raw: Œº=0.004051851851851852

=== Iteration 24/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.46s
EPOCH 1 took 19.33s
update_step :  24
reward/intrinsic_batch_mean :  3.299063783446467e-05
reward/extrinsic_batch_mean :  0.004162962962962963
loss/policy :  -0.00013746710134331477
loss/rnd :  3.737672090430737e-06
loss/value :  0.3388045554359754
loss/value_i :  2.8380635933100358e-05
loss/value_e :  0.33877617391673004
loss/entropy :  2.4794821775320806
reward/intrinsic_running :  0.02253351535136089
reward/extrinsic_running :  0.004162962962962963
reward/intrinsic_std_running :  0.10750709787879036
reward/extrinsic_std_running :  0.21111100142947117
reward/intrinsic_batch_std :  2.3123062153937455e-05
reward/intrinsic_batch_max :  0.0003829798079095781
reward/intrinsic_batch_min :  4.1444532143941615e-06
reward/total_batch :  0.002097976800398714
time/iteration_time :  111.87685132026672
time/fps :  2413.367884541893
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0001, Value Loss: 0.3388, Entropy: 2.4795
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=20.7
Extrinsic raw: Œº=0.004162962962962963

=== Iteration 25/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.37s
EPOCH 1 took 19.17s
update_step :  25
reward/intrinsic_batch_mean :  3.4422967984324644e-05
reward/extrinsic_batch_mean :  0.004629629629629629
loss/policy :  -0.0002589886090859319
loss/rnd :  3.7256520775399897e-06
loss/value :  0.4344163794409145
loss/value_i :  2.8231563633060873e-05
loss/value_e :  0.4343881480621569
loss/entropy :  2.4783072905106978
reward/intrinsic_running :  0.021645404462333328
reward/extrinsic_running :  0.004629629629629629
reward/intrinsic_std_running :  0.10542483334586723
reward/extrinsic_std_running :  0.2213528519084653
reward/intrinsic_batch_std :  2.217545511766323e-05
reward/intrinsic_batch_max :  0.0003344678261782974
reward/intrinsic_batch_min :  3.3760918540792773e-06
reward/total_batch :  0.002332026298806977
time/iteration_time :  110.8213586807251
time/fps :  2436.353454011212
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2436
Policy Loss: -0.0003, Value Loss: 0.4344, Entropy: 2.4783
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=22.0
Extrinsic raw: Œº=0.004629629629629629

=== Iteration 26/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.53s
EPOCH 1 took 19.13s
update_step :  26
reward/intrinsic_batch_mean :  3.3343114586784427e-05
reward/extrinsic_batch_mean :  0.0041555555555555556
loss/policy :  -0.0001559405716375984
loss/rnd :  3.7310051497611725e-06
loss/value :  0.4188774180683223
loss/value_i :  2.7912486819497477e-05
loss/value_e :  0.4188495059356545
loss/entropy :  2.477158116571831
reward/intrinsic_running :  0.0208248931894026
reward/extrinsic_running :  0.0041555555555555556
reward/intrinsic_std_running :  0.10345893082502469
reward/extrinsic_std_running :  0.21111991911450126
reward/intrinsic_batch_std :  2.2533341543745972e-05
reward/intrinsic_batch_max :  0.00034719129325821996
reward/intrinsic_batch_min :  3.1013903480925364e-06
reward/total_batch :  0.00209444933507117
time/iteration_time :  112.48154592514038
time/fps :  2400.39375151985
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: -0.0002, Value Loss: 0.4189, Entropy: 2.4772
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=21.8
Extrinsic raw: Œº=0.0041555555555555556

=== Iteration 27/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.16s
EPOCH 1 took 18.85s
update_step :  27
reward/intrinsic_batch_mean :  3.888347120777056e-05
reward/extrinsic_batch_mean :  0.005659259259259259
loss/policy :  -0.00056391413178944
loss/rnd :  3.7235743300036783e-06
loss/value :  0.44515159861607984
loss/value_i :  2.992921847842147e-05
loss/value_e :  0.4451216703111475
loss/entropy :  2.4753208088152334
reward/intrinsic_running :  0.02006683785201777
reward/extrinsic_running :  0.005659259259259259
reward/intrinsic_std_running :  0.10159850811829038
reward/extrinsic_std_running :  0.2436402375988603
reward/intrinsic_batch_std :  2.591290959006651e-05
reward/intrinsic_batch_max :  0.00037949878606013954
reward/intrinsic_batch_min :  4.430819444678491e-06
reward/total_batch :  0.0028490713652335148
time/iteration_time :  111.06414151191711
time/fps :  2431.0276595531886
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0006, Value Loss: 0.4452, Entropy: 2.4753
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=25.8
Extrinsic raw: Œº=0.005659259259259259

=== Iteration 28/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.82s
EPOCH 1 took 18.50s
update_step :  28
reward/intrinsic_batch_mean :  3.4621909512740484e-05
reward/extrinsic_batch_mean :  0.003711111111111111
loss/policy :  -0.00038961814910483855
loss/rnd :  3.437057247620859e-06
loss/value :  0.41529685258865356
loss/value_i :  3.1225922364021905e-05
loss/value_e :  0.41526562743114703
loss/entropy :  2.47753939484105
reward/intrinsic_running :  0.019361518332080396
reward/extrinsic_running :  0.003711111111111111
reward/intrinsic_std_running :  0.09983505010068254
reward/extrinsic_std_running :  0.20032641388185793
reward/intrinsic_batch_std :  2.351621543592406e-05
reward/intrinsic_batch_max :  0.00034262059489265084
reward/intrinsic_batch_min :  3.6306778383732308e-06
reward/total_batch :  0.001872866510311926
time/iteration_time :  110.97470664978027
time/fps :  2432.986832324594
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0004, Value Loss: 0.4153, Entropy: 2.4775
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=23.4
Extrinsic raw: Œº=0.003711111111111111

=== Iteration 29/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.81s
EPOCH 1 took 18.76s
update_step :  29
reward/intrinsic_batch_mean :  3.50460270911585e-05
reward/extrinsic_batch_mean :  0.0038074074074074074
loss/policy :  -0.0005603920660426163
loss/rnd :  3.41218684973159e-06
loss/value :  0.35060308941385965
loss/value_i :  2.7504677332630806e-05
loss/value_e :  0.35057558390227234
loss/entropy :  2.477296207890366
reward/intrinsic_running :  0.018704750043238693
reward/extrinsic_running :  0.0038074074074074074
reward/intrinsic_std_running :  0.09816019881587876
reward/extrinsic_std_running :  0.2040523352002762
reward/intrinsic_batch_std :  2.399469612861353e-05
reward/intrinsic_batch_max :  0.0003313262131996453
reward/intrinsic_batch_min :  3.91870071325684e-06
reward/total_batch :  0.001921226717249283
time/iteration_time :  109.88761758804321
time/fps :  2457.055725898079
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.9s | FPS: 2457
Policy Loss: -0.0006, Value Loss: 0.3506, Entropy: 2.4773
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=24.1
Extrinsic raw: Œº=0.0038074074074074074

=== Iteration 30/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.96s
EPOCH 1 took 19.16s
update_step :  30
reward/intrinsic_batch_mean :  3.328918815818556e-05
reward/extrinsic_batch_mean :  0.004977777777777778
loss/policy :  -0.00010856621586506002
loss/rnd :  3.2185785164873586e-06
loss/value :  0.42512640989187994
loss/value_i :  2.5985419845462523e-05
loss/value_e :  0.4251004245245095
loss/entropy :  2.474599411993316
reward/intrinsic_running :  0.01809103672361818
reward/extrinsic_running :  0.004977777777777778
reward/intrinsic_std_running :  0.09656690418484626
reward/extrinsic_std_running :  0.22788325362770875
reward/intrinsic_batch_std :  2.156198586507935e-05
reward/intrinsic_batch_max :  0.00032201927388086915
reward/intrinsic_batch_min :  2.9598190849355888e-06
reward/total_batch :  0.002505533482967982
time/iteration_time :  110.46540212631226
time/fps :  2444.2042015224556
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2444
Policy Loss: -0.0001, Value Loss: 0.4251, Entropy: 2.4746
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=23.3
Extrinsic raw: Œº=0.004977777777777778

=== Iteration 31/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.55s
EPOCH 1 took 18.80s
update_step :  31
reward/intrinsic_batch_mean :  3.6346088727212325e-05
reward/extrinsic_batch_mean :  0.006414814814814815
loss/policy :  -0.0008558641286733539
loss/rnd :  3.497384334354358e-06
loss/value :  0.5546530999920585
loss/value_i :  2.4842075342321273e-05
loss/value_e :  0.5546282547892947
loss/entropy :  2.4702095877040517
reward/intrinsic_running :  0.017517647191923932
reward/extrinsic_running :  0.006414814814814815
reward/intrinsic_std_running :  0.0950485093291711
reward/extrinsic_std_running :  0.2583630057564052
reward/intrinsic_batch_std :  2.6889431683804022e-05
reward/intrinsic_batch_max :  0.000451756757684052
reward/intrinsic_batch_min :  3.1367123938252917e-06
reward/total_batch :  0.003225580451771014
time/iteration_time :  112.39209318161011
time/fps :  2402.304222270487
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0009, Value Loss: 0.5547, Entropy: 2.4702
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.005, sum=25.8
Extrinsic raw: Œº=0.006414814814814815

=== Iteration 32/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.67s
EPOCH 1 took 19.26s
update_step :  32
reward/intrinsic_batch_mean :  3.5772307753332254e-05
reward/extrinsic_batch_mean :  0.004814814814814815
loss/policy :  -0.0004635677095476157
loss/rnd :  3.3279246908381483e-06
loss/value :  0.4543836207100839
loss/value_i :  2.4362864678550977e-05
loss/value_e :  0.454359255956881
loss/entropy :  2.4698262178536616
reward/intrinsic_running :  0.01697980727724671
reward/extrinsic_running :  0.004814814814814815
reward/intrinsic_std_running :  0.09359950741643654
reward/extrinsic_std_running :  0.22462924796157
reward/intrinsic_batch_std :  2.539685856188525e-05
reward/intrinsic_batch_max :  0.00039006330189295113
reward/intrinsic_batch_min :  3.572992227418581e-06
reward/total_batch :  0.0024252935612840737
time/iteration_time :  111.2624454498291
time/fps :  2426.694819697716
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2427
Policy Loss: -0.0005, Value Loss: 0.4544, Entropy: 2.4698
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=25.8
Extrinsic raw: Œº=0.004814814814814815

=== Iteration 33/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.75s
EPOCH 1 took 19.23s
update_step :  33
reward/intrinsic_batch_mean :  3.59468921547415e-05
reward/extrinsic_batch_mean :  0.004896296296296296
loss/policy :  -0.0009811751316936518
loss/rnd :  3.302539897903802e-06
loss/value :  0.5453388519359358
loss/value_i :  2.701864397033315e-05
loss/value_e :  0.5453118329698389
loss/entropy :  2.470031156684413
reward/intrinsic_running :  0.016474537017898663
reward/extrinsic_running :  0.004896296296296296
reward/intrinsic_std_running :  0.09221473361692023
reward/extrinsic_std_running :  0.22797439018204468
reward/intrinsic_batch_std :  2.622989028738827e-05
reward/intrinsic_batch_max :  0.00041397687164135277
reward/intrinsic_batch_min :  3.540289071679581e-06
reward/total_batch :  0.002466121594225519
time/iteration_time :  111.60622477531433
time/fps :  2419.2199005347957
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: -0.0010, Value Loss: 0.5453, Entropy: 2.4700
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=26.3
Extrinsic raw: Œº=0.004896296296296296

=== Iteration 34/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.79s
EPOCH 1 took 19.32s
update_step :  34
reward/intrinsic_batch_mean :  3.655473156689671e-05
reward/extrinsic_batch_mean :  0.005577777777777778
loss/policy :  -0.0006425987625279407
loss/rnd :  3.329780073809988e-06
loss/value :  0.6585881926796653
loss/value_i :  2.717019070229126e-05
loss/value_e :  0.6585610242504062
loss/entropy :  2.4618739865042945
reward/intrinsic_running :  0.015998873054952404
reward/extrinsic_running :  0.005577777777777778
reward/intrinsic_std_running :  0.09088960047913186
reward/extrinsic_std_running :  0.2405133388667654
reward/intrinsic_batch_std :  2.4763093878771344e-05
reward/intrinsic_batch_max :  0.0003076364519074559
reward/intrinsic_batch_min :  3.4459428661648417e-06
reward/total_batch :  0.0028071662546723373
time/iteration_time :  110.69530940055847
time/fps :  2439.1277413841153
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2439
Policy Loss: -0.0006, Value Loss: 0.6586, Entropy: 2.4619
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.003, sum=27.1
Extrinsic raw: Œº=0.005577777777777778

=== Iteration 35/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 18.23s
update_step :  35
reward/intrinsic_batch_mean :  3.83339712457975e-05
reward/extrinsic_batch_mean :  0.004992592592592593
loss/policy :  -0.0001407596123912795
loss/rnd :  4.1088525049968725e-06
loss/value :  0.575740117466811
loss/value_i :  2.502136337143108e-05
loss/value_e :  0.5757150948047638
loss/entropy :  2.462585575652845
reward/intrinsic_running :  0.015550738844893162
reward/extrinsic_running :  0.004992592592592593
reward/intrinsic_std_running :  0.08961987432765542
reward/extrinsic_std_running :  0.22786667629855958
reward/intrinsic_batch_std :  2.9443337546591094e-05
reward/intrinsic_batch_max :  0.0003877732087858021
reward/intrinsic_batch_min :  3.578764335543383e-06
reward/total_batch :  0.002515463281919195
time/iteration_time :  111.03457546234131
time/fps :  2431.6749884055143
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0001, Value Loss: 0.5757, Entropy: 2.4626
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.004, sum=28.9
Extrinsic raw: Œº=0.004992592592592593

=== Iteration 36/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.34s
EPOCH 1 took 19.24s
update_step :  36
reward/intrinsic_batch_mean :  0.00011047700215034031
reward/extrinsic_batch_mean :  0.0045703703703703705
loss/policy :  -0.0006585053157653998
loss/rnd :  8.891039724954735e-06
loss/value :  0.5913758079210917
loss/value_i :  2.7385489622908857e-05
loss/value_e :  0.5913484236507704
loss/entropy :  2.454815557508758
reward/intrinsic_running :  0.015143551228421658
reward/extrinsic_running :  0.0045703703703703705
reward/intrinsic_std_running :  0.08839922827048115
reward/extrinsic_std_running :  0.2178800227356107
reward/intrinsic_batch_std :  3.8843141385759004e-05
reward/intrinsic_batch_max :  0.0006041575106792152
reward/intrinsic_batch_min :  3.254378316341899e-05
reward/total_batch :  0.0023404236862603553
time/iteration_time :  112.59974789619446
time/fps :  2397.8739299568647
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0007, Value Loss: 0.5914, Entropy: 2.4548
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=84.4
Extrinsic raw: Œº=0.0045703703703703705

=== Iteration 37/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 18.34s
update_step :  37
reward/intrinsic_batch_mean :  0.00017467937382343397
reward/extrinsic_batch_mean :  0.004807407407407408
loss/policy :  -9.893881691492756e-05
loss/rnd :  8.487080235957393e-06
loss/value :  0.6730631192525228
loss/value_i :  2.761860017044731e-05
loss/value_e :  0.6730355033368776
loss/entropy :  2.4580700289119375
reward/intrinsic_running :  0.014771828418593431
reward/extrinsic_running :  0.004807407407407408
reward/intrinsic_std_running :  0.08722499663221422
reward/extrinsic_std_running :  0.22463765049342108
reward/intrinsic_batch_std :  3.0554923330369864e-05
reward/intrinsic_batch_max :  0.0006526198121719062
reward/intrinsic_batch_min :  0.0001129400625359267
reward/total_batch :  0.0024910433906154207
time/iteration_time :  110.60625982284546
time/fps :  2441.0914936681743
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2441
Policy Loss: -0.0001, Value Loss: 0.6731, Entropy: 2.4581
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.007, sum=135.2
Extrinsic raw: Œº=0.004807407407407408

=== Iteration 38/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 19.17s
update_step :  38
reward/intrinsic_batch_mean :  4.1210027918748016e-05
reward/extrinsic_batch_mean :  0.006718518518518519
loss/policy :  -0.000810130661579244
loss/rnd :  1.483061829055783e-05
loss/value :  0.805288808815407
loss/value_i :  2.8896402000100352e-05
loss/value_e :  0.8052599104967985
loss/entropy :  2.439104766556711
reward/intrinsic_running :  0.014391623666938596
reward/extrinsic_running :  0.006718518518518519
reward/intrinsic_std_running :  0.08610071566476012
reward/extrinsic_std_running :  0.2610577671803937
reward/intrinsic_batch_std :  2.490768762077595e-05
reward/intrinsic_batch_max :  0.0005034424248151481
reward/intrinsic_batch_min :  7.14530642653699e-06
reward/total_batch :  0.0033798642732186333
time/iteration_time :  111.89440536499023
time/fps :  2412.989274300913
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0008, Value Loss: 0.8053, Entropy: 2.4391
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.006, sum=32.3
Extrinsic raw: Œº=0.006718518518518519

=== Iteration 39/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.56s
EPOCH 1 took 19.94s
update_step :  39
reward/intrinsic_batch_mean :  5.01065345035992e-05
reward/extrinsic_batch_mean :  0.0038666666666666667
loss/policy :  -0.0003093923442065716
loss/rnd :  4.004198158878408e-06
loss/value :  0.6807394858562585
loss/value_i :  2.609215343082641e-05
loss/value_e :  0.6807133943745585
loss/entropy :  2.4527661655888413
reward/intrinsic_running :  0.014032611452126718
reward/extrinsic_running :  0.0038666666666666667
reward/intrinsic_std_running :  0.08501850494497958
reward/extrinsic_std_running :  0.20397860454251351
reward/intrinsic_batch_std :  3.1105388576392527e-05
reward/intrinsic_batch_max :  0.000492054270580411
reward/intrinsic_batch_min :  9.402603609487414e-06
reward/total_batch :  0.0019583866005851327
time/iteration_time :  112.85487389564514
time/fps :  2392.453162897192
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: -0.0003, Value Loss: 0.6807, Entropy: 2.4528
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=39.8
Extrinsic raw: Œº=0.0038666666666666667

=== Iteration 40/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.28s
EPOCH 1 took 19.18s
update_step :  40
reward/intrinsic_batch_mean :  4.265443831792018e-05
reward/extrinsic_batch_mean :  0.007229629629629629
loss/policy :  -0.00033639208854627657
loss/rnd :  3.522796153750581e-06
loss/value :  0.9774230330279379
loss/value_i :  3.2387801377009247e-05
loss/value_e :  0.9773906433221066
loss/entropy :  2.427261739066153
reward/intrinsic_running :  0.0136899689665627
reward/extrinsic_running :  0.007229629629629629
reward/intrinsic_std_running :  0.08397631674186667
reward/extrinsic_std_running :  0.2722327963680741
reward/intrinsic_batch_std :  2.805659455165275e-05
reward/intrinsic_batch_max :  0.0005568990018218756
reward/intrinsic_batch_min :  4.680848633142887e-06
reward/total_batch :  0.0036361420339737745
time/iteration_time :  111.95204758644104
time/fps :  2411.7468668139018
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2412
Policy Loss: -0.0003, Value Loss: 0.9774, Entropy: 2.4273
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=34.3
Extrinsic raw: Œº=0.007229629629629629

=== Iteration 41/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.27s
EPOCH 1 took 19.91s
update_step :  41
reward/intrinsic_batch_mean :  4.182536171744383e-05
reward/extrinsic_batch_mean :  0.005148148148148148
loss/policy :  -3.6890921833356984e-05
loss/rnd :  3.4492189487619642e-06
loss/value :  0.8127371135986212
loss/value_i :  3.329168311844996e-05
loss/value_e :  0.8127038235014136
loss/entropy :  2.4408170020941533
reward/intrinsic_running :  0.013363749511164784
reward/extrinsic_running :  0.005148148148148148
reward/intrinsic_std_running :  0.08297155236428343
reward/extrinsic_std_running :  0.23108315061157236
reward/intrinsic_batch_std :  2.9681769851870657e-05
reward/intrinsic_batch_max :  0.0004434454604052007
reward/intrinsic_batch_min :  4.468573024496436e-06
reward/total_batch :  0.002594986754932796
time/iteration_time :  111.25990462303162
time/fps :  2426.750237786093
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2427
Policy Loss: -0.0000, Value Loss: 0.8127, Entropy: 2.4408
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.005, sum=34.0
Extrinsic raw: Œº=0.005148148148148148

=== Iteration 42/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 18.80s
update_step :  42
reward/intrinsic_batch_mean :  4.3310757589002874e-05
reward/extrinsic_batch_mean :  0.007562962962962963
loss/policy :  -0.0003152215618738961
loss/rnd :  3.529740638441581e-06
loss/value :  1.0385165991205159
loss/value_i :  3.363803035895354e-05
loss/value_e :  1.038482946879936
loss/entropy :  2.4226300969268335
reward/intrinsic_running :  0.013053235758184956
reward/extrinsic_running :  0.007562962962962963
reward/intrinsic_std_running :  0.08200195553011458
reward/extrinsic_std_running :  0.2775791941025629
reward/intrinsic_batch_std :  2.777674290101993e-05
reward/intrinsic_batch_max :  0.00042425372521393
reward/intrinsic_batch_min :  4.421528046805179e-06
reward/total_batch :  0.003803136860275983
time/iteration_time :  110.11565923690796
time/fps :  2451.9673393509765
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2452
Policy Loss: -0.0003, Value Loss: 1.0385, Entropy: 2.4226
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.005, sum=35.7
Extrinsic raw: Œº=0.007562962962962963

=== Iteration 43/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.75s
EPOCH 1 took 18.63s
update_step :  43
reward/intrinsic_batch_mean :  3.986952307484359e-05
reward/extrinsic_batch_mean :  0.0057777777777777775
loss/policy :  -8.195108371596275e-05
loss/rnd :  3.2194242776588937e-06
loss/value :  0.8480849175742178
loss/value_i :  3.2886466132450465e-05
loss/value_e :  0.8480520302599127
loss/entropy :  2.4408748438864043
reward/intrinsic_running :  0.01275653036261198
reward/extrinsic_running :  0.0057777777777777775
reward/intrinsic_std_running :  0.08106564555831862
reward/extrinsic_std_running :  0.24351581184244273
reward/intrinsic_batch_std :  2.2541165461295652e-05
reward/intrinsic_batch_max :  0.00041971224709413946
reward/intrinsic_batch_min :  4.2866099647653755e-06
reward/total_batch :  0.0029088236504263105
time/iteration_time :  112.048415184021
time/fps :  2409.67263621328
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0001, Value Loss: 0.8481, Entropy: 2.4409
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.005, sum=33.2
Extrinsic raw: Œº=0.0057777777777777775

=== Iteration 44/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.35s
EPOCH 1 took 18.40s
update_step :  44
reward/intrinsic_batch_mean :  3.99311577667403e-05
reward/extrinsic_batch_mean :  0.004140740740740741
loss/policy :  -0.00031797829168764025
loss/rnd :  3.1928656474547372e-06
loss/value :  0.7379295148632743
loss/value_i :  2.8479836587256145e-05
loss/value_e :  0.7379010355833805
loss/entropy :  2.451243920759721
reward/intrinsic_running :  0.012473243525628787
reward/extrinsic_running :  0.004140740740740741
reward/intrinsic_std_running :  0.08016067965438069
reward/extrinsic_std_running :  0.20742129834435685
reward/intrinsic_batch_std :  2.5954698469504198e-05
reward/intrinsic_batch_max :  0.00042567410855554044
reward/intrinsic_batch_min :  5.677663011738332e-06
reward/total_batch :  0.0020903359492537407
time/iteration_time :  110.2324812412262
time/fps :  2449.3687972889597
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2449
Policy Loss: -0.0003, Value Loss: 0.7379, Entropy: 2.4512
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.000, max=0.005, sum=33.6
Extrinsic raw: Œº=0.004140740740740741

=== Iteration 45/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.91s
EPOCH 1 took 18.76s
update_step :  45
reward/intrinsic_batch_mean :  4.090906462986621e-05
reward/extrinsic_batch_mean :  0.006688888888888889
loss/policy :  6.439722280695356e-05
loss/rnd :  3.233602187306546e-06
loss/value :  0.9831409246632548
loss/value_i :  3.0741967913689386e-05
loss/value_e :  0.9831101867285642
loss/entropy :  2.4350990707224067
reward/intrinsic_running :  0.012202633364782455
reward/extrinsic_running :  0.006688888888888889
reward/intrinsic_std_running :  0.07928532606208508
reward/extrinsic_std_running :  0.26108690100528453
reward/intrinsic_batch_std :  2.6518174853285574e-05
reward/intrinsic_batch_max :  0.0005029389285482466
reward/intrinsic_batch_min :  5.029190106142778e-06
reward/total_batch :  0.0033648989767593777
time/iteration_time :  112.7348940372467
time/fps :  2394.999368259433
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0001, Value Loss: 0.9831, Entropy: 2.4351
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=34.8
Extrinsic raw: Œº=0.006688888888888889

=== Iteration 46/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.55s
EPOCH 1 took 19.66s
update_step :  46
reward/intrinsic_batch_mean :  4.1724364239908704e-05
reward/extrinsic_batch_mean :  0.00694074074074074
loss/policy :  -0.0007021983300078181
loss/rnd :  3.267178327047132e-06
loss/value :  0.9711115531849138
loss/value_i :  3.3595952531455126e-05
loss/value_e :  0.9710779551303748
loss/entropy :  2.4296920335654058
reward/intrinsic_running :  0.011943852895583898
reward/extrinsic_running :  0.00694074074074074
reward/intrinsic_std_running :  0.07843800804985615
reward/extrinsic_std_running :  0.26673605383274707
reward/intrinsic_batch_std :  2.757107350244517e-05
reward/intrinsic_batch_max :  0.00048279797192662954
reward/intrinsic_batch_min :  4.255531621311093e-06
reward/total_batch :  0.0034912325524903247
time/iteration_time :  112.02113389968872
time/fps :  2410.259480517098
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0007, Value Loss: 0.9711, Entropy: 2.4297
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=35.9
Extrinsic raw: Œº=0.00694074074074074

=== Iteration 47/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 18.74s
update_step :  47
reward/intrinsic_batch_mean :  4.077539745591181e-05
reward/extrinsic_batch_mean :  0.005503703703703703
loss/policy :  -0.00030362050694582814
loss/rnd :  3.158101817875418e-06
loss/value :  0.7568555537498358
loss/value_i :  3.1544169580615055e-05
loss/value_e :  0.7568240120555415
loss/entropy :  2.4460354248682656
reward/intrinsic_running :  0.011695806454667442
reward/extrinsic_running :  0.005503703703703703
reward/intrinsic_std_running :  0.07761731090496404
reward/extrinsic_std_running :  0.23733724634957967
reward/intrinsic_batch_std :  2.5948899552974044e-05
reward/intrinsic_batch_max :  0.0004315171972848475
reward/intrinsic_batch_min :  4.598216492013307e-06
reward/total_batch :  0.0027722395505798076
time/iteration_time :  110.74674201011658
time/fps :  2437.9949703200823
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2438
Policy Loss: -0.0003, Value Loss: 0.7569, Entropy: 2.4460
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=35.5
Extrinsic raw: Œº=0.005503703703703703

=== Iteration 48/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.24s
EPOCH 1 took 19.26s
update_step :  48
reward/intrinsic_batch_mean :  4.1380516915018636e-05
reward/extrinsic_batch_mean :  0.004851851851851852
loss/policy :  -0.0004108995243300204
loss/rnd :  3.173832744847239e-06
loss/value :  0.7589284046129747
loss/value_i :  2.9684456256456375e-05
loss/value_e :  0.7588987196936752
loss/entropy :  2.4449499809380733
reward/intrinsic_running :  0.011458189433603529
reward/extrinsic_running :  0.004851851851851852
reward/intrinsic_std_running :  0.07682181733154017
reward/extrinsic_std_running :  0.22458722692212624
reward/intrinsic_batch_std :  2.5147618216985737e-05
reward/intrinsic_batch_max :  0.0004954285104759037
reward/intrinsic_batch_min :  5.34860464540543e-06
reward/total_batch :  0.002446616184383435
time/iteration_time :  111.7616868019104
time/fps :  2415.854732745361
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: -0.0004, Value Loss: 0.7589, Entropy: 2.4449
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=36.4
Extrinsic raw: Œº=0.004851851851851852

=== Iteration 49/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.27s
EPOCH 1 took 18.76s
update_step :  49
reward/intrinsic_batch_mean :  4.410702316165919e-05
reward/extrinsic_batch_mean :  0.006866666666666667
loss/policy :  -8.656211977006134e-05
loss/rnd :  3.3454953223333703e-06
loss/value :  0.9384555247696963
loss/value_i :  3.1086706919516224e-05
loss/value_e :  0.9384244409474459
loss/entropy :  2.435729388034705
reward/intrinsic_running :  0.011230593563998277
reward/extrinsic_running :  0.006866666666666667
reward/intrinsic_std_running :  0.07605023170391981
reward/extrinsic_std_running :  0.2638761578215558
reward/intrinsic_batch_std :  3.0237675969387732e-05
reward/intrinsic_batch_max :  0.0004853116406593472
reward/intrinsic_batch_min :  4.060278570250375e-06
reward/total_batch :  0.003455386844914163
time/iteration_time :  110.06567621231079
time/fps :  2453.0808267527877
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2453
Policy Loss: -0.0001, Value Loss: 0.9385, Entropy: 2.4357
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=39.1
Extrinsic raw: Œº=0.006866666666666667

=== Iteration 50/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 19.29s
update_step :  50
reward/intrinsic_batch_mean :  4.3070115449066816e-05
reward/extrinsic_batch_mean :  0.006525925925925926
loss/policy :  -4.1846527231179856e-05
loss/rnd :  3.23764753361364e-06
loss/value :  0.9458056616060662
loss/value_i :  3.404302545580625e-05
loss/value_e :  0.9457716219352953
loss/entropy :  2.4408421010682075
reward/intrinsic_running :  0.011011875053056812
reward/extrinsic_running :  0.006525925925925926
reward/intrinsic_std_running :  0.07530145596707519
reward/extrinsic_std_running :  0.2582526850351151
reward/intrinsic_batch_std :  2.521687314161537e-05
reward/intrinsic_batch_max :  0.0004188245802652091
reward/intrinsic_batch_min :  4.962221282767132e-06
reward/total_batch :  0.0032844980206874967
time/iteration_time :  111.7646803855896
time/fps :  2415.7900247958164
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: -0.0000, Value Loss: 0.9458, Entropy: 2.4408
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=38.6
Extrinsic raw: Œº=0.006525925925925926

=== Iteration 51/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.50s
EPOCH 1 took 18.46s
update_step :  51
reward/intrinsic_batch_mean :  4.1593790781593676e-05
reward/extrinsic_batch_mean :  0.005051851851851852
loss/policy :  -0.0003449913594081546
loss/rnd :  3.0952595614397786e-06
loss/value :  0.7863284972580996
loss/value_i :  3.0033495794200324e-05
loss/value_e :  0.7862984655481396
loss/entropy :  2.448895002856399
reward/intrinsic_running :  0.010801484017379941
reward/extrinsic_running :  0.005051851851851852
reward/intrinsic_std_running :  0.07457439345148291
reward/extrinsic_std_running :  0.2278003452837275
reward/intrinsic_batch_std :  2.387217024426944e-05
reward/intrinsic_batch_max :  0.00048323438386432827
reward/intrinsic_batch_min :  6.287096766754985e-06
reward/total_batch :  0.0025467228213167225
time/iteration_time :  111.88763070106506
time/fps :  2413.135377952282
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0003, Value Loss: 0.7863, Entropy: 2.4489
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=37.6
Extrinsic raw: Œº=0.005051851851851852

=== Iteration 52/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.91s
EPOCH 1 took 18.40s
update_step :  52
reward/intrinsic_batch_mean :  4.1867795906236334e-05
reward/extrinsic_batch_mean :  0.004733333333333333
loss/policy :  -4.722876209681007e-05
loss/rnd :  3.085874061870334e-06
loss/value :  0.7061995755542408
loss/value_i :  2.9196583620267287e-05
loss/value_e :  0.7061703810186097
loss/entropy :  2.4578298980539497
reward/intrinsic_running :  0.010599148731408738
reward/extrinsic_running :  0.004733333333333333
reward/intrinsic_std_running :  0.07386798719298347
reward/extrinsic_std_running :  0.22123350158197616
reward/intrinsic_batch_std :  2.7948249659753843e-05
reward/intrinsic_batch_max :  0.00044192152563482523
reward/intrinsic_batch_min :  5.55443648408982e-06
reward/total_batch :  0.0023876005646197847
time/iteration_time :  110.33268117904663
time/fps :  2447.14437385825
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.3s | FPS: 2447
Policy Loss: -0.0000, Value Loss: 0.7062, Entropy: 2.4578
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=38.3
Extrinsic raw: Œº=0.004733333333333333

=== Iteration 53/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.53s
EPOCH 1 took 19.85s
update_step :  53
reward/intrinsic_batch_mean :  4.41680979897245e-05
reward/extrinsic_batch_mean :  0.007837037037037036
loss/policy :  -0.0004422377039163345
loss/rnd :  3.22341667690511e-06
loss/value :  1.046001714287382
loss/value_i :  3.2369860849884745e-05
loss/value_e :  1.0459693390311617
loss/entropy :  2.4330579475923018
reward/intrinsic_running :  0.010404745988738544
reward/extrinsic_running :  0.007837037037037036
reward/intrinsic_std_running :  0.07318123088660357
reward/extrinsic_std_running :  0.28287817577883523
reward/intrinsic_batch_std :  2.712623960749573e-05
reward/intrinsic_batch_max :  0.0005046335863880813
reward/intrinsic_batch_min :  4.4331804929242935e-06
reward/total_batch :  0.0039406025675133806
time/iteration_time :  111.31305170059204
time/fps :  2425.591571473949
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: -0.0004, Value Loss: 1.0460, Entropy: 2.4331
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=40.7
Extrinsic raw: Œº=0.007837037037037036

=== Iteration 54/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 19.15s
update_step :  54
reward/intrinsic_batch_mean :  4.4274234387625326e-05
reward/extrinsic_batch_mean :  0.0062370370370370375
loss/policy :  -0.00025689091566935974
loss/rnd :  3.2045637474518363e-06
loss/value :  0.8435152687809684
loss/value_i :  2.8883807124547083e-05
loss/value_e :  0.8434863858150713
loss/entropy :  2.4418217557849307
reward/intrinsic_running :  0.010217480378027152
reward/extrinsic_running :  0.0062370370370370375
reward/intrinsic_std_running :  0.07251327942742514
reward/extrinsic_std_running :  0.25245092540802655
reward/intrinsic_batch_std :  2.8207301788506694e-05
reward/intrinsic_batch_max :  0.00042393142939545214
reward/intrinsic_batch_min :  5.6238973229483236e-06
reward/total_batch :  0.0031406556357123313
time/iteration_time :  110.48319220542908
time/fps :  2443.8106340914755
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2444
Policy Loss: -0.0003, Value Loss: 0.8435, Entropy: 2.4418
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=41.2
Extrinsic raw: Œº=0.0062370370370370375

=== Iteration 55/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.99s
EPOCH 1 took 19.43s
update_step :  55
reward/intrinsic_batch_mean :  4.7241680381867576e-05
reward/extrinsic_batch_mean :  0.005666666666666667
loss/policy :  -0.0006233038192008142
loss/rnd :  3.388543463546684e-06
loss/value :  0.7922929516344359
loss/value_i :  2.9600278029454675e-05
loss/value_e :  0.7922633488972982
loss/entropy :  2.4441873918880117
reward/intrinsic_running :  0.010037362442694481
reward/extrinsic_running :  0.005666666666666667
reward/intrinsic_std_running :  0.071863237069991
reward/extrinsic_std_running :  0.2404188474771107
reward/intrinsic_batch_std :  3.514567990836677e-05
reward/intrinsic_batch_max :  0.0005334807792678475
reward/intrinsic_batch_min :  5.3891335483058356e-06
reward/total_batch :  0.0028569541735242675
time/iteration_time :  111.6424822807312
time/fps :  2418.4342239996963
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2418
Policy Loss: -0.0006, Value Loss: 0.7923, Entropy: 2.4442
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=44.4
Extrinsic raw: Œº=0.005666666666666667

=== Iteration 56/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.14s
EPOCH 1 took 18.66s
update_step :  56
reward/intrinsic_batch_mean :  4.490147635494429e-05
reward/extrinsic_batch_mean :  0.006807407407407407
loss/policy :  -0.00035141910043559176
loss/rnd :  3.190821454760832e-06
loss/value :  0.8823540445530054
loss/value_i :  2.9318341920302235e-05
loss/value_e :  0.8823247290018833
loss/entropy :  2.435672236211372
reward/intrinsic_running :  0.00986331981200724
reward/extrinsic_running :  0.006807407407407407
reward/intrinsic_std_running :  0.07123040788399948
reward/extrinsic_std_running :  0.2639338299873606
reward/intrinsic_batch_std :  2.8752816493943828e-05
reward/intrinsic_batch_max :  0.00048373587196692824
reward/intrinsic_batch_min :  5.043602413934423e-06
reward/total_batch :  0.0034261544418811756
time/iteration_time :  108.66340374946594
time/fps :  2484.737185506459
data/episodes_collected :  60
data/frames_collected :  270000
Timer 108.7s | FPS: 2485
Policy Loss: -0.0004, Value Loss: 0.8824, Entropy: 2.4357
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=42.5
Extrinsic raw: Œº=0.006807407407407407

=== Iteration 57/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.87s
EPOCH 1 took 18.36s
update_step :  57
reward/intrinsic_batch_mean :  4.4412615770603155e-05
reward/extrinsic_batch_mean :  0.007407407407407408
loss/policy :  -0.00017323831244456497
loss/rnd :  3.1293819492103383e-06
loss/value :  0.8907880774050048
loss/value_i :  2.816089685934871e-05
loss/value_e :  0.8907599124041471
loss/entropy :  2.4325520125302402
reward/intrinsic_running :  0.009695293316733022
reward/extrinsic_running :  0.007407407407407408
reward/intrinsic_std_running :  0.07061401215731714
reward/extrinsic_std_running :  0.2749086392697223
reward/intrinsic_batch_std :  2.4848264050429135e-05
reward/intrinsic_batch_max :  0.0005425165290944278
reward/intrinsic_batch_min :  5.581369805440772e-06
reward/total_batch :  0.0037259100115890056
time/iteration_time :  111.22449803352356
time/fps :  2427.5227559905084
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: -0.0002, Value Loss: 0.8908, Entropy: 2.4326
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=42.5
Extrinsic raw: Œº=0.007407407407407408

=== Iteration 58/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 19.47s
update_step :  58
reward/intrinsic_batch_mean :  4.388726370383396e-05
reward/extrinsic_batch_mean :  0.006562962962962963
loss/policy :  -0.00023858596272696036
loss/rnd :  3.070621911512827e-06
loss/value :  0.7792451119784153
loss/value_i :  2.784283628209254e-05
loss/value_e :  0.779217268481399
loss/entropy :  2.437972549236182
reward/intrinsic_running :  0.009532962870417275
reward/extrinsic_running :  0.006562962962962963
reward/intrinsic_std_running :  0.07001335279323687
reward/extrinsic_std_running :  0.2582158903624355
reward/intrinsic_batch_std :  2.5314460626515512e-05
reward/intrinsic_batch_max :  0.0004073233576491475
reward/intrinsic_batch_min :  4.576360424835002e-06
reward/total_batch :  0.0033034251133333987
time/iteration_time :  111.45376062393188
time/fps :  2422.5292936596015
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2423
Policy Loss: -0.0002, Value Loss: 0.7792, Entropy: 2.4380
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=42.3
Extrinsic raw: Œº=0.006562962962962963

=== Iteration 59/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 18.93s
update_step :  59
reward/intrinsic_batch_mean :  4.351456080412727e-05
reward/extrinsic_batch_mean :  0.0063407407407407405
loss/policy :  -0.0002988686388892926
loss/rnd :  3.011429140370279e-06
loss/value :  0.8639952368808516
loss/value_i :  2.7758531552645955e-05
loss/value_e :  0.8639674773721984
loss/entropy :  2.440471128983931
reward/intrinsic_running :  0.00937604512938509
reward/extrinsic_running :  0.0063407407407407405
reward/intrinsic_std_running :  0.0694277706683036
reward/extrinsic_std_running :  0.2554092188644192
reward/intrinsic_batch_std :  2.4904113264980373e-05
reward/intrinsic_batch_max :  0.00044020311906933784
reward/intrinsic_batch_min :  5.779665571026271e-06
reward/total_batch :  0.003192127650772434
time/iteration_time :  111.194753408432
time/fps :  2428.1721189511236
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: -0.0003, Value Loss: 0.8640, Entropy: 2.4405
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=42.3
Extrinsic raw: Œº=0.0063407407407407405

=== Iteration 60/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 19.16s
update_step :  60
reward/intrinsic_batch_mean :  4.3660076945720736e-05
reward/extrinsic_batch_mean :  0.0044
loss/policy :  1.2968491346603542e-05
loss/rnd :  3.0029552921074685e-06
loss/value :  0.6309343662225839
loss/value_i :  2.356136464544706e-05
loss/value_e :  0.630910805680535
loss/entropy :  2.4513224363327026
reward/intrinsic_running :  0.009224347822024062
reward/extrinsic_running :  0.0044
reward/intrinsic_std_running :  0.06885663610044827
reward/extrinsic_std_running :  0.21448277838144073
reward/intrinsic_batch_std :  2.7986046908064587e-05
reward/intrinsic_batch_max :  0.0004262570582795888
reward/intrinsic_batch_min :  4.940888629789697e-06
reward/total_batch :  0.0022218300384728605
time/iteration_time :  111.2968590259552
time/fps :  2425.9444728537587
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: 0.0000, Value Loss: 0.6309, Entropy: 2.4513
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=42.8
Extrinsic raw: Œº=0.0044

=== Iteration 61/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 18.87s
update_step :  61
reward/intrinsic_batch_mean :  4.417763596307109e-05
reward/extrinsic_batch_mean :  0.008044444444444444
loss/policy :  -0.0002302644633428744
loss/rnd :  3.0077328574407147e-06
loss/value :  0.9401158609173514
loss/value_i :  2.416996495881132e-05
loss/value_e :  0.9400916948462977
loss/entropy :  2.4371146650025337
reward/intrinsic_running :  0.009077638084511886
reward/extrinsic_running :  0.008044444444444444
reward/intrinsic_std_running :  0.06829936111803273
reward/extrinsic_std_running :  0.28542708394073885
reward/intrinsic_batch_std :  2.3571427488869843e-05
reward/intrinsic_batch_max :  0.0003868491912726313
reward/intrinsic_batch_min :  5.2499731282296125e-06
reward/total_batch :  0.004044311040203758
time/iteration_time :  111.54111909866333
time/fps :  2420.631980222221
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: -0.0002, Value Loss: 0.9401, Entropy: 2.4371
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=43.7
Extrinsic raw: Œº=0.008044444444444444

=== Iteration 62/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.82s
EPOCH 1 took 19.55s
update_step :  62
reward/intrinsic_batch_mean :  4.615440670087183e-05
reward/extrinsic_batch_mean :  0.007703703703703704
loss/policy :  -0.00045184752988544375
loss/rnd :  3.1030363336895155e-06
loss/value :  0.862419271107876
loss/value_i :  2.751821235010125e-05
loss/value_e :  0.8623917518240033
loss/entropy :  2.433331016338233
reward/intrinsic_running :  0.00893582542053564
reward/extrinsic_running :  0.007703703703703704
reward/intrinsic_std_running :  0.06775537568534575
reward/extrinsic_std_running :  0.2802378374556835
reward/intrinsic_batch_std :  2.7343425792753793e-05
reward/intrinsic_batch_max :  0.0004106218402739614
reward/intrinsic_batch_min :  5.131231773702893e-06
reward/total_batch :  0.0038749290552022877
time/iteration_time :  112.23214173316956
time/fps :  2405.727947720373
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: -0.0005, Value Loss: 0.8624, Entropy: 2.4333
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=46.0
Extrinsic raw: Œº=0.007703703703703704

=== Iteration 63/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.38s
EPOCH 1 took 18.63s
update_step :  63
reward/intrinsic_batch_mean :  4.4798500492820663e-05
reward/extrinsic_batch_mean :  0.006844444444444445
loss/policy :  -0.00017942719502819025
loss/rnd :  3.006574922547963e-06
loss/value :  0.899304601279172
loss/value_i :  2.505664495842983e-05
loss/value_e :  0.8992795447508494
loss/entropy :  2.442116860187415
reward/intrinsic_running :  0.008798325228216629
reward/extrinsic_running :  0.006844444444444445
reward/intrinsic_std_running :  0.06722420374114585
reward/extrinsic_std_running :  0.26389778792012597
reward/intrinsic_batch_std :  2.374068475582917e-05
reward/intrinsic_batch_max :  0.0004543485410977155
reward/intrinsic_batch_min :  5.408248398452997e-06
reward/total_batch :  0.0034446214724686325
time/iteration_time :  110.11525845527649
time/fps :  2451.9762636679548
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2452
Policy Loss: -0.0002, Value Loss: 0.8993, Entropy: 2.4421
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=45.0
Extrinsic raw: Œº=0.006844444444444445

=== Iteration 64/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.93s
EPOCH 1 took 18.43s
update_step :  64
reward/intrinsic_batch_mean :  4.394926489062022e-05
reward/extrinsic_batch_mean :  0.005481481481481481
loss/policy :  -0.00022828533882134116
loss/rnd :  2.9268039725138806e-06
loss/value :  0.6688371679999612
loss/value_i :  2.499264761960755e-05
loss/value_e :  0.6688121751402364
loss/entropy :  2.4456767241160073
reward/intrinsic_running :  0.008665012537171377
reward/extrinsic_running :  0.005481481481481481
reward/intrinsic_std_running :  0.06670534118683956
reward/extrinsic_std_running :  0.23736116727708131
reward/intrinsic_batch_std :  2.6058890564519654e-05
reward/intrinsic_batch_max :  0.0004270715871825814
reward/intrinsic_batch_min :  5.621767741104122e-06
reward/total_batch :  0.002762715373186051
time/iteration_time :  112.00983738899231
time/fps :  2410.502562041341
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0002, Value Loss: 0.6688, Entropy: 2.4457
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=44.5
Extrinsic raw: Œº=0.005481481481481481

=== Iteration 65/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 19.14s
update_step :  65
reward/intrinsic_batch_mean :  4.841780939516832e-05
reward/extrinsic_batch_mean :  0.00797037037037037
loss/policy :  -0.00019761029596503994
loss/rnd :  3.1989154890790372e-06
loss/value :  0.8479373482140627
loss/value_i :  2.681128521406649e-05
loss/value_e :  0.847910536961122
loss/entropy :  2.4363706039659903
reward/intrinsic_running :  0.008536170262620829
reward/extrinsic_running :  0.00797037037037037
reward/intrinsic_std_running :  0.06619826118848139
reward/extrinsic_std_running :  0.28549403420479647
reward/intrinsic_batch_std :  3.12672758396568e-05
reward/intrinsic_batch_max :  0.0004892406286671758
reward/intrinsic_batch_min :  5.942409188719466e-06
reward/total_batch :  0.004009394089882769
time/iteration_time :  112.45915746688843
time/fps :  2400.8716238114857
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: -0.0002, Value Loss: 0.8479, Entropy: 2.4364
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=49.4
Extrinsic raw: Œº=0.00797037037037037

=== Iteration 66/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.40s
EPOCH 1 took 18.82s
update_step :  66
reward/intrinsic_batch_mean :  4.925855737707968e-05
reward/extrinsic_batch_mean :  0.009488888888888889
loss/policy :  1.7727795762546135e-06
loss/rnd :  3.235193696237922e-06
loss/value :  1.112137258052826
loss/value_i :  2.7324818719617642e-05
loss/value_e :  1.1121099293231964
loss/entropy :  2.426970286802812
reward/intrinsic_running :  0.008411301695427578
reward/extrinsic_running :  0.009488888888888889
reward/intrinsic_std_running :  0.06570255951406337
reward/extrinsic_std_running :  0.3102847525327679
reward/intrinsic_batch_std :  2.8351301963052304e-05
reward/intrinsic_batch_max :  0.0005637583672069013
reward/intrinsic_batch_min :  5.2447103371378034e-06
reward/total_batch :  0.0047690737231329845
time/iteration_time :  110.06285285949707
time/fps :  2453.143753639331
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2453
Policy Loss: 0.0000, Value Loss: 1.1121, Entropy: 2.4270
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=50.6
Extrinsic raw: Œº=0.009488888888888889

=== Iteration 67/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.59s
EPOCH 1 took 19.76s
update_step :  67
reward/intrinsic_batch_mean :  4.88963561663493e-05
reward/extrinsic_batch_mean :  0.007333333333333333
loss/policy :  0.0001869129625971034
loss/rnd :  3.160387092121351e-06
loss/value :  0.8161211429220258
loss/value_i :  2.4334978358335018e-05
loss/value_e :  0.8160968070680444
loss/entropy :  2.444504344102108
reward/intrinsic_running :  0.008290089292276565
reward/extrinsic_running :  0.007333333333333333
reward/intrinsic_std_running :  0.06521783486842019
reward/extrinsic_std_running :  0.27497797891629233
reward/intrinsic_batch_std :  3.134849642043128e-05
reward/intrinsic_batch_max :  0.0005983301089145243
reward/intrinsic_batch_min :  4.036873633594951e-06
reward/total_batch :  0.0036911148447498414
time/iteration_time :  111.71215581893921
time/fps :  2416.925875440185
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0002, Value Loss: 0.8161, Entropy: 2.4445
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=50.6
Extrinsic raw: Œº=0.007333333333333333

=== Iteration 68/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.25s
EPOCH 1 took 19.02s
update_step :  68
reward/intrinsic_batch_mean :  4.854937857456173e-05
reward/extrinsic_batch_mean :  0.0084
loss/policy :  -0.0005493408852172169
loss/rnd :  3.144537265942552e-06
loss/value :  0.8873716619881716
loss/value_i :  2.402050402892972e-05
loss/value_e :  0.8873476368008237
loss/entropy :  2.4344435280019585
reward/intrinsic_running :  0.008172390596697682
reward/extrinsic_running :  0.0084
reward/intrinsic_std_running :  0.0647436859104774
reward/extrinsic_std_running :  0.29317513916125665
reward/intrinsic_batch_std :  3.1586902965523396e-05
reward/intrinsic_batch_max :  0.0004949964350089431
reward/intrinsic_batch_min :  5.293826689012349e-06
reward/total_batch :  0.004224274689287281
time/iteration_time :  111.36237812042236
time/fps :  2424.517189351272
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2425
Policy Loss: -0.0005, Value Loss: 0.8874, Entropy: 2.4344
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=50.6
Extrinsic raw: Œº=0.0084

=== Iteration 69/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.93s
EPOCH 1 took 18.68s
update_step :  69
reward/intrinsic_batch_mean :  4.578470531561362e-05
reward/extrinsic_batch_mean :  0.0062370370370370375
loss/policy :  -0.00046414684303189546
loss/rnd :  3.0649534272180805e-06
loss/value :  0.768628458182017
loss/value_i :  2.1533835548104957e-05
loss/value_e :  0.7686069246494409
loss/entropy :  2.4453848528139517
reward/intrinsic_running :  0.008057817840312329
reward/extrinsic_running :  0.0062370370370370375
reward/intrinsic_std_running :  0.06427976149824277
reward/extrinsic_std_running :  0.25245092540802655
reward/intrinsic_batch_std :  2.889477131286052e-05
reward/intrinsic_batch_max :  0.00042196232243441045
reward/intrinsic_batch_min :  5.6269936976605095e-06
reward/total_batch :  0.0031414108711763254
time/iteration_time :  111.86582159996033
time/fps :  2413.605837228265
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: -0.0005, Value Loss: 0.7686, Entropy: 2.4454
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=48.1
Extrinsic raw: Œº=0.0062370370370370375

=== Iteration 70/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.66s
EPOCH 1 took 18.70s
update_step :  70
reward/intrinsic_batch_mean :  5.2764721112409326e-05
reward/extrinsic_batch_mean :  0.00951111111111111
loss/policy :  -0.00032448249906089836
loss/rnd :  3.327773735387988e-06
loss/value :  1.0828368627663814
loss/value_i :  2.290561160682983e-05
loss/value_e :  1.0828139511021702
loss/entropy :  2.4244549671808877
reward/intrinsic_running :  0.007947096964858694
reward/extrinsic_running :  0.00951111111111111
reward/intrinsic_std_running :  0.06382559666331726
reward/extrinsic_std_running :  0.3102661668970493
reward/intrinsic_batch_std :  2.534114609838446e-05
reward/intrinsic_batch_max :  0.0005227330257184803
reward/intrinsic_batch_min :  1.0978539648931473e-05
reward/total_batch :  0.00478193791611176
time/iteration_time :  109.8359625339508
time/fps :  2458.211261330202
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.8s | FPS: 2458
Policy Loss: -0.0003, Value Loss: 1.0828, Entropy: 2.4245
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=55.8
Extrinsic raw: Œº=0.00951111111111111

=== Iteration 71/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.37s
update_step :  71
reward/intrinsic_batch_mean :  4.950209107577798e-05
reward/extrinsic_batch_mean :  0.009755555555555556
loss/policy :  1.4827492123004049e-05
loss/rnd :  3.1324353709682e-06
loss/value :  1.0936108195420466
loss/value_i :  2.5006841524648763e-05
loss/value_e :  1.0935858135873622
loss/entropy :  2.422975605184382
reward/intrinsic_running :  0.007839223236428711
reward/extrinsic_running :  0.009755555555555556
reward/intrinsic_std_running :  0.06338095452132385
reward/extrinsic_std_running :  0.3150385271363598
reward/intrinsic_batch_std :  3.056580187241377e-05
reward/intrinsic_batch_max :  0.0005100268754176795
reward/intrinsic_batch_min :  5.005437742511276e-06
reward/total_batch :  0.004902528823315667
time/iteration_time :  110.77631330490112
time/fps :  2437.3441572915594
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: 0.0000, Value Loss: 1.0936, Entropy: 2.4230
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=52.7
Extrinsic raw: Œº=0.009755555555555556

=== Iteration 72/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 19.68s
update_step :  72
reward/intrinsic_batch_mean :  4.799782067336006e-05
reward/extrinsic_batch_mean :  0.0076962962962962966
loss/policy :  -0.0003472564629081524
loss/rnd :  3.026466891132066e-06
loss/value :  0.9383699451432084
loss/value_i :  2.4576284004345354e-05
loss/value_e :  0.9383453672582452
loss/entropy :  2.4277678222367256
reward/intrinsic_running :  0.00773415862883466
reward/extrinsic_running :  0.0076962962962962966
reward/intrinsic_std_running :  0.06294549687023389
reward/extrinsic_std_running :  0.2802446490472492
reward/intrinsic_batch_std :  2.769065598479992e-05
reward/intrinsic_batch_max :  0.00040506335790269077
reward/intrinsic_batch_min :  4.606419679475948e-06
reward/total_batch :  0.0038721470584848284
time/iteration_time :  111.3445942401886
time/fps :  2424.9044315305114
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: -0.0003, Value Loss: 0.9384, Entropy: 2.4278
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.006, sum=51.5
Extrinsic raw: Œº=0.0076962962962962966

=== Iteration 73/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 18.93s
update_step :  73
reward/intrinsic_batch_mean :  4.875947910642464e-05
reward/extrinsic_batch_mean :  0.008762962962962964
loss/policy :  -0.00031187142083195573
loss/rnd :  3.0287565991646703e-06
loss/value :  0.9573248110034249
loss/value_i :  2.6018958730370894e-05
loss/value_e :  0.9572987935759805
loss/entropy :  2.428572734196981
reward/intrinsic_running :  0.0076319983027914404
reward/extrinsic_running :  0.008762962962962964
reward/intrinsic_std_running :  0.06251888802565869
reward/extrinsic_std_running :  0.2981192082573037
reward/intrinsic_batch_std :  2.989418502312822e-05
reward/intrinsic_batch_max :  0.0004526108969002962
reward/intrinsic_batch_min :  5.52768415218452e-06
reward/total_batch :  0.0044058612210346945
time/iteration_time :  112.31631755828857
time/fps :  2403.9249671792227
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: -0.0003, Value Loss: 0.9573, Entropy: 2.4286
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=52.6
Extrinsic raw: Œº=0.008762962962962964

=== Iteration 74/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.20s
EPOCH 1 took 19.64s
update_step :  74
reward/intrinsic_batch_mean :  4.8239347974595146e-05
reward/extrinsic_batch_mean :  0.006414814814814815
loss/policy :  -0.00020566617472054944
loss/rnd :  2.9912266585818017e-06
loss/value :  0.7942440807819366
loss/value_i :  2.2359327996320754e-05
loss/value_e :  0.7942217227184412
loss/entropy :  2.438598950703939
reward/intrinsic_running :  0.007532564644272934
reward/extrinsic_running :  0.006414814814814815
reward/intrinsic_std_running :  0.06210083926526135
reward/extrinsic_std_running :  0.2553348530614821
reward/intrinsic_batch_std :  3.2209319687480904e-05
reward/intrinsic_batch_max :  0.0005540941492654383
reward/intrinsic_batch_min :  5.185532700124895e-06
reward/total_batch :  0.003231527081394705
time/iteration_time :  112.06020212173462
time/fps :  2409.419177262328
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: -0.0002, Value Loss: 0.7942, Entropy: 2.4386
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=52.4
Extrinsic raw: Œº=0.006414814814814815

=== Iteration 75/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.49s
EPOCH 1 took 18.69s
update_step :  75
reward/intrinsic_batch_mean :  4.897171336570291e-05
reward/extrinsic_batch_mean :  0.00882962962962963
loss/policy :  -0.0006694278157683033
loss/rnd :  3.0137812762570153e-06
loss/value :  1.015739738038092
loss/value_i :  2.3471812517417483e-05
loss/value_e :  1.0157162700638627
loss/entropy :  2.430193117170623
reward/intrinsic_running :  0.007435807597621005
reward/extrinsic_running :  0.00882962962962963
reward/intrinsic_std_running :  0.0616910610669044
reward/extrinsic_std_running :  0.30065946137561955
reward/intrinsic_batch_std :  3.144056088749923e-05
reward/intrinsic_batch_max :  0.0005962489522062242
reward/intrinsic_batch_min :  5.621091077046003e-06
reward/total_batch :  0.004439300671497667
time/iteration_time :  109.24169111251831
time/fps :  2471.583854573448
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.2s | FPS: 2472
Policy Loss: -0.0007, Value Loss: 1.0157, Entropy: 2.4302
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=53.6
Extrinsic raw: Œº=0.00882962962962963

=== Iteration 76/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.23s
EPOCH 1 took 19.09s
update_step :  76
reward/intrinsic_batch_mean :  4.909895017151737e-05
reward/extrinsic_batch_mean :  0.009792592592592592
loss/policy :  -0.00030328019762016606
loss/rnd :  3.011368710648447e-06
loss/value :  1.1129468471714945
loss/value_i :  2.2704403267143238e-05
loss/value_e :  1.1129241450266405
loss/entropy :  2.42473105950789
reward/intrinsic_running :  0.007341579966828947
reward/extrinsic_running :  0.009792592592592592
reward/intrinsic_std_running :  0.06128928889386049
reward/extrinsic_std_running :  0.31500798570233335
reward/intrinsic_batch_std :  2.8816777322982826e-05
reward/intrinsic_batch_max :  0.00045578903518617153
reward/intrinsic_batch_min :  4.437535153556382e-06
reward/total_batch :  0.004920845771382055
time/iteration_time :  110.418874502182
time/fps :  2445.2341252098568
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2445
Policy Loss: -0.0003, Value Loss: 1.1129, Entropy: 2.4247
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.007, sum=54.1
Extrinsic raw: Œº=0.009792592592592592

=== Iteration 77/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.67s
EPOCH 1 took 18.72s
update_step :  77
reward/intrinsic_batch_mean :  4.954270812328037e-05
reward/extrinsic_batch_mean :  0.007022222222222222
loss/policy :  -0.00020299096242083715
loss/rnd :  2.328882812614183e-05
loss/value :  0.8695133111693643
loss/value_i :  2.231790393015024e-05
loss/value_e :  0.8694909928422986
loss/entropy :  2.440023573962125
reward/intrinsic_running :  0.007249803744363352
reward/extrinsic_running :  0.007022222222222222
reward/intrinsic_std_running :  0.0608952634081635
reward/extrinsic_std_running :  0.2666575405845807
reward/intrinsic_batch_std :  3.0810364289248945e-05
reward/intrinsic_batch_max :  0.0005637370049953461
reward/intrinsic_batch_min :  6.73680688123568e-06
reward/total_batch :  0.003535882465172751
time/iteration_time :  110.10036993026733
time/fps :  2452.307836667633
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2452
Policy Loss: -0.0002, Value Loss: 0.8695, Entropy: 2.4400
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=54.9
Extrinsic raw: Œº=0.007022222222222222

=== Iteration 78/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.80s
EPOCH 1 took 18.59s
update_step :  78
reward/intrinsic_batch_mean :  0.00013544006325736754
reward/extrinsic_batch_mean :  0.008696296296296296
loss/policy :  -0.0005245631601252226
loss/rnd :  9.972605983999859e-06
loss/value :  0.9735931979887413
loss/value_i :  2.374607670803512e-05
loss/value_e :  0.9735694509564023
loss/entropy :  2.435284238873106
reward/intrinsic_running :  0.007166468023667325
reward/extrinsic_running :  0.008696296296296296
reward/intrinsic_std_running :  0.06050807357340535
reward/extrinsic_std_running :  0.2981770608479334
reward/intrinsic_batch_std :  4.3924770427843614e-05
reward/intrinsic_batch_max :  0.0007899366319179535
reward/intrinsic_batch_min :  5.691279147868045e-05
reward/total_batch :  0.004415868179776831
time/iteration_time :  111.60948061943054
time/fps :  2419.1493276512447
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: -0.0005, Value Loss: 0.9736, Entropy: 2.4353
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=151.1
Extrinsic raw: Œº=0.008696296296296296

=== Iteration 79/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.62s
EPOCH 1 took 19.60s
update_step :  79
reward/intrinsic_batch_mean :  6.689583748298497e-05
reward/extrinsic_batch_mean :  0.007859259259259259
loss/policy :  -0.0008425887966895419
loss/rnd :  3.460577889916639e-06
loss/value :  0.9543724647074034
loss/value_i :  2.488540904420061e-05
loss/value_e :  0.9543475779620084
loss/entropy :  2.4303287917917427
reward/intrinsic_running :  0.0070803856741160675
reward/extrinsic_running :  0.007859259259259259
reward/intrinsic_std_running :  0.0601287002445737
reward/extrinsic_std_running :  0.2828579191294917
reward/intrinsic_batch_std :  3.885773486012825e-05
reward/intrinsic_batch_max :  0.0005779519560746849
reward/intrinsic_batch_min :  1.0895976629399229e-05
reward/total_batch :  0.003963077548371122
time/iteration_time :  113.47788667678833
time/fps :  2379.3181905918236
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: -0.0008, Value Loss: 0.9544, Entropy: 2.4303
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=75.1
Extrinsic raw: Œº=0.007859259259259259

=== Iteration 80/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 18.57s
update_step :  80
reward/intrinsic_batch_mean :  5.566464357098421e-05
reward/extrinsic_batch_mean :  0.010251851851851852
loss/policy :  -0.0004804991520800148
loss/rnd :  3.2963440720447e-06
loss/value :  1.1448868621479382
loss/value_i :  2.403752621444944e-05
loss/value_e :  1.1448628216078787
loss/entropy :  2.417629989710721
reward/intrinsic_running :  0.006995656603923186
reward/extrinsic_running :  0.010251851851851852
reward/intrinsic_std_running :  0.059756461387122387
reward/extrinsic_std_running :  0.3219594112564047
reward/intrinsic_batch_std :  3.773082842325243e-05
reward/intrinsic_batch_max :  0.0006890418007969856
reward/intrinsic_batch_min :  5.877414878341369e-06
reward/total_batch :  0.005153758247711418
time/iteration_time :  111.05569076538086
time/fps :  2431.2126478093683
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0005, Value Loss: 1.1449, Entropy: 2.4176
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=62.9
Extrinsic raw: Œº=0.010251851851851852

=== Iteration 81/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.66s
EPOCH 1 took 19.56s
update_step :  81
reward/intrinsic_batch_mean :  4.9027855847365305e-05
reward/extrinsic_batch_mean :  0.008992592592592592
loss/policy :  -0.00017996657301079142
loss/rnd :  2.888955061114922e-06
loss/value :  0.9899535576502482
loss/value_i :  2.2204529958606035e-05
loss/value_e :  0.9899313540169687
loss/entropy :  2.4285932129079644
reward/intrinsic_running :  0.006912561666601322
reward/extrinsic_running :  0.008992592592592592
reward/intrinsic_std_running :  0.05939110014275349
reward/extrinsic_std_running :  0.30309615871305884
reward/intrinsic_batch_std :  2.6441445446860306e-05
reward/intrinsic_batch_max :  0.000505299074575305
reward/intrinsic_batch_min :  7.082815500325523e-06
reward/total_batch :  0.004520810224219979
time/iteration_time :  112.12346625328064
time/fps :  2408.0596954618322
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: -0.0002, Value Loss: 0.9900, Entropy: 2.4286
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=55.7
Extrinsic raw: Œº=0.008992592592592592

=== Iteration 82/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.11s
EPOCH 1 took 18.54s
update_step :  82
reward/intrinsic_batch_mean :  5.269935088689871e-05
reward/extrinsic_batch_mean :  0.010577777777777778
loss/policy :  -0.00020312900640860653
loss/rnd :  3.0943715432151677e-06
loss/value :  1.1625687976678212
loss/value_i :  2.513571463637301e-05
loss/value_e :  1.1625436607635382
loss/entropy :  2.4219375559777925
reward/intrinsic_running :  0.0068317361550123065
reward/extrinsic_running :  0.010577777777777778
reward/intrinsic_std_running :  0.05903233204178244
reward/extrinsic_std_running :  0.32649536249140676
reward/intrinsic_batch_std :  3.385990432905778e-05
reward/intrinsic_batch_max :  0.0005953171639703214
reward/intrinsic_batch_min :  6.389030204445589e-06
reward/total_batch :  0.005315238564332339
time/iteration_time :  111.08422684669495
time/fps :  2430.588101158785
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0002, Value Loss: 1.1626, Entropy: 2.4219
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=60.3
Extrinsic raw: Œº=0.010577777777777778

=== Iteration 83/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 22.49s
EPOCH 1 took 24.38s
update_step :  83
reward/intrinsic_batch_mean :  5.215305520978964e-05
reward/extrinsic_batch_mean :  0.009933333333333334
loss/policy :  -0.0002642028345938095
loss/rnd :  3.0493606883200384e-06
loss/value :  1.225055335146008
loss/value_i :  2.3777238284034837e-05
loss/value_e :  1.225031558311347
loss/entropy :  2.430092627351934
reward/intrinsic_running :  0.006752785560104514
reward/extrinsic_running :  0.009933333333333334
reward/intrinsic_std_running :  0.05867999432341348
reward/extrinsic_std_running :  0.31735223333072676
reward/intrinsic_batch_std :  3.0039652599845143e-05
reward/intrinsic_batch_max :  0.0005332985310815275
reward/intrinsic_batch_min :  5.7135002862196416e-06
reward/total_batch :  0.0049927431942715615
time/iteration_time :  121.20032143592834
time/fps :  2227.716864123446
data/episodes_collected :  60
data/frames_collected :  270000
Timer 121.2s | FPS: 2228
Policy Loss: -0.0003, Value Loss: 1.2251, Entropy: 2.4301
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=60.0
Extrinsic raw: Œº=0.009933333333333334

=== Iteration 84/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.53s
EPOCH 1 took 19.74s
update_step :  84
reward/intrinsic_batch_mean :  5.028341883523724e-05
reward/extrinsic_batch_mean :  0.009133333333333334
loss/policy :  -0.00013608397090468895
loss/rnd :  2.9248602893196884e-06
loss/value :  1.0717322745106437
loss/value_i :  2.284370202687569e-05
loss/value_e :  1.0717094359975872
loss/entropy :  2.434949762893446
reward/intrinsic_running :  0.006675581707081978
reward/extrinsic_running :  0.009133333333333334
reward/intrinsic_std_running :  0.058333904321062675
reward/extrinsic_std_running :  0.3055321841566867
reward/intrinsic_batch_std :  2.8362590143483754e-05
reward/intrinsic_batch_max :  0.000476514600450173
reward/intrinsic_batch_min :  4.32787737736362e-06
reward/total_batch :  0.004591808376084285
time/iteration_time :  111.81328082084656
time/fps :  2414.73998453376
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: -0.0001, Value Loss: 1.0717, Entropy: 2.4349
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=58.2
Extrinsic raw: Œº=0.009133333333333334

=== Iteration 85/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.05s
EPOCH 1 took 18.44s
update_step :  85
reward/intrinsic_batch_mean :  5.14712541588947e-05
reward/extrinsic_batch_mean :  0.009192592592592592
loss/policy :  -0.00024461950163117075
loss/rnd :  2.9769506923140865e-06
loss/value :  1.071613685651259
loss/value_i :  2.25795877144485e-05
loss/value_e :  1.0715911072311979
loss/entropy :  2.426834312352267
reward/intrinsic_running :  0.006600238020869989
reward/extrinsic_running :  0.009192592592592592
reward/intrinsic_std_running :  0.05799386114747983
reward/extrinsic_std_running :  0.30548191426847243
reward/intrinsic_batch_std :  3.159381281351386e-05
reward/intrinsic_batch_max :  0.0004908755072392523
reward/intrinsic_batch_min :  4.776662080985261e-06
reward/total_batch :  0.0046220319233757435
time/iteration_time :  111.76490807533264
time/fps :  2415.785103299262
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: -0.0002, Value Loss: 1.0716, Entropy: 2.4268
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=59.9
Extrinsic raw: Œº=0.009192592592592592

=== Iteration 86/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.52s
EPOCH 1 took 18.95s
update_step :  86
reward/intrinsic_batch_mean :  5.1295940355305867e-05
reward/extrinsic_batch_mean :  0.010207407407407408
loss/policy :  -5.893089300198798e-05
loss/rnd :  2.9552896910789776e-06
loss/value :  1.092370716008273
loss/value_i :  2.23359916576142e-05
loss/value_e :  1.0923483705881871
loss/entropy :  2.4290203325676196
reward/intrinsic_running :  0.006526631593441556
reward/extrinsic_running :  0.010207407407407408
reward/intrinsic_std_running :  0.05765969610997529
reward/extrinsic_std_running :  0.3219953322941255
reward/intrinsic_batch_std :  2.9852985366904463e-05
reward/intrinsic_batch_max :  0.0005495764198713005
reward/intrinsic_batch_min :  4.791535957338056e-06
reward/total_batch :  0.005129351673881357
time/iteration_time :  111.90154433250427
time/fps :  2412.835333154312
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0001, Value Loss: 1.0924, Entropy: 2.4290
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=60.1
Extrinsic raw: Œº=0.010207407407407408

=== Iteration 87/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.24s
update_step :  87
reward/intrinsic_batch_mean :  5.248036676540424e-05
reward/extrinsic_batch_mean :  0.011711111111111111
loss/policy :  -0.00036561548316085737
loss/rnd :  3.003411310683904e-06
loss/value :  1.146901834191698
loss/value_i :  2.385414906960002e-05
loss/value_e :  1.1468779842058818
loss/entropy :  2.418766281821511
reward/intrinsic_running :  0.006454770051284386
reward/extrinsic_running :  0.011711111111111111
reward/intrinsic_std_running :  0.05733123500497184
reward/extrinsic_std_running :  0.3441681838366702
reward/intrinsic_batch_std :  2.943688089293345e-05
reward/intrinsic_batch_max :  0.0005633385153487325
reward/intrinsic_batch_min :  4.732271008833777e-06
reward/total_batch :  0.005881795738938258
time/iteration_time :  112.285404920578
time/fps :  2404.5867776936557
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: -0.0004, Value Loss: 1.1469, Entropy: 2.4188
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=61.8
Extrinsic raw: Œº=0.011711111111111111

=== Iteration 88/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.05s
EPOCH 1 took 18.92s
update_step :  88
reward/intrinsic_batch_mean :  5.03870578061011e-05
reward/extrinsic_batch_mean :  0.00931851851851852
loss/policy :  -0.0006278548477866659
loss/rnd :  2.858922653792957e-06
loss/value :  0.9830081508015142
loss/value_i :  2.2486673212066915e-05
loss/value_e :  0.9829856608853196
loss/entropy :  2.434994527787873
reward/intrinsic_running :  0.006384401862220822
reward/extrinsic_running :  0.00931851851851852
reward/intrinsic_std_running :  0.05700833804855683
reward/extrinsic_std_running :  0.3079114507596564
reward/intrinsic_batch_std :  3.12311970040363e-05
reward/intrinsic_batch_max :  0.0005327488179318607
reward/intrinsic_batch_min :  4.110081135877408e-06
reward/total_batch :  0.00468445278816231
time/iteration_time :  112.6582133769989
time/fps :  2396.629521333463
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: -0.0006, Value Loss: 0.9830, Entropy: 2.4350
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=59.7
Extrinsic raw: Œº=0.00931851851851852

=== Iteration 89/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.75s
EPOCH 1 took 19.23s
update_step :  89
reward/intrinsic_batch_mean :  5.1581145728886e-05
reward/extrinsic_batch_mean :  0.011466666666666667
loss/policy :  -0.0007858907973224467
loss/rnd :  2.917914922694432e-06
loss/value :  1.2511068203232505
loss/value_i :  2.3161651397734232e-05
loss/value_e :  1.251083664821856
loss/entropy :  2.419298847516378
reward/intrinsic_running :  0.006315661306243186
reward/extrinsic_running :  0.011466666666666667
reward/intrinsic_std_running :  0.05669083010677126
reward/extrinsic_std_running :  0.3398065855093975
reward/intrinsic_batch_std :  2.771992397919052e-05
reward/intrinsic_batch_max :  0.0004994900082238019
reward/intrinsic_batch_min :  4.336462097853655e-06
reward/total_batch :  0.005759123906197776
time/iteration_time :  110.97283434867859
time/fps :  2433.0278809645906
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0008, Value Loss: 1.2511, Entropy: 2.4193
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=61.4
Extrinsic raw: Œº=0.011466666666666667

=== Iteration 90/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 18.86s
update_step :  90
reward/intrinsic_batch_mean :  5.470767040628912e-05
reward/extrinsic_batch_mean :  0.01142962962962963
loss/policy :  -0.00015557034269229254
loss/rnd :  3.0749609143668115e-06
loss/value :  1.1892872109557644
loss/value_i :  2.2715766080540504e-05
loss/value_e :  1.1892644970706014
loss/entropy :  2.4127993728175308
reward/intrinsic_running :  0.006248619061956302
reward/extrinsic_running :  0.01142962962962963
reward/intrinsic_std_running :  0.056378550125801306
reward/extrinsic_std_running :  0.33983508071570245
reward/intrinsic_batch_std :  3.1978061472879756e-05
reward/intrinsic_batch_max :  0.0008019412634894252
reward/intrinsic_batch_min :  4.777499270858243e-06
reward/total_batch :  0.005742168650017959
time/iteration_time :  110.23037767410278
time/fps :  2449.415539500896
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2449
Policy Loss: -0.0002, Value Loss: 1.1893, Entropy: 2.4128
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=65.5
Extrinsic raw: Œº=0.01142962962962963

=== Iteration 91/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.72s
EPOCH 1 took 19.75s
update_step :  91
reward/intrinsic_batch_mean :  5.630596846265824e-05
reward/extrinsic_batch_mean :  0.010540740740740741
loss/policy :  -0.00046542287815431007
loss/rnd :  3.1098724231483312e-06
loss/value :  1.1526538422613433
loss/value_i :  2.4123336874199044e-05
loss/value_e :  1.152629722248424
loss/entropy :  2.4187669573408184
reward/intrinsic_running :  0.0061831125052897755
reward/extrinsic_running :  0.010540740740740741
reward/intrinsic_std_running :  0.056071367581679084
reward/extrinsic_std_running :  0.3265249185196531
reward/intrinsic_batch_std :  3.613622596294966e-05
reward/intrinsic_batch_max :  0.000574061821680516
reward/intrinsic_batch_min :  5.536843673326075e-06
reward/total_batch :  0.0052985233546017
time/iteration_time :  111.99497985839844
time/fps :  2410.8223452638344
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0005, Value Loss: 1.1527, Entropy: 2.4188
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=67.8
Extrinsic raw: Œº=0.010540740740740741

=== Iteration 92/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.73s
EPOCH 1 took 19.09s
update_step :  92
reward/intrinsic_batch_mean :  5.37795576222076e-05
reward/extrinsic_batch_mean :  0.011977777777777778
loss/policy :  -0.00010978118834001097
loss/rnd :  2.9923772589509925e-06
loss/value :  1.2470182053970569
loss/value_i :  2.2678079072978687e-05
loss/value_e :  1.2469955249266191
loss/entropy :  2.4155950040528267
reward/intrinsic_running :  0.0061188700405164186
reward/extrinsic_running :  0.011977777777777778
reward/intrinsic_std_running :  0.05576916750403554
reward/extrinsic_std_running :  0.3484583181761814
reward/intrinsic_batch_std :  3.011652589716213e-05
reward/intrinsic_batch_max :  0.000514672719873488
reward/intrinsic_batch_min :  4.430186891113408e-06
reward/total_batch :  0.006015778667699993
time/iteration_time :  111.27637028694153
time/fps :  2426.3911493856926
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: -0.0001, Value Loss: 1.2470, Entropy: 2.4156
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=65.1
Extrinsic raw: Œº=0.011977777777777778

=== Iteration 93/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 18.90s
update_step :  93
reward/intrinsic_batch_mean :  5.375077411118346e-05
reward/extrinsic_batch_mean :  0.012125925925925925
loss/policy :  -1.403340116446612e-05
loss/rnd :  2.977400585581508e-06
loss/value :  1.272388416709322
loss/value_i :  2.230845022881333e-05
loss/value_e :  1.2723661119287664
loss/entropy :  2.4095874844175396
reward/intrinsic_running :  0.0060559983740794505
reward/extrinsic_running :  0.012125925925925925
reward/intrinsic_std_running :  0.05547180174936642
reward/extrinsic_std_running :  0.35057254608509647
reward/intrinsic_batch_std :  3.0082409198029137e-05
reward/intrinsic_batch_max :  0.0005108288023620844
reward/intrinsic_batch_min :  4.411153440742055e-06
reward/total_batch :  0.006089838350018554
time/iteration_time :  112.18021869659424
time/fps :  2406.8414479583926
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: -0.0000, Value Loss: 1.2724, Entropy: 2.4096
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=65.4
Extrinsic raw: Œº=0.012125925925925925

=== Iteration 94/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 18.78s
update_step :  94
reward/intrinsic_batch_mean :  5.4907191541294904e-05
reward/extrinsic_batch_mean :  0.012533333333333334
loss/policy :  -8.607859843212998e-05
loss/rnd :  3.019348034947391e-06
loss/value :  1.2483782623753403
loss/value_i :  2.3019270663622372e-05
loss/value_e :  1.2483552405328462
loss/entropy :  2.4101864460742837
reward/intrinsic_running :  0.005994494680709752
reward/extrinsic_running :  0.012533333333333334
reward/intrinsic_std_running :  0.055179138800982755
reward/extrinsic_std_running :  0.35468080172333977
reward/intrinsic_batch_std :  3.080727591160653e-05
reward/intrinsic_batch_max :  0.0004628384776879102
reward/intrinsic_batch_min :  4.31807893619407e-06
reward/total_batch :  0.006294120262437314
time/iteration_time :  111.59234666824341
time/fps :  2419.520765189139
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: -0.0001, Value Loss: 1.2484, Entropy: 2.4102
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=67.2
Extrinsic raw: Œº=0.012533333333333334

=== Iteration 95/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 18.85s
update_step :  95
reward/intrinsic_batch_mean :  5.6029180943450126e-05
reward/extrinsic_batch_mean :  0.013340740740740742
loss/policy :  -0.0002818706332508362
loss/rnd :  3.068912581676903e-06
loss/value :  1.2938947235092972
loss/value_i :  2.2213627055338513e-05
loss/value_e :  1.2938725090388097
loss/entropy :  2.409507950146993
reward/intrinsic_running :  0.00593435238027186
reward/extrinsic_running :  0.013340740740740742
reward/intrinsic_std_running :  0.05489105229447128
reward/extrinsic_std_running :  0.36702480818287136
reward/intrinsic_batch_std :  3.271363782936344e-05
reward/intrinsic_batch_max :  0.0007899996126070619
reward/intrinsic_batch_min :  4.294251539249672e-06
reward/total_batch :  0.006698384960842096
time/iteration_time :  112.91730809211731
time/fps :  2391.130328574035
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: -0.0003, Value Loss: 1.2939, Entropy: 2.4095
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=68.9
Extrinsic raw: Œº=0.013340740740740742

=== Iteration 96/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.47s
update_step :  96
reward/intrinsic_batch_mean :  5.538716177616152e-05
reward/extrinsic_batch_mean :  0.012592592592592593
loss/policy :  -0.0005536607744406039
loss/rnd :  3.0226182437245646e-06
loss/value :  1.2806401740420947
loss/value_i :  2.349759572759715e-05
loss/value_e :  1.2806166771686438
loss/entropy :  2.4159724062139336
reward/intrinsic_running :  0.005875387173280737
reward/extrinsic_running :  0.012592592592592593
reward/intrinsic_std_running :  0.054607438385932516
reward/extrinsic_std_running :  0.35682335698953127
reward/intrinsic_batch_std :  3.2449453094527894e-05
reward/intrinsic_batch_max :  0.0006304647540673614
reward/intrinsic_batch_min :  4.579487267619697e-06
reward/total_batch :  0.006323989877184377
time/iteration_time :  112.5426173210144
time/fps :  2399.0911747667747
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: -0.0006, Value Loss: 1.2806, Entropy: 2.4160
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=68.5
Extrinsic raw: Œº=0.012592592592592593

=== Iteration 97/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.75s
EPOCH 1 took 19.03s
update_step :  97
reward/intrinsic_batch_mean :  5.518383739028515e-05
reward/extrinsic_batch_mean :  0.013222222222222222
loss/policy :  -0.000728101473545063
loss/rnd :  2.992874445942906e-06
loss/value :  1.2373134295145671
loss/value_i :  2.1464912826945003e-05
loss/value_e :  1.2372919673269445
loss/entropy :  2.4082671837373213
reward/intrinsic_running :  0.005817624994799716
reward/extrinsic_running :  0.013222222222222222
reward/intrinsic_std_running :  0.05432817616778118
reward/extrinsic_std_running :  0.36498501575872266
reward/intrinsic_batch_std :  2.76808534175928e-05
reward/intrinsic_batch_max :  0.0004681612772401422
reward/intrinsic_batch_min :  6.004365786793642e-06
reward/total_batch :  0.006638703029806254
time/iteration_time :  111.0586199760437
time/fps :  2431.1485237097427
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0007, Value Loss: 1.2373, Entropy: 2.4083
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=68.6
Extrinsic raw: Œº=0.013222222222222222

=== Iteration 98/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 19.72s
update_step :  98
reward/intrinsic_batch_mean :  5.758662036532095e-05
reward/extrinsic_batch_mean :  0.015022222222222222
loss/policy :  -0.00028781493451926065
loss/rnd :  3.1083523853422692e-06
loss/value :  1.4361909104116035
loss/value_i :  2.310302095958667e-05
loss/value_e :  1.436167810902451
loss/entropy :  2.4007495750080454
reward/intrinsic_running :  0.0057611451589204355
reward/extrinsic_running :  0.015022222222222222
reward/intrinsic_std_running :  0.05405314405123244
reward/extrinsic_std_running :  0.3884969605995158
reward/intrinsic_batch_std :  2.9641107340568813e-05
reward/intrinsic_batch_max :  0.000414298934629187
reward/intrinsic_batch_min :  4.360060756880557e-06
reward/total_batch :  0.007539904421293772
time/iteration_time :  111.46614456176758
time/fps :  2422.2601495863423
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: -0.0003, Value Loss: 1.4362, Entropy: 2.4007
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=71.9
Extrinsic raw: Œº=0.015022222222222222

=== Iteration 99/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.36s
EPOCH 1 took 18.50s
update_step :  99
reward/intrinsic_batch_mean :  5.8288044166255094e-05
reward/extrinsic_batch_mean :  0.0132
loss/policy :  -0.0002259026778946546
loss/rnd :  3.159162078549288e-06
loss/value :  1.2872548211704602
loss/value_i :  2.2632351277879383e-05
loss/value_e :  1.287232184048855
loss/entropy :  2.4095321424079663
reward/intrinsic_running :  0.005705831042460065
reward/extrinsic_running :  0.0132
reward/intrinsic_std_running :  0.053782244492949216
reward/extrinsic_std_running :  0.3650010410944058
reward/intrinsic_batch_std :  3.621664743600701e-05
reward/intrinsic_batch_max :  0.0005313290166668594
reward/intrinsic_batch_min :  4.535029802354984e-06
reward/total_batch :  0.006629144022083128
time/iteration_time :  110.2055275440216
time/fps :  2449.9678556699296
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2450
Policy Loss: -0.0002, Value Loss: 1.2873, Entropy: 2.4095
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=73.2
Extrinsic raw: Œº=0.0132

=== Iteration 100/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.30s
EPOCH 1 took 19.18s
update_step :  100
reward/intrinsic_batch_mean :  5.9903333725264084e-05
reward/extrinsic_batch_mean :  0.011318518518518518
loss/policy :  0.00011589298127077971
loss/rnd :  3.2086912824524916e-06
loss/value :  1.1234725180900458
loss/value_i :  2.1033650475808166e-05
loss/value_e :  1.1234514785535408
loss/entropy :  2.424557422146653
reward/intrinsic_running :  0.005651662377271655
reward/extrinsic_running :  0.011318518518518518
reward/intrinsic_std_running :  0.05351537314645558
reward/extrinsic_std_running :  0.337624657951792
reward/intrinsic_batch_std :  3.672707770388135e-05
reward/intrinsic_batch_max :  0.0005377044435590506
reward/intrinsic_batch_min :  6.450274213420926e-06
reward/total_batch :  0.005689210926121891
time/iteration_time :  112.82169103622437
time/fps :  2393.1568257854724
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0001, Value Loss: 1.1235, Entropy: 2.4246
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=75.6
Extrinsic raw: Œº=0.011318518518518518

=== Iteration 101/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 18.74s
update_step :  101
reward/intrinsic_batch_mean :  5.8140743917613656e-05
reward/extrinsic_batch_mean :  0.014103703703703703
loss/policy :  -0.0006062975331918675
loss/rnd :  3.1534801344219665e-06
loss/value :  1.306129312876499
loss/value_i :  2.243254204420902e-05
loss/value_e :  1.30610688346805
loss/entropy :  2.410437226295471
reward/intrinsic_running :  0.005598507174531322
reward/extrinsic_running :  0.014103703703703703
reward/intrinsic_std_running :  0.05325244073614386
reward/extrinsic_std_running :  0.37693841277232504
reward/intrinsic_batch_std :  3.6412373186754736e-05
reward/intrinsic_batch_max :  0.0006504582124762237
reward/intrinsic_batch_min :  4.466836799110752e-06
reward/total_batch :  0.007080922223810658
time/iteration_time :  111.13825821876526
time/fps :  2429.406437777082
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2429
Policy Loss: -0.0006, Value Loss: 1.3061, Entropy: 2.4104
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=73.7
Extrinsic raw: Œº=0.014103703703703703

=== Iteration 102/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.15s
EPOCH 1 took 18.84s
update_step :  102
reward/intrinsic_batch_mean :  5.8637962876383865e-05
reward/extrinsic_batch_mean :  0.014414814814814814
loss/policy :  -0.00014132216209404623
loss/rnd :  3.169747956097567e-06
loss/value :  1.4120089718789766
loss/value_i :  2.043301331220639e-05
loss/value_e :  1.411988545547832
loss/entropy :  2.413649259191571
reward/intrinsic_running :  0.005546411031814147
reward/extrinsic_running :  0.014414814814814814
reward/intrinsic_std_running :  0.052993344385018716
reward/extrinsic_std_running :  0.3808270606862013
reward/intrinsic_batch_std :  3.705857925405834e-05
reward/intrinsic_batch_max :  0.0007496804464608431
reward/intrinsic_batch_min :  5.858669737790478e-06
reward/total_batch :  0.007236726388845599
time/iteration_time :  112.14668869972229
time/fps :  2407.5610535674123
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: -0.0001, Value Loss: 1.4120, Entropy: 2.4136
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=74.7
Extrinsic raw: Œº=0.014414814814814814

=== Iteration 103/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.09s
EPOCH 1 took 19.66s
update_step :  103
reward/intrinsic_batch_mean :  5.960885745954767e-05
reward/extrinsic_batch_mean :  0.013822222222222222
loss/policy :  -0.000480100035378145
loss/rnd :  2.920620094107907e-06
loss/value :  1.308361398451256
loss/value_i :  2.0603133414238762e-05
loss/value_e :  1.308340791499976
loss/entropy :  2.415141250147964
reward/intrinsic_running :  0.005495343416809791
reward/extrinsic_running :  0.013822222222222222
reward/intrinsic_std_running :  0.052737990571898916
reward/extrinsic_std_running :  0.3729880122523385
reward/intrinsic_batch_std :  3.130121884033328e-05
reward/intrinsic_batch_max :  0.0004454665759112686
reward/intrinsic_batch_min :  9.197095096169505e-06
reward/total_batch :  0.006940915539840884
time/iteration_time :  110.71882843971252
time/fps :  2438.609618661361
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2439
Policy Loss: -0.0005, Value Loss: 1.3084, Entropy: 2.4151
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.008, sum=76.3
Extrinsic raw: Œº=0.013822222222222222

=== Iteration 104/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 19.39s
update_step :  104
reward/intrinsic_batch_mean :  5.5300059665912865e-05
reward/extrinsic_batch_mean :  0.014407407407407407
loss/policy :  -0.0006538694812634001
loss/rnd :  2.8792009440318602e-06
loss/value :  1.473709548964645
loss/value_i :  2.0967819678348448e-05
loss/value_e :  1.4736885771606907
loss/entropy :  2.3987401615489614
reward/intrinsic_running :  0.005445050815186197
reward/extrinsic_running :  0.014407407407407407
reward/intrinsic_std_running :  0.0524863126572895
reward/extrinsic_std_running :  0.3808322036705113
reward/intrinsic_batch_std :  2.884930395369637e-05
reward/intrinsic_batch_max :  0.0004937521880492568
reward/intrinsic_batch_min :  4.852364327234682e-06
reward/total_batch :  0.00723135373353666
time/iteration_time :  111.37399411201477
time/fps :  2424.264319087332
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0007, Value Loss: 1.4737, Entropy: 2.3987
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=71.1
Extrinsic raw: Œº=0.014407407407407407

=== Iteration 105/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.87s
EPOCH 1 took 19.33s
update_step :  105
reward/intrinsic_batch_mean :  5.695395932632015e-05
reward/extrinsic_batch_mean :  0.014088888888888889
loss/policy :  -0.00023396381716751918
loss/rnd :  2.968838798827192e-06
loss/value :  1.367734974080866
loss/value_i :  2.1073075031657055e-05
loss/value_e :  1.36771390654824
loss/entropy :  2.3970714915882456
reward/intrinsic_running :  0.005395767965267236
reward/extrinsic_running :  0.014088888888888889
reward/intrinsic_std_running :  0.05223819846967349
reward/extrinsic_std_running :  0.3769487924092149
reward/intrinsic_batch_std :  3.0613529663706015e-05
reward/intrinsic_batch_max :  0.0005494546494446695
reward/intrinsic_batch_min :  5.672374300047522e-06
reward/total_batch :  0.007072921424107604
time/iteration_time :  111.81075549125671
time/fps :  2414.794523243457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: -0.0002, Value Loss: 1.3677, Entropy: 2.3971
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=73.6
Extrinsic raw: Œº=0.014088888888888889

=== Iteration 106/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 18.70s
update_step :  106
reward/intrinsic_batch_mean :  5.6249230522007566e-05
reward/extrinsic_batch_mean :  0.014681481481481481
loss/policy :  0.0001474224770363159
loss/rnd :  2.9154784656246635e-06
loss/value :  1.5793506557291204
loss/value_i :  1.9660756841017935e-05
loss/value_e :  1.5793309970335527
loss/entropy :  2.4021731867934717
reward/intrinsic_running :  0.005347395666490152
reward/extrinsic_running :  0.014681481481481481
reward/intrinsic_std_running :  0.051993571383880485
reward/extrinsic_std_running :  0.3847067310514902
reward/intrinsic_batch_std :  2.933122477144624e-05
reward/intrinsic_batch_max :  0.0005144845345057547
reward/intrinsic_batch_min :  4.8927304305834696e-06
reward/total_batch :  0.007368865356001744
time/iteration_time :  111.67875933647156
time/fps :  2417.6486343882993
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: 0.0001, Value Loss: 1.5794, Entropy: 2.4022
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=73.0
Extrinsic raw: Œº=0.014681481481481481

=== Iteration 107/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 19.76s
update_step :  107
reward/intrinsic_batch_mean :  5.910945830661755e-05
reward/extrinsic_batch_mean :  0.015785185185185187
loss/policy :  -0.00015680808009523335
loss/rnd :  3.0511813589107604e-06
loss/value :  1.594975765907403
loss/value_i :  2.1484802842182532e-05
loss/value_e :  1.594954277529861
loss/entropy :  2.39697768832698
reward/intrinsic_running :  0.00530001268271536
reward/extrinsic_running :  0.015785185185185187
reward/intrinsic_std_running :  0.051752340796172885
reward/extrinsic_std_running :  0.3978726929314467
reward/intrinsic_batch_std :  3.317766015576857e-05
reward/intrinsic_batch_max :  0.0005297192838042974
reward/intrinsic_batch_min :  4.428799002198502e-06
reward/total_batch :  0.007922147321745902
time/iteration_time :  112.56489086151123
time/fps :  2398.6164596577582
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: -0.0002, Value Loss: 1.5950, Entropy: 2.3970
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=77.1
Extrinsic raw: Œº=0.015785185185185187

=== Iteration 108/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 19.03s
update_step :  108
reward/intrinsic_batch_mean :  5.816794985886965e-05
reward/extrinsic_batch_mean :  0.015718518518518517
loss/policy :  -0.00026767419176670074
loss/rnd :  3.011476327298045e-06
loss/value :  1.5949083855657866
loss/value_i :  2.4477202962523073e-05
loss/value_e :  1.5948839079249988
loss/entropy :  2.400602698326111
reward/intrinsic_running :  0.005253458159320463
reward/extrinsic_running :  0.015718518518518517
reward/intrinsic_std_running :  0.05151444145432971
reward/extrinsic_std_running :  0.39791721923129714
reward/intrinsic_batch_std :  3.6039822247747346e-05
reward/intrinsic_batch_max :  0.000544307695236057
reward/intrinsic_batch_min :  4.288209311198443e-06
reward/total_batch :  0.007888343234188694
time/iteration_time :  111.47621202468872
time/fps :  2422.0413942680693
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: -0.0003, Value Loss: 1.5949, Entropy: 2.4006
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=76.2
Extrinsic raw: Œº=0.015718518518518517

=== Iteration 109/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.02s
EPOCH 1 took 18.64s
update_step :  109
reward/intrinsic_batch_mean :  6.196835390817595e-05
reward/extrinsic_batch_mean :  0.01574074074074074
loss/policy :  0.0001802669031541992
loss/rnd :  3.1138951113241617e-06
loss/value :  1.551052917133678
loss/value_i :  2.3201973211447086e-05
loss/value_e :  1.5510297110586455
loss/entropy :  2.3993402430505464
reward/intrinsic_running :  0.005207908170915796
reward/extrinsic_running :  0.01574074074074074
reward/intrinsic_std_running :  0.05127977866107749
reward/extrinsic_std_running :  0.39790237892604624
reward/intrinsic_batch_std :  3.852112452276314e-05
reward/intrinsic_batch_max :  0.00046967403613962233
reward/intrinsic_batch_min :  5.800777671538526e-06
reward/total_batch :  0.007901354547324458
time/iteration_time :  112.54315733909607
time/fps :  2399.0796631596313
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0002, Value Loss: 1.5511, Entropy: 2.3993
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=81.6
Extrinsic raw: Œº=0.01574074074074074

=== Iteration 110/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.56s
EPOCH 1 took 19.28s
update_step :  110
reward/intrinsic_batch_mean :  5.7545694863525835e-05
reward/extrinsic_batch_mean :  0.016777777777777777
loss/policy :  -0.00021025748515746795
loss/rnd :  3.0832349149491303e-06
loss/value :  1.5864135857784387
loss/value_i :  2.1239554702002682e-05
loss/value_e :  1.5863923412380796
loss/entropy :  2.3858589548053164
reward/intrinsic_running :  0.005162983762946813
reward/extrinsic_running :  0.016777777777777777
reward/intrinsic_std_running :  0.05104831185092118
reward/extrinsic_std_running :  0.4106859513269037
reward/intrinsic_batch_std :  2.965426589845849e-05
reward/intrinsic_batch_max :  0.0008416191558353603
reward/intrinsic_batch_min :  4.891908247373067e-06
reward/total_batch :  0.008417661736320652
time/iteration_time :  111.7268431186676
time/fps :  2416.6081530937636
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: -0.0002, Value Loss: 1.5864, Entropy: 2.3859
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.016, sum=76.1
Extrinsic raw: Œº=0.016777777777777777

=== Iteration 111/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.17s
EPOCH 1 took 18.93s
update_step :  111
reward/intrinsic_batch_mean :  6.253142371149604e-05
reward/extrinsic_batch_mean :  0.017496296296296298
loss/policy :  0.0002634267500869817
loss/rnd :  3.8958197144507505e-06
loss/value :  1.7928708773670774
loss/value_i :  2.175659122285927e-05
loss/value_e :  1.792849119865533
loss/entropy :  2.388846025322423
reward/intrinsic_running :  0.005119088887289893
reward/extrinsic_running :  0.017496296296296298
reward/intrinsic_std_running :  0.050819930388826144
reward/extrinsic_std_running :  0.4195912803894703
reward/intrinsic_batch_std :  3.286911798311039e-05
reward/intrinsic_batch_max :  0.000608074595220387
reward/intrinsic_batch_min :  8.356003490916919e-06
reward/total_batch :  0.008779413860003898
time/iteration_time :  110.91891932487488
time/fps :  2434.2105174067387
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2434
Policy Loss: 0.0003, Value Loss: 1.7929, Entropy: 2.3888
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=83.1
Extrinsic raw: Œº=0.017496296296296298

=== Iteration 112/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.24s
EPOCH 1 took 20.17s
update_step :  112
reward/intrinsic_batch_mean :  8.24200312082852e-05
reward/extrinsic_batch_mean :  0.017459259259259258
loss/policy :  -0.00046786560348912394
loss/rnd :  5.597098251972497e-06
loss/value :  1.8759062398563733
loss/value_i :  2.3527078486619178e-05
loss/value_e :  1.875882712277499
loss/entropy :  2.3974752353899405
reward/intrinsic_running :  0.005076771754986404
reward/extrinsic_running :  0.017459259259259258
reward/intrinsic_std_running :  0.05059451299113265
reward/extrinsic_std_running :  0.41961488980683154
reward/intrinsic_batch_std :  4.053294927971246e-05
reward/intrinsic_batch_max :  0.0005364686367101967
reward/intrinsic_batch_min :  2.524180854379665e-05
reward/total_batch :  0.008770839645233772
time/iteration_time :  113.67201948165894
time/fps :  2375.2547129116915
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: -0.0005, Value Loss: 1.8759, Entropy: 2.3975
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.011, sum=110.0
Extrinsic raw: Œº=0.017459259259259258

=== Iteration 113/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 18.97s
update_step :  113
reward/intrinsic_batch_mean :  5.899039366607516e-05
reward/extrinsic_batch_mean :  0.017325925925925925
loss/policy :  -9.239257809840086e-05
loss/rnd :  3.1008982528929305e-06
loss/value :  1.8764473272092415
loss/value_i :  2.0875534270696033e-05
loss/value_e :  1.8764264529401606
loss/entropy :  2.3964986223163027
reward/intrinsic_running :  0.005034248153955736
reward/extrinsic_running :  0.017325925925925925
reward/intrinsic_std_running :  0.050372156837822826
reward/extrinsic_std_running :  0.4178425599234739
reward/intrinsic_batch_std :  2.8928789967337375e-05
reward/intrinsic_batch_max :  0.00047230435302481055
reward/intrinsic_batch_min :  7.199332685559057e-06
reward/total_batch :  0.008692458159796
time/iteration_time :  112.00599503517151
time/fps :  2410.5852540769456
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0001, Value Loss: 1.8764, Entropy: 2.3965
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=79.0
Extrinsic raw: Œº=0.017325925925925925

=== Iteration 114/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.24s
EPOCH 1 took 19.34s
update_step :  114
reward/intrinsic_batch_mean :  6.072637280423671e-05
reward/extrinsic_batch_mean :  0.019548148148148148
loss/policy :  -0.00012929455966293585
loss/rnd :  3.5838021989492876e-06
loss/value :  1.891502851789648
loss/value_i :  2.2106087409624845e-05
loss/value_e :  1.8914807384664363
loss/entropy :  2.3964717496525156
reward/intrinsic_running :  0.004992529648832774
reward/extrinsic_running :  0.019548148148148148
reward/intrinsic_std_running :  0.05015270202201006
reward/extrinsic_std_running :  0.4435455835861664
reward/intrinsic_batch_std :  4.179508284224002e-05
reward/intrinsic_batch_max :  0.0006577425519935787
reward/intrinsic_batch_min :  5.324424364516744e-06
reward/total_batch :  0.009804437260476192
time/iteration_time :  112.26557183265686
time/fps :  2405.0115773913503
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: -0.0001, Value Loss: 1.8915, Entropy: 2.3965
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=81.7
Extrinsic raw: Œº=0.019548148148148148

=== Iteration 115/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.64s
update_step :  115
reward/intrinsic_batch_mean :  5.870977145082347e-05
reward/extrinsic_batch_mean :  0.018333333333333333
loss/policy :  -0.00027854931911199606
loss/rnd :  2.8662505490667005e-06
loss/value :  1.8821593179847256
loss/value_i :  2.257312964061522e-05
loss/value_e :  1.8821367458863691
loss/entropy :  2.394528992248304
reward/intrinsic_running :  0.004951450014082161
reward/extrinsic_running :  0.018333333333333333
reward/intrinsic_std_running :  0.04993609793655027
reward/extrinsic_std_running :  0.43004844688321653
reward/intrinsic_batch_std :  3.667144494786558e-05
reward/intrinsic_batch_max :  0.0005611259257420897
reward/intrinsic_batch_min :  5.36323477717815e-06
reward/total_batch :  0.009196021552392079
time/iteration_time :  111.60356092453003
time/fps :  2419.277644577872
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: -0.0003, Value Loss: 1.8822, Entropy: 2.3945
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=79.4
Extrinsic raw: Œº=0.018333333333333333

=== Iteration 116/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.44s
EPOCH 1 took 18.80s
update_step :  116
reward/intrinsic_batch_mean :  5.911900779147227e-05
reward/extrinsic_batch_mean :  0.02082222222222222
loss/policy :  -0.00045367461908344097
loss/rnd :  2.9609782876088335e-06
loss/value :  2.1496595975124473
loss/value_i :  2.3180462338848773e-05
loss/value_e :  2.1496364113056297
loss/entropy :  2.3986229535305137
reward/intrinsic_running :  0.004911081446868158
reward/extrinsic_running :  0.02082222222222222
reward/intrinsic_std_running :  0.049722275757830135
reward/extrinsic_std_running :  0.48956495224753976
reward/intrinsic_batch_std :  3.752252461585105e-05
reward/intrinsic_batch_max :  0.0004838797904085368
reward/intrinsic_batch_min :  4.324057499616174e-06
reward/total_batch :  0.010440670615006847
time/iteration_time :  112.71385717391968
time/fps :  2395.446369858364
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: -0.0005, Value Loss: 2.1497, Entropy: 2.3986
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=80.3
Extrinsic raw: Œº=0.02082222222222222

=== Iteration 117/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.72s
EPOCH 1 took 19.03s
update_step :  117
reward/intrinsic_batch_mean :  5.945088412410971e-05
reward/extrinsic_batch_mean :  0.017955555555555554
loss/policy :  -4.343412618971232e-05
loss/rnd :  6.816732955237305e-06
loss/value :  1.6402616446668452
loss/value_i :  2.0625287161789004e-05
loss/value_e :  1.6402410088163433
loss/entropy :  2.3972107316508438
reward/intrinsic_running :  0.004871398408298676
reward/extrinsic_running :  0.017955555555555554
reward/intrinsic_std_running :  0.04951117691523441
reward/extrinsic_std_running :  0.4248265505176099
reward/intrinsic_batch_std :  3.317415922299818e-05
reward/intrinsic_batch_max :  0.00044478150084614754
reward/intrinsic_batch_min :  4.976282980351243e-06
reward/total_batch :  0.009007503219839832
time/iteration_time :  112.02409934997559
time/fps :  2410.195677239862
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0000, Value Loss: 1.6403, Entropy: 2.3972
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=81.1
Extrinsic raw: Œº=0.017955555555555554

=== Iteration 118/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.03s
EPOCH 1 took 19.62s
update_step :  118
reward/intrinsic_batch_mean :  6.968939306271851e-05
reward/extrinsic_batch_mean :  0.017207407407407407
loss/policy :  -0.0009151181334759299
loss/rnd :  3.130304035590653e-06
loss/value :  1.5962120601625154
loss/value_i :  2.068094845802107e-05
loss/value_e :  1.5961913773507783
loss/entropy :  2.397599017981327
reward/intrinsic_running :  0.004832774606212543
reward/extrinsic_running :  0.017207407407407407
reward/intrinsic_std_running :  0.04930270847020097
reward/extrinsic_std_running :  0.4160531233227456
reward/intrinsic_batch_std :  3.607126141796651e-05
reward/intrinsic_batch_max :  0.0004582223773468286
reward/intrinsic_batch_min :  9.210058124153875e-06
reward/total_batch :  0.008638548400235063
time/iteration_time :  111.46849775314331
time/fps :  2422.209013688679
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: -0.0009, Value Loss: 1.5962, Entropy: 2.3976
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.009, sum=95.4
Extrinsic raw: Œº=0.017207407407407407

=== Iteration 119/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.56s
EPOCH 1 took 19.79s
update_step :  119
reward/intrinsic_batch_mean :  5.860877303250028e-05
reward/extrinsic_batch_mean :  0.01808888888888889
loss/policy :  -0.000274459849055292
loss/rnd :  2.865574598135109e-06
loss/value :  1.7188261946042378
loss/value_i :  1.9126680413275167e-05
loss/value_e :  1.7188070705442717
loss/entropy :  2.3989843491351968
reward/intrinsic_running :  0.004794361006639288
reward/extrinsic_running :  0.01808888888888889
reward/intrinsic_std_running :  0.04909689116443985
reward/extrinsic_std_running :  0.42656966721469347
reward/intrinsic_batch_std :  3.411853768494752e-05
reward/intrinsic_batch_max :  0.0004964089021086693
reward/intrinsic_batch_min :  4.347868070908589e-06
reward/total_batch :  0.009073748830960696
time/iteration_time :  112.61433243751526
time/fps :  2397.56338430378
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0003, Value Loss: 1.7188, Entropy: 2.3990
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=80.6
Extrinsic raw: Œº=0.01808888888888889

=== Iteration 120/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 18.93s
update_step :  120
reward/intrinsic_batch_mean :  5.862507492286871e-05
reward/extrinsic_batch_mean :  0.018466666666666666
loss/policy :  -0.00026106490721841425
loss/rnd :  2.849362031707697e-06
loss/value :  1.7599902116891109
loss/value_i :  1.942675176409962e-05
loss/value_e :  1.7599707877997197
loss/entropy :  2.386383244485566
reward/intrinsic_running :  0.004756604450218302
reward/extrinsic_running :  0.018466666666666666
reward/intrinsic_std_running :  0.04889362811186034
reward/extrinsic_std_running :  0.4317703659225454
reward/intrinsic_batch_std :  2.9391560141268062e-05
reward/intrinsic_batch_max :  0.0004676826065406203
reward/intrinsic_batch_min :  4.432145942701027e-06
reward/total_batch :  0.009262645870794768
time/iteration_time :  111.40254187583923
time/fps :  2423.6430825871225
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0003, Value Loss: 1.7600, Entropy: 2.3864
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=80.9
Extrinsic raw: Œº=0.018466666666666666

=== Iteration 121/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 18.65s
update_step :  121
reward/intrinsic_batch_mean :  5.671840616596455e-05
reward/extrinsic_batch_mean :  0.020703703703703703
loss/policy :  -0.00017372966050805354
loss/rnd :  2.9438692040044274e-06
loss/value :  1.8270926963199268
loss/value_i :  1.8904487357455462e-05
loss/value_e :  1.827073796228929
loss/entropy :  2.3869262355746645
reward/intrinsic_running :  0.0047193786292950264
reward/extrinsic_running :  0.020703703703703703
reward/intrinsic_std_running :  0.048692877122147045
reward/extrinsic_std_running :  0.45667585674571265
reward/intrinsic_batch_std :  2.8825138616489614e-05
reward/intrinsic_batch_max :  0.0005197770660743117
reward/intrinsic_batch_min :  4.454558620636817e-06
reward/total_batch :  0.010380211054934835
time/iteration_time :  110.72431707382202
time/fps :  2438.488736128179
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2438
Policy Loss: -0.0002, Value Loss: 1.8271, Entropy: 2.3869
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=78.6
Extrinsic raw: Œº=0.020703703703703703

=== Iteration 122/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.32s
EPOCH 1 took 18.83s
update_step :  122
reward/intrinsic_batch_mean :  0.0001155319090686303
reward/extrinsic_batch_mean :  0.020674074074074074
loss/policy :  5.9415704692417585e-05
loss/rnd :  4.815221786609045e-06
loss/value :  1.955304781595866
loss/value_i :  1.8567944497397438e-05
loss/value_e :  1.9552862192645217
loss/entropy :  2.3950392802556357
reward/intrinsic_running :  0.0046848893016568135
reward/extrinsic_running :  0.020674074074074074
reward/intrinsic_std_running :  0.04849439078076135
reward/extrinsic_std_running :  0.4566934189995254
reward/intrinsic_batch_std :  3.7516039994377355e-05
reward/intrinsic_batch_max :  0.0007697981782257557
reward/intrinsic_batch_min :  4.6818910050205886e-05
reward/total_batch :  0.010394802991571353
time/iteration_time :  110.91994333267212
time/fps :  2434.1880448875954
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2434
Policy Loss: 0.0001, Value Loss: 1.9553, Entropy: 2.3950
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=160.8
Extrinsic raw: Œº=0.020674074074074074

=== Iteration 123/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 18.02s
update_step :  123
reward/intrinsic_batch_mean :  7.39124029722276e-05
reward/extrinsic_batch_mean :  0.019533333333333333
loss/policy :  0.00024619496914304114
loss/rnd :  5.001370905946797e-06
loss/value :  1.885032771211682
loss/value_i :  1.8471275711128715e-05
loss/value_e :  1.8850143100276138
loss/entropy :  2.39815058852687
reward/intrinsic_running :  0.00464945510072688
reward/extrinsic_running :  0.019533333333333333
reward/intrinsic_std_running :  0.048298443370790166
reward/extrinsic_std_running :  0.44355458639395334
reward/intrinsic_batch_std :  3.52169119265148e-05
reward/intrinsic_batch_max :  0.0005672630504705012
reward/intrinsic_batch_min :  1.7296326404903084e-05
reward/total_batch :  0.00980362286815278
time/iteration_time :  112.89043998718262
time/fps :  2391.6994214094243
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0002, Value Loss: 1.8850, Entropy: 2.3982
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=103.3
Extrinsic raw: Œº=0.019533333333333333

=== Iteration 124/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.20s
EPOCH 1 took 19.68s
update_step :  124
reward/intrinsic_batch_mean :  9.523118017669832e-05
reward/extrinsic_batch_mean :  0.02337037037037037
loss/policy :  8.888944505473994e-05
loss/rnd :  2.9677646718041752e-06
loss/value :  1.8247355927120557
loss/value_i :  1.8924398621796474e-05
loss/value_e :  1.8247166601094333
loss/entropy :  2.40259004722942
reward/intrinsic_running :  0.0046153348534153345
reward/extrinsic_running :  0.02337037037037037
reward/intrinsic_std_running :  0.0481047866933784
reward/extrinsic_std_running :  0.4848731524191661
reward/intrinsic_batch_std :  3.7751144373459095e-05
reward/intrinsic_batch_max :  0.0005876324721612036
reward/intrinsic_batch_min :  2.3752476408844814e-05
reward/total_batch :  0.011732800775273534
time/iteration_time :  112.4469645023346
time/fps :  2401.131957585163
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0001, Value Loss: 1.8247, Entropy: 2.4026
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=133.6
Extrinsic raw: Œº=0.02337037037037037

=== Iteration 125/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.49s
EPOCH 1 took 19.12s
update_step :  125
reward/intrinsic_batch_mean :  6.056056733188463e-05
reward/extrinsic_batch_mean :  0.022133333333333335
loss/policy :  -0.00020639061007056046
loss/rnd :  3.0156646020755447e-06
loss/value :  1.9236153797669844
loss/value_i :  1.8403898552192416e-05
loss/value_e :  1.9235969673503528
loss/entropy :  2.403204665039525
reward/intrinsic_running :  0.004580527324482701
reward/extrinsic_running :  0.022133333333333335
reward/intrinsic_std_running :  0.04791354966796024
reward/extrinsic_std_running :  0.4725805093079674
reward/intrinsic_batch_std :  3.820625791445457e-05
reward/intrinsic_batch_max :  0.0005304157384671271
reward/intrinsic_batch_min :  5.381807113735704e-06
reward/total_batch :  0.01109694695033261
time/iteration_time :  110.99329972267151
time/fps :  2432.5792698714567
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0002, Value Loss: 1.9236, Entropy: 2.4032
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=85.3
Extrinsic raw: Œº=0.022133333333333335

=== Iteration 126/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 19.97s
update_step :  126
reward/intrinsic_batch_mean :  5.940232458937384e-05
reward/extrinsic_batch_mean :  0.02208888888888889
loss/policy :  -0.0003978320129328605
loss/rnd :  2.8030502548834635e-06
loss/value :  1.8749950076594497
loss/value_i :  1.7692503206490073e-05
loss/value_e :  1.8749773123047568
loss/entropy :  2.405238292433999
reward/intrinsic_running :  0.00454622529280428
reward/extrinsic_running :  0.02208888888888889
reward/intrinsic_std_running :  0.04772457931282294
reward/extrinsic_std_running :  0.4726060996560441
reward/intrinsic_batch_std :  3.38175024825257e-05
reward/intrinsic_batch_max :  0.0004971015732735395
reward/intrinsic_batch_min :  4.735657057608478e-06
reward/total_batch :  0.011074145606739132
time/iteration_time :  112.41380214691162
time/fps :  2401.8402975743293
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0004, Value Loss: 1.8750, Entropy: 2.4052
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=84.0
Extrinsic raw: Œº=0.02208888888888889

=== Iteration 127/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 18.38s
update_step :  127
reward/intrinsic_batch_mean :  6.002626757166312e-05
reward/extrinsic_batch_mean :  0.022074074074074072
loss/policy :  -0.0003809923320218469
loss/rnd :  2.981334460221688e-06
loss/value :  2.2030317783355713
loss/value_i :  1.877417432269519e-05
loss/value_e :  2.203013013709675
loss/entropy :  2.4041965513518364
reward/intrinsic_running :  0.0045124839299986105
reward/extrinsic_running :  0.022074074074074072
reward/intrinsic_std_running :  0.047537825365397426
reward/extrinsic_std_running :  0.5029853046911547
reward/intrinsic_batch_std :  3.58918009011535e-05
reward/intrinsic_batch_max :  0.0005443758564069867
reward/intrinsic_batch_min :  5.366145160223823e-06
reward/total_batch :  0.011067050170822868
time/iteration_time :  110.98374676704407
time/fps :  2432.78865478143
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0004, Value Loss: 2.2030, Entropy: 2.4042
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=85.2
Extrinsic raw: Œº=0.022074074074074072

=== Iteration 128/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.58s
EPOCH 1 took 18.78s
update_step :  128
reward/intrinsic_batch_mean :  5.9502836811858556e-05
reward/extrinsic_batch_mean :  0.023007407407407407
loss/policy :  -0.00028152045155310947
loss/rnd :  3.3422423698401404e-06
loss/value :  2.39816907861016
loss/value_i :  1.7565665791952405e-05
loss/value_e :  2.3981514934337502
loss/entropy :  2.4051805517890235
reward/intrinsic_running :  0.004479249341316992
reward/extrinsic_running :  0.023007407407407407
reward/intrinsic_std_running :  0.047353248474491065
reward/extrinsic_std_running :  0.5398596456322396
reward/intrinsic_batch_std :  3.811575394254631e-05
reward/intrinsic_batch_max :  0.0005183008615858853
reward/intrinsic_batch_min :  4.003783487860346e-06
reward/total_batch :  0.011533455122109633
time/iteration_time :  112.09516906738281
time/fps :  2408.6675835039528
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: -0.0003, Value Loss: 2.3982, Entropy: 2.4052
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=84.8
Extrinsic raw: Œº=0.023007407407407407

=== Iteration 129/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.63s
EPOCH 1 took 19.31s
update_step :  129
reward/intrinsic_batch_mean :  0.00010689151963829149
reward/extrinsic_batch_mean :  0.020162962962962962
loss/policy :  -0.00011922853159238443
loss/rnd :  6.117761451853519e-06
loss/value :  2.050503261161573
loss/value_i :  1.737473160050506e-05
loss/value_e :  2.0504858818921177
loss/entropy :  2.412644230958187
reward/intrinsic_running :  0.004448101118990867
reward/extrinsic_running :  0.020162962962962962
reward/intrinsic_std_running :  0.047170669138599054
reward/extrinsic_std_running :  0.4518613062763168
reward/intrinsic_batch_std :  3.7167252516926516e-05
reward/intrinsic_batch_max :  0.0005512659554369748
reward/intrinsic_batch_min :  4.883205838268623e-05
reward/total_batch :  0.010134927241300627
time/iteration_time :  111.12967109680176
time/fps :  2429.5941609042557
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: -0.0001, Value Loss: 2.0505, Entropy: 2.4126
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=153.0
Extrinsic raw: Œº=0.020162962962962962

=== Iteration 130/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.67s
EPOCH 1 took 18.53s
update_step :  130
reward/intrinsic_batch_mean :  6.565101943961054e-05
reward/extrinsic_batch_mean :  0.023133333333333332
loss/policy :  5.953319751742211e-05
loss/rnd :  2.771058268880359e-06
loss/value :  2.216003903836915
loss/value_i :  1.653134404477896e-05
loss/value_e :  2.215987371675896
loss/entropy :  2.4121116363640986
reward/intrinsic_running :  0.004416053199465753
reward/extrinsic_running :  0.023133333333333332
reward/intrinsic_std_running :  0.04699030374712251
reward/extrinsic_std_running :  0.513133111024449
reward/intrinsic_batch_std :  3.6808604603797654e-05
reward/intrinsic_batch_max :  0.0005621772143058479
reward/intrinsic_batch_min :  1.2168944522272795e-05
reward/total_batch :  0.01159949217638647
time/iteration_time :  111.53052067756653
time/fps :  2420.862005841136
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0001, Value Loss: 2.2160, Entropy: 2.4121
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=94.3
Extrinsic raw: Œº=0.023133333333333332

=== Iteration 131/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.82s
EPOCH 1 took 19.02s
update_step :  131
reward/intrinsic_batch_mean :  5.906506671104176e-05
reward/extrinsic_batch_mean :  0.02185185185185185
loss/policy :  -0.00023478304237042639
loss/rnd :  2.7525048732389803e-06
loss/value :  1.9477424097783638
loss/value_i :  1.600684733851019e-05
loss/value_e :  1.9477264086405437
loss/entropy :  2.4103157267426
reward/intrinsic_running :  0.004384275430639914
reward/extrinsic_running :  0.02185185185185185
reward/intrinsic_std_running :  0.046812010860113176
reward/extrinsic_std_running :  0.46944046312870874
reward/intrinsic_batch_std :  4.062268318810658e-05
reward/intrinsic_batch_max :  0.0004969428409822285
reward/intrinsic_batch_min :  3.3161581995955203e-06
reward/total_batch :  0.010955458459281447
time/iteration_time :  112.37822556495667
time/fps :  2402.600669681646
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: -0.0002, Value Loss: 1.9477, Entropy: 2.4103
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=85.2
Extrinsic raw: Œº=0.02185185185185185

=== Iteration 132/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.73s
EPOCH 1 took 18.49s
update_step :  132
reward/intrinsic_batch_mean :  5.76035195135706e-05
reward/extrinsic_batch_mean :  0.02362962962962963
loss/policy :  -0.0002471975599429711
loss/rnd :  2.6788802367236437e-06
loss/value :  2.3449660738309226
loss/value_i :  1.5474519455672247e-05
loss/value_e :  2.3449506019101
loss/entropy :  2.414243094848864
reward/intrinsic_running :  0.00435290786907874
reward/extrinsic_running :  0.02362962962962963
reward/intrinsic_std_running :  0.046635737977885575
reward/extrinsic_std_running :  0.5188992729021514
reward/intrinsic_batch_std :  3.539453999794409e-05
reward/intrinsic_batch_max :  0.0004769308725371957
reward/intrinsic_batch_min :  3.826020474662073e-06
reward/total_batch :  0.0118436165745716
time/iteration_time :  112.06320142745972
time/fps :  2409.3546905740977
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: -0.0002, Value Loss: 2.3450, Entropy: 2.4142
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=83.4
Extrinsic raw: Œº=0.02362962962962963

=== Iteration 133/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 19.99s
update_step :  133
reward/intrinsic_batch_mean :  6.0383679656398376e-05
reward/extrinsic_batch_mean :  0.023125925925925925
loss/policy :  -0.00019699124933333334
loss/rnd :  2.7903067320673443e-06
loss/value :  2.1749489957636055
loss/value_i :  1.641610810331644e-05
loss/value_e :  2.174932573780869
loss/entropy :  2.4149353829297153
reward/intrinsic_running :  0.0043221049522807154
reward/extrinsic_running :  0.023125925925925925
reward/intrinsic_std_running :  0.04646143352906434
reward/extrinsic_std_running :  0.5160160840104462
reward/intrinsic_batch_std :  4.0415818260652044e-05
reward/intrinsic_batch_max :  0.0005149462958797812
reward/intrinsic_batch_min :  4.584952421282651e-06
reward/total_batch :  0.011593154802791161
time/iteration_time :  112.59874606132507
time/fps :  2397.8952647745195
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0002, Value Loss: 2.1749, Entropy: 2.4149
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=87.7
Extrinsic raw: Œº=0.023125925925925925

=== Iteration 134/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.57s
EPOCH 1 took 18.75s
update_step :  134
reward/intrinsic_batch_mean :  6.063107519911244e-05
reward/extrinsic_batch_mean :  0.024444444444444446
loss/policy :  -0.00011241149772875801
loss/rnd :  2.8067041808533375e-06
loss/value :  2.159755305810408
loss/value_i :  1.4842850360406429e-05
loss/value_e :  2.1597404624476577
loss/entropy :  2.4198475534265693
reward/intrinsic_running :  0.004291755319006899
reward/extrinsic_running :  0.024444444444444446
reward/intrinsic_std_running :  0.046289069452943574
reward/extrinsic_std_running :  0.525775147922417
reward/intrinsic_batch_std :  4.1598344749533544e-05
reward/intrinsic_batch_max :  0.0005041147815063596
reward/intrinsic_batch_min :  3.177294274792075e-06
reward/total_batch :  0.01225253775982178
time/iteration_time :  110.24112296104431
time/fps :  2449.176793086636
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2449
Policy Loss: -0.0001, Value Loss: 2.1598, Entropy: 2.4198
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.011, sum=88.4
Extrinsic raw: Œº=0.024444444444444446

=== Iteration 135/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.66s
EPOCH 1 took 18.90s
update_step :  135
reward/intrinsic_batch_mean :  5.8231423993617714e-05
reward/extrinsic_batch_mean :  0.022096296296296298
loss/policy :  -6.847551655179511e-05
loss/rnd :  2.680679709886714e-06
loss/value :  1.9831418521476514
loss/value_i :  1.7220892294228012e-05
loss/value_e :  1.9831246372425195
loss/entropy :  2.427020929076455
reward/intrinsic_running :  0.004261794093327932
reward/extrinsic_running :  0.022096296296296298
reward/intrinsic_std_running :  0.04611861452229334
reward/extrinsic_std_running :  0.5029732836447246
reward/intrinsic_batch_std :  3.790000431109954e-05
reward/intrinsic_batch_max :  0.0005609752261079848
reward/intrinsic_batch_min :  3.3870098832267104e-06
reward/total_batch :  0.011077263860144957
time/iteration_time :  111.06321811676025
time/fps :  2431.0478714577694
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0001, Value Loss: 1.9831, Entropy: 2.4270
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=85.2
Extrinsic raw: Œº=0.022096296296296298

=== Iteration 136/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 18.81s
update_step :  136
reward/intrinsic_batch_mean :  5.849537336743769e-05
reward/extrinsic_batch_mean :  0.02262222222222222
loss/policy :  -0.0006715965723604754
loss/rnd :  2.692582477197213e-06
loss/value :  1.9565407706029487
loss/value_i :  2.0132599412604716e-05
loss/value_e :  1.956520645907431
loss/entropy :  2.426535624446291
reward/intrinsic_running :  0.004232276595833092
reward/extrinsic_running :  0.02262222222222222
reward/intrinsic_std_running :  0.04595002863197459
reward/extrinsic_std_running :  0.5357162857011462
reward/intrinsic_batch_std :  4.003241492557461e-05
reward/intrinsic_batch_max :  0.0005353513406589627
reward/intrinsic_batch_min :  3.068790647375863e-06
reward/total_batch :  0.011340358797794828
time/iteration_time :  111.64166522026062
time/fps :  2418.4519235476314
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2418
Policy Loss: -0.0007, Value Loss: 1.9565, Entropy: 2.4265
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=85.9
Extrinsic raw: Œº=0.02262222222222222

=== Iteration 137/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.63s
EPOCH 1 took 18.90s
update_step :  137
reward/intrinsic_batch_mean :  5.916098215340618e-05
reward/extrinsic_batch_mean :  0.021185185185185185
loss/policy :  -0.00025272506966509604
loss/rnd :  2.7412160699730688e-06
loss/value :  1.9596906575289639
loss/value_i :  1.3641100891122319e-05
loss/value_e :  1.9596770152901157
loss/entropy :  2.423618692340273
reward/intrinsic_running :  0.00420318160453479
reward/extrinsic_running :  0.021185185185185185
reward/intrinsic_std_running :  0.04578327854217622
reward/extrinsic_std_running :  0.4941090775539972
reward/intrinsic_batch_std :  3.719129003453942e-05
reward/intrinsic_batch_max :  0.000625516171567142
reward/intrinsic_batch_min :  2.9936275041109184e-06
reward/total_batch :  0.010622173083669296
time/iteration_time :  111.82731175422668
time/fps :  2414.437007959238
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: -0.0003, Value Loss: 1.9597, Entropy: 2.4236
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=87.2
Extrinsic raw: Œº=0.021185185185185185

=== Iteration 138/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.28s
EPOCH 1 took 19.32s
update_step :  138
reward/intrinsic_batch_mean :  7.232395280475936e-05
reward/extrinsic_batch_mean :  0.022274074074074075
loss/policy :  -0.00026402738082899964
loss/rnd :  2.84124437119758e-06
loss/value :  1.9639829595883687
loss/value_i :  1.4210305890270375e-05
loss/value_e :  1.9639687483960933
loss/entropy :  2.4157258741783374
reward/intrinsic_running :  0.004174909033508244
reward/extrinsic_running :  0.022274074074074075
reward/intrinsic_std_running :  0.04561829654791561
reward/extrinsic_std_running :  0.4741426715995407
reward/intrinsic_batch_std :  3.9851730428348524e-05
reward/intrinsic_batch_max :  0.0005550202913582325
reward/intrinsic_batch_min :  9.70215205597924e-06
reward/total_batch :  0.011173199013439416
time/iteration_time :  112.20174050331116
time/fps :  2406.3797833156796
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: -0.0003, Value Loss: 1.9640, Entropy: 2.4157
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=107.0
Extrinsic raw: Œº=0.022274074074074075

=== Iteration 139/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.66s
EPOCH 1 took 18.15s
update_step :  139
reward/intrinsic_batch_mean :  5.964352367480522e-05
reward/extrinsic_batch_mean :  0.021777777777777778
loss/policy :  -0.0004724160147209962
loss/rnd :  4.5647673852561805e-06
loss/value :  1.9072133645866856
loss/value_i :  1.352809971594428e-05
loss/value_e :  1.9071998379447244
loss/entropy :  2.4126522468798086
reward/intrinsic_running :  0.004146661171563957
reward/extrinsic_running :  0.021777777777777778
reward/intrinsic_std_running :  0.045455117501560297
reward/extrinsic_std_running :  0.4694833514449162
reward/intrinsic_batch_std :  3.4408420319310945e-05
reward/intrinsic_batch_max :  0.00047657155664637685
reward/intrinsic_batch_min :  3.6456456200539833e-06
reward/total_batch :  0.010918710650726292
time/iteration_time :  110.9699432849884
time/fps :  2433.0912678453587
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0005, Value Loss: 1.9072, Entropy: 2.4127
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=88.6
Extrinsic raw: Œº=0.021777777777777778

=== Iteration 140/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 19.74s
update_step :  140
reward/intrinsic_batch_mean :  6.014933209900374e-05
reward/extrinsic_batch_mean :  0.019874074074074075
loss/policy :  4.896802728939237e-05
loss/rnd :  2.76436226227595e-06
loss/value :  1.8146924358425718
loss/value_i :  1.3236793179341035e-05
loss/value_e :  1.814679199999029
loss/entropy :  2.4160789142955434
reward/intrinsic_running :  0.004118825989070974
reward/extrinsic_running :  0.019874074074074075
reward/intrinsic_std_running :  0.04529367624826275
reward/extrinsic_std_running :  0.4485794686543474
reward/intrinsic_batch_std :  3.497726849374991e-05
reward/intrinsic_batch_max :  0.000470335828140378
reward/intrinsic_batch_min :  5.048040293331724e-06
reward/total_batch :  0.00996711170308654
time/iteration_time :  112.53913569450378
time/fps :  2399.16539552015
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0000, Value Loss: 1.8147, Entropy: 2.4161
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=89.6
Extrinsic raw: Œº=0.019874074074074075

=== Iteration 141/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 19.45s
update_step :  141
reward/intrinsic_batch_mean :  6.039503632633838e-05
reward/extrinsic_batch_mean :  0.020125925925925926
loss/policy :  6.553082091682661e-05
loss/rnd :  3.918380901847161e-06
loss/value :  1.735394091317148
loss/value_i :  1.2481254709035222e-05
loss/value_e :  1.7353816122719736
loss/entropy :  2.416818268371351
reward/intrinsic_running :  0.004091393584098583
reward/extrinsic_running :  0.020125925925925926
reward/intrinsic_std_running :  0.045133942263015946
reward/extrinsic_std_running :  0.48194680710987386
reward/intrinsic_batch_std :  3.520284801026076e-05
reward/intrinsic_batch_max :  0.0004627183952834457
reward/intrinsic_batch_min :  4.107471340830671e-06
reward/total_batch :  0.010093160481126132
time/iteration_time :  112.16064262390137
time/fps :  2407.261528496834
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0001, Value Loss: 1.7354, Entropy: 2.4168
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.010, sum=90.3
Extrinsic raw: Œº=0.020125925925925926

=== Iteration 142/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.73s
EPOCH 1 took 19.24s
update_step :  142
reward/intrinsic_batch_mean :  9.344976008549027e-05
reward/extrinsic_batch_mean :  0.01934074074074074
loss/policy :  -0.00010737400611326325
loss/rnd :  4.636343037005148e-06
loss/value :  1.6698541081312932
loss/value_i :  1.1842834103872795e-05
loss/value_e :  1.6698422612565937
loss/entropy :  2.417302854133375
reward/intrinsic_running :  0.0040652830521222556
reward/extrinsic_running :  0.01934074074074074
reward/intrinsic_std_running :  0.04497580865682679
reward/extrinsic_std_running :  0.44191503562400136
reward/intrinsic_batch_std :  4.012413041741084e-05
reward/intrinsic_batch_max :  0.0005804576794616878
reward/intrinsic_batch_min :  2.5167822968796827e-05
reward/total_batch :  0.009717095250413116
time/iteration_time :  111.90181922912598
time/fps :  2412.8294058129486
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0001, Value Loss: 1.6699, Entropy: 2.4173
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=140.3
Extrinsic raw: Œº=0.01934074074074074

=== Iteration 143/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 18.56s
update_step :  143
reward/intrinsic_batch_mean :  8.215152823702536e-05
reward/extrinsic_batch_mean :  0.023881481481481483
loss/policy :  -0.0004419989532889855
loss/rnd :  2.73948900499046e-06
loss/value :  2.1823195670590256
loss/value_i :  1.227759386176441e-05
loss/value_e :  2.1823072921146047
loss/entropy :  2.412854805137172
reward/intrinsic_running :  0.004039218584588105
reward/extrinsic_running :  0.023881481481481483
reward/intrinsic_std_running :  0.04481935164602819
reward/extrinsic_std_running :  0.5479997709090066
reward/intrinsic_batch_std :  3.843350231237628e-05
reward/intrinsic_batch_max :  0.0005720375338569283
reward/intrinsic_batch_min :  2.66790266323369e-05
reward/total_batch :  0.011981816504859254
time/iteration_time :  111.42355704307556
time/fps :  2423.185968615415
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: -0.0004, Value Loss: 2.1823, Entropy: 2.4129
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=123.7
Extrinsic raw: Œº=0.023881481481481483

=== Iteration 144/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.71s
EPOCH 1 took 18.01s
update_step :  144
reward/intrinsic_batch_mean :  6.12275993398658e-05
reward/extrinsic_batch_mean :  0.019503703703703704
loss/policy :  -6.534333343469453e-05
loss/rnd :  2.7243327925437675e-06
loss/value :  1.8041108557672212
loss/value_i :  1.2264232337298436e-05
loss/value_e :  1.804098595272411
loss/entropy :  2.4075402093656137
reward/intrinsic_running :  0.004012905447104892
reward/extrinsic_running :  0.019503703703703704
reward/intrinsic_std_running :  0.04466456668388897
reward/extrinsic_std_running :  0.4435725899769678
reward/intrinsic_batch_std :  3.703606774957436e-05
reward/intrinsic_batch_max :  0.0006065728375688195
reward/intrinsic_batch_min :  3.2093871595861856e-06
reward/total_batch :  0.009782465651521785
time/iteration_time :  111.50267481803894
time/fps :  2421.466574148222
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: -0.0001, Value Loss: 1.8041, Entropy: 2.4075
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=92.5
Extrinsic raw: Œº=0.019503703703703704

=== Iteration 145/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 18.78s
update_step :  145
reward/intrinsic_batch_mean :  6.049494807454418e-05
reward/extrinsic_batch_mean :  0.02005925925925926
loss/policy :  -0.00027775908727728
loss/rnd :  2.671220296647472e-06
loss/value :  1.7719290527430447
loss/value_i :  1.2505119491723951e-05
loss/value_e :  1.77191654660485
loss/entropy :  2.4061608025521943
reward/intrinsic_running :  0.00398693995340513
reward/extrinsic_running :  0.02005925925925926
reward/intrinsic_std_running :  0.044511375593327976
reward/extrinsic_std_running :  0.45019896445843943
reward/intrinsic_batch_std :  3.71500502847922e-05
reward/intrinsic_batch_max :  0.0005949134938418865
reward/intrinsic_batch_min :  3.839143118966604e-06
reward/total_batch :  0.010059877103666902
time/iteration_time :  111.29746437072754
time/fps :  2425.9312781883373
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: -0.0003, Value Loss: 1.7719, Entropy: 2.4062
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=91.7
Extrinsic raw: Œº=0.02005925925925926

=== Iteration 146/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.34s
EPOCH 1 took 18.59s
update_step :  146
reward/intrinsic_batch_mean :  6.026847510559795e-05
reward/extrinsic_batch_mean :  0.0212
loss/policy :  -0.00011582123856483535
loss/rnd :  2.8648678897463302e-06
loss/value :  1.8990750114123027
loss/value_i :  1.1998596398894513e-05
loss/value_e :  1.8990630110104878
loss/entropy :  2.4084941943486533
reward/intrinsic_running :  0.003961315709453234
reward/extrinsic_running :  0.0212
reward/intrinsic_std_running :  0.044359751188029935
reward/extrinsic_std_running :  0.4631480492839795
reward/intrinsic_batch_std :  3.842775932594378e-05
reward/intrinsic_batch_max :  0.0006296786013990641
reward/intrinsic_batch_min :  3.184352408425184e-06
reward/total_batch :  0.0106301342375528
time/iteration_time :  111.84418392181396
time/fps :  2414.0727799377282
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: -0.0001, Value Loss: 1.8991, Entropy: 2.4085
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=91.7
Extrinsic raw: Œº=0.0212

=== Iteration 147/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.39s
EPOCH 1 took 19.78s
update_step :  147
reward/intrinsic_batch_mean :  6.610360773605256e-05
reward/extrinsic_batch_mean :  0.02182962962962963
loss/policy :  -0.00028417018245708084
loss/rnd :  2.805832950385097e-06
loss/value :  2.069077533302885
loss/value_i :  1.2380804037093185e-05
loss/value_e :  2.0690651535987854
loss/entropy :  2.4047624667485556
reward/intrinsic_running :  0.003936179084747259
reward/extrinsic_running :  0.02182962962962963
reward/intrinsic_std_running :  0.04420965405269253
reward/extrinsic_std_running :  0.5000160596049149
reward/intrinsic_batch_std :  3.68572295067209e-05
reward/intrinsic_batch_max :  0.0005801531369797885
reward/intrinsic_batch_min :  8.289955076179467e-06
reward/total_batch :  0.010947866618682842
time/iteration_time :  112.58039665222168
time/fps :  2398.286096238157
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0003, Value Loss: 2.0691, Entropy: 2.4048
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=100.9
Extrinsic raw: Œº=0.02182962962962963

=== Iteration 148/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.46s
update_step :  148
reward/intrinsic_batch_mean :  6.512396397166514e-05
reward/extrinsic_batch_mean :  0.020511111111111112
loss/policy :  -7.547943845786381e-05
loss/rnd :  3.4048010327365552e-06
loss/value :  2.0895795406717244
loss/value_i :  1.2079881909096112e-05
loss/value_e :  2.0895674734404595
loss/entropy :  2.408800385215066
reward/intrinsic_running :  0.003911360445025636
reward/extrinsic_running :  0.020511111111111112
reward/intrinsic_std_running :  0.0440610724307594
reward/extrinsic_std_running :  0.486550250408773
reward/intrinsic_batch_std :  4.3717994630654357e-05
reward/intrinsic_batch_max :  0.0007625348516739905
reward/intrinsic_batch_min :  4.641590749088209e-06
reward/total_batch :  0.01028811753754139
time/iteration_time :  111.42895197868347
time/fps :  2423.0686478290795
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: -0.0001, Value Loss: 2.0896, Entropy: 2.4088
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.017, sum=99.8
Extrinsic raw: Œº=0.020511111111111112

=== Iteration 149/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.70s
EPOCH 1 took 19.66s
update_step :  149
reward/intrinsic_batch_mean :  7.44350432374631e-05
reward/extrinsic_batch_mean :  0.020370370370370372
loss/policy :  -0.00010183527465966164
loss/rnd :  3.312465875034942e-06
loss/value :  2.0872847961656973
loss/value_i :  1.2464740118020652e-05
loss/value_e :  2.0872723406011406
loss/entropy :  2.3997435931003457
reward/intrinsic_running :  0.0038871219360638856
reward/extrinsic_running :  0.020370370370370372
reward/intrinsic_std_running :  0.0439139581739179
reward/extrinsic_std_running :  0.48502754012286836
reward/intrinsic_batch_std :  3.7023368034228006e-05
reward/intrinsic_batch_max :  0.000589137664064765
reward/intrinsic_batch_min :  1.6167718058568425e-05
reward/total_batch :  0.010222402706803918
time/iteration_time :  111.72335410118103
time/fps :  2416.68362154145
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: -0.0001, Value Loss: 2.0873, Entropy: 2.3997
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=114.4
Extrinsic raw: Œº=0.020370370370370372

=== Iteration 150/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.23s
EPOCH 1 took 18.68s
update_step :  150
reward/intrinsic_batch_mean :  6.12604218069565e-05
reward/extrinsic_batch_mean :  0.02182962962962963
loss/policy :  -0.0002355926227403071
loss/rnd :  2.657507913929955e-06
loss/value :  1.9679930932594067
loss/value_i :  1.2313178034894394e-05
loss/value_e :  1.967980769547549
loss/entropy :  2.4019330089742486
reward/intrinsic_running :  0.003862849024634516
reward/extrinsic_running :  0.02182962962962963
reward/intrinsic_std_running :  0.04376833695426169
reward/extrinsic_std_running :  0.4694533312622205
reward/intrinsic_batch_std :  3.983372096902232e-05
reward/intrinsic_batch_max :  0.0005962522700428963
reward/intrinsic_batch_min :  3.5895143355446635e-06
reward/total_batch :  0.010945445025718294
time/iteration_time :  110.80077838897705
time/fps :  2436.805985713732
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: -0.0002, Value Loss: 1.9680, Entropy: 2.4019
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=94.5
Extrinsic raw: Œº=0.02182962962962963

=== Iteration 151/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 18.63s
update_step :  151
reward/intrinsic_batch_mean :  6.240335355421309e-05
reward/extrinsic_batch_mean :  0.022125925925925927
loss/policy :  0.0005532071121375669
loss/rnd :  2.6745674162928923e-06
loss/value :  2.2719943938833294
loss/value_i :  1.1633025348022453e-05
loss/value_e :  2.2719827673651953
loss/entropy :  2.3930368531833994
reward/intrinsic_running :  0.0038389237182400245
reward/extrinsic_running :  0.022125925925925927
reward/intrinsic_std_running :  0.04362415261738074
reward/extrinsic_std_running :  0.5029572536085706
reward/intrinsic_batch_std :  3.888391248806519e-05
reward/intrinsic_batch_max :  0.0006049718358553946
reward/intrinsic_batch_min :  5.708618573407875e-06
reward/total_batch :  0.01109416463974007
time/iteration_time :  111.72690105438232
time/fps :  2416.606899967442
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0006, Value Loss: 2.2720, Entropy: 2.3930
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=96.6
Extrinsic raw: Œº=0.022125925925925927

=== Iteration 152/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 18.94s
update_step :  152
reward/intrinsic_batch_mean :  6.431973351721994e-05
reward/extrinsic_batch_mean :  0.02448888888888889
loss/policy :  0.00015649740640638453
loss/rnd :  2.7869566910147006e-06
loss/value :  2.5779096989920647
loss/value_i :  1.1322796884390604e-05
loss/value_e :  2.577898372303356
loss/entropy :  2.3941191218116065
reward/intrinsic_running :  0.003815352234506084
reward/extrinsic_running :  0.02448888888888889
reward/intrinsic_std_running :  0.04348138061406025
reward/extrinsic_std_running :  0.5533469859984602
reward/intrinsic_batch_std :  3.9221480952212134e-05
reward/intrinsic_batch_max :  0.0006149733089841902
reward/intrinsic_batch_min :  5.623393917630892e-06
reward/total_batch :  0.012276604311203055
time/iteration_time :  111.36947011947632
time/fps :  2424.362796288301
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0002, Value Loss: 2.5779, Entropy: 2.3941
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=99.8
Extrinsic raw: Œº=0.02448888888888889

=== Iteration 153/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 19.45s
update_step :  153
reward/intrinsic_batch_mean :  6.081946345427274e-05
reward/extrinsic_batch_mean :  0.02319259259259259
loss/policy :  -0.0002031400129481247
loss/rnd :  2.6138649838520163e-06
loss/value :  2.5583121704332754
loss/value_i :  1.0650372821670096e-05
loss/value_e :  2.5583015246824785
loss/entropy :  2.397559563318888
reward/intrinsic_running :  0.0037919924091348867
reward/extrinsic_running :  0.02319259259259259
reward/intrinsic_std_running :  0.04334000915284062
reward/extrinsic_std_running :  0.5679194256399444
reward/intrinsic_batch_std :  3.974897035586321e-05
reward/intrinsic_batch_max :  0.0005856641801074147
reward/intrinsic_batch_min :  3.675278776427149e-06
reward/total_batch :  0.011626706028023431
time/iteration_time :  112.39766192436218
time/fps :  2402.185200095141
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0002, Value Loss: 2.5583, Entropy: 2.3976
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=94.7
Extrinsic raw: Œº=0.02319259259259259

=== Iteration 154/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.39s
EPOCH 1 took 20.07s
update_step :  154
reward/intrinsic_batch_mean :  6.01935139225639e-05
reward/extrinsic_batch_mean :  0.025614814814814816
loss/policy :  -0.0003102253964849903
loss/rnd :  2.6029246445239442e-06
loss/value :  2.7253462003939077
loss/value_i :  1.1985827079501398e-05
loss/value_e :  2.7253341999920933
loss/entropy :  2.3916957197767315
reward/intrinsic_running :  0.0037689139037474085
reward/extrinsic_running :  0.025614814814814816
reward/intrinsic_std_running :  0.04320000934334696
reward/extrinsic_std_running :  0.5639308072237912
reward/intrinsic_batch_std :  3.9169039455164264e-05
reward/intrinsic_batch_max :  0.0005565094761550426
reward/intrinsic_batch_min :  2.7405183118389687e-06
reward/total_batch :  0.01283750416436869
time/iteration_time :  113.20840668678284
time/fps :  2384.9818922636837
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: -0.0003, Value Loss: 2.7253, Entropy: 2.3917
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=94.1
Extrinsic raw: Œº=0.025614814814814816

=== Iteration 155/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.24s
update_step :  155
reward/intrinsic_batch_mean :  5.9777459108526844e-05
reward/extrinsic_batch_mean :  0.022407407407407407
loss/policy :  -0.0003355174002618614
loss/rnd :  2.5911302069895705e-06
loss/value :  2.0041758689013394
loss/value_i :  1.1340491903066516e-05
loss/value_e :  2.0041645169258118
loss/entropy :  2.3987163991639107
reward/intrinsic_running :  0.003746122558886193
reward/extrinsic_running :  0.022407407407407407
reward/intrinsic_std_running :  0.04306135834953243
reward/extrinsic_std_running :  0.4757039041142871
reward/intrinsic_batch_std :  3.9877285825406025e-05
reward/intrinsic_batch_max :  0.0005919086397625506
reward/intrinsic_batch_min :  2.9036095838819165e-06
reward/total_batch :  0.011233592433257967
time/iteration_time :  111.97325682640076
time/fps :  2411.2900495392228
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0003, Value Loss: 2.0042, Entropy: 2.3987
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=93.7
Extrinsic raw: Œº=0.022407407407407407

=== Iteration 156/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 19.98s
update_step :  156
reward/intrinsic_batch_mean :  6.598834286549525e-05
reward/extrinsic_batch_mean :  0.02220740740740741
loss/policy :  -9.27731595187321e-05
loss/rnd :  2.659388745528166e-06
loss/value :  2.206645273801052
loss/value_i :  1.085264506345442e-05
loss/value_e :  2.2066344221433005
loss/entropy :  2.395733370925441
reward/intrinsic_running :  0.0037237707177781377
reward/extrinsic_running :  0.02220740740740741
reward/intrinsic_std_running :  0.042924021892536954
reward/extrinsic_std_running :  0.4741809483699047
reward/intrinsic_batch_std :  4.0899097924846254e-05
reward/intrinsic_batch_max :  0.0008053043275140226
reward/intrinsic_batch_min :  8.555231943319086e-06
reward/total_batch :  0.011136697875136452
time/iteration_time :  113.21695184707642
time/fps :  2384.801883420183
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: -0.0001, Value Loss: 2.2066, Entropy: 2.3957
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=103.8
Extrinsic raw: Œº=0.02220740740740741

=== Iteration 157/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.55s
EPOCH 1 took 18.75s
update_step :  157
reward/intrinsic_batch_mean :  6.002048973787842e-05
reward/extrinsic_batch_mean :  0.021762962962962963
loss/policy :  -3.0848796141623154e-05
loss/rnd :  2.551639233912063e-06
loss/value :  2.0477943366224114
loss/value_i :  1.1017406601846838e-05
loss/value_e :  2.0477833133755308
loss/entropy :  2.4031212257616446
reward/intrinsic_running :  0.0037015486211705757
reward/extrinsic_running :  0.021762962962962963
reward/intrinsic_std_running :  0.042788003507085476
reward/extrinsic_std_running :  0.4694919272355691
reward/intrinsic_batch_std :  3.837520756487088e-05
reward/intrinsic_batch_max :  0.0006001580040901899
reward/intrinsic_batch_min :  4.029819137940649e-06
reward/total_batch :  0.010911491726350421
time/iteration_time :  110.3626139163971
time/fps :  2446.4806551658235
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: -0.0000, Value Loss: 2.0478, Entropy: 2.4031
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=94.7
Extrinsic raw: Œº=0.021762962962962963

=== Iteration 158/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.62s
EPOCH 1 took 20.07s
update_step :  158
reward/intrinsic_batch_mean :  5.947792214804361e-05
reward/extrinsic_batch_mean :  0.026837037037037038
loss/policy :  -0.0002625483722306054
loss/rnd :  2.696003486397041e-06
loss/value :  2.738687840375033
loss/value_i :  1.1211514488836242e-05
loss/value_e :  2.7386766347018154
loss/entropy :  2.3972750829927847
reward/intrinsic_running :  0.0036795862932404834
reward/extrinsic_running :  0.026837037037037038
reward/intrinsic_std_running :  0.042653271951262034
reward/extrinsic_std_running :  0.5995138117509133
reward/intrinsic_batch_std :  4.267125221500969e-05
reward/intrinsic_batch_max :  0.0006578605389222503
reward/intrinsic_batch_min :  2.8731005841109436e-06
reward/total_batch :  0.013448257479592541
time/iteration_time :  111.54043483734131
time/fps :  2420.6468299477156
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: -0.0003, Value Loss: 2.7387, Entropy: 2.3973
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.015, sum=94.1
Extrinsic raw: Œº=0.026837037037037038

=== Iteration 159/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.27s
EPOCH 1 took 18.30s
update_step :  159
reward/intrinsic_batch_mean :  6.843237989377046e-05
reward/extrinsic_batch_mean :  0.0296
loss/policy :  -0.00033277628333025586
loss/rnd :  5.897482389738081e-06
loss/value :  2.736917737758521
loss/value_i :  1.1038314507018324e-05
loss/value_e :  2.7369067018682305
loss/entropy :  2.386203494938937
reward/intrinsic_running :  0.0036581077580500067
reward/extrinsic_running :  0.0296
reward/intrinsic_std_running :  0.042519788227929345
reward/extrinsic_std_running :  0.6224427291816582
reward/intrinsic_batch_std :  3.836487810939784e-05
reward/intrinsic_batch_max :  0.0006068729562684894
reward/intrinsic_batch_min :  1.0430785550852306e-05
reward/total_batch :  0.014834216189946885
time/iteration_time :  110.89467167854309
time/fps :  2434.7427690905192
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2435
Policy Loss: -0.0003, Value Loss: 2.7369, Entropy: 2.3862
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=108.6
Extrinsic raw: Œº=0.0296

=== Iteration 160/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.06s
EPOCH 1 took 18.25s
update_step :  160
reward/intrinsic_batch_mean :  0.00013241734696607131
reward/extrinsic_batch_mean :  0.028948148148148146
loss/policy :  -0.0004685489876657922
loss/rnd :  9.143992663280876e-06
loss/value :  3.0265551516504
loss/value_i :  1.18160605779849e-05
loss/value_e :  3.0265433390935264
loss/entropy :  2.387536883354187
reward/intrinsic_running :  0.0036384355187972887
reward/extrinsic_running :  0.028948148148148146
reward/intrinsic_std_running :  0.04238743277055691
reward/extrinsic_std_running :  0.6627824101749467
reward/intrinsic_batch_std :  5.064157720753091e-05
reward/intrinsic_batch_max :  0.000865279755089432
reward/intrinsic_batch_min :  3.702842877828516e-05
reward/total_batch :  0.014540282747557108
time/iteration_time :  112.27305865287781
time/fps :  2404.8512015226843
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: -0.0005, Value Loss: 3.0266, Entropy: 2.3875
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.020, sum=210.9
Extrinsic raw: Œº=0.028948148148148146

=== Iteration 161/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 19.38s
update_step :  161
reward/intrinsic_batch_mean :  8.25878149433939e-05
reward/extrinsic_batch_mean :  0.02666666666666667
loss/policy :  -0.0006034416643077831
loss/rnd :  3.412048306817076e-06
loss/value :  2.662153041724003
loss/value_i :  1.1483500105841262e-05
loss/value_e :  2.662141547058568
loss/entropy :  2.392676176446857
reward/intrinsic_running :  0.0036178032548660247
reward/extrinsic_running :  0.02666666666666667
reward/intrinsic_std_running :  0.04225639682619589
reward/extrinsic_std_running :  0.5729973175556112
reward/intrinsic_batch_std :  5.3975067485740883e-05
reward/intrinsic_batch_max :  0.0007711424841545522
reward/intrinsic_batch_min :  1.6464315194753e-05
reward/total_batch :  0.01337462724080503
time/iteration_time :  110.80244588851929
time/fps :  2436.76931348296
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: -0.0006, Value Loss: 2.6622, Entropy: 2.3927
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=131.9
Extrinsic raw: Œº=0.02666666666666667

=== Iteration 162/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 19.19s
update_step :  162
reward/intrinsic_batch_mean :  6.769707391737298e-05
reward/extrinsic_batch_mean :  0.02971851851851852
loss/policy :  9.343585891959567e-05
loss/rnd :  2.7345468245612485e-06
loss/value :  3.0479993495074185
loss/value_i :  1.277573900634624e-05
loss/value_e :  3.0479865832762285
loss/entropy :  2.3913841753294975
reward/intrinsic_running :  0.003597076310353857
reward/extrinsic_running :  0.02971851851851852
reward/intrinsic_std_running :  0.042126595525098974
reward/extrinsic_std_running :  0.6236378893752943
reward/intrinsic_batch_std :  4.385751149986792e-05
reward/intrinsic_batch_max :  0.0005575548857450485
reward/intrinsic_batch_min :  7.477820872736629e-06
reward/total_batch :  0.014893107796217947
time/iteration_time :  110.40665578842163
time/fps :  2445.5047394734597
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: 0.0001, Value Loss: 3.0480, Entropy: 2.3914
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=108.5
Extrinsic raw: Œº=0.02971851851851852

=== Iteration 163/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.98s
EPOCH 1 took 19.12s
update_step :  163
reward/intrinsic_batch_mean :  6.471248753782507e-05
reward/extrinsic_batch_mean :  0.02331851851851852
loss/policy :  0.0001617130615572519
loss/rnd :  2.6165137218082566e-06
loss/value :  2.0385339711651658
loss/value_i :  1.6612991037783846e-05
loss/value_e :  2.038517343275475
loss/entropy :  2.3939040646408545
reward/intrinsic_running :  0.0035765190268180107
reward/extrinsic_running :  0.02331851851851852
reward/intrinsic_std_running :  0.041997989645125196
reward/extrinsic_std_running :  0.4849023827206624
reward/intrinsic_batch_std :  4.294331028434903e-05
reward/intrinsic_batch_max :  0.0006235843757167459
reward/intrinsic_batch_min :  6.136764568509534e-06
reward/total_batch :  0.011691615503028172
time/iteration_time :  111.62098479270935
time/fps :  2418.8999989689696
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0002, Value Loss: 2.0385, Entropy: 2.3939
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=104.0
Extrinsic raw: Œº=0.02331851851851852

=== Iteration 164/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 18.01s
update_step :  164
reward/intrinsic_batch_mean :  6.161431349840953e-05
reward/extrinsic_batch_mean :  0.029318518518518518
loss/policy :  -0.00016374966203743085
loss/rnd :  2.5783077062717923e-06
loss/value :  3.297069209994692
loss/value_i :  1.1866187047747768e-05
loss/value_e :  3.2970573251897637
loss/entropy :  2.3946838704022495
reward/intrinsic_running :  0.003556142408744986
reward/extrinsic_running :  0.029318518518518518
reward/intrinsic_std_running :  0.04187055984438721
reward/extrinsic_std_running :  0.666138442421603
reward/intrinsic_batch_std :  3.93633220191517e-05
reward/intrinsic_batch_max :  0.0005263669299893081
reward/intrinsic_batch_min :  3.5811822272080462e-06
reward/total_batch :  0.014690066416008464
time/iteration_time :  110.00378823280334
time/fps :  2454.460926641847
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.0s | FPS: 2454
Policy Loss: -0.0002, Value Loss: 3.2971, Entropy: 2.3947
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=99.3
Extrinsic raw: Œº=0.029318518518518518

=== Iteration 165/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 19.16s
update_step :  165
reward/intrinsic_batch_mean :  6.133404336755861e-05
reward/extrinsic_batch_mean :  0.025318518518518518
loss/policy :  1.972381604983556e-05
loss/rnd :  2.5706338860662514e-06
loss/value :  2.451398809750875
loss/value_i :  1.196891787802804e-05
loss/value_e :  2.4513868563102954
loss/entropy :  2.396119825767748
reward/intrinsic_running :  0.003536004794838566
reward/extrinsic_running :  0.025318518518518518
reward/intrinsic_std_running :  0.041744283579354884
reward/extrinsic_std_running :  0.5057774455942843
reward/intrinsic_batch_std :  3.9594686943945386e-05
reward/intrinsic_batch_max :  0.000509805278852582
reward/intrinsic_batch_min :  4.72380315841292e-06
reward/total_batch :  0.012689926280943039
time/iteration_time :  110.44884443283081
time/fps :  2444.570618972839
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2445
Policy Loss: 0.0000, Value Loss: 2.4514, Entropy: 2.3961
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=99.2
Extrinsic raw: Œº=0.025318518518518518

=== Iteration 166/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.07s
EPOCH 1 took 19.24s
update_step :  166
reward/intrinsic_batch_mean :  6.103883184548101e-05
reward/extrinsic_batch_mean :  0.023755555555555554
loss/policy :  -0.00010153328978710554
loss/rnd :  2.579377506304864e-06
loss/value :  2.296792147737561
loss/value_i :  1.0666428365904281e-05
loss/value_e :  2.2967814803123474
loss/entropy :  2.395728169065533
reward/intrinsic_running :  0.003516102956911756
reward/extrinsic_running :  0.023755555555555554
reward/intrinsic_std_running :  0.04161914340013447
reward/extrinsic_std_running :  0.51883284922227
reward/intrinsic_batch_std :  3.9291986436399246e-05
reward/intrinsic_batch_max :  0.0006080782623030245
reward/intrinsic_batch_min :  2.993381031046738e-06
reward/total_batch :  0.011908297193700517
time/iteration_time :  112.41173481941223
time/fps :  2401.8844690347582
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0001, Value Loss: 2.2968, Entropy: 2.3957
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.015, sum=99.0
Extrinsic raw: Œº=0.023755555555555554

=== Iteration 167/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.85s
update_step :  167
reward/intrinsic_batch_mean :  6.10560160365013e-05
reward/extrinsic_batch_mean :  0.024037037037037037
loss/policy :  0.00011660583020949906
loss/rnd :  2.5258773072864367e-06
loss/value :  2.0929159196940335
loss/value_i :  9.388926421458812e-06
loss/value_e :  2.092906532865582
loss/entropy :  2.3996237299659033
reward/intrinsic_running :  0.0034964315084689353
reward/extrinsic_running :  0.024037037037037037
reward/intrinsic_std_running :  0.04149512262882693
reward/extrinsic_std_running :  0.49245793063273213
reward/intrinsic_batch_std :  3.9882874754502715e-05
reward/intrinsic_batch_max :  0.0006496519199572504
reward/intrinsic_batch_min :  3.647092171377153e-06
reward/total_batch :  0.01204904652653677
time/iteration_time :  112.25773358345032
time/fps :  2405.1795041745345
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0001, Value Loss: 2.0929, Entropy: 2.3996
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.016, sum=99.3
Extrinsic raw: Œº=0.024037037037037037

=== Iteration 168/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 18.66s
update_step :  168
reward/intrinsic_batch_mean :  5.9940266680799445e-05
reward/extrinsic_batch_mean :  0.023562962962962963
loss/policy :  6.565442934956853e-05
loss/rnd :  9.485124582114981e-06
loss/value :  2.2188912395275002
loss/value_i :  1.0046849652236702e-05
loss/value_e :  2.2188811880169492
loss/entropy :  2.4001321106246025
reward/intrinsic_running :  0.0034769647447647615
reward/extrinsic_running :  0.023562962962962963
reward/intrinsic_std_running :  0.041372206169873894
reward/extrinsic_std_running :  0.5174334540489227
reward/intrinsic_batch_std :  3.8848869133096776e-05
reward/intrinsic_batch_max :  0.0005251323455013335
reward/intrinsic_batch_min :  3.089362962782616e-06
reward/total_batch :  0.011811451614821881
time/iteration_time :  111.44486689567566
time/fps :  2422.722620798219
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: 0.0001, Value Loss: 2.2189, Entropy: 2.4001
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=97.8
Extrinsic raw: Œº=0.023562962962962963

=== Iteration 169/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.00s
EPOCH 1 took 19.01s
update_step :  169
reward/intrinsic_batch_mean :  0.0002865447973082256
reward/extrinsic_batch_mean :  0.02617037037037037
loss/policy :  4.794847072017464e-05
loss/rnd :  3.6177960826976094e-06
loss/value :  2.726856549580892
loss/value_i :  1.1053849365535742e-05
loss/value_e :  2.7268454920161855
loss/entropy :  2.4061853632782446
reward/intrinsic_running :  0.003462780871172934
reward/extrinsic_running :  0.02617037037037037
reward/intrinsic_std_running :  0.04125003567613447
reward/extrinsic_std_running :  0.5946118564768329
reward/intrinsic_batch_std :  5.515508517952954e-05
reward/intrinsic_batch_max :  0.001063828356564045
reward/intrinsic_batch_min :  0.0001551842869957909
reward/total_batch :  0.013228457583839299
time/iteration_time :  113.24402093887329
time/fps :  2384.2318363610584
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: 0.0000, Value Loss: 2.7269, Entropy: 2.4062
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.007, max=0.026, sum=468.9
Extrinsic raw: Œº=0.02617037037037037

=== Iteration 170/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.48s
EPOCH 1 took 19.31s
update_step :  170
reward/intrinsic_batch_mean :  6.124721503201726e-05
reward/extrinsic_batch_mean :  0.0286
loss/policy :  -0.00023998710799567175
loss/rnd :  2.507680102842807e-06
loss/value :  2.755112890041236
loss/value_i :  1.0586576935924258e-05
loss/value_e :  2.7551022948640767
loss/entropy :  2.398172364090428
reward/intrinsic_running :  0.0034437637660666635
reward/extrinsic_running :  0.0286
reward/intrinsic_std_running :  0.04112927658650184
reward/extrinsic_std_running :  0.6139675187451484
reward/intrinsic_batch_std :  4.2022781629871184e-05
reward/intrinsic_batch_max :  0.0007015940500423312
reward/intrinsic_batch_min :  2.9301911581569584e-06
reward/total_batch :  0.014330623607516009
time/iteration_time :  112.06818222999573
time/fps :  2409.247608263007
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: -0.0002, Value Loss: 2.7551, Entropy: 2.3982
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.017, sum=100.5
Extrinsic raw: Œº=0.0286

=== Iteration 171/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 18.64s
update_step :  171
reward/intrinsic_batch_mean :  5.964877203617747e-05
reward/extrinsic_batch_mean :  0.028918518518518517
loss/policy :  -0.00032384399762094927
loss/rnd :  2.4350318123348793e-06
loss/value :  3.0436981591311367
loss/value_i :  1.2480573910910277e-05
loss/value_e :  3.043685678279761
loss/entropy :  2.4016323161847666
reward/intrinsic_running :  0.0034249312705211536
reward/extrinsic_running :  0.028918518518518517
reward/intrinsic_std_running :  0.0410095747543806
reward/extrinsic_std_running :  0.6627948797478956
reward/intrinsic_batch_std :  3.9687357000800214e-05
reward/intrinsic_batch_max :  0.0007014157599769533
reward/intrinsic_batch_min :  2.6244947548548225e-06
reward/total_batch :  0.014489083645277347
time/iteration_time :  110.38633108139038
time/fps :  2445.955014130534
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: -0.0003, Value Loss: 3.0437, Entropy: 2.4016
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.017, sum=98.2
Extrinsic raw: Œº=0.028918518518518517

=== Iteration 172/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 19.17s
update_step :  172
reward/intrinsic_batch_mean :  5.881623289655922e-05
reward/extrinsic_batch_mean :  0.028918518518518517
loss/policy :  -0.0002077544150145541
loss/rnd :  2.3998698066641353e-06
loss/value :  3.248615154714295
loss/value_i :  1.139508269647415e-05
loss/value_e :  3.248603763002338
loss/entropy :  2.3992830406535757
reward/intrinsic_running :  0.003406295102736171
reward/extrinsic_running :  0.028918518518518517
reward/intrinsic_std_running :  0.04089091369026318
reward/extrinsic_std_running :  0.7059802856533167
reward/intrinsic_batch_std :  3.958867467306948e-05
reward/intrinsic_batch_max :  0.0006046346970833838
reward/intrinsic_batch_min :  2.8316833322605817e-06
reward/total_batch :  0.014488667375707538
time/iteration_time :  111.16068172454834
time/fps :  2428.916374128121
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2429
Policy Loss: -0.0002, Value Loss: 3.2486, Entropy: 2.3993
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.015, sum=97.1
Extrinsic raw: Œº=0.028918518518518517

=== Iteration 173/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.98s
EPOCH 1 took 18.44s
update_step :  173
reward/intrinsic_batch_mean :  6.003266472982971e-05
reward/extrinsic_batch_mean :  0.029296296296296296
loss/policy :  -0.00010800501463977112
loss/rnd :  2.44772278082647e-06
loss/value :  2.4835361459038476
loss/value_i :  9.478489546106147e-06
loss/value_e :  2.483526666959127
loss/entropy :  2.3991425506996387
reward/intrinsic_running :  0.00338790218532746
reward/extrinsic_running :  0.029296296296296296
reward/intrinsic_std_running :  0.04077327455620466
reward/extrinsic_std_running :  0.5955802222181271
reward/intrinsic_batch_std :  4.054194123383863e-05
reward/intrinsic_batch_max :  0.0005964084411971271
reward/intrinsic_batch_min :  2.648440840857802e-06
reward/total_batch :  0.014678164480513062
time/iteration_time :  111.01164150238037
time/fps :  2432.177349563924
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0001, Value Loss: 2.4835, Entropy: 2.3991
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.015, sum=99.4
Extrinsic raw: Œº=0.029296296296296296

=== Iteration 174/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 20.07s
update_step :  174
reward/intrinsic_batch_mean :  5.9346698866644416e-05
reward/extrinsic_batch_mean :  0.030644444444444443
loss/policy :  -0.00020755622024422115
loss/rnd :  2.4107349507616935e-06
loss/value :  2.6365052190693943
loss/value_i :  9.431143070921252e-06
loss/value_e :  2.636495797923117
loss/entropy :  2.399431925831419
reward/intrinsic_running :  0.003369696484328864
reward/extrinsic_running :  0.030644444444444443
reward/intrinsic_std_running :  0.04065664673537905
reward/extrinsic_std_running :  0.6306652803210822
reward/intrinsic_batch_std :  4.052526369642335e-05
reward/intrinsic_batch_max :  0.0005370739963836968
reward/intrinsic_batch_min :  2.7407515972299734e-06
reward/total_batch :  0.015351895571655543
time/iteration_time :  112.97363471984863
time/fps :  2389.9381538847047
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: -0.0002, Value Loss: 2.6365, Entropy: 2.3994
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=98.5
Extrinsic raw: Œº=0.030644444444444443

=== Iteration 175/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 19.00s
update_step :  175
reward/intrinsic_batch_mean :  6.040507649903938e-05
reward/extrinsic_batch_mean :  0.031244444444444443
loss/policy :  -1.7857798824975774e-05
loss/rnd :  2.4450015141128185e-06
loss/value :  2.9324089469331684
loss/value_i :  9.559932963880287e-06
loss/value_e :  2.9323994029651987
loss/entropy :  2.3945991378841978
reward/intrinsic_running :  0.0033517082889069553
reward/extrinsic_running :  0.031244444444444443
reward/intrinsic_std_running :  0.04054101323810245
reward/extrinsic_std_running :  0.6582198829578058
reward/intrinsic_batch_std :  3.9218995183777674e-05
reward/intrinsic_batch_max :  0.0005354442982934415
reward/intrinsic_batch_min :  2.9680550142074935e-06
reward/total_batch :  0.015652424760471743
time/iteration_time :  111.47611212730408
time/fps :  2422.0435647384616
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: -0.0000, Value Loss: 2.9324, Entropy: 2.3946
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=100.6
Extrinsic raw: Œº=0.031244444444444443

=== Iteration 176/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.57s
EPOCH 1 took 19.33s
update_step :  176
reward/intrinsic_batch_mean :  6.033839194269267e-05
reward/extrinsic_batch_mean :  0.03253333333333333
loss/policy :  -2.6182111469097435e-05
loss/rnd :  2.4351353328132643e-06
loss/value :  3.2097464510888765
loss/value_i :  1.0122491816714914e-05
loss/value_e :  3.2097363219116675
loss/entropy :  2.3925890344561953
reward/intrinsic_running :  0.0033339240261959983
reward/extrinsic_running :  0.03253333333333333
reward/intrinsic_std_running :  0.04042636078920151
reward/extrinsic_std_running :  0.6900408662079638
reward/intrinsic_batch_std :  3.863220597906147e-05
reward/intrinsic_batch_max :  0.0005273155402392149
reward/intrinsic_batch_min :  2.9319267014216166e-06
reward/total_batch :  0.016296835862638012
time/iteration_time :  111.07307982444763
time/fps :  2430.8320290275406
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0000, Value Loss: 3.2097, Entropy: 2.3926
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=100.7
Extrinsic raw: Œº=0.03253333333333333

=== Iteration 177/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.54s
EPOCH 1 took 18.74s
update_step :  177
reward/intrinsic_batch_mean :  5.9666363433657187e-05
reward/extrinsic_batch_mean :  0.030933333333333334
loss/policy :  3.4372615973001246e-05
loss/rnd :  2.399362418862328e-06
loss/value :  3.0569603009657427
loss/value_i :  9.575686707455933e-06
loss/value_e :  3.056950735323357
loss/entropy :  2.393454190456506
reward/intrinsic_running :  0.0033163242515429547
reward/extrinsic_running :  0.030933333333333334
reward/intrinsic_std_running :  0.04031267679826617
reward/extrinsic_std_running :  0.6781938016471344
reward/intrinsic_batch_std :  3.843860484121631e-05
reward/intrinsic_batch_max :  0.0005818333011120558
reward/intrinsic_batch_min :  2.6700367925514e-06
reward/total_batch :  0.015496499848383496
time/iteration_time :  110.20763444900513
time/fps :  2449.921018175319
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2450
Policy Loss: 0.0000, Value Loss: 3.0570, Entropy: 2.3935
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.014, sum=99.9
Extrinsic raw: Œº=0.030933333333333334

=== Iteration 178/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.70s
EPOCH 1 took 19.11s
update_step :  178
reward/intrinsic_batch_mean :  6.043887419777834e-05
reward/extrinsic_batch_mean :  0.03400740740740741
loss/policy :  -1.2911733585607374e-05
loss/rnd :  2.4300809607005003e-06
loss/value :  3.1783121354652173
loss/value_i :  9.40111981022214e-06
loss/value_e :  3.1783027359933564
loss/entropy :  2.3870138146660547
reward/intrinsic_running :  0.0032989351744430887
reward/extrinsic_running :  0.03400740740740741
reward/intrinsic_std_running :  0.04019994551707677
reward/extrinsic_std_running :  0.7006260269036256
reward/intrinsic_batch_std :  3.786013151022253e-05
reward/intrinsic_batch_max :  0.0005089190090075135
reward/intrinsic_batch_min :  3.16895307150844e-06
reward/total_batch :  0.017033923140802595
time/iteration_time :  111.90701460838318
time/fps :  2412.717388135683
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0000, Value Loss: 3.1783, Entropy: 2.3870
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=101.5
Extrinsic raw: Œº=0.03400740740740741

=== Iteration 179/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.35s
EPOCH 1 took 18.38s
update_step :  179
reward/intrinsic_batch_mean :  5.8260209332055875e-05
reward/extrinsic_batch_mean :  0.03162962962962963
loss/policy :  -0.00031977906562105727
loss/rnd :  2.364838034433584e-06
loss/value :  2.884603084939899
loss/value_i :  9.27435213739183e-06
loss/value_e :  2.884593801064925
loss/entropy :  2.384897130908388
reward/intrinsic_running :  0.0032816893623804294
reward/extrinsic_running :  0.03162962962962963
reward/intrinsic_std_running :  0.040088158539801064
reward/extrinsic_std_running :  0.6388064187244573
reward/intrinsic_batch_std :  3.652879375628833e-05
reward/intrinsic_batch_max :  0.00047882378567010164
reward/intrinsic_batch_min :  5.205030447541503e-06
reward/total_batch :  0.015843944919480844
time/iteration_time :  109.57891845703125
time/fps :  2463.977595342612
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.6s | FPS: 2464
Policy Loss: -0.0003, Value Loss: 2.8846, Entropy: 2.3849
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.012, sum=98.1
Extrinsic raw: Œº=0.03162962962962963

=== Iteration 180/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 18.47s
update_step :  180
reward/intrinsic_batch_mean :  6.104879153187573e-05
reward/extrinsic_batch_mean :  0.029725925925925926
loss/policy :  -0.00040217503688340497
loss/rnd :  2.4303567580787013e-06
loss/value :  2.6093595027923584
loss/value_i :  1.0916980224437518e-05
loss/value_e :  2.6093485897237603
loss/entropy :  2.39367980668039
reward/intrinsic_running :  0.0032646939288980916
reward/extrinsic_running :  0.029725925925925926
reward/intrinsic_std_running :  0.039977294551531296
reward/extrinsic_std_running :  0.6236345668991977
reward/intrinsic_batch_std :  4.1562414806901894e-05
reward/intrinsic_batch_max :  0.0006949037779122591
reward/intrinsic_batch_min :  2.903290805988945e-06
reward/total_batch :  0.014893487358728901
time/iteration_time :  111.98444890975952
time/fps :  2411.0490575131034
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0004, Value Loss: 2.6094, Entropy: 2.3937
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=103.1
Extrinsic raw: Œº=0.029725925925925926

=== Iteration 181/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.51s
EPOCH 1 took 19.47s
update_step :  181
reward/intrinsic_batch_mean :  6.15330374949466e-05
reward/extrinsic_batch_mean :  0.03258518518518518
loss/policy :  8.82210623592872e-05
loss/rnd :  2.502560505490692e-06
loss/value :  3.2639778418974443
loss/value_i :  1.0105189217442371e-05
loss/value_e :  3.2639677452318594
loss/entropy :  2.39445474653533
reward/intrinsic_running :  0.0032478912860214116
reward/extrinsic_running :  0.03258518518518518
reward/intrinsic_std_running :  0.03986734480224348
reward/extrinsic_std_running :  0.7317010003099593
reward/intrinsic_batch_std :  3.8749471313254346e-05
reward/intrinsic_batch_max :  0.0006226683035492897
reward/intrinsic_batch_min :  3.336554073030129e-06
reward/total_batch :  0.016323359111340065
time/iteration_time :  112.38909578323364
time/fps :  2402.3682913220746
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: 0.0001, Value Loss: 3.2640, Entropy: 2.3945
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=104.2
Extrinsic raw: Œº=0.03258518518518518

=== Iteration 182/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.72s
EPOCH 1 took 18.82s
update_step :  182
reward/intrinsic_batch_mean :  5.977318014872624e-05
reward/extrinsic_batch_mean :  0.029081481481481482
loss/policy :  -7.368471812118183e-05
loss/rnd :  2.375327519323698e-06
loss/value :  2.6396241188049316
loss/value_i :  8.765402636720065e-06
loss/value_e :  2.6396153515035454
loss/entropy :  2.4008475397572373
reward/intrinsic_running :  0.0032312295312871327
reward/extrinsic_running :  0.029081481481481482
reward/intrinsic_std_running :  0.03975830054875326
reward/extrinsic_std_running :  0.5944983948749704
reward/intrinsic_batch_std :  3.8161494450250616e-05
reward/intrinsic_batch_max :  0.0005564467865042388
reward/intrinsic_batch_min :  3.1577685604133876e-06
reward/total_batch :  0.014570627330815104
time/iteration_time :  111.20960259437561
time/fps :  2427.847898933641
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: -0.0001, Value Loss: 2.6396, Entropy: 2.4008
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=101.5
Extrinsic raw: Œº=0.029081481481481482

=== Iteration 183/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.18s
EPOCH 1 took 20.10s
update_step :  183
reward/intrinsic_batch_mean :  5.866448208014979e-05
reward/extrinsic_batch_mean :  0.027037037037037037
loss/policy :  -0.00021575324574245536
loss/rnd :  2.3728328821534612e-06
loss/value :  2.691655494950034
loss/value_i :  1.0027095468654862e-05
loss/value_e :  2.6916454578890945
loss/entropy :  2.4027909112699106
reward/intrinsic_running :  0.0032147293865409893
reward/extrinsic_running :  0.027037037037037037
reward/intrinsic_std_running :  0.03965014768635804
reward/extrinsic_std_running :  0.6020109191504803
reward/intrinsic_batch_std :  3.702435622227444e-05
reward/intrinsic_batch_max :  0.0005276888841763139
reward/intrinsic_batch_min :  2.9903701488365186e-06
reward/total_batch :  0.013547850759558593
time/iteration_time :  111.8331139087677
time/fps :  2414.3117415139063
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: -0.0002, Value Loss: 2.6917, Entropy: 2.4028
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=99.9
Extrinsic raw: Œº=0.027037037037037037

=== Iteration 184/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.34s
EPOCH 1 took 18.98s
update_step :  184
reward/intrinsic_batch_mean :  6.842756111974369e-05
reward/extrinsic_batch_mean :  0.030637037037037036
loss/policy :  -0.00029465514120547044
loss/rnd :  2.4082512860938246e-06
loss/value :  2.905537283781803
loss/value_i :  1.2398452960923985e-05
loss/value_e :  2.9055248950466965
loss/entropy :  2.394322976921544
reward/intrinsic_running :  0.0031985966754753763
reward/extrinsic_running :  0.030637037037037036
reward/intrinsic_std_running :  0.039542858566528956
reward/extrinsic_std_running :  0.6760193138530378
reward/intrinsic_batch_std :  3.954689414415324e-05
reward/intrinsic_batch_max :  0.0006274959887377918
reward/intrinsic_batch_min :  1.1693842679960653e-05
reward/total_batch :  0.01535273229907839
time/iteration_time :  110.46164512634277
time/fps :  2444.2873333199227
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2444
Policy Loss: -0.0003, Value Loss: 2.9055, Entropy: 2.3943
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=116.8
Extrinsic raw: Œº=0.030637037037037036

=== Iteration 185/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.75s
EPOCH 1 took 19.37s
update_step :  185
reward/intrinsic_batch_mean :  5.854316263686862e-05
reward/extrinsic_batch_mean :  0.03285925925925926
loss/policy :  0.00032905570873426217
loss/rnd :  2.35367077617742e-06
loss/value :  3.0126015887115942
loss/value_i :  1.149296210287227e-05
loss/value_e :  3.012590094046159
loss/entropy :  2.3910068237420283
reward/intrinsic_running :  0.003182448576572609
reward/extrinsic_running :  0.03285925925925926
reward/intrinsic_std_running :  0.039436449804251664
reward/extrinsic_std_running :  0.6704130088343052
reward/intrinsic_batch_std :  3.7678045497192284e-05
reward/intrinsic_batch_max :  0.000510275480337441
reward/intrinsic_batch_min :  3.314828290967853e-06
reward/total_batch :  0.016458901210948066
time/iteration_time :  111.43919634819031
time/fps :  2422.845900255674
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: 0.0003, Value Loss: 3.0126, Entropy: 2.3910
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=100.2
Extrinsic raw: Œº=0.03285925925925926

=== Iteration 186/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 18.89s
update_step :  186
reward/intrinsic_batch_mean :  5.98968761996932e-05
reward/extrinsic_batch_mean :  0.029466666666666665
loss/policy :  -8.628125369520576e-05
loss/rnd :  2.274636851022175e-06
loss/value :  2.6534920352877993
loss/value_i :  1.7681419649306918e-05
loss/value_e :  2.653474374250932
loss/entropy :  2.3928180969122685
reward/intrinsic_running :  0.0031664881295325356
reward/extrinsic_running :  0.029466666666666665
reward/intrinsic_std_running :  0.039330894391116165
reward/extrinsic_std_running :  0.5969290645865288
reward/intrinsic_batch_std :  3.679662613873251e-05
reward/intrinsic_batch_max :  0.0006087496876716614
reward/intrinsic_batch_min :  5.131632860866375e-06
reward/total_batch :  0.014763281771433179
time/iteration_time :  110.98095750808716
time/fps :  2432.8497975008477
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: -0.0001, Value Loss: 2.6535, Entropy: 2.3928
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=102.8
Extrinsic raw: Œº=0.029466666666666665

=== Iteration 187/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 18.97s
update_step :  187
reward/intrinsic_batch_mean :  5.869972906026238e-05
reward/extrinsic_batch_mean :  0.02902962962962963
loss/policy :  -0.0003488837524359538
loss/rnd :  2.3086714587737913e-06
loss/value :  2.615597269751809
loss/value_i :  1.3053766424215581e-05
loss/value_e :  2.615584207303596
loss/entropy :  2.3878009716669717
reward/intrinsic_running :  0.0031506768748195803
reward/extrinsic_running :  0.02902962962962963
reward/intrinsic_std_running :  0.039226183634092034
reward/extrinsic_std_running :  0.5932130519872358
reward/intrinsic_batch_std :  3.617170546528194e-05
reward/intrinsic_batch_max :  0.0005001624813303351
reward/intrinsic_batch_min :  3.3077944863180164e-06
reward/total_batch :  0.014544164679344947
time/iteration_time :  112.54132127761841
time/fps :  2399.1188030746544
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: -0.0003, Value Loss: 2.6156, Entropy: 2.3878
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.013, sum=101.0
Extrinsic raw: Œº=0.02902962962962963

=== Iteration 188/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.46s
EPOCH 1 took 18.94s
update_step :  188
reward/intrinsic_batch_mean :  5.951417263873332e-05
reward/extrinsic_batch_mean :  0.032096296296296296
loss/policy :  6.177632674349077e-05
loss/rnd :  2.3219110868343376e-06
loss/value :  3.0114581946170693
loss/value_i :  8.517997423151622e-06
loss/value_e :  3.0114496765714702
loss/entropy :  2.378745357195536
reward/intrinsic_running :  0.003135043179201399
reward/extrinsic_running :  0.032096296296296296
reward/intrinsic_std_running :  0.03912230404723979
reward/extrinsic_std_running :  0.664911170609351
reward/intrinsic_batch_std :  3.792676343098213e-05
reward/intrinsic_batch_max :  0.0007918851333670318
reward/intrinsic_batch_min :  2.821312818923616e-06
reward/total_batch :  0.016077905234467515
time/iteration_time :  111.39098072052002
time/fps :  2423.8946300098573
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0001, Value Loss: 3.0115, Entropy: 2.3787
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=102.7
Extrinsic raw: Œº=0.032096296296296296

=== Iteration 189/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.29s
EPOCH 1 took 18.23s
update_step :  189
reward/intrinsic_batch_mean :  6.118444334506758e-05
reward/extrinsic_batch_mean :  0.033466666666666665
loss/policy :  -0.0002644333792638711
loss/rnd :  2.382955303250073e-06
loss/value :  3.3862732901717676
loss/value_i :  9.566353431485671e-06
loss/value_e :  3.3862637281417847
loss/entropy :  2.383910829370672
reward/intrinsic_running :  0.003119599784089881
reward/extrinsic_running :  0.033466666666666665
reward/intrinsic_std_running :  0.03901924353999607
reward/extrinsic_std_running :  0.7173500493715278
reward/intrinsic_batch_std :  3.903844457640011e-05
reward/intrinsic_batch_max :  0.0005949988262727857
reward/intrinsic_batch_min :  2.457264827171457e-06
reward/total_batch :  0.016763925555005867
time/iteration_time :  112.03953528404236
time/fps :  2409.8636192616887
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0003, Value Loss: 3.3863, Entropy: 2.3839
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=105.8
Extrinsic raw: Œº=0.033466666666666665

=== Iteration 190/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.36s
EPOCH 1 took 19.66s
update_step :  190
reward/intrinsic_batch_mean :  6.24629430556659e-05
reward/extrinsic_batch_mean :  0.03285925925925926
loss/policy :  5.828363502973154e-05
loss/rnd :  2.4245476190503035e-06
loss/value :  3.5777645111083984
loss/value_i :  9.460381230989393e-06
loss/value_e :  3.5777550538380942
loss/entropy :  2.384053699897997
reward/intrinsic_running :  0.0031043390010251507
reward/extrinsic_running :  0.03285925925925926
reward/intrinsic_std_running :  0.0389169917240538
reward/extrinsic_std_running :  0.7132410964558377
reward/intrinsic_batch_std :  3.9401019752670295e-05
reward/intrinsic_batch_max :  0.0006341779371723533
reward/intrinsic_batch_min :  3.702989488374442e-06
reward/total_batch :  0.016460861101157465
time/iteration_time :  111.95594143867493
time/fps :  2411.6629857281437
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2412
Policy Loss: 0.0001, Value Loss: 3.5778, Entropy: 2.3841
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=108.3
Extrinsic raw: Œº=0.03285925925925926

=== Iteration 191/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.79s
EPOCH 1 took 19.36s
update_step :  191
reward/intrinsic_batch_mean :  6.144387456637964e-05
reward/extrinsic_batch_mean :  0.030192592592592594
loss/policy :  0.000426107136952465
loss/rnd :  2.3925079190259124e-06
loss/value :  2.999526302019755
loss/value_i :  9.97429027517104e-06
loss/value_e :  2.9995163426254736
loss/entropy :  2.389829144333348
reward/intrinsic_running :  0.003089224075734035
reward/extrinsic_running :  0.030192592592592594
reward/intrinsic_std_running :  0.03881554062050444
reward/extrinsic_std_running :  0.603071981408476
reward/intrinsic_batch_std :  3.979765864324377e-05
reward/intrinsic_batch_max :  0.0006698028300888836
reward/intrinsic_batch_min :  2.941853836091468e-06
reward/total_batch :  0.015127018233579486
time/iteration_time :  111.68161058425903
time/fps :  2417.5869114664715
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: 0.0004, Value Loss: 2.9995, Entropy: 2.3898
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=106.9
Extrinsic raw: Œº=0.030192592592592594

=== Iteration 192/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.52s
EPOCH 1 took 20.01s
update_step :  192
reward/intrinsic_batch_mean :  6.0839487660376576e-05
reward/extrinsic_batch_mean :  0.02808888888888889
loss/policy :  5.331558702781683e-05
loss/rnd :  2.476092879877604e-06
loss/value :  2.763786893902403
loss/value_i :  8.996380901490655e-06
loss/value_e :  2.763777884570035
loss/entropy :  2.3922599192821616
reward/intrinsic_running :  0.0030742542175420926
reward/extrinsic_running :  0.02808888888888889
reward/intrinsic_std_running :  0.03871487969844584
reward/extrinsic_std_running :  0.5597452259954446
reward/intrinsic_batch_std :  3.977030870659687e-05
reward/intrinsic_batch_max :  0.000688100466504693
reward/intrinsic_batch_min :  3.400788045837544e-06
reward/total_batch :  0.014074864188274633
time/iteration_time :  112.28960371017456
time/fps :  2404.49686416994
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0001, Value Loss: 2.7638, Entropy: 2.3923
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=106.1
Extrinsic raw: Œº=0.02808888888888889

=== Iteration 193/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 18.22s
update_step :  193
reward/intrinsic_batch_mean :  6.484923256030015e-05
reward/extrinsic_batch_mean :  0.027674074074074073
loss/policy :  -0.0002166479799515483
loss/rnd :  2.347371481515769e-06
loss/value :  2.861852071501992
loss/value_i :  9.16938652704685e-06
loss/value_e :  2.8618429032239048
loss/entropy :  2.3883971228744043
reward/intrinsic_running :  0.0030595079379290894
reward/extrinsic_running :  0.027674074074074073
reward/intrinsic_std_running :  0.0386149927920035
reward/extrinsic_std_running :  0.5819418938746075
reward/intrinsic_batch_std :  3.837038259210197e-05
reward/intrinsic_batch_max :  0.0006913469987921417
reward/intrinsic_batch_min :  6.6155625972896814e-06
reward/total_batch :  0.013869461653317186
time/iteration_time :  111.2381854057312
time/fps :  2427.2240599322927
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2427
Policy Loss: -0.0002, Value Loss: 2.8619, Entropy: 2.3884
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=113.4
Extrinsic raw: Œº=0.027674074074074073

=== Iteration 194/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.97s
EPOCH 1 took 19.44s
update_step :  194
reward/intrinsic_batch_mean :  6.007729376462723e-05
reward/extrinsic_batch_mean :  0.027933333333333334
loss/policy :  -0.0002021950645994917
loss/rnd :  2.312763671618472e-06
loss/value :  2.6086867072365503
loss/value_i :  9.551992799529355e-06
loss/value_e :  2.6086771632685806
loss/entropy :  2.386222936890342
reward/intrinsic_running :  0.003044823755664106
reward/extrinsic_running :  0.027933333333333334
reward/intrinsic_std_running :  0.03851588160035674
reward/extrinsic_std_running :  0.5585640544852156
reward/intrinsic_batch_std :  3.74702742910473e-05
reward/intrinsic_batch_max :  0.0005025764694437385
reward/intrinsic_batch_min :  2.9950958833069308e-06
reward/total_batch :  0.01399670531354898
time/iteration_time :  113.69309210777283
time/fps :  2374.814467567295
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: -0.0002, Value Loss: 2.6087, Entropy: 2.3862
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=105.3
Extrinsic raw: Œº=0.027933333333333334

=== Iteration 195/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 19.01s
update_step :  195
reward/intrinsic_batch_mean :  6.029568928880609e-05
reward/extrinsic_batch_mean :  0.028266666666666666
loss/policy :  -2.1875024189780973e-05
loss/rnd :  2.32283263923102e-06
loss/value :  2.7372785770531856
loss/value_i :  8.065281228868336e-06
loss/value_e :  2.7372705105579263
loss/entropy :  2.3877513986645322
reward/intrinsic_running :  0.003030293140170834
reward/extrinsic_running :  0.028266666666666666
reward/intrinsic_std_running :  0.03841752945719854
reward/extrinsic_std_running :  0.5869830863863998
reward/intrinsic_batch_std :  3.880812331725506e-05
reward/intrinsic_batch_max :  0.0004963931860402226
reward/intrinsic_batch_min :  2.4294727154483553e-06
reward/total_batch :  0.014163481177977735
time/iteration_time :  112.29847764968872
time/fps :  2404.306858390866
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: -0.0000, Value Loss: 2.7373, Entropy: 2.3878
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=105.9
Extrinsic raw: Œº=0.028266666666666666

=== Iteration 196/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.77s
EPOCH 1 took 18.76s
update_step :  196
reward/intrinsic_batch_mean :  6.190864870839976e-05
reward/extrinsic_batch_mean :  0.028133333333333333
loss/policy :  -0.00011248527990766999
loss/rnd :  2.36584826256369e-06
loss/value :  2.7354548447059863
loss/value_i :  8.184916134379103e-06
loss/value_e :  2.73544666261384
loss/entropy :  2.38432333686135
reward/intrinsic_running :  0.0030159379588771762
reward/extrinsic_running :  0.028133333333333333
reward/intrinsic_std_running :  0.03831992488602564
reward/extrinsic_std_running :  0.585719877428464
reward/intrinsic_batch_std :  3.818597947906366e-05
reward/intrinsic_batch_max :  0.0005186761845834553
reward/intrinsic_batch_min :  2.9001068924117135e-06
reward/total_batch :  0.014097620991020866
time/iteration_time :  112.00340557098389
time/fps :  2410.6409856339887
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0001, Value Loss: 2.7355, Entropy: 2.3843
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=109.1
Extrinsic raw: Œº=0.028133333333333333

=== Iteration 197/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.14s
EPOCH 1 took 19.62s
update_step :  197
reward/intrinsic_batch_mean :  6.0298069971247096e-05
reward/extrinsic_batch_mean :  0.02914074074074074
loss/policy :  -0.00010113091566106023
loss/rnd :  2.3041181665658685e-06
loss/value :  2.9376037987795742
loss/value_i :  7.429061290829188e-06
loss/value_e :  2.937596371679595
loss/entropy :  2.382312615712484
reward/intrinsic_running :  0.0030017035997611636
reward/extrinsic_running :  0.02914074074074074
reward/intrinsic_std_running :  0.03822306228814243
reward/extrinsic_std_running :  0.6423819120529348
reward/intrinsic_batch_std :  3.89235539500567e-05
reward/intrinsic_batch_max :  0.0005058561800979078
reward/intrinsic_batch_min :  2.2896110749570653e-06
reward/total_batch :  0.014600519405355995
time/iteration_time :  113.23283433914185
time/fps :  2384.4673815311144
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: -0.0001, Value Loss: 2.9376, Entropy: 2.3823
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=106.5
Extrinsic raw: Œº=0.02914074074074074

=== Iteration 198/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 18.77s
update_step :  198
reward/intrinsic_batch_mean :  6.139481432132083e-05
reward/extrinsic_batch_mean :  0.031066666666666666
loss/policy :  -9.771102023395625e-05
loss/rnd :  2.3730628534008935e-06
loss/value :  3.228783213731014
loss/value_i :  8.392620691555555e-06
loss/value_e :  3.228774829344316
loss/entropy :  2.3805895935405386
reward/intrinsic_running :  0.00298762224326742
reward/extrinsic_running :  0.031066666666666666
reward/intrinsic_std_running :  0.03812692982842588
reward/extrinsic_std_running :  0.6792845168372491
reward/intrinsic_batch_std :  3.80721667543133e-05
reward/intrinsic_batch_max :  0.000544629234354943
reward/intrinsic_batch_min :  2.6967818484990858e-06
reward/total_batch :  0.015564030740493994
time/iteration_time :  112.1302216053009
time/fps :  2407.9146204704894
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: -0.0001, Value Loss: 3.2288, Entropy: 2.3806
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=108.7
Extrinsic raw: Œº=0.031066666666666666

=== Iteration 199/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.44s
EPOCH 1 took 21.36s
update_step :  199
reward/intrinsic_batch_mean :  6.155931014874551e-05
reward/extrinsic_batch_mean :  0.033155555555555556
loss/policy :  -7.954937102498882e-05
loss/rnd :  2.3816382377900123e-06
loss/value :  3.4068241733493227
loss/value_i :  7.697608122147027e-06
loss/value_e :  3.4068164717067373
loss/entropy :  2.380005009246595
reward/intrinsic_running :  0.0029736813920365483
reward/extrinsic_running :  0.033155555555555556
reward/intrinsic_std_running :  0.038031519129927284
reward/extrinsic_std_running :  0.7153015201237575
reward/intrinsic_batch_std :  4.0347561406609296e-05
reward/intrinsic_batch_max :  0.0005933581269346178
reward/intrinsic_batch_min :  3.4444581160641974e-06
reward/total_batch :  0.01660855743285215
time/iteration_time :  114.20881128311157
time/fps :  2364.0907997080762
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.2s | FPS: 2364
Policy Loss: -0.0001, Value Loss: 3.4068, Entropy: 2.3800
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=109.3
Extrinsic raw: Œº=0.033155555555555556

=== Iteration 200/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.87s
EPOCH 1 took 18.90s
update_step :  200
reward/intrinsic_batch_mean :  6.087681957850253e-05
reward/extrinsic_batch_mean :  0.03255555555555555
loss/policy :  -0.00026845967504689753
loss/rnd :  2.3658522278227876e-06
loss/value :  3.3078878901221533
loss/value_i :  7.674195289423965e-06
loss/value_e :  3.3078801993167763
loss/entropy :  2.385965123321071
reward/intrinsic_running :  0.0029598633285603934
reward/extrinsic_running :  0.03255555555555555
reward/intrinsic_std_running :  0.03793682230111837
reward/extrinsic_std_running :  0.6900317670268324
reward/intrinsic_batch_std :  3.843191472765812e-05
reward/intrinsic_batch_max :  0.0006371932104229927
reward/intrinsic_batch_min :  4.309842097427463e-06
reward/total_batch :  0.016308216187567028
time/iteration_time :  115.27694916725159
time/fps :  2342.185510203482
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2342
Policy Loss: -0.0003, Value Loss: 3.3079, Entropy: 2.3860
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=108.3
Extrinsic raw: Œº=0.03255555555555555

=== Iteration 201/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 19.58s
update_step :  201
reward/intrinsic_batch_mean :  6.12760780994163e-05
reward/extrinsic_batch_mean :  0.03362222222222222
loss/policy :  -0.00011321480732559311
loss/rnd :  2.4280119394902475e-06
loss/value :  3.4581036639936045
loss/value_i :  7.429442348438897e-06
loss/value_e :  3.458096226056417
loss/entropy :  2.3834781827348652
reward/intrinsic_running :  0.002946186577295754
reward/extrinsic_running :  0.03362222222222222
reward/intrinsic_std_running :  0.03784282901010493
reward/extrinsic_std_running :  0.7584969969096697
reward/intrinsic_batch_std :  3.665798541647842e-05
reward/intrinsic_batch_max :  0.0004913838347420096
reward/intrinsic_batch_min :  3.767628868445172e-06
reward/total_batch :  0.016841749150160817
time/iteration_time :  113.58402514457703
time/fps :  2377.0948393167673
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2377
Policy Loss: -0.0001, Value Loss: 3.4581, Entropy: 2.3835
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=109.3
Extrinsic raw: Œº=0.03362222222222222

=== Iteration 202/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.51s
EPOCH 1 took 18.81s
update_step :  202
reward/intrinsic_batch_mean :  5.9814837283624066e-05
reward/extrinsic_batch_mean :  0.027674074074074073
loss/policy :  -0.00011258928288677426
loss/rnd :  2.2691860460161646e-06
loss/value :  2.680034370133371
loss/value_i :  7.157700992772306e-06
loss/value_e :  2.680027192289179
loss/entropy :  2.3926720185713335
reward/intrinsic_running :  0.002932624039864576
reward/extrinsic_running :  0.027674074074074073
reward/intrinsic_std_running :  0.03774953244652529
reward/extrinsic_std_running :  0.5819418938746075
reward/intrinsic_batch_std :  3.7403515567411396e-05
reward/intrinsic_batch_max :  0.00046321554691530764
reward/intrinsic_batch_min :  5.0178769015474245e-06
reward/total_batch :  0.013866944455678848
time/iteration_time :  110.75657963752747
time/fps :  2437.7784225878745
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2438
Policy Loss: -0.0001, Value Loss: 2.6800, Entropy: 2.3927
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=107.0
Extrinsic raw: Œº=0.027674074074074073

=== Iteration 203/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.12s
EPOCH 1 took 18.67s
update_step :  203
reward/intrinsic_batch_mean :  6.036645898038168e-05
reward/extrinsic_batch_mean :  0.029014814814814816
loss/policy :  -0.0005251148723993648
loss/rnd :  2.2925783909930475e-06
loss/value :  2.5912362174554304
loss/value_i :  6.9496258233949915e-06
loss/value_e :  2.591229259967804
loss/entropy :  2.388846552733219
reward/intrinsic_running :  0.002919195648133214
reward/extrinsic_running :  0.029014814814814816
reward/intrinsic_std_running :  0.03765692247400073
reward/extrinsic_std_running :  0.5932200202059216
reward/intrinsic_batch_std :  3.947182142277512e-05
reward/intrinsic_batch_max :  0.0007202982087619603
reward/intrinsic_batch_min :  3.6406906929187244e-06
reward/total_batch :  0.014537590636897598
time/iteration_time :  112.68599247932434
time/fps :  2396.038709509877
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: -0.0005, Value Loss: 2.5912, Entropy: 2.3888
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=108.2
Extrinsic raw: Œº=0.029014814814814816

=== Iteration 204/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.65s
EPOCH 1 took 18.50s
update_step :  204
reward/intrinsic_batch_mean :  7.959694141191667e-05
reward/extrinsic_batch_mean :  0.03114074074074074
loss/policy :  -5.01037257808176e-06
loss/rnd :  2.341772714812991e-06
loss/value :  3.17984050692934
loss/value_i :  7.794783793239427e-06
loss/value_e :  3.1798327005270757
loss/entropy :  2.3849346095865425
reward/intrinsic_running :  0.002906220862240064
reward/extrinsic_running :  0.03114074074074074
reward/intrinsic_std_running :  0.03756496798091995
reward/extrinsic_std_running :  0.7215573913978935
reward/intrinsic_batch_std :  3.9507541665034494e-05
reward/intrinsic_batch_max :  0.0006154366419650614
reward/intrinsic_batch_min :  1.8571661712485366e-05
reward/total_batch :  0.015610168841076329
time/iteration_time :  111.66066336631775
time/fps :  2418.0404437884167
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: -0.0000, Value Loss: 3.1798, Entropy: 2.3849
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=143.0
Extrinsic raw: Œº=0.03114074074074074

=== Iteration 205/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.01s
EPOCH 1 took 18.99s
update_step :  205
reward/intrinsic_batch_mean :  5.886963869969367e-05
reward/extrinsic_batch_mean :  0.03348148148148148
loss/policy :  -0.00022731741443170574
loss/rnd :  2.2017510204794677e-06
loss/value :  3.564991882353118
loss/value_i :  8.440451920526385e-06
loss/value_e :  3.564983451005184
loss/entropy :  2.38262216611342
reward/intrinsic_running :  0.002893020283432534
reward/extrinsic_running :  0.03348148148148148
reward/intrinsic_std_running :  0.03747370873008785
reward/extrinsic_std_running :  0.7575235662081862
reward/intrinsic_batch_std :  3.9261864745989126e-05
reward/intrinsic_batch_max :  0.0006894858670420945
reward/intrinsic_batch_min :  3.1042109185364097e-06
reward/total_batch :  0.016770175560090587
time/iteration_time :  113.23896503448486
time/fps :  2384.3382877773247
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: -0.0002, Value Loss: 3.5650, Entropy: 2.3826
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=106.0
Extrinsic raw: Œº=0.03348148148148148

=== Iteration 206/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.29s
EPOCH 1 took 19.90s
update_step :  206
reward/intrinsic_batch_mean :  5.686056904719239e-05
reward/extrinsic_batch_mean :  0.03242962962962963
loss/policy :  0.00021498781191467336
loss/rnd :  2.10543248268743e-06
loss/value :  3.584070082866784
loss/value_i :  9.082267951905095e-06
loss/value_e :  3.584061015735973
loss/entropy :  2.382613351850799
reward/intrinsic_running :  0.00287992112459961
reward/extrinsic_running :  0.03242962962962963
reward/intrinsic_std_running :  0.03738311321288641
reward/extrinsic_std_running :  0.730697399401733
reward/intrinsic_batch_std :  3.632844558334345e-05
reward/intrinsic_batch_max :  0.0006165945087559521
reward/intrinsic_batch_min :  4.156569957558531e-06
reward/total_batch :  0.01624324509933841
time/iteration_time :  111.54010009765625
time/fps :  2420.6540944790977
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0002, Value Loss: 3.5841, Entropy: 2.3826
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=102.7
Extrinsic raw: Œº=0.03242962962962963

=== Iteration 207/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 19.13s
update_step :  207
reward/intrinsic_batch_mean :  5.58478179341903e-05
reward/extrinsic_batch_mean :  0.03142222222222222
loss/policy :  -0.0001099172849067007
loss/rnd :  2.0807573333293092e-06
loss/value :  3.2785661365046646
loss/value_i :  7.79031366123077e-06
loss/value_e :  3.2785583553892192
loss/entropy :  2.3802276091142134
reward/intrinsic_running :  0.002866930357656878
reward/extrinsic_running :  0.03142222222222222
reward/intrinsic_std_running :  0.0372931728635399
reward/extrinsic_std_running :  0.7236006005634615
reward/intrinsic_batch_std :  3.559057273278161e-05
reward/intrinsic_batch_max :  0.000583143497351557
reward/intrinsic_batch_min :  2.4927601316449e-06
reward/total_batch :  0.015739035020078205
time/iteration_time :  112.89470410346985
time/fps :  2391.609085157268
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: -0.0001, Value Loss: 3.2786, Entropy: 2.3802
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.001, max=0.016, sum=101.1
Extrinsic raw: Œº=0.03142222222222222

=== Iteration 208/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.82s
update_step :  208
reward/intrinsic_batch_mean :  5.779656190072139e-05
reward/extrinsic_batch_mean :  0.02888148148148148
loss/policy :  0.0002002463496120816
loss/rnd :  2.1744503183898898e-06
loss/value :  2.985645792701028
loss/value_i :  7.169925772883069e-06
loss/value_e :  2.985638622081641
loss/entropy :  2.3798964926690767
reward/intrinsic_running :  0.0028540918764491698
reward/extrinsic_running :  0.02888148148148148
reward/intrinsic_std_running :  0.037203876622298605
reward/extrinsic_std_running :  0.6400688105584096
reward/intrinsic_batch_std :  3.683939590972275e-05
reward/intrinsic_batch_max :  0.0005536279641091824
reward/intrinsic_batch_min :  2.5969477519538486e-06
reward/total_batch :  0.014469639021691101
time/iteration_time :  113.83432006835938
time/fps :  2371.8681662776266
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.8s | FPS: 2372
Policy Loss: 0.0002, Value Loss: 2.9856, Entropy: 2.3799
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=104.9
Extrinsic raw: Œº=0.02888148148148148

=== Iteration 209/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.55s
EPOCH 1 took 18.91s
update_step :  209
reward/intrinsic_batch_mean :  5.716237997996224e-05
reward/extrinsic_batch_mean :  0.03348888888888889
loss/policy :  -0.00013014378738730693
loss/rnd :  2.1299861834973632e-06
loss/value :  3.563993710460085
loss/value_i :  7.5575440364032564e-06
loss/value_e :  3.5639861569260107
loss/entropy :  2.380589170889421
reward/intrinsic_running :  0.0028413677356444083
reward/extrinsic_running :  0.03348888888888889
reward/intrinsic_std_running :  0.03711521936534201
reward/extrinsic_std_running :  0.7575207941569966
reward/intrinsic_batch_std :  3.798554255163126e-05
reward/intrinsic_batch_max :  0.0007215698133222759
reward/intrinsic_batch_min :  2.6385798719275044e-06
reward/total_batch :  0.016773025634434426
time/iteration_time :  111.58903050422668
time/fps :  2419.592667666139
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: -0.0001, Value Loss: 3.5640, Entropy: 2.3806
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=104.0
Extrinsic raw: Œº=0.03348888888888889

=== Iteration 210/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 18.80s
update_step :  210
reward/intrinsic_batch_mean :  5.8394353487555806e-05
reward/extrinsic_batch_mean :  0.03521481481481482
loss/policy :  0.00010235376954149228
loss/rnd :  2.2071448718248354e-06
loss/value :  3.479509848536867
loss/value_i :  7.537308192695491e-06
loss/value_e :  3.479502309452404
loss/entropy :  2.374426740588564
reward/intrinsic_running :  0.002828775059801673
reward/extrinsic_running :  0.03521481481481482
reward/intrinsic_std_running :  0.037027192175697984
reward/extrinsic_std_running :  0.729563993438041
reward/intrinsic_batch_std :  3.7658007826405496e-05
reward/intrinsic_batch_max :  0.0007471348508261144
reward/intrinsic_batch_min :  3.0032688300707377e-06
reward/total_batch :  0.017636604584151186
time/iteration_time :  112.30599164962769
time/fps :  2404.1459946531277
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0001, Value Loss: 3.4795, Entropy: 2.3744
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=106.5
Extrinsic raw: Œº=0.03521481481481482

=== Iteration 211/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 18.24s
update_step :  211
reward/intrinsic_batch_mean :  5.914064846386922e-05
reward/extrinsic_batch_mean :  0.03701481481481481
loss/policy :  0.0002105714696826357
loss/rnd :  2.1695807872950383e-06
loss/value :  3.6505095452973335
loss/value_i :  7.251000459456753e-06
loss/value_e :  3.6505023060422954
loss/entropy :  2.375131267489809
reward/intrinsic_running :  0.0028163115414557706
reward/extrinsic_running :  0.03701481481481481
reward/intrinsic_std_running :  0.036939787618795544
reward/extrinsic_std_running :  0.7804867283393452
reward/intrinsic_batch_std :  3.6562207556757785e-05
reward/intrinsic_batch_max :  0.0005831316229887307
reward/intrinsic_batch_min :  4.26805763709126e-06
reward/total_batch :  0.018536977731639342
time/iteration_time :  111.77463746070862
time/fps :  2415.574822104981
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0002, Value Loss: 3.6505, Entropy: 2.3751
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=108.1
Extrinsic raw: Œº=0.03701481481481481

=== Iteration 212/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.97s
EPOCH 1 took 19.12s
update_step :  212
reward/intrinsic_batch_mean :  6.286460371951829e-05
reward/extrinsic_batch_mean :  0.03894074074074074
loss/policy :  -2.407368314875798e-06
loss/rnd :  2.1387866781603377e-06
loss/value :  3.983642169923493
loss/value_i :  7.5132916690839036e-06
loss/value_e :  3.9836346633506543
loss/entropy :  2.3764512286041723
reward/intrinsic_running :  0.0028040223495436655
reward/extrinsic_running :  0.03894074074074074
reward/intrinsic_std_running :  0.03685299511131954
reward/extrinsic_std_running :  0.8468538223851507
reward/intrinsic_batch_std :  3.6589464602486364e-05
reward/intrinsic_batch_max :  0.0005892813205718994
reward/intrinsic_batch_min :  9.360534022562206e-06
reward/total_batch :  0.01950180267223013
time/iteration_time :  112.75860571861267
time/fps :  2394.495730762943
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: -0.0000, Value Loss: 3.9836, Entropy: 2.3765
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=115.1
Extrinsic raw: Œº=0.03894074074074074

=== Iteration 213/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 18.72s
update_step :  213
reward/intrinsic_batch_mean :  5.58632846871458e-05
reward/extrinsic_batch_mean :  0.03742962962962963
loss/policy :  -0.00016594582363419855
loss/rnd :  2.0485543101048362e-06
loss/value :  3.715669292392153
loss/value_i :  8.014592209071976e-06
loss/value_e :  3.7156612764705312
loss/entropy :  2.3698987491203076
reward/intrinsic_running :  0.0027917375814604578
reward/extrinsic_running :  0.03742962962962963
reward/intrinsic_std_running :  0.03676681928118113
reward/extrinsic_std_running :  0.7833185250679815
reward/intrinsic_batch_std :  3.618098914060415e-05
reward/intrinsic_batch_max :  0.0006599196931347251
reward/intrinsic_batch_min :  2.380124897172209e-06
reward/total_batch :  0.01874274645715839
time/iteration_time :  111.67224431037903
time/fps :  2417.7896814679284
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: -0.0002, Value Loss: 3.7157, Entropy: 2.3699
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=102.6
Extrinsic raw: Œº=0.03742962962962963

=== Iteration 214/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.87s
EPOCH 1 took 19.21s
update_step :  214
reward/intrinsic_batch_mean :  5.78094913679841e-05
reward/extrinsic_batch_mean :  0.03456296296296296
loss/policy :  0.0002960094663483853
loss/rnd :  2.637731371936697e-06
loss/value :  3.536517417792118
loss/value_i :  9.310656444292611e-06
loss/value_e :  3.5365080905683115
loss/entropy :  2.3693965420578467
reward/intrinsic_running :  0.0027795945213504006
reward/extrinsic_running :  0.03456296296296296
reward/intrinsic_std_running :  0.03668124330762111
reward/extrinsic_std_running :  0.7048284751405823
reward/intrinsic_batch_std :  3.838899940047578e-05
reward/intrinsic_batch_max :  0.0007511166040785611
reward/intrinsic_batch_min :  2.4268115339509677e-06
reward/total_batch :  0.017310386227165474
time/iteration_time :  112.68734002113342
time/fps :  2396.010057113462
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0003, Value Loss: 3.5365, Entropy: 2.3694
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=106.4
Extrinsic raw: Œº=0.03456296296296296

=== Iteration 215/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 19.60s
update_step :  215
reward/intrinsic_batch_mean :  5.654200196162896e-05
reward/extrinsic_batch_mean :  0.03744444444444445
loss/policy :  -0.0002410907940374631
loss/rnd :  2.1336063479214897e-06
loss/value :  3.838682514248472
loss/value_i :  8.437315066409859e-06
loss/value_e :  3.8386740829005386
loss/entropy :  2.3643229296713164
reward/intrinsic_running :  0.002767543047911014
reward/extrinsic_running :  0.03744444444444445
reward/intrinsic_std_running :  0.03659626355500689
reward/extrinsic_std_running :  0.7832185179843364
reward/intrinsic_batch_std :  3.645654495207121e-05
reward/intrinsic_batch_max :  0.000639581645373255
reward/intrinsic_batch_min :  3.0943567708163755e-06
reward/total_batch :  0.01875049322320304
time/iteration_time :  113.02672863006592
time/fps :  2388.8154888009212
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: -0.0002, Value Loss: 3.8387, Entropy: 2.3643
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=104.3
Extrinsic raw: Œº=0.03744444444444445

=== Iteration 216/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 19.22s
update_step :  216
reward/intrinsic_batch_mean :  6.198337045820894e-05
reward/extrinsic_batch_mean :  0.03492592592592592
loss/policy :  -1.1887861215985719e-05
loss/rnd :  2.1506524696881324e-06
loss/value :  3.692128174232714
loss/value_i :  7.805063488018332e-06
loss/value_e :  3.6921203642180473
loss/entropy :  2.3713623213045523
reward/intrinsic_running :  0.0027556860148516197
reward/extrinsic_running :  0.03492592592592592
reward/intrinsic_std_running :  0.03651186588707532
reward/extrinsic_std_running :  0.7476274783372286
reward/intrinsic_batch_std :  3.6630390267890765e-05
reward/intrinsic_batch_max :  0.0005185150657780468
reward/intrinsic_batch_min :  5.9988997236359864e-06
reward/total_batch :  0.017493954648192065
time/iteration_time :  112.56466913223267
time/fps :  2398.6211844395325
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: -0.0000, Value Loss: 3.6921, Entropy: 2.3714
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=114.6
Extrinsic raw: Œº=0.03492592592592592

=== Iteration 217/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 20.02s
update_step :  217
reward/intrinsic_batch_mean :  5.548148601909041e-05
reward/extrinsic_batch_mean :  0.039348148148148146
loss/policy :  -0.00030879152208482
loss/rnd :  2.020601579550368e-06
loss/value :  3.911104679107666
loss/value_i :  7.7730768763021e-06
loss/value_e :  3.9110969160542344
loss/entropy :  2.357488397395972
reward/intrinsic_running :  0.0027438350999865846
reward/extrinsic_running :  0.039348148148148146
reward/intrinsic_std_running :  0.036428056594892934
reward/extrinsic_std_running :  0.8138385618283228
reward/intrinsic_batch_std :  3.4025588658873335e-05
reward/intrinsic_batch_max :  0.0004912528092972934
reward/intrinsic_batch_min :  2.860994754882995e-06
reward/total_batch :  0.019701814817083618
time/iteration_time :  112.42125129699707
time/fps :  2401.6811491157287
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0003, Value Loss: 3.9111, Entropy: 2.3575
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=102.8
Extrinsic raw: Œº=0.039348148148148146

=== Iteration 218/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.37s
EPOCH 1 took 18.72s
update_step :  218
reward/intrinsic_batch_mean :  5.690201436017459e-05
reward/extrinsic_batch_mean :  0.03757037037037037
loss/policy :  3.926209032987103e-06
loss/rnd :  2.063120363841749e-06
loss/value :  4.175230177966031
loss/value_i :  8.032656682410037e-06
loss/value_e :  4.175222158432007
loss/entropy :  2.3698418935139975
reward/intrinsic_running :  0.0027321142542133556
reward/extrinsic_running :  0.03757037037037037
reward/intrinsic_std_running :  0.03634482033459597
reward/extrinsic_std_running :  0.8211709935230096
reward/intrinsic_batch_std :  3.6422104198277696e-05
reward/intrinsic_batch_max :  0.0006845198222436011
reward/intrinsic_batch_min :  4.332800926931668e-06
reward/total_batch :  0.018813636192365275
time/iteration_time :  111.59086537361145
time/fps :  2419.5528827205285
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0000, Value Loss: 4.1752, Entropy: 2.3698
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=105.7
Extrinsic raw: Œº=0.03757037037037037

=== Iteration 219/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.87s
EPOCH 1 took 19.43s
update_step :  219
reward/intrinsic_batch_mean :  5.680796359231829e-05
reward/extrinsic_batch_mean :  0.03911851851851852
loss/policy :  4.401955657434001e-05
loss/rnd :  2.0641408926883633e-06
loss/value :  4.24041899767789
loss/value_i :  7.716893716144224e-06
loss/value_e :  4.240411274360888
loss/entropy :  2.3655163808302446
reward/intrinsic_running :  0.002720496786016389
reward/extrinsic_running :  0.03911851851851852
reward/intrinsic_std_running :  0.03626215228743371
reward/extrinsic_std_running :  0.865010875991158
reward/intrinsic_batch_std :  3.624749904812652e-05
reward/intrinsic_batch_max :  0.00045360211515799165
reward/intrinsic_batch_min :  2.9255054414534243e-06
reward/total_batch :  0.019587663241055417
time/iteration_time :  112.64299392700195
time/fps :  2396.9533353754155
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2397
Policy Loss: 0.0000, Value Loss: 4.2404, Entropy: 2.3655
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.013, sum=105.7
Extrinsic raw: Œº=0.03911851851851852

=== Iteration 220/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.41s
EPOCH 1 took 18.96s
update_step :  220
reward/intrinsic_batch_mean :  5.601400746744629e-05
reward/extrinsic_batch_mean :  0.03548148148148148
loss/policy :  -3.9079714704050936e-05
loss/rnd :  2.030568604520037e-06
loss/value :  3.8945706974376333
loss/value_i :  7.638321201077567e-06
loss/value_e :  3.894563053593491
loss/entropy :  2.360601468519731
reward/intrinsic_running :  0.002708969330330257
reward/extrinsic_running :  0.03548148148148148
reward/intrinsic_std_running :  0.0361800468381172
reward/extrinsic_std_running :  0.71105057226876
reward/intrinsic_batch_std :  3.524190423594785e-05
reward/intrinsic_batch_max :  0.0005386128323152661
reward/intrinsic_batch_min :  3.4441966363374377e-06
reward/total_batch :  0.017768747744474463
time/iteration_time :  112.58521246910095
time/fps :  2398.183509882362
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0000, Value Loss: 3.8946, Entropy: 2.3606
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=104.5
Extrinsic raw: Œº=0.03548148148148148

=== Iteration 221/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.01s
EPOCH 1 took 18.88s
update_step :  221
reward/intrinsic_batch_mean :  5.8336278916559186e-05
reward/extrinsic_batch_mean :  0.035111111111111114
loss/policy :  3.449682315642183e-05
loss/rnd :  2.0835088131813486e-06
loss/value :  3.9488676497430513
loss/value_i :  8.104204694477216e-06
loss/value_e :  3.948859539898959
loss/entropy :  2.3711414048165986
reward/intrinsic_running :  0.002697582310471154
reward/extrinsic_running :  0.035111111111111114
reward/intrinsic_std_running :  0.0360984941933758
reward/extrinsic_std_running :  0.7681318045334423
reward/intrinsic_batch_std :  4.1739463547028326e-05
reward/intrinsic_batch_max :  0.0008196646231226623
reward/intrinsic_batch_min :  4.08164714826853e-06
reward/total_batch :  0.017584723695013838
time/iteration_time :  113.17579936981201
time/fps :  2385.6690343997566
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0000, Value Loss: 3.9489, Entropy: 2.3711
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=109.1
Extrinsic raw: Œº=0.035111111111111114

=== Iteration 222/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 18.88s
update_step :  222
reward/intrinsic_batch_mean :  5.7193595908157244e-05
reward/extrinsic_batch_mean :  0.03489629629629629
loss/policy :  -0.0003237530649075228
loss/rnd :  2.058079406775836e-06
loss/value :  4.036227302117781
loss/value_i :  7.395351751642231e-06
loss/value_e :  4.036219889467413
loss/entropy :  2.3695885520992856
reward/intrinsic_running :  0.002686276601327433
reward/extrinsic_running :  0.03489629629629629
reward/intrinsic_std_running :  0.0360174919081637
reward/extrinsic_std_running :  0.7476387697185605
reward/intrinsic_batch_std :  3.519206459490196e-05
reward/intrinsic_batch_max :  0.000439289549831301
reward/intrinsic_batch_min :  3.3514054393890547e-06
reward/total_batch :  0.017476744946102227
time/iteration_time :  111.4372980594635
time/fps :  2422.8871724431674
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: -0.0003, Value Loss: 4.0362, Entropy: 2.3696
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.012, sum=107.2
Extrinsic raw: Œº=0.03489629629629629

=== Iteration 223/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 19.09s
update_step :  223
reward/intrinsic_batch_mean :  5.806738763667454e-05
reward/extrinsic_batch_mean :  0.037481481481481484
loss/policy :  0.00048077747994808084
loss/rnd :  2.0801508002698412e-06
loss/value :  4.299088962150343
loss/value_i :  7.822347049913139e-06
loss/value_e :  4.299081162972883
loss/entropy :  2.3681546485785283
reward/intrinsic_running :  0.0026750841209560463
reward/extrinsic_running :  0.037481481481481484
reward/intrinsic_std_running :  0.03593703166173681
reward/extrinsic_std_running :  0.8381211072379726
reward/intrinsic_batch_std :  3.755669679342208e-05
reward/intrinsic_batch_max :  0.0005480792024172843
reward/intrinsic_batch_min :  3.5619627851701807e-06
reward/total_batch :  0.01876977443455908
time/iteration_time :  112.11186861991882
time/fps :  2408.3088019463207
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: 0.0005, Value Loss: 4.2991, Entropy: 2.3682
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=109.1
Extrinsic raw: Œº=0.037481481481481484

=== Iteration 224/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.67s
EPOCH 1 took 19.90s
update_step :  224
reward/intrinsic_batch_mean :  5.6361380811389005e-05
reward/extrinsic_batch_mean :  0.033933333333333336
loss/policy :  0.00024352913191471475
loss/rnd :  2.036632188471479e-06
loss/value :  3.9603298288403135
loss/value_i :  8.462143389834003e-06
loss/value_e :  3.9603213758179634
loss/entropy :  2.3675006050052065
reward/intrinsic_running :  0.00266396789130895
reward/extrinsic_running :  0.033933333333333336
reward/intrinsic_std_running :  0.03585710984622122
reward/extrinsic_std_running :  0.7604289793219302
reward/intrinsic_batch_std :  3.603841703444879e-05
reward/intrinsic_batch_max :  0.0005430383607745171
reward/intrinsic_batch_min :  2.953658167825779e-06
reward/total_batch :  0.01699484735707236
time/iteration_time :  111.75008583068848
time/fps :  2416.1055268366817
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0002, Value Loss: 3.9603, Entropy: 2.3675
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=106.1
Extrinsic raw: Œº=0.033933333333333336

=== Iteration 225/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 18.67s
update_step :  225
reward/intrinsic_batch_mean :  5.9069078783728334e-05
reward/extrinsic_batch_mean :  0.038177777777777776
loss/policy :  0.0005488910762571984
loss/rnd :  2.0908389890819583e-06
loss/value :  4.442707639752013
loss/value_i :  7.710919651964849e-06
loss/value_e :  4.442699930884621
loss/entropy :  2.3633870500506777
reward/intrinsic_running :  0.0026529834949570452
reward/extrinsic_running :  0.038177777777777776
reward/intrinsic_std_running :  0.03577771661269642
reward/extrinsic_std_running :  0.9019576722159062
reward/intrinsic_batch_std :  3.755798273773764e-05
reward/intrinsic_batch_max :  0.0005591681692749262
reward/intrinsic_batch_min :  5.229824182606535e-06
reward/total_batch :  0.019118423428280754
time/iteration_time :  111.7202398777008
time/fps :  2416.750987068831
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0005, Value Loss: 4.4427, Entropy: 2.3634
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=111.4
Extrinsic raw: Œº=0.038177777777777776

=== Iteration 226/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.99s
EPOCH 1 took 19.11s
update_step :  226
reward/intrinsic_batch_mean :  5.736723364547019e-05
reward/extrinsic_batch_mean :  0.03481481481481481
loss/policy :  0.00018145911444938093
loss/rnd :  2.049952417054914e-06
loss/value :  4.015408198038737
loss/value_i :  7.600503474322702e-06
loss/value_e :  4.015400597543428
loss/entropy :  2.365277142235727
reward/intrinsic_running :  0.002642074883057421
reward/extrinsic_running :  0.03481481481481481
reward/intrinsic_std_running :  0.035698849854502675
reward/extrinsic_std_running :  0.7662142161078103
reward/intrinsic_batch_std :  3.629887034204222e-05
reward/intrinsic_batch_max :  0.000489654194097966
reward/intrinsic_batch_min :  2.393799150013365e-06
reward/total_batch :  0.017436091024230143
time/iteration_time :  112.54072880744934
time/fps :  2399.131433224982
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0002, Value Loss: 4.0154, Entropy: 2.3653
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=108.5
Extrinsic raw: Œº=0.03481481481481481

=== Iteration 227/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 18.84s
update_step :  227
reward/intrinsic_batch_mean :  5.63767899827528e-05
reward/extrinsic_batch_mean :  0.0354
loss/policy :  -0.00016230110574697116
loss/rnd :  2.025745795270433e-06
loss/value :  3.9479604851115835
loss/value_i :  6.880363495535373e-06
loss/value_e :  3.947953614321622
loss/entropy :  2.3679556051890054
reward/intrinsic_running :  0.002631247870760709
reward/extrinsic_running :  0.0354
reward/intrinsic_std_running :  0.03562050335828709
reward/extrinsic_std_running :  0.7699510489490731
reward/intrinsic_batch_std :  3.7001927830111136e-05
reward/intrinsic_batch_max :  0.0006958814337849617
reward/intrinsic_batch_min :  2.2379626898327842e-06
reward/total_batch :  0.017728188394991375
time/iteration_time :  112.04198122024536
time/fps :  2409.811010653679
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: -0.0002, Value Loss: 3.9480, Entropy: 2.3680
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=106.8
Extrinsic raw: Œº=0.0354

=== Iteration 228/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 19.58s
update_step :  228
reward/intrinsic_batch_mean :  5.802475746851862e-05
reward/extrinsic_batch_mean :  0.03871111111111111
loss/policy :  0.00021042073124342343
loss/rnd :  2.026689712968646e-06
loss/value :  4.236920555432637
loss/value_i :  8.384752301494839e-06
loss/value_e :  4.2369121493715225
loss/entropy :  2.3692553296233667
reward/intrinsic_running :  0.0026205334309807584
reward/extrinsic_running :  0.03871111111111111
reward/intrinsic_std_running :  0.03554266923904881
reward/extrinsic_std_running :  0.9125247667195358
reward/intrinsic_batch_std :  3.8936342573369535e-05
reward/intrinsic_batch_max :  0.0006397078977897763
reward/intrinsic_batch_min :  3.560215645848075e-06
reward/total_batch :  0.019384567934289814
time/iteration_time :  112.83265352249146
time/fps :  2392.9243137597546
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0002, Value Loss: 4.2369, Entropy: 2.3693
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=110.2
Extrinsic raw: Œº=0.03871111111111111

=== Iteration 229/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 18.45s
update_step :  229
reward/intrinsic_batch_mean :  5.662740059869302e-05
reward/extrinsic_batch_mean :  0.03957777777777778
loss/policy :  0.00010775439714603691
loss/rnd :  2.0119479028256717e-06
loss/value :  4.464314782258236
loss/value_i :  7.851263490010751e-06
loss/value_e :  4.464306943344347
loss/entropy :  2.3673147613351997
reward/intrinsic_running :  0.0026098872644058357
reward/extrinsic_running :  0.03957777777777778
reward/intrinsic_std_running :  0.035465344786880765
reward/extrinsic_std_running :  0.9010571401839857
reward/intrinsic_batch_std :  3.6171644851648794e-05
reward/intrinsic_batch_max :  0.0005640016752295196
reward/intrinsic_batch_min :  4.8241954573313706e-06
reward/total_batch :  0.019817202589188235
time/iteration_time :  111.21386241912842
time/fps :  2427.754905071626
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0001, Value Loss: 4.4643, Entropy: 2.3673
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=107.8
Extrinsic raw: Œº=0.03957777777777778

=== Iteration 230/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.17s
EPOCH 1 took 19.60s
update_step :  230
reward/intrinsic_batch_mean :  5.681284360267724e-05
reward/extrinsic_batch_mean :  0.04025185185185185
loss/policy :  0.0001241889646432052
loss/rnd :  2.1563202890871307e-06
loss/value :  4.347334551088737
loss/value_i :  9.063303409537625e-06
loss/value_e :  4.3473254875703295
loss/entropy :  2.3738680138732446
reward/intrinsic_running :  0.0025993342553169633
reward/extrinsic_running :  0.04025185185185185
reward/intrinsic_std_running :  0.035388522797235984
reward/extrinsic_std_running :  0.890294464133604
reward/intrinsic_batch_std :  3.761468065403187e-05
reward/intrinsic_batch_max :  0.0005653299740515649
reward/intrinsic_batch_min :  2.9801508389937226e-06
reward/total_batch :  0.020154332347727264
time/iteration_time :  113.68278861045837
time/fps :  2375.029705905376
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: 0.0001, Value Loss: 4.3473, Entropy: 2.3739
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=108.4
Extrinsic raw: Œº=0.04025185185185185

=== Iteration 231/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.38s
EPOCH 1 took 19.30s
update_step :  231
reward/intrinsic_batch_mean :  5.8124012832660005e-05
reward/extrinsic_batch_mean :  0.03983703703703704
loss/policy :  -0.0005007581573657014
loss/rnd :  2.0778846254126453e-06
loss/value :  3.9990494829235654
loss/value_i :  9.756727022801043e-06
loss/value_e :  3.999039725823836
loss/entropy :  2.3757165670394897
reward/intrinsic_running :  0.0025888889131964305
reward/extrinsic_running :  0.03983703703703704
reward/intrinsic_std_running :  0.03531219674496947
reward/extrinsic_std_running :  0.8344736927030373
reward/intrinsic_batch_std :  3.854976679276412e-05
reward/intrinsic_batch_max :  0.0005567024345509708
reward/intrinsic_batch_min :  3.991062385466648e-06
reward/total_batch :  0.01994758052493485
time/iteration_time :  111.24939513206482
time/fps :  2426.979487659069
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2427
Policy Loss: -0.0005, Value Loss: 3.9990, Entropy: 2.3757
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=111.1
Extrinsic raw: Œº=0.03983703703703704

=== Iteration 232/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.91s
EPOCH 1 took 18.62s
update_step :  232
reward/intrinsic_batch_mean :  5.825591386707216e-05
reward/extrinsic_batch_mean :  0.033718518518518516
loss/policy :  3.900681886906651e-05
loss/rnd :  2.084012852389027e-06
loss/value :  3.4632985013903994
loss/value_i :  6.5205258854830666e-06
loss/value_e :  3.463291981003501
loss/entropy :  2.377552036083106
reward/intrinsic_running :  0.0025785319889066335
reward/extrinsic_running :  0.033718518518518516
reward/intrinsic_std_running :  0.035236362561273264
reward/extrinsic_std_running :  0.6547293096511899
reward/intrinsic_batch_std :  3.9846768920287106e-05
reward/intrinsic_batch_max :  0.0006088333902880549
reward/intrinsic_batch_min :  3.3363746752002044e-06
reward/total_batch :  0.016888387216192794
time/iteration_time :  112.2632098197937
time/fps :  2405.062178726293
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0000, Value Loss: 3.4633, Entropy: 2.3776
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=111.6
Extrinsic raw: Œº=0.033718518518518516

=== Iteration 233/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 19.48s
update_step :  233
reward/intrinsic_batch_mean :  5.885002200811195e-05
reward/extrinsic_batch_mean :  0.032437037037037035
loss/policy :  -0.00032901474288805866
loss/rnd :  2.0158893186927536e-06
loss/value :  3.543779300920891
loss/value_i :  6.867335996778848e-06
loss/value_e :  3.543772426518527
loss/entropy :  2.378221175887368
reward/intrinsic_running :  0.0025682756159676207
reward/extrinsic_running :  0.032437037037037035
reward/intrinsic_std_running :  0.035161014039643536
reward/extrinsic_std_running :  0.7306945362426933
reward/intrinsic_batch_std :  3.9041888588408056e-05
reward/intrinsic_batch_max :  0.0007255985401570797
reward/intrinsic_batch_min :  5.558082648349227e-06
reward/total_batch :  0.016247943529522572
time/iteration_time :  112.82264828681946
time/fps :  2393.1365209013875
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: -0.0003, Value Loss: 3.5438, Entropy: 2.3782
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=113.0
Extrinsic raw: Œº=0.032437037037037035

=== Iteration 234/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 19.09s
update_step :  234
reward/intrinsic_batch_mean :  5.699516861358023e-05
reward/extrinsic_batch_mean :  0.03394814814814815
loss/policy :  -2.3879256332293153e-05
loss/rnd :  1.9973308415942346e-06
loss/value :  3.970501350634026
loss/value_i :  6.9300013392697135e-06
loss/value_e :  3.970494411208413
loss/entropy :  2.380447366020896
reward/intrinsic_running :  0.002558082021970701
reward/extrinsic_running :  0.03394814814814815
reward/intrinsic_std_running :  0.03508614849996017
reward/extrinsic_std_running :  0.8609336690457463
reward/intrinsic_batch_std :  3.781094554563139e-05
reward/intrinsic_batch_max :  0.0007110775914043188
reward/intrinsic_batch_min :  3.214757271052804e-06
reward/total_batch :  0.017002571658380865
time/iteration_time :  112.1985137462616
time/fps :  2406.4489892496126
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: -0.0000, Value Loss: 3.9705, Entropy: 2.3804
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=109.6
Extrinsic raw: Œº=0.03394814814814815

=== Iteration 235/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 19.56s
update_step :  235
reward/intrinsic_batch_mean :  5.712734288997496e-05
reward/extrinsic_batch_mean :  0.03482222222222222
loss/policy :  -0.00010576336044874607
loss/rnd :  2.9976231830501505e-06
loss/value :  3.818820277849833
loss/value_i :  7.384068360558806e-06
loss/value_e :  3.8188129193855054
loss/entropy :  2.3817303722554986
reward/intrinsic_running :  0.0025479744480041053
reward/extrinsic_running :  0.03482222222222222
reward/intrinsic_std_running :  0.03501175918764484
reward/extrinsic_std_running :  0.7871928594853305
reward/intrinsic_batch_std :  3.7538151670665995e-05
reward/intrinsic_batch_max :  0.0006176761235110462
reward/intrinsic_batch_min :  2.6705597520049196e-06
reward/total_batch :  0.0174396747825561
time/iteration_time :  112.84012627601624
time/fps :  2392.765844124968
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: -0.0001, Value Loss: 3.8188, Entropy: 2.3817
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=110.1
Extrinsic raw: Œº=0.03482222222222222

=== Iteration 236/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.64s
EPOCH 1 took 18.55s
update_step :  236
reward/intrinsic_batch_mean :  5.8985430481731816e-05
reward/extrinsic_batch_mean :  0.04208888888888889
loss/policy :  0.00014768615338570353
loss/rnd :  2.112345898143703e-06
loss/value :  4.314821286634966
loss/value_i :  6.263850984782259e-06
loss/value_e :  4.314815008279049
loss/entropy :  2.377781979965441
reward/intrinsic_running :  0.0025379757942752303
reward/extrinsic_running :  0.04208888888888889
reward/intrinsic_std_running :  0.03493783943974724
reward/extrinsic_std_running :  0.9307895928580417
reward/intrinsic_batch_std :  3.63817555362896e-05
reward/intrinsic_batch_max :  0.0006572182173840702
reward/intrinsic_batch_min :  6.65972538627102e-06
reward/total_batch :  0.02107393715968531
time/iteration_time :  112.88421368598938
time/fps :  2391.8313392434166
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0001, Value Loss: 4.3148, Entropy: 2.3778
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=114.0
Extrinsic raw: Œº=0.04208888888888889

=== Iteration 237/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.41s
EPOCH 1 took 19.16s
update_step :  237
reward/intrinsic_batch_mean :  5.653486733934659e-05
reward/extrinsic_batch_mean :  0.04827407407407407
loss/policy :  -0.0003788115626031702
loss/rnd :  1.9592830988062126e-06
loss/value :  4.473899368083838
loss/value_i :  7.041491278758975e-06
loss/value_e :  4.473892349185365
loss/entropy :  2.374109159816395
reward/intrinsic_running :  0.002528025957356655
reward/extrinsic_running :  0.04827407407407407
reward/intrinsic_std_running :  0.03486438848126489
reward/extrinsic_std_running :  1.0374716340941899
reward/intrinsic_batch_std :  4.270198392234632e-05
reward/intrinsic_batch_max :  0.0007739800494164228
reward/intrinsic_batch_min :  4.816169621335575e-06
reward/total_batch :  0.02416530447070671
time/iteration_time :  112.65608286857605
time/fps :  2396.674845467337
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: -0.0004, Value Loss: 4.4739, Entropy: 2.3741
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=109.5
Extrinsic raw: Œº=0.04827407407407407

=== Iteration 238/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.99s
EPOCH 1 took 20.32s
update_step :  238
reward/intrinsic_batch_mean :  5.5800667241961764e-05
reward/extrinsic_batch_mean :  0.04187407407407408
loss/policy :  -3.567407089356107e-05
loss/rnd :  1.9379076427343755e-06
loss/value :  4.439940868001996
loss/value_i :  6.956219439499281e-06
loss/value_e :  4.439933917739174
loss/entropy :  2.3751718600591025
reward/intrinsic_running :  0.002518145916750747
reward/extrinsic_running :  0.04187407407407408
reward/intrinsic_std_running :  0.03479139960487691
reward/extrinsic_std_running :  0.8810212334400861
reward/intrinsic_batch_std :  3.940897890758886e-05
reward/intrinsic_batch_max :  0.0006563204806298018
reward/intrinsic_batch_min :  2.9876173357479274e-06
reward/total_batch :  0.02096493737065802
time/iteration_time :  113.69230389595032
time/fps :  2374.8309318025645
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: -0.0000, Value Loss: 4.4399, Entropy: 2.3752
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=108.3
Extrinsic raw: Œº=0.04187407407407408

=== Iteration 239/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 19.31s
update_step :  239
reward/intrinsic_batch_mean :  5.4213739658667625e-05
reward/extrinsic_batch_mean :  0.04159259259259259
loss/policy :  0.00019170435949821365
loss/rnd :  1.8828207768103422e-06
loss/value :  4.1414630521427505
loss/value_i :  6.554212322126577e-06
loss/value_e :  4.141456495631825
loss/entropy :  2.374270872636275
reward/intrinsic_running :  0.0025083263860411023
reward/extrinsic_running :  0.04159259259259259
reward/intrinsic_std_running :  0.03471886865550309
reward/extrinsic_std_running :  0.8623351483578057
reward/intrinsic_batch_std :  3.623163382229979e-05
reward/intrinsic_batch_max :  0.0005000006640329957
reward/intrinsic_batch_min :  2.6344189336668933e-06
reward/total_batch :  0.020823403166125628
time/iteration_time :  112.27599477767944
time/fps :  2404.7883123603924
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0002, Value Loss: 4.1415, Entropy: 2.3743
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=105.4
Extrinsic raw: Œº=0.04159259259259259

=== Iteration 240/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.03s
EPOCH 1 took 19.03s
update_step :  240
reward/intrinsic_batch_mean :  5.554770523083924e-05
reward/extrinsic_batch_mean :  0.04307407407407408
loss/policy :  -0.00023423899212061906
loss/rnd :  1.9262943445055774e-06
loss/value :  4.39147111863801
loss/value_i :  6.536632058255649e-06
loss/value_e :  4.391464572964293
loss/entropy :  2.3712598663387876
reward/intrinsic_running :  0.0024985993312641726
reward/extrinsic_running :  0.04307407407407408
reward/intrinsic_std_running :  0.03464678873719682
reward/extrinsic_std_running :  0.9041141531468461
reward/intrinsic_batch_std :  3.7499857918883966e-05
reward/intrinsic_batch_max :  0.0005828762659803033
reward/intrinsic_batch_min :  3.1665206279285485e-06
reward/total_batch :  0.02156481088965246
time/iteration_time :  111.97010111808777
time/fps :  2411.3580081101127
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: -0.0002, Value Loss: 4.3915, Entropy: 2.3713
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=108.2
Extrinsic raw: Œº=0.04307407407407408

=== Iteration 241/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.60s
EPOCH 1 took 18.15s
update_step :  241
reward/intrinsic_batch_mean :  5.4202383841766274e-05
reward/extrinsic_batch_mean :  0.03562962962962963
loss/policy :  0.0003314573107424869
loss/rnd :  1.8719921072398862e-06
loss/value :  4.068172187516184
loss/value_i :  6.773470865730567e-06
loss/value_e :  4.068165414261095
loss/entropy :  2.3794213099913164
reward/intrinsic_running :  0.0024889451374931243
reward/extrinsic_running :  0.03562962962962963
reward/intrinsic_std_running :  0.03457515640127309
reward/extrinsic_std_running :  0.7120841683577781
reward/intrinsic_batch_std :  3.742500063825011e-05
reward/intrinsic_batch_max :  0.0007171991746872663
reward/intrinsic_batch_min :  2.91104970528977e-06
reward/total_batch :  0.017841916006735698
time/iteration_time :  111.92420673370361
time/fps :  2412.346782518631
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: 0.0003, Value Loss: 4.0682, Entropy: 2.3794
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=105.8
Extrinsic raw: Œº=0.03562962962962963

=== Iteration 242/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.59s
EPOCH 1 took 19.51s
update_step :  242
reward/intrinsic_batch_mean :  5.6833347501658325e-05
reward/extrinsic_batch_mean :  0.04102962962962963
loss/policy :  -0.0003570915736914189
loss/rnd :  1.9583769234155954e-06
loss/value :  4.223073197133614
loss/value_i :  7.30284116136979e-06
loss/value_e :  4.22306591091734
loss/entropy :  2.376039010105711
reward/intrinsic_running :  0.0024793953776813694
reward/extrinsic_running :  0.04102962962962963
reward/intrinsic_std_running :  0.03450396497025884
reward/extrinsic_std_running :  0.8927412502303372
reward/intrinsic_batch_std :  4.2661489317350714e-05
reward/intrinsic_batch_max :  0.0008251079707406461
reward/intrinsic_batch_min :  2.4203302473324584e-06
reward/total_batch :  0.020543231488565645
time/iteration_time :  111.95823669433594
time/fps :  2411.613544228493
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2412
Policy Loss: -0.0004, Value Loss: 4.2231, Entropy: 2.3760
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=111.2
Extrinsic raw: Œº=0.04102962962962963

=== Iteration 243/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.54s
EPOCH 1 took 18.96s
update_step :  243
reward/intrinsic_batch_mean :  5.432582794546424e-05
reward/extrinsic_batch_mean :  0.0400962962962963
loss/policy :  0.00020954577308712584
loss/rnd :  1.8735121312657252e-06
loss/value :  4.0331342256430425
loss/value_i :  7.125800941525306e-06
loss/value_e :  4.0331271164345015
loss/entropy :  2.379561008829059
reward/intrinsic_running :  0.002469890518923049
reward/extrinsic_running :  0.0400962962962963
reward/intrinsic_std_running :  0.03443321362849844
reward/extrinsic_std_running :  0.8000299010530014
reward/intrinsic_batch_std :  3.6411711338913846e-05
reward/intrinsic_batch_max :  0.0006396655808202922
reward/intrinsic_batch_min :  3.5377609037823277e-06
reward/total_batch :  0.02007531106212088
time/iteration_time :  112.22860169410706
time/fps :  2405.8038318602457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0002, Value Loss: 4.0331, Entropy: 2.3796
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=106.5
Extrinsic raw: Œº=0.0400962962962963

=== Iteration 244/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 19.54s
update_step :  244
reward/intrinsic_batch_mean :  5.4110679848815416e-05
reward/extrinsic_batch_mean :  0.04385185185185185
loss/policy :  5.2066802957349203e-05
loss/rnd :  1.8379672507183964e-06
loss/value :  4.666047916267857
loss/value_i :  6.2724832746012415e-06
loss/value_e :  4.6660416234623305
loss/entropy :  2.382805430527889
reward/intrinsic_running :  0.002460462948083407
reward/extrinsic_running :  0.04385185185185185
reward/intrinsic_std_running :  0.03436289577231507
reward/extrinsic_std_running :  1.0160212779816107
reward/intrinsic_batch_std :  3.645516906599143e-05
reward/intrinsic_batch_max :  0.000637179531622678
reward/intrinsic_batch_min :  3.3766900742193684e-06
reward/total_batch :  0.02195298126585033
time/iteration_time :  112.31749701499939
time/fps :  2403.899723334673
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0001, Value Loss: 4.6660, Entropy: 2.3828
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=106.3
Extrinsic raw: Œº=0.04385185185185185

=== Iteration 245/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.56s
EPOCH 1 took 19.05s
update_step :  245
reward/intrinsic_batch_mean :  5.466715322493285e-05
reward/extrinsic_batch_mean :  0.041444444444444443
loss/policy :  -0.0006110350708089148
loss/rnd :  1.8728319325804699e-06
loss/value :  4.485904769463972
loss/value_i :  6.588350626054417e-06
loss/value_e :  4.485898191278631
loss/entropy :  2.3740838657725942
reward/intrinsic_running :  0.0024511184645928923
reward/extrinsic_running :  0.041444444444444443
reward/intrinsic_std_running :  0.03429300655488189
reward/extrinsic_std_running :  0.8785114444471915
reward/intrinsic_batch_std :  3.679133480111088e-05
reward/intrinsic_batch_max :  0.0005613272078335285
reward/intrinsic_batch_min :  2.6828222416952485e-06
reward/total_batch :  0.02074955579883469
time/iteration_time :  112.52747225761414
time/fps :  2399.4140682541683
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: -0.0006, Value Loss: 4.4859, Entropy: 2.3741
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=107.6
Extrinsic raw: Œº=0.041444444444444443

=== Iteration 246/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.29s
EPOCH 1 took 19.59s
update_step :  246
reward/intrinsic_batch_mean :  5.380184386815219e-05
reward/extrinsic_batch_mean :  0.04462222222222222
loss/policy :  -0.00040643931557001037
loss/rnd :  1.8430606639247509e-06
loss/value :  4.8971959822105635
loss/value_i :  6.8922402767908135e-06
loss/value_e :  4.89718906807177
loss/entropy :  2.3750146771922256
reward/intrinsic_running :  0.0024418395540716656
reward/extrinsic_running :  0.04462222222222222
reward/intrinsic_std_running :  0.03422354277146773
reward/extrinsic_std_running :  0.9901335328325703
reward/intrinsic_batch_std :  3.878261121464929e-05
reward/intrinsic_batch_max :  0.0008437986834906042
reward/intrinsic_batch_min :  2.786945742627722e-06
reward/total_batch :  0.02233801203304519
time/iteration_time :  112.55082845687866
time/fps :  2398.916149279563
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: -0.0004, Value Loss: 4.8972, Entropy: 2.3750
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=106.1
Extrinsic raw: Œº=0.04462222222222222

=== Iteration 247/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.44s
EPOCH 1 took 18.98s
update_step :  247
reward/intrinsic_batch_mean :  5.754015702465646e-05
reward/extrinsic_batch_mean :  0.04042962962962963
loss/policy :  0.00019760305682818094
loss/rnd :  1.952441013227971e-06
loss/value :  4.381241997083028
loss/value_i :  6.838009477922407e-06
loss/value_e :  4.381235151579886
loss/entropy :  2.3745988751902725
reward/intrinsic_running :  0.0024326794808023555
reward/extrinsic_running :  0.04042962962962963
reward/intrinsic_std_running :  0.03415449648155847
reward/extrinsic_std_running :  0.8379884869777571
reward/intrinsic_batch_std :  3.9124791956121186e-05
reward/intrinsic_batch_max :  0.0006457415875047445
reward/intrinsic_batch_min :  3.583874331525294e-06
reward/total_batch :  0.020243584893327143
time/iteration_time :  111.62873959541321
time/fps :  2418.7319589792646
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0002, Value Loss: 4.3812, Entropy: 2.3746
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=113.7
Extrinsic raw: Œº=0.04042962962962963

=== Iteration 248/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 18.66s
update_step :  248
reward/intrinsic_batch_mean :  5.4538945098997996e-05
reward/extrinsic_batch_mean :  0.04365925925925926
loss/policy :  -0.00017484291597749248
loss/rnd :  1.8638028860330065e-06
loss/value :  4.801570718938654
loss/value_i :  9.729687290569982e-06
loss/value_e :  4.80156100880016
loss/entropy :  2.3661631020632656
reward/intrinsic_running :  0.0024235552500578073
reward/extrinsic_running :  0.04365925925925926
reward/intrinsic_std_running :  0.03408586888610341
reward/extrinsic_std_running :  0.9074411411416656
reward/intrinsic_batch_std :  3.547847545776759e-05
reward/intrinsic_batch_max :  0.0005348980193957686
reward/intrinsic_batch_min :  2.5891142740874784e-06
reward/total_batch :  0.02185689910217913
time/iteration_time :  112.24656391143799
time/fps :  2405.4188439392115
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2405
Policy Loss: -0.0002, Value Loss: 4.8016, Entropy: 2.3662
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=108.0
Extrinsic raw: Œº=0.04365925925925926

=== Iteration 249/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.41s
update_step :  249
reward/intrinsic_batch_mean :  5.6180793552310344e-05
reward/extrinsic_batch_mean :  0.03977777777777778
loss/policy :  0.0002664778805796452
loss/rnd :  1.911908868530163e-06
loss/value :  4.521941856904463
loss/value_i :  8.005594708899452e-06
loss/value_e :  4.5219338590448555
loss/entropy :  2.3720740368871978
reward/intrinsic_running :  0.002414523360912244
reward/extrinsic_running :  0.03977777777777778
reward/intrinsic_std_running :  0.0340176520667996
reward/extrinsic_std_running :  0.7794176046697532
reward/intrinsic_batch_std :  3.686238534789356e-05
reward/intrinsic_batch_max :  0.0004880095075350255
reward/intrinsic_batch_min :  3.3578521652088966e-06
reward/total_batch :  0.019916979285665045
time/iteration_time :  110.56704449653625
time/fps :  2441.9572869062113
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2442
Policy Loss: 0.0003, Value Loss: 4.5219, Entropy: 2.3721
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=111.5
Extrinsic raw: Œº=0.03977777777777778

=== Iteration 250/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 18.54s
update_step :  250
reward/intrinsic_batch_mean :  5.5562050244383565e-05
reward/extrinsic_batch_mean :  0.042837037037037035
loss/policy :  0.00016291056443041077
loss/rnd :  1.8878489079339267e-06
loss/value :  4.55391809795842
loss/value_i :  6.408449370141942e-06
loss/value_e :  4.553911696780812
loss/entropy :  2.3748232704220396
reward/intrinsic_running :  0.002405554140192205
reward/extrinsic_running :  0.042837037037037035
reward/intrinsic_std_running :  0.03394984383147363
reward/extrinsic_std_running :  0.9025510077503768
reward/intrinsic_batch_std :  3.888845758175442e-05
reward/intrinsic_batch_max :  0.000935995252802968
reward/intrinsic_batch_min :  2.353072886762675e-06
reward/total_batch :  0.021446299543640707
time/iteration_time :  111.41424632072449
time/fps :  2423.3884706517692
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: 0.0002, Value Loss: 4.5539, Entropy: 2.3748
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=110.5
Extrinsic raw: Œº=0.042837037037037035

=== Iteration 251/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 18.61s
update_step :  251
reward/intrinsic_batch_mean :  5.5141841057344144e-05
reward/extrinsic_batch_mean :  0.04487407407407407
loss/policy :  -0.00019461040673459965
loss/rnd :  1.865535483775051e-06
loss/value :  4.859005263357451
loss/value_i :  5.995105318630301e-06
loss/value_e :  4.858999273993752
loss/entropy :  2.3749249667832344
reward/intrinsic_running :  0.002396652848613382
reward/extrinsic_running :  0.04487407407407407
reward/intrinsic_std_running :  0.03388243968860994
reward/extrinsic_std_running :  0.9765743333649037
reward/intrinsic_batch_std :  3.80385767876122e-05
reward/intrinsic_batch_max :  0.0004902668879367411
reward/intrinsic_batch_min :  2.8890074190712767e-06
reward/total_batch :  0.02246460795756571
time/iteration_time :  111.05543279647827
time/fps :  2431.218295234649
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0002, Value Loss: 4.8590, Entropy: 2.3749
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.014, sum=109.9
Extrinsic raw: Œº=0.04487407407407407

=== Iteration 252/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.37s
EPOCH 1 took 19.21s
update_step :  252
reward/intrinsic_batch_mean :  5.520801457544924e-05
reward/extrinsic_batch_mean :  0.04218518518518519
loss/policy :  0.0002903597178925393
loss/rnd :  1.8636412026794322e-06
loss/value :  4.7004974791497895
loss/value_i :  6.133542835110954e-06
loss/value_e :  4.7004913561271895
loss/entropy :  2.3671212413094262
reward/intrinsic_running :  0.0023878181082253613
reward/extrinsic_running :  0.04218518518518519
reward/intrinsic_std_running :  0.033815435678628755
reward/extrinsic_std_running :  0.8993094279434243
reward/intrinsic_batch_std :  3.7485937126293996e-05
reward/intrinsic_batch_max :  0.0005449989112094045
reward/intrinsic_batch_min :  4.220212758809794e-06
reward/total_batch :  0.021120196599880316
time/iteration_time :  113.15529584884644
time/fps :  2386.101313019125
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0003, Value Loss: 4.7005, Entropy: 2.3671
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=110.2
Extrinsic raw: Œº=0.04218518518518519

=== Iteration 253/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.59s
EPOCH 1 took 19.74s
update_step :  253
reward/intrinsic_batch_mean :  5.454245326687939e-05
reward/extrinsic_batch_mean :  0.04654814814814815
loss/policy :  -0.00040184213315969276
loss/rnd :  1.8408347841614159e-06
loss/value :  4.89153722560767
loss/value_i :  6.9491012792158555e-06
loss/value_e :  4.89153028979446
loss/entropy :  2.3684196038679644
reward/intrinsic_running :  0.0023790469455988953
reward/extrinsic_running :  0.04654814814814815
reward/intrinsic_std_running :  0.03374882801779757
reward/extrinsic_std_running :  1.071259180995403
reward/intrinsic_batch_std :  3.730354545536284e-05
reward/intrinsic_batch_max :  0.0006263365503400564
reward/intrinsic_batch_min :  2.337769956284319e-06
reward/total_batch :  0.023301345300707516
time/iteration_time :  112.86810064315796
time/fps :  2392.1727969324816
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: -0.0004, Value Loss: 4.8915, Entropy: 2.3684
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=109.1
Extrinsic raw: Œº=0.04654814814814815

=== Iteration 254/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 19.76s
update_step :  254
reward/intrinsic_batch_mean :  5.341364866328351e-05
reward/extrinsic_batch_mean :  0.04091851851851852
loss/policy :  0.00012486594884345928
loss/rnd :  1.7966260122992743e-06
loss/value :  4.527980479327115
loss/value_i :  6.05779574112658e-06
loss/value_e :  4.527974406878154
loss/entropy :  2.368383371468746
reward/intrinsic_running :  0.002370327109910517
reward/extrinsic_running :  0.04091851851851852
reward/intrinsic_std_running :  0.03368261354308529
reward/extrinsic_std_running :  0.9083642853185332
reward/intrinsic_batch_std :  3.598456940058961e-05
reward/intrinsic_batch_max :  0.0005363145610317588
reward/intrinsic_batch_min :  2.54083238360181e-06
reward/total_batch :  0.020485966083590903
time/iteration_time :  112.68781518936157
time/fps :  2395.9999539106307
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0001, Value Loss: 4.5280, Entropy: 2.3684
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=107.0
Extrinsic raw: Œº=0.04091851851851852

=== Iteration 255/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.35s
EPOCH 1 took 20.08s
update_step :  255
reward/intrinsic_batch_mean :  5.577015075824521e-05
reward/extrinsic_batch_mean :  0.040903703703703706
loss/policy :  0.00036232793971783286
loss/rnd :  2.078448129726563e-06
loss/value :  4.843930533438018
loss/value_i :  2.6767888295415272e-05
loss/value_e :  4.843903765533909
loss/entropy :  2.368833130056208
reward/intrinsic_running :  0.0023617058287207374
reward/extrinsic_running :  0.040903703703703706
reward/intrinsic_std_running :  0.033616785396055705
reward/extrinsic_std_running :  0.9083690298720707
reward/intrinsic_batch_std :  4.175808569853717e-05
reward/intrinsic_batch_max :  0.0006364297005347908
reward/intrinsic_batch_min :  2.663662371560349e-06
reward/total_batch :  0.020479736927230974
time/iteration_time :  112.01415300369263
time/fps :  2410.40969163155
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0004, Value Loss: 4.8439, Entropy: 2.3688
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=112.0
Extrinsic raw: Œº=0.040903703703703706

=== Iteration 256/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 18.80s
update_step :  256
reward/intrinsic_batch_mean :  0.00014178814402861193
reward/extrinsic_batch_mean :  0.04172592592592592
loss/policy :  -0.0001221903494848503
loss/rnd :  2.292157844432509e-06
loss/value :  4.95935134454207
loss/value_i :  8.154818543158454e-06
loss/value_e :  4.959343187736742
loss/entropy :  2.3656465501496284
reward/intrinsic_running :  0.002354178873040738
reward/extrinsic_running :  0.04172592592592592
reward/intrinsic_std_running :  0.03355127928651044
reward/extrinsic_std_running :  0.9284732903047497
reward/intrinsic_batch_std :  4.131247940731728e-05
reward/intrinsic_batch_max :  0.0006916261045262218
reward/intrinsic_batch_min :  7.751565863145515e-05
reward/total_batch :  0.020933857034977268
time/iteration_time :  111.45230460166931
time/fps :  2422.56094178564
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2423
Policy Loss: -0.0001, Value Loss: 4.9594, Entropy: 2.3656
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.021, sum=285.3
Extrinsic raw: Œº=0.04172592592592592

=== Iteration 257/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.84s
EPOCH 1 took 18.99s
update_step :  257
reward/intrinsic_batch_mean :  5.653678010599429e-05
reward/extrinsic_batch_mean :  0.04205925925925926
loss/policy :  8.701340200125493e-06
loss/rnd :  1.8619284605158486e-06
loss/value :  5.0145345384424385
loss/value_i :  6.318721165316123e-06
loss/value_e :  5.014528227574898
loss/entropy :  2.3651724150686553
reward/intrinsic_running :  0.0023456903219902857
reward/extrinsic_running :  0.04205925925925926
reward/intrinsic_std_running :  0.033486216465516076
reward/extrinsic_std_running :  0.9466595755834806
reward/intrinsic_batch_std :  3.958702339769069e-05
reward/intrinsic_batch_max :  0.0007100459188222885
reward/intrinsic_batch_min :  2.8556084998854203e-06
reward/total_batch :  0.02105789801968263
time/iteration_time :  111.75945448875427
time/fps :  2415.9029876722293
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0000, Value Loss: 5.0145, Entropy: 2.3652
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=114.0
Extrinsic raw: Œº=0.04205925925925926

=== Iteration 258/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.14s
EPOCH 1 took 19.46s
update_step :  258
reward/intrinsic_batch_mean :  5.4298385008897404e-05
reward/extrinsic_batch_mean :  0.04314074074074074
loss/policy :  9.346620848218938e-06
loss/rnd :  1.8380319264713652e-06
loss/value :  4.644452141992973
loss/value_i :  6.11133873462677e-06
loss/value_e :  4.644446037032387
loss/entropy :  2.368860074968049
reward/intrinsic_running :  0.0023372405264706748
reward/extrinsic_running :  0.04314074074074074
reward/intrinsic_std_running :  0.033421532446505635
reward/extrinsic_std_running :  0.9674967636118746
reward/intrinsic_batch_std :  4.062034865143974e-05
reward/intrinsic_batch_max :  0.0008326937677338719
reward/intrinsic_batch_min :  2.449599151077564e-06
reward/total_batch :  0.02159751956287482
time/iteration_time :  112.2391426563263
time/fps :  2405.5778902974507
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0000, Value Loss: 4.6445, Entropy: 2.3689
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=109.7
Extrinsic raw: Œº=0.04314074074074074

=== Iteration 259/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.21s
EPOCH 1 took 19.29s
update_step :  259
reward/intrinsic_batch_mean :  5.5041684511380246e-05
reward/extrinsic_batch_mean :  0.04151851851851852
loss/policy :  -0.00032831412593650657
loss/rnd :  2.894815901816566e-06
loss/value :  4.741964621977373
loss/value_i :  6.254414157328111e-06
loss/value_e :  4.741958350846262
loss/entropy :  2.3743100383064966
reward/intrinsic_running :  0.002328864828448539
reward/extrinsic_running :  0.04151851851851852
reward/intrinsic_std_running :  0.03335722120402636
reward/extrinsic_std_running :  0.9435346809214322
reward/intrinsic_batch_std :  3.764587755683026e-05
reward/intrinsic_batch_max :  0.0009592862334102392
reward/intrinsic_batch_min :  3.6011094834975665e-06
reward/total_batch :  0.020786780101514947
time/iteration_time :  111.85604000091553
time/fps :  2413.8169024917215
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: -0.0003, Value Loss: 4.7420, Entropy: 2.3743
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=111.4
Extrinsic raw: Œº=0.04151851851851852

=== Iteration 260/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 18.85s
update_step :  260
reward/intrinsic_batch_mean :  0.00020443713907141635
reward/extrinsic_batch_mean :  0.043614814814814815
loss/policy :  1.8876733851026405e-05
loss/rnd :  2.9575893501549384e-06
loss/value :  4.760055621465047
loss/value_i :  7.21285151815788e-06
loss/value_e :  4.7600484111092305
loss/entropy :  2.370654770822236
reward/intrinsic_running :  0.002322293203911741
reward/extrinsic_running :  0.043614814814814815
reward/intrinsic_std_running :  0.033293180269600084
reward/extrinsic_std_running :  0.9542854451848423
reward/intrinsic_batch_std :  6.836719062990062e-05
reward/intrinsic_batch_max :  0.001258884440176189
reward/intrinsic_batch_min :  8.098513353615999e-05
reward/total_batch :  0.021909625976943115
time/iteration_time :  112.19142937660217
time/fps :  2406.600945368731
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0000, Value Loss: 4.7601, Entropy: 2.3707
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.006, max=0.038, sum=414.5
Extrinsic raw: Œº=0.043614814814814815

=== Iteration 261/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.23s
EPOCH 1 took 19.36s
update_step :  261
reward/intrinsic_batch_mean :  0.00012059872585588083
reward/extrinsic_batch_mean :  0.04639259259259259
loss/policy :  -0.0004097303573155042
loss/rnd :  2.002235257322988e-06
loss/value :  4.827954574064775
loss/value_i :  6.5171551465358455e-06
loss/value_e :  4.827948050065474
loss/entropy :  2.365922945918459
reward/intrinsic_running :  0.0023147943597431925
reward/extrinsic_running :  0.04639259259259259
reward/intrinsic_std_running :  0.0332295594951946
reward/extrinsic_std_running :  1.0566471894194833
reward/intrinsic_batch_std :  4.207275686733102e-05
reward/intrinsic_batch_max :  0.0007576251518912613
reward/intrinsic_batch_min :  4.401157275424339e-05
reward/total_batch :  0.023256595659224236
time/iteration_time :  112.40581727027893
time/fps :  2402.0109150648946
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0004, Value Loss: 4.8280, Entropy: 2.3659
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.023, sum=245.0
Extrinsic raw: Œº=0.04639259259259259

=== Iteration 262/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.74s
EPOCH 1 took 19.64s
update_step :  262
reward/intrinsic_batch_mean :  5.4125700601889546e-05
reward/extrinsic_batch_mean :  0.04891851851851852
loss/policy :  -0.0004738412610480957
loss/rnd :  1.7614287878242259e-06
loss/value :  4.913612987055923
loss/value_i :  6.6689694146286156e-06
loss/value_e :  4.913606318560514
loss/entropy :  2.3696762720743814
reward/intrinsic_running :  0.002306586737620854
reward/extrinsic_running :  0.04891851851851852
reward/intrinsic_std_running :  0.033166348918666384
reward/extrinsic_std_running :  1.0957660675720202
reward/intrinsic_batch_std :  3.537680673964634e-05
reward/intrinsic_batch_max :  0.0004970890586264431
reward/intrinsic_batch_min :  3.5237510473962175e-06
reward/total_batch :  0.024486322109560206
time/iteration_time :  112.29668951034546
time/fps :  2404.3451430073187
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: -0.0005, Value Loss: 4.9136, Entropy: 2.3697
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=110.2
Extrinsic raw: Œº=0.04891851851851852

=== Iteration 263/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.82s
EPOCH 1 took 19.53s
update_step :  263
reward/intrinsic_batch_mean :  5.121659580904128e-05
reward/extrinsic_batch_mean :  0.04917037037037037
loss/policy :  6.526587601525314e-05
loss/rnd :  1.6901036140166759e-06
loss/value :  5.497728571747288
loss/value_i :  6.135473478769365e-06
loss/value_e :  5.497722430662676
loss/entropy :  2.3641626690373276
reward/intrinsic_running :  0.002298404077385485
reward/extrinsic_running :  0.04917037037037037
reward/intrinsic_std_running :  0.03310350008087063
reward/extrinsic_std_running :  1.069768431437319
reward/intrinsic_batch_std :  3.342355926514387e-05
reward/intrinsic_batch_max :  0.0006647144909948111
reward/intrinsic_batch_min :  2.8245556222827872e-06
reward/total_batch :  0.024610793483089706
time/iteration_time :  112.95477867126465
time/fps :  2390.3371169960706
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0001, Value Loss: 5.4977, Entropy: 2.3642
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=104.4
Extrinsic raw: Œº=0.04917037037037037

=== Iteration 264/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.14s
EPOCH 1 took 18.88s
update_step :  264
reward/intrinsic_batch_mean :  5.420902478886597e-05
reward/extrinsic_batch_mean :  0.04711851851851852
loss/policy :  -0.00029254198307171464
loss/rnd :  1.7898458447069225e-06
loss/value :  5.024749546340018
loss/value_i :  6.150055324641554e-06
loss/value_e :  5.024743376356183
loss/entropy :  2.3615539904796714
reward/intrinsic_running :  0.0022903173962653097
reward/extrinsic_running :  0.04711851851851852
reward/intrinsic_std_running :  0.03304100502781237
reward/extrinsic_std_running :  1.0173304903983273
reward/intrinsic_batch_std :  3.7532920721418275e-05
reward/intrinsic_batch_max :  0.0005745087401010096
reward/intrinsic_batch_min :  3.292130713816732e-06
reward/total_batch :  0.02358636377165369
time/iteration_time :  111.37229299545288
time/fps :  2424.301347652271
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0003, Value Loss: 5.0247, Entropy: 2.3616
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=110.7
Extrinsic raw: Œº=0.04711851851851852

=== Iteration 265/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.65s
EPOCH 1 took 18.80s
update_step :  265
reward/intrinsic_batch_mean :  5.380359373103366e-05
reward/extrinsic_batch_mean :  0.046703703703703706
loss/policy :  0.00042819216458045764
loss/rnd :  1.778592945811397e-06
loss/value :  5.150921944415931
loss/value_i :  6.513435058271473e-06
loss/value_e :  5.1509154493158515
loss/entropy :  2.3634735851576836
reward/intrinsic_running :  0.002282284187513319
reward/extrinsic_running :  0.046703703703703706
reward/intrinsic_std_running :  0.032978863091535374
reward/extrinsic_std_running :  1.0296458691764894
reward/intrinsic_batch_std :  3.9216661678972415e-05
reward/intrinsic_batch_max :  0.0009444718598388135
reward/intrinsic_batch_min :  3.1876675166131463e-06
reward/total_batch :  0.02337875364871737
time/iteration_time :  112.55138158798218
time/fps :  2398.90435986287
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0004, Value Loss: 5.1509, Entropy: 2.3635
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=110.1
Extrinsic raw: Œº=0.046703703703703706

=== Iteration 266/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 19.18s
update_step :  266
reward/intrinsic_batch_mean :  5.2197483820809454e-05
reward/extrinsic_batch_mean :  0.050525925925925926
loss/policy :  9.636973933965871e-05
loss/rnd :  1.712480888837683e-06
loss/value :  5.4702989043611465
loss/value_i :  6.39228015974037e-06
loss/value_e :  5.470292510408344
loss/entropy :  2.361853447827426
reward/intrinsic_running :  0.00227429533706767
reward/extrinsic_running :  0.050525925925925926
reward/intrinsic_std_running :  0.03291707147014013
reward/extrinsic_std_running :  1.075914297355404
reward/intrinsic_batch_std :  3.763160598990914e-05
reward/intrinsic_batch_max :  0.0008636530255898833
reward/intrinsic_batch_min :  5.192417120269965e-06
reward/total_batch :  0.025289061704873366
time/iteration_time :  112.56670355796814
time/fps :  2398.577833994747
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0001, Value Loss: 5.4703, Entropy: 2.3619
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=107.0
Extrinsic raw: Œº=0.050525925925925926

=== Iteration 267/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 18.49s
update_step :  267
reward/intrinsic_batch_mean :  5.2186778154302575e-05
reward/extrinsic_batch_mean :  0.05065925925925926
loss/policy :  8.734299406183489e-06
loss/rnd :  1.7116539686757086e-06
loss/value :  5.482843803636955
loss/value_i :  6.587764091543222e-06
loss/value_e :  5.482837214614406
loss/entropy :  2.3585957397114146
reward/intrinsic_running :  0.0022663660093166465
reward/extrinsic_running :  0.05065925925925926
reward/intrinsic_std_running :  0.03285562590409138
reward/extrinsic_std_running :  1.0902736364850185
reward/intrinsic_batch_std :  3.7984869304480546e-05
reward/intrinsic_batch_max :  0.0007356395944952965
reward/intrinsic_batch_min :  2.572198127381853e-06
reward/total_batch :  0.02535572301870678
time/iteration_time :  111.12176132202148
time/fps :  2429.7671022110853
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0000, Value Loss: 5.4828, Entropy: 2.3586
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=107.2
Extrinsic raw: Œº=0.05065925925925926

=== Iteration 268/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 19.98s
update_step :  268
reward/intrinsic_batch_mean :  5.12795285306277e-05
reward/extrinsic_batch_mean :  0.04922962962962963
loss/policy :  0.00024801427565707303
loss/rnd :  1.6862776970866076e-06
loss/value :  5.654384815331661
loss/value_i :  6.6390018191393185e-06
loss/value_e :  5.654378182960279
loss/entropy :  2.362222588423527
reward/intrinsic_running :  0.002258484776466056
reward/extrinsic_running :  0.04922962962962963
reward/intrinsic_std_running :  0.03279452382247287
reward/extrinsic_std_running :  1.0697518572823894
reward/intrinsic_batch_std :  3.579040943327395e-05
reward/intrinsic_batch_max :  0.000618266174569726
reward/intrinsic_batch_min :  3.958136858273065e-06
reward/total_batch :  0.02464045457908013
time/iteration_time :  113.2697126865387
time/fps :  2383.691046760178
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2384
Policy Loss: 0.0002, Value Loss: 5.6544, Entropy: 2.3622
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=105.5
Extrinsic raw: Œº=0.04922962962962963

=== Iteration 269/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.59s
EPOCH 1 took 19.17s
update_step :  269
reward/intrinsic_batch_mean :  5.406484041471534e-05
reward/extrinsic_batch_mean :  0.04902962962962963
loss/policy :  0.0003365070072256706
loss/rnd :  1.769691536854666e-06
loss/value :  5.475125941363248
loss/value_i :  6.127321801779379e-06
loss/value_e :  5.475119800278635
loss/entropy :  2.3580945802457407
reward/intrinsic_running :  0.0022506867471395924
reward/extrinsic_running :  0.04902962962962963
reward/intrinsic_std_running :  0.03273375979560432
reward/extrinsic_std_running :  1.0121336937069627
reward/intrinsic_batch_std :  3.779126691586702e-05
reward/intrinsic_batch_max :  0.0006610784912481904
reward/intrinsic_batch_min :  3.0319949928525602e-06
reward/total_batch :  0.024541847235022174
time/iteration_time :  111.34224796295166
time/fps :  2424.955530714995
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: 0.0003, Value Loss: 5.4751, Entropy: 2.3581
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=111.5
Extrinsic raw: Œº=0.04902962962962963

=== Iteration 270/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.58s
EPOCH 1 took 20.25s
update_step :  270
reward/intrinsic_batch_mean :  5.2100944314420136e-05
reward/extrinsic_batch_mean :  0.050103703703703706
loss/policy :  0.00017145503035421962
loss/rnd :  1.699426702957267e-06
loss/value :  5.98370361328125
loss/value_i :  5.442682701565597e-06
loss/value_e :  5.983698151328347
loss/entropy :  2.3578425898696436
reward/intrinsic_running :  0.0022429276980450424
reward/extrinsic_running :  0.050103703703703706
reward/intrinsic_std_running :  0.032673333482062146
reward/extrinsic_std_running :  1.087569831042444
reward/intrinsic_batch_std :  3.6124360659869566e-05
reward/intrinsic_batch_max :  0.0007956093177199364
reward/intrinsic_batch_min :  2.964492978208e-06
reward/total_batch :  0.025077902324009062
time/iteration_time :  113.10624432563782
time/fps :  2387.1361091493604
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2387
Policy Loss: 0.0002, Value Loss: 5.9837, Entropy: 2.3578
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=107.6
Extrinsic raw: Œº=0.050103703703703706

=== Iteration 271/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.82s
EPOCH 1 took 18.46s
update_step :  271
reward/intrinsic_batch_mean :  5.36467166392497e-05
reward/extrinsic_batch_mean :  0.052148148148148145
loss/policy :  0.00036701613906629836
loss/rnd :  1.735837694620083e-06
loss/value :  5.620255571423155
loss/value_i :  5.751403030058789e-06
loss/value_e :  5.6202498349276455
loss/entropy :  2.362409613349221
reward/intrinsic_running :  0.002235241638958079
reward/extrinsic_running :  0.052148148148148145
reward/intrinsic_std_running :  0.03261323956741138
reward/extrinsic_std_running :  1.1103982503356271
reward/intrinsic_batch_std :  3.571361900638121e-05
reward/intrinsic_batch_max :  0.0004768271173816174
reward/intrinsic_batch_min :  3.838003522105282e-06
reward/total_batch :  0.0261008974323937
time/iteration_time :  111.75137305259705
time/fps :  2416.0776966285816
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0004, Value Loss: 5.6203, Entropy: 2.3624
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=111.0
Extrinsic raw: Œº=0.052148148148148145

=== Iteration 272/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.36s
EPOCH 1 took 18.83s
update_step :  272
reward/intrinsic_batch_mean :  5.2117416192726925e-05
reward/extrinsic_batch_mean :  0.05057777777777778
loss/policy :  -0.00024115555799763763
loss/rnd :  1.69479879945577e-06
loss/value :  5.475360747539636
loss/value_i :  5.849151627692415e-06
loss/value_e :  5.475354917121656
loss/entropy :  2.3602018717563515
reward/intrinsic_running :  0.0022275967278557016
reward/extrinsic_running :  0.05057777777777778
reward/intrinsic_std_running :  0.03255347698754448
reward/extrinsic_std_running :  1.103095492771519
reward/intrinsic_batch_std :  3.546605175795639e-05
reward/intrinsic_batch_max :  0.0006325080757960677
reward/intrinsic_batch_min :  2.6268189685652032e-06
reward/total_batch :  0.02531494759698525
time/iteration_time :  112.24399185180664
time/fps :  2405.4739638668166
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2405
Policy Loss: -0.0002, Value Loss: 5.4754, Entropy: 2.3602
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=108.1
Extrinsic raw: Œº=0.05057777777777778

=== Iteration 273/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.88s
EPOCH 1 took 18.87s
update_step :  273
reward/intrinsic_batch_mean :  5.354952604717187e-05
reward/extrinsic_batch_mean :  0.04652592592592593
loss/policy :  -1.7034994953340202e-05
loss/rnd :  1.739062693931456e-06
loss/value :  5.827187075759426
loss/value_i :  6.131193245120372e-06
loss/value_e :  5.8271809346748125
loss/entropy :  2.3578355998703926
reward/intrinsic_running :  0.0022200198613776187
reward/extrinsic_running :  0.04652592592592593
reward/intrinsic_std_running :  0.032494040995119794
reward/extrinsic_std_running :  0.9772496199529662
reward/intrinsic_batch_std :  3.8513954000015895e-05
reward/intrinsic_batch_max :  0.0006838605040684342
reward/intrinsic_batch_min :  2.4304181351908483e-06
reward/total_batch :  0.02328973772598655
time/iteration_time :  111.10671329498291
time/fps :  2430.0961840457217
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: -0.0000, Value Loss: 5.8272, Entropy: 2.3578
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=111.2
Extrinsic raw: Œº=0.04652592592592593

=== Iteration 274/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.86s
EPOCH 1 took 19.19s
update_step :  274
reward/intrinsic_batch_mean :  5.1700786718524964e-05
reward/extrinsic_batch_mean :  0.05500740740740741
loss/policy :  -9.788698022902915e-05
loss/rnd :  1.7193433381400995e-06
loss/value :  5.7873224850856895
loss/value_i :  5.037753218554523e-05
loss/value_e :  5.78727211374225
loss/entropy :  2.3585624225211865
reward/intrinsic_running :  0.0022124801819680354
reward/extrinsic_running :  0.05500740740740741
reward/intrinsic_std_running :  0.032434930502296996
reward/extrinsic_std_running :  1.1994088512837158
reward/intrinsic_batch_std :  3.724213670987859e-05
reward/intrinsic_batch_max :  0.000656318268738687
reward/intrinsic_batch_min :  3.0049686756683514e-06
reward/total_batch :  0.027529554097062967
time/iteration_time :  112.85125231742859
time/fps :  2392.5299405676296
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2393
Policy Loss: -0.0001, Value Loss: 5.7873, Entropy: 2.3586
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=107.6
Extrinsic raw: Œº=0.05500740740740741

=== Iteration 275/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.34s
EPOCH 1 took 18.83s
update_step :  275
reward/intrinsic_batch_mean :  5.272849413006582e-05
reward/extrinsic_batch_mean :  0.05321481481481481
loss/policy :  6.673816736138454e-05
loss/rnd :  1.6974906126658122e-06
loss/value :  5.932886773889715
loss/value_i :  8.248024979559087e-06
loss/value_e :  5.932878559285944
loss/entropy :  2.3627999154004184
reward/intrinsic_running :  0.0022050036863113303
reward/extrinsic_running :  0.05321481481481481
reward/intrinsic_std_running :  0.03237614089827355
reward/extrinsic_std_running :  1.1541734408798243
reward/intrinsic_batch_std :  3.649772931237263e-05
reward/intrinsic_batch_max :  0.0007580280071124434
reward/intrinsic_batch_min :  5.001032150175888e-06
reward/total_batch :  0.02663377165447244
time/iteration_time :  112.77684998512268
time/fps :  2394.1083656408023
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0001, Value Loss: 5.9329, Entropy: 2.3628
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=109.9
Extrinsic raw: Œº=0.05321481481481481

=== Iteration 276/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.94s
EPOCH 1 took 19.06s
update_step :  276
reward/intrinsic_batch_mean :  5.192848156072311e-05
reward/extrinsic_batch_mean :  0.05099259259259259
loss/policy :  0.00037437831986497974
loss/rnd :  1.681799298666826e-06
loss/value :  6.167702783237804
loss/value_i :  5.819349002139819e-06
loss/value_e :  6.16769696004463
loss/entropy :  2.3673872514204546
reward/intrinsic_running :  0.0021975709326738117
reward/extrinsic_running :  0.05099259259259259
reward/intrinsic_std_running :  0.03231767045625995
reward/extrinsic_std_running :  1.1184213974023176
reward/intrinsic_batch_std :  3.555351958069641e-05
reward/intrinsic_batch_max :  0.0006759128300473094
reward/intrinsic_batch_min :  2.4843116079864558e-06
reward/total_batch :  0.025522260537076655
time/iteration_time :  112.46226358413696
time/fps :  2400.805313668647
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0004, Value Loss: 6.1677, Entropy: 2.3674
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=108.5
Extrinsic raw: Œº=0.05099259259259259

=== Iteration 277/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.58s
EPOCH 1 took 19.64s
update_step :  277
reward/intrinsic_batch_mean :  5.403658086187433e-05
reward/extrinsic_batch_mean :  0.05187407407407407
loss/policy :  0.00015009198543311592
loss/rnd :  1.7422932104995144e-06
loss/value :  5.75924901528792
loss/value_i :  5.72134436107731e-06
loss/value_e :  5.759243322141243
loss/entropy :  2.36508630622517
reward/intrinsic_running :  0.0021902157403760323
reward/extrinsic_running :  0.05187407407407407
reward/intrinsic_std_running :  0.032259514155140175
reward/extrinsic_std_running :  1.1223494730689803
reward/intrinsic_batch_std :  3.641170313101649e-05
reward/intrinsic_batch_max :  0.0005088772741146386
reward/intrinsic_batch_min :  4.097273176739691e-06
reward/total_batch :  0.025964055327467973
time/iteration_time :  111.89011812210083
time/fps :  2413.0817317161172
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0002, Value Loss: 5.7592, Entropy: 2.3651
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=113.1
Extrinsic raw: Œº=0.05187407407407407

=== Iteration 278/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.81s
EPOCH 1 took 19.10s
update_step :  278
reward/intrinsic_batch_mean :  5.6087612181154666e-05
reward/extrinsic_batch_mean :  0.05
loss/policy :  0.00010851380295317733
loss/rnd :  2.5045093821063347e-06
loss/value :  5.796399434407552
loss/value_i :  5.758028009950067e-06
loss/value_e :  5.796393683462432
loss/entropy :  2.365607651797208
reward/intrinsic_running :  0.0021829326034235267
reward/extrinsic_running :  0.05
reward/intrinsic_std_running :  0.032201669537767735
reward/extrinsic_std_running :  1.0592712379535072
reward/intrinsic_batch_std :  4.1607512994330835e-05
reward/intrinsic_batch_max :  0.0009549967362545431
reward/intrinsic_batch_min :  3.7233510283840587e-06
reward/total_batch :  0.02502804380609058
time/iteration_time :  111.09011101722717
time/fps :  2430.459358872457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0001, Value Loss: 5.7964, Entropy: 2.3656
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=117.6
Extrinsic raw: Œº=0.05

=== Iteration 279/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.75s
update_step :  279
reward/intrinsic_batch_mean :  7.139502838876473e-05
reward/extrinsic_batch_mean :  0.0476962962962963
loss/policy :  4.602901004325373e-05
loss/rnd :  1.8618561522420019e-06
loss/value :  5.802956024805705
loss/value_i :  5.678731564661245e-06
loss/value_e :  5.802950338883833
loss/entropy :  2.365615458199472
reward/intrinsic_running :  0.002175857080474026
reward/extrinsic_running :  0.0476962962962963
reward/intrinsic_std_running :  0.032144125359644976
reward/extrinsic_std_running :  0.9907475051067104
reward/intrinsic_batch_std :  3.995396106794425e-05
reward/intrinsic_batch_max :  0.0009422115399502218
reward/intrinsic_batch_min :  1.7475951608503237e-05
reward/total_batch :  0.023883845662342532
time/iteration_time :  111.20542287826538
time/fps :  2427.9391509132092
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0000, Value Loss: 5.8030, Entropy: 2.3656
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=149.9
Extrinsic raw: Œº=0.0476962962962963

=== Iteration 280/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 18.20s
update_step :  280
reward/intrinsic_batch_mean :  5.439883311981383e-05
reward/extrinsic_batch_mean :  0.05040740740740741
loss/policy :  0.00012386609245313042
loss/rnd :  1.7445765331213998e-06
loss/value :  5.505613269227924
loss/value_i :  5.489093472065041e-06
loss/value_e :  5.50560779282541
loss/entropy :  2.376041824167425
reward/intrinsic_running :  0.002168658117486925
reward/extrinsic_running :  0.05040740740740741
reward/intrinsic_std_running :  0.03208689931962031
reward/extrinsic_std_running :  1.115793946172635
reward/intrinsic_batch_std :  4.001400814556465e-05
reward/intrinsic_batch_max :  0.0005653755506500602
reward/intrinsic_batch_min :  5.382868948800024e-06
reward/total_batch :  0.02523090312026361
time/iteration_time :  111.20903062820435
time/fps :  2427.860385751117
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0001, Value Loss: 5.5056, Entropy: 2.3760
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=114.4
Extrinsic raw: Œº=0.05040740740740741

=== Iteration 281/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 19.72s
update_step :  281
reward/intrinsic_batch_mean :  5.280804868534351e-05
reward/extrinsic_batch_mean :  0.05305185185185185
loss/policy :  -0.00032282377563233513
loss/rnd :  1.6906340785240128e-06
loss/value :  5.785546179973718
loss/value_i :  5.315274599772899e-06
loss/value_e :  5.785540876966534
loss/entropy :  2.3660878268155185
reward/intrinsic_running :  0.0021614885804379707
reward/extrinsic_running :  0.05305185185185185
reward/intrinsic_std_running :  0.03202997915322413
reward/extrinsic_std_running :  1.1019143027680143
reward/intrinsic_batch_std :  3.809682816216438e-05
reward/intrinsic_batch_max :  0.0008418358629569411
reward/intrinsic_batch_min :  4.7399475988640916e-06
reward/total_batch :  0.026552329950268596
time/iteration_time :  113.29987382888794
time/fps :  2383.056493141111
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2383
Policy Loss: -0.0003, Value Loss: 5.7855, Entropy: 2.3661
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=111.3
Extrinsic raw: Œº=0.05305185185185185

=== Iteration 282/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.35s
EPOCH 1 took 18.33s
update_step :  282
reward/intrinsic_batch_mean :  5.4082545149086166e-05
reward/extrinsic_batch_mean :  0.048740740740740744
loss/policy :  5.9078975799352385e-05
loss/rnd :  1.7438022913059588e-06
loss/value :  5.604630051237164
loss/value_i :  5.2169435259036785e-06
loss/value_e :  5.604624849377257
loss/entropy :  2.370790564652645
reward/intrinsic_running :  0.0021543849604522794
reward/extrinsic_running :  0.048740740740740744
reward/intrinsic_std_running :  0.0319733598883161
reward/extrinsic_std_running :  1.0814917198906537
reward/intrinsic_batch_std :  3.755073408737461e-05
reward/intrinsic_batch_max :  0.0006136882002465427
reward/intrinsic_batch_min :  5.596299615717726e-06
reward/total_batch :  0.024397411642944917
time/iteration_time :  112.1752200126648
time/fps :  2406.9487001631596
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0001, Value Loss: 5.6046, Entropy: 2.3708
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=114.2
Extrinsic raw: Œº=0.048740740740740744

=== Iteration 283/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 20.12s
update_step :  283
reward/intrinsic_batch_mean :  5.181536613365636e-05
reward/extrinsic_batch_mean :  0.05254074074074074
loss/policy :  -2.8918187044010583e-05
loss/rnd :  1.644565284922547e-06
loss/value :  5.433070327296401
loss/value_i :  5.173771231773461e-06
loss/value_e :  5.4330651615605206
loss/entropy :  2.373463171901125
reward/intrinsic_running :  0.00214730907568555
reward/extrinsic_running :  0.05254074074074074
reward/intrinsic_std_running :  0.03191704120971946
reward/extrinsic_std_running :  1.150912129496285
reward/intrinsic_batch_std :  3.553967248010967e-05
reward/intrinsic_batch_max :  0.0004911150899715722
reward/intrinsic_batch_min :  3.2039151847129688e-06
reward/total_batch :  0.0262962780534372
time/iteration_time :  113.33166289329529
time/fps :  2382.3880556152435
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2382
Policy Loss: -0.0000, Value Loss: 5.4331, Entropy: 2.3735
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=109.6
Extrinsic raw: Œº=0.05254074074074074

=== Iteration 284/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.88s
EPOCH 1 took 19.22s
update_step :  284
reward/intrinsic_batch_mean :  5.133686664688934e-05
reward/extrinsic_batch_mean :  0.053392592592592596
loss/policy :  -0.00023262363869104195
loss/rnd :  1.6402468490510231e-06
loss/value :  5.497399019472526
loss/value_i :  5.171135881303626e-06
loss/value_e :  5.497393846511841
loss/entropy :  2.373989289457148
reward/intrinsic_running :  0.0021402786354106445
reward/extrinsic_running :  0.053392592592592596
reward/intrinsic_std_running :  0.03186101934755626
reward/extrinsic_std_running :  1.1675588531207695
reward/intrinsic_batch_std :  3.6145590850336546e-05
reward/intrinsic_batch_max :  0.0007608290761709213
reward/intrinsic_batch_min :  2.6770978820422897e-06
reward/total_batch :  0.026721964729619744
time/iteration_time :  111.33341932296753
time/fps :  2425.1478275068152
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: -0.0002, Value Loss: 5.4974, Entropy: 2.3740
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=108.8
Extrinsic raw: Œº=0.053392592592592596

=== Iteration 285/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 19.96s
update_step :  285
reward/intrinsic_batch_mean :  5.4971375964184216e-05
reward/extrinsic_batch_mean :  0.051614814814814815
loss/policy :  8.490701139001457e-05
loss/rnd :  1.7512317761043739e-06
loss/value :  5.753012093630704
loss/value_i :  5.714288466730398e-06
loss/value_e :  5.753006414933638
loss/entropy :  2.372745987140771
reward/intrinsic_running :  0.002133330132941281
reward/extrinsic_running :  0.051614814814814815
reward/intrinsic_std_running :  0.031805289442458994
reward/extrinsic_std_running :  1.160001111015976
reward/intrinsic_batch_std :  3.803185715983359e-05
reward/intrinsic_batch_max :  0.000745255034416914
reward/intrinsic_batch_min :  3.178252882207744e-06
reward/total_batch :  0.0258348930953895
time/iteration_time :  112.75317406654358
time/fps :  2394.611080665933
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2395
Policy Loss: 0.0001, Value Loss: 5.7530, Entropy: 2.3727
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=116.7
Extrinsic raw: Œº=0.051614814814814815

=== Iteration 286/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.84s
EPOCH 1 took 18.96s
update_step :  286
reward/intrinsic_batch_mean :  5.4920806973462245e-05
reward/extrinsic_batch_mean :  0.05245925925925926
loss/policy :  -0.00032735515780972713
loss/rnd :  1.731004734513893e-06
loss/value :  5.652246309049202
loss/value_i :  5.4518242395164576e-06
loss/value_e :  5.652240839871493
loss/entropy :  2.3682577104279487
reward/intrinsic_running :  0.0021264268845565914
reward/extrinsic_running :  0.05245925925925926
reward/intrinsic_std_running :  0.03174985116285039
reward/extrinsic_std_running :  1.124895002593002
reward/intrinsic_batch_std :  3.849017052196354e-05
reward/intrinsic_batch_max :  0.0005228658556006849
reward/intrinsic_batch_min :  6.105227384978207e-06
reward/total_batch :  0.02625709003311636
time/iteration_time :  110.95128607749939
time/fps :  2433.5004085613323
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2434
Policy Loss: -0.0003, Value Loss: 5.6522, Entropy: 2.3683
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=116.8
Extrinsic raw: Œº=0.05245925925925926

=== Iteration 287/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 18.59s
update_step :  287
reward/intrinsic_batch_mean :  5.4209007034148304e-05
reward/extrinsic_batch_mean :  0.054429629629629626
loss/policy :  -0.00023241093643291882
loss/rnd :  1.731633927427152e-06
loss/value :  5.297435261986473
loss/value_i :  5.419619617786146e-06
loss/value_e :  5.297429814483181
loss/entropy :  2.3728705608483516
reward/intrinsic_running :  0.0021195641250700285
reward/extrinsic_running :  0.054429629629629626
reward/intrinsic_std_running :  0.0316947022420379
reward/extrinsic_std_running :  1.1845175641850256
reward/intrinsic_batch_std :  3.818822695631959e-05
reward/intrinsic_batch_max :  0.0007213071221485734
reward/intrinsic_batch_min :  4.85185546494904e-06
reward/total_batch :  0.02724191931833189
time/iteration_time :  111.49805045127869
time/fps :  2421.5670041511794
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: -0.0002, Value Loss: 5.2974, Entropy: 2.3729
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=115.4
Extrinsic raw: Œº=0.054429629629629626

=== Iteration 288/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.51s
EPOCH 1 took 18.46s
update_step :  288
reward/intrinsic_batch_mean :  5.434495760215483e-05
reward/extrinsic_batch_mean :  0.05208148148148148
loss/policy :  -2.2907082562927496e-05
loss/rnd :  1.7175817657571866e-06
loss/value :  5.5877836834300645
loss/value_i :  5.6801367615359295e-06
loss/value_e :  5.587778019182609
loss/entropy :  2.3709112550273086
reward/intrinsic_running :  0.0021127526986416847
reward/extrinsic_running :  0.05208148148148148
reward/intrinsic_std_running :  0.03163983946175148
reward/extrinsic_std_running :  1.1745710489009695
reward/intrinsic_batch_std :  3.799863559792521e-05
reward/intrinsic_batch_max :  0.0006057089776732028
reward/intrinsic_batch_min :  2.50289940595394e-06
reward/total_batch :  0.026067913219541817
time/iteration_time :  111.00421071052551
time/fps :  2432.3401632402974
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0000, Value Loss: 5.5878, Entropy: 2.3709
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=115.9
Extrinsic raw: Œº=0.05208148148148148

=== Iteration 289/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.77s
EPOCH 1 took 19.08s
update_step :  289
reward/intrinsic_batch_mean :  6.0265502358820585e-05
reward/extrinsic_batch_mean :  0.0534
loss/policy :  -8.341421683629353e-05
loss/rnd :  1.8840094295421406e-06
loss/value :  5.414436636549054
loss/value_i :  6.242770289397661e-06
loss/value_e :  5.414430387092359
loss/entropy :  2.3625269947629985
reward/intrinsic_running :  0.002106046652261569
reward/extrinsic_running :  0.0534
reward/intrinsic_std_running :  0.03158525812353616
reward/extrinsic_std_running :  1.1801774486789565
reward/intrinsic_batch_std :  6.217471928245775e-05
reward/intrinsic_batch_max :  0.0012866382021456957
reward/intrinsic_batch_min :  3.0802002584096044e-06
reward/total_batch :  0.02673013275117941
time/iteration_time :  112.31753420829773
time/fps :  2403.898927297258
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: -0.0001, Value Loss: 5.4144, Entropy: 2.3625
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=128.8
Extrinsic raw: Œº=0.0534

=== Iteration 290/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.77s
EPOCH 1 took 18.11s
update_step :  290
reward/intrinsic_batch_mean :  5.422315434357019e-05
reward/extrinsic_batch_mean :  0.05146666666666667
loss/policy :  0.00020099519557940462
loss/rnd :  1.6956925881486589e-06
loss/value :  6.0652579033013545
loss/value_i :  5.888136587545335e-06
loss/value_e :  6.065252029534542
loss/entropy :  2.369683272910841
reward/intrinsic_running :  0.002099325299940751
reward/extrinsic_running :  0.05146666666666667
reward/intrinsic_std_running :  0.03153096095664272
reward/extrinsic_std_running :  1.1593689522353994
reward/intrinsic_batch_std :  3.7212342664774236e-05
reward/intrinsic_batch_max :  0.0006206001853570342
reward/intrinsic_batch_min :  3.353316060383804e-06
reward/total_batch :  0.02576044491050512
time/iteration_time :  110.4882972240448
time/fps :  2443.6977198816107
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2444
Policy Loss: 0.0002, Value Loss: 6.0653, Entropy: 2.3697
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=116.1
Extrinsic raw: Œº=0.05146666666666667

=== Iteration 291/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.96s
EPOCH 1 took 18.83s
update_step :  291
reward/intrinsic_batch_mean :  5.5031184711013475e-05
reward/extrinsic_batch_mean :  0.05463703703703704
loss/policy :  -0.00019160707796055993
loss/rnd :  1.8571043972659744e-06
loss/value :  5.3866120251742275
loss/value_i :  6.6059236346380645e-06
loss/value_e :  5.386605421702067
loss/entropy :  2.375871271798105
reward/intrinsic_running :  0.0020926589529115655
reward/extrinsic_running :  0.05463703703703704
reward/intrinsic_std_running :  0.03147694234925285
reward/extrinsic_std_running :  1.2460574780596028
reward/intrinsic_batch_std :  3.970559535565378e-05
reward/intrinsic_batch_max :  0.0005631552776321769
reward/intrinsic_batch_min :  2.484942797309486e-06
reward/total_batch :  0.027346034110874027
time/iteration_time :  113.32324433326721
time/fps :  2382.5650385190984
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2383
Policy Loss: -0.0002, Value Loss: 5.3866, Entropy: 2.3759
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=118.0
Extrinsic raw: Œº=0.05463703703703704

=== Iteration 292/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 17.69s
EPOCH 1 took 19.27s
update_step :  292
reward/intrinsic_batch_mean :  5.753450968377702e-05
reward/extrinsic_batch_mean :  0.05700740740740741
loss/policy :  -9.395446420857104e-05
loss/rnd :  1.7693582328843838e-06
loss/value :  5.073520277485703
loss/value_i :  5.572816035331043e-06
loss/value_e :  5.073514707160719
loss/entropy :  2.376217170195146
reward/intrinsic_running :  0.002086062267676065
reward/extrinsic_running :  0.05700740740740741
reward/intrinsic_std_running :  0.03142319898753195
reward/extrinsic_std_running :  1.3131056514222237
reward/intrinsic_batch_std :  4.0538534589556146e-05
reward/intrinsic_batch_max :  0.0008201751625165343
reward/intrinsic_batch_min :  6.236866283870768e-06
reward/total_batch :  0.028532470958545594
time/iteration_time :  110.3670585155487
time/fps :  2446.382132780697
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: -0.0001, Value Loss: 5.0735, Entropy: 2.3762
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=123.6
Extrinsic raw: Œº=0.05700740740740741

=== Iteration 293/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.87s
EPOCH 1 took 18.53s
update_step :  293
reward/intrinsic_batch_mean :  5.619942158334231e-05
reward/extrinsic_batch_mean :  0.05594814814814815
loss/policy :  0.000619118988238783
loss/rnd :  1.7755722469149933e-06
loss/value :  5.624966130112156
loss/value_i :  5.832642197371267e-06
loss/value_e :  5.624960270794955
loss/entropy :  2.369906049786192
reward/intrinsic_running :  0.002079492766378235
reward/extrinsic_running :  0.05594814814814815
reward/intrinsic_std_running :  0.03136973098785389
reward/extrinsic_std_running :  1.2513427562453392
reward/intrinsic_batch_std :  3.81113559041494e-05
reward/intrinsic_batch_max :  0.0006660741637460887
reward/intrinsic_batch_min :  6.153261892904993e-06
reward/total_batch :  0.028002173784865747
time/iteration_time :  111.88484978675842
time/fps :  2413.195356785066
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0006, Value Loss: 5.6250, Entropy: 2.3699
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=120.9
Extrinsic raw: Œº=0.05594814814814815

=== Iteration 294/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.36s
EPOCH 1 took 19.08s
update_step :  294
reward/intrinsic_batch_mean :  5.413813907358013e-05
reward/extrinsic_batch_mean :  0.05865925925925926
loss/policy :  -2.3108487243227888e-05
loss/rnd :  1.7651251603252383e-06
loss/value :  5.382245591192534
loss/value_i :  5.820032315155417e-06
loss/value_e :  5.382239789673776
loss/entropy :  2.369077696944728
reward/intrinsic_running :  0.0020729513742077763
reward/extrinsic_running :  0.05865925925925926
reward/intrinsic_std_running :  0.03131653600620773
reward/extrinsic_std_running :  1.3192196832918455
reward/intrinsic_batch_std :  3.7038407637887184e-05
reward/intrinsic_batch_max :  0.0005209649098105729
reward/intrinsic_batch_min :  3.7185873225098476e-06
reward/total_batch :  0.02935669869916642
time/iteration_time :  111.01823425292969
time/fps :  2432.032916186243
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0000, Value Loss: 5.3822, Entropy: 2.3691
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=116.7
Extrinsic raw: Œº=0.05865925925925926

=== Iteration 295/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 18.46s
update_step :  295
reward/intrinsic_batch_mean :  5.733273803363975e-05
reward/extrinsic_batch_mean :  0.051385185185185187
loss/policy :  0.0003500095124102452
loss/rnd :  1.6785796012961576e-06
loss/value :  6.049522652770534
loss/value_i :  6.282915337303138e-06
loss/value_e :  6.049516352740201
loss/entropy :  2.36694166877053
reward/intrinsic_running :  0.0020664813333747412
reward/extrinsic_running :  0.051385185185185187
reward/intrinsic_std_running :  0.03126360907174122
reward/extrinsic_std_running :  1.1714348307710012
reward/intrinsic_batch_std :  3.684326226622015e-05
reward/intrinsic_batch_max :  0.0004822136543225497
reward/intrinsic_batch_min :  8.578541383030824e-06
reward/total_batch :  0.025721258961609414
time/iteration_time :  111.25415182113647
time/fps :  2426.875721762542
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2427
Policy Loss: 0.0004, Value Loss: 6.0495, Entropy: 2.3669
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=123.8
Extrinsic raw: Œº=0.051385185185185187

=== Iteration 296/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.42s
EPOCH 1 took 19.57s
update_step :  296
reward/intrinsic_batch_mean :  5.336193643609443e-05
reward/extrinsic_batch_mean :  0.05162962962962963
loss/policy :  -0.0004105656008698244
loss/rnd :  6.269466086216584e-06
loss/value :  5.892356475194295
loss/value_i :  4.956830765546659e-05
loss/value_e :  5.892306876905037
loss/entropy :  2.3601787090301514
reward/intrinsic_running :  0.0020600160393023674
reward/extrinsic_running :  0.05162962962962963
reward/intrinsic_std_running :  0.03121095194134378
reward/extrinsic_std_running :  1.185264907040964
reward/intrinsic_batch_std :  3.56256617442395e-05
reward/intrinsic_batch_max :  0.0005246541113592684
reward/intrinsic_batch_min :  2.245960104119149e-06
reward/total_batch :  0.025841495783032863
time/iteration_time :  112.69018054008484
time/fps :  2395.949662215323
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: -0.0004, Value Loss: 5.8924, Entropy: 2.3602
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=115.4
Extrinsic raw: Œº=0.05162962962962963

=== Iteration 297/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.65s
EPOCH 1 took 18.82s
update_step :  297
reward/intrinsic_batch_mean :  0.00014275817751865057
reward/extrinsic_batch_mean :  0.050444444444444445
loss/policy :  0.0002531122529145443
loss/rnd :  3.302276283965043e-06
loss/value :  6.626425222917036
loss/value_i :  5.594815671760113e-06
loss/value_e :  6.626419616468025
loss/entropy :  2.3706111113230386
reward/intrinsic_running :  0.002054451920303703
reward/extrinsic_running :  0.050444444444444445
reward/intrinsic_std_running :  0.03115851156576573
reward/extrinsic_std_running :  1.1302948593777653
reward/intrinsic_batch_std :  4.608142593311283e-05
reward/intrinsic_batch_max :  0.0009277171920984983
reward/intrinsic_batch_min :  5.0574766646604985e-05
reward/total_batch :  0.02529360131098155
time/iteration_time :  111.98889470100403
time/fps :  2410.953342479764
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0003, Value Loss: 6.6264, Entropy: 2.3706
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.030, sum=309.3
Extrinsic raw: Œº=0.050444444444444445

=== Iteration 298/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 20.29s
update_step :  298
reward/intrinsic_batch_mean :  5.382875493816957e-05
reward/extrinsic_batch_mean :  0.05209629629629629
loss/policy :  -8.971380091018297e-05
loss/rnd :  1.640318037681771e-06
loss/value :  5.877585859009714
loss/value_i :  5.5555826472272836e-06
loss/value_e :  5.877580317583951
loss/entropy :  2.3679788401632598
reward/intrinsic_running :  0.0020480739022591386
reward/extrinsic_running :  0.05209629629629629
reward/intrinsic_std_running :  0.031106382609016207
reward/extrinsic_std_running :  1.1871132329159086
reward/intrinsic_batch_std :  3.808713190953456e-05
reward/intrinsic_batch_max :  0.000775741646066308
reward/intrinsic_batch_min :  5.8858331613009796e-06
reward/total_batch :  0.02607506252561723
time/iteration_time :  111.88270449638367
time/fps :  2413.241628501455
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: -0.0001, Value Loss: 5.8776, Entropy: 2.3680
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=116.8
Extrinsic raw: Œº=0.05209629629629629

=== Iteration 299/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.88s
EPOCH 1 took 18.93s
update_step :  299
reward/intrinsic_batch_mean :  5.183551571816578e-05
reward/extrinsic_batch_mean :  0.059162962962962966
loss/policy :  0.0001892311124582634
loss/rnd :  1.6043103586884118e-06
loss/value :  6.014202645330718
loss/value_i :  5.324392153246056e-06
loss/value_e :  6.014197320649118
loss/entropy :  2.371602365464875
reward/intrinsic_running :  0.002041719299450704
reward/extrinsic_running :  0.059162962962962966
reward/intrinsic_std_running :  0.031054515589148728
reward/extrinsic_std_running :  1.2987856590900162
reward/intrinsic_batch_std :  3.638159601308889e-05
reward/intrinsic_batch_max :  0.0005762273794971406
reward/intrinsic_batch_min :  5.3767853387398645e-06
reward/total_batch :  0.029607399239340564
time/iteration_time :  110.61664009094238
time/fps :  2440.862421585235
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2441
Policy Loss: 0.0002, Value Loss: 6.0142, Entropy: 2.3716
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=112.7
Extrinsic raw: Œº=0.059162962962962966

=== Iteration 300/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.88s
EPOCH 1 took 19.89s
update_step :  300
reward/intrinsic_batch_mean :  5.3536667762536025e-05
reward/extrinsic_batch_mean :  0.05577777777777778
loss/policy :  -5.350094888302864e-05
loss/rnd :  1.6334980021824639e-06
loss/value :  6.86884957371336
loss/value_i :  5.795148016466445e-06
loss/value_e :  6.868843779419407
loss/entropy :  2.3709429068998857
reward/intrinsic_running :  0.002035422898972405
reward/extrinsic_running :  0.05577777777777778
reward/intrinsic_std_running :  0.03100290619789651
reward/extrinsic_std_running :  1.2507627105189425
reward/intrinsic_batch_std :  3.7750729074569776e-05
reward/intrinsic_batch_max :  0.0005336528993211687
reward/intrinsic_batch_min :  6.717341875628335e-06
reward/total_batch :  0.027915657222770156
time/iteration_time :  112.94105076789856
time/fps :  2390.6276607508116
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: -0.0001, Value Loss: 6.8688, Entropy: 2.3709
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=116.6
Extrinsic raw: Œº=0.05577777777777778

=== Iteration 301/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.17s
EPOCH 1 took 18.64s
update_step :  301
reward/intrinsic_batch_mean :  5.066384235903603e-05
reward/extrinsic_batch_mean :  0.05756296296296296
loss/policy :  -0.0001726686129007827
loss/rnd :  1.5709176199324606e-06
loss/value :  6.365912242369219
loss/value_i :  5.575048452087548e-06
loss/value_e :  6.365906686493845
loss/entropy :  2.3680851387255117
reward/intrinsic_running :  0.002029139093585887
reward/extrinsic_running :  0.05756296296296296
reward/intrinsic_std_running :  0.030951555013240203
reward/extrinsic_std_running :  1.2577675054983404
reward/intrinsic_batch_std :  3.549563868678998e-05
reward/intrinsic_batch_max :  0.0007011282141320407
reward/intrinsic_batch_min :  4.264798917574808e-06
reward/total_batch :  0.028806813402661
time/iteration_time :  110.30087733268738
time/fps :  2447.8499766201426
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.3s | FPS: 2448
Policy Loss: -0.0002, Value Loss: 6.3659, Entropy: 2.3681
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=110.5
Extrinsic raw: Œº=0.05756296296296296

=== Iteration 302/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 19.41s
update_step :  302
reward/intrinsic_batch_mean :  5.0284437453444333e-05
reward/extrinsic_batch_mean :  0.05798518518518519
loss/policy :  0.0004253136787817559
loss/rnd :  1.5601422591537288e-06
loss/value :  6.026827956690933
loss/value_i :  5.474768379303207e-06
loss/value_e :  6.026822480288419
loss/entropy :  2.3717819596781875
reward/intrinsic_running :  0.0020228912550055798
reward/extrinsic_running :  0.05798518518518519
reward/intrinsic_std_running :  0.030900458475925163
reward/extrinsic_std_running :  1.2712259815142297
reward/intrinsic_batch_std :  3.475496753990988e-05
reward/intrinsic_batch_max :  0.0005384843097999692
reward/intrinsic_batch_min :  5.997829248372e-06
reward/total_batch :  0.029017734811319317
time/iteration_time :  112.61887907981873
time/fps :  2397.4665900256146
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2397
Policy Loss: 0.0004, Value Loss: 6.0268, Entropy: 2.3718
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=109.8
Extrinsic raw: Œº=0.05798518518518519

=== Iteration 303/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.76s
EPOCH 1 took 18.07s
update_step :  303
reward/intrinsic_batch_mean :  5.4206233786711286e-05
reward/extrinsic_batch_mean :  0.052474074074074076
loss/policy :  8.669583687812768e-05
loss/rnd :  1.648921912681434e-06
loss/value :  6.522988131552031
loss/value_i :  5.898420037434941e-06
loss/value_e :  6.522982221661192
loss/entropy :  2.3679430918260054
reward/intrinsic_running :  0.002016720816625201
reward/extrinsic_running :  0.052474074074074076
reward/intrinsic_std_running :  0.030849612379587117
reward/extrinsic_std_running :  1.2136454838374167
reward/intrinsic_batch_std :  4.9208777782839315e-05
reward/intrinsic_batch_max :  0.0009577239397913218
reward/intrinsic_batch_min :  3.2275181638397044e-06
reward/total_batch :  0.026264140153930395
time/iteration_time :  111.9969220161438
time/fps :  2410.780538781957
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0001, Value Loss: 6.5230, Entropy: 2.3679
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=118.6
Extrinsic raw: Œº=0.052474074074074076

=== Iteration 304/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.69s
EPOCH 1 took 18.83s
update_step :  304
reward/intrinsic_batch_mean :  4.980538182372348e-05
reward/extrinsic_batch_mean :  0.05996296296296296
loss/policy :  -0.0005755231250077486
loss/rnd :  1.6087222778685717e-06
loss/value :  5.616960048675537
loss/value_i :  5.30960587776931e-06
loss/value_e :  5.616954738443548
loss/entropy :  2.371835553284847
reward/intrinsic_running :  0.0020105504127289633
reward/extrinsic_running :  0.05996296296296296
reward/intrinsic_std_running :  0.030799018509955957
reward/extrinsic_std_running :  1.3242107357601103
reward/intrinsic_batch_std :  3.4745260746394853e-05
reward/intrinsic_batch_max :  0.0005751709686592221
reward/intrinsic_batch_min :  4.801700924872421e-06
reward/total_batch :  0.030006384172393343
time/iteration_time :  113.79246759414673
time/fps :  2372.7405311482
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.8s | FPS: 2373
Policy Loss: -0.0006, Value Loss: 5.6170, Entropy: 2.3718
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=109.2
Extrinsic raw: Œº=0.05996296296296296

=== Iteration 305/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.30s
EPOCH 1 took 19.67s
update_step :  305
reward/intrinsic_batch_mean :  5.0942393462187115e-05
reward/extrinsic_batch_mean :  0.06526666666666667
loss/policy :  0.00034082119677667367
loss/rnd :  1.5704610329218365e-06
loss/value :  6.415135564226093
loss/value_i :  5.75071381221774e-06
loss/value_e :  6.415129842180194
loss/entropy :  2.365529118162213
reward/intrinsic_running :  0.0020044283810304905
reward/extrinsic_running :  0.06526666666666667
reward/intrinsic_std_running :  0.030748672364059097
reward/extrinsic_std_running :  1.3979864763824248
reward/intrinsic_batch_std :  4.194399053010152e-05
reward/intrinsic_batch_max :  0.0009296239586547017
reward/intrinsic_batch_min :  5.611988399323309e-06
reward/total_batch :  0.03265880453006443
time/iteration_time :  112.80637907981873
time/fps :  2393.4816647997836
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0003, Value Loss: 6.4151, Entropy: 2.3655
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=111.8
Extrinsic raw: Œº=0.06526666666666667

=== Iteration 306/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.35s
EPOCH 1 took 19.64s
update_step :  306
reward/intrinsic_batch_mean :  5.0294777805949575e-05
reward/extrinsic_batch_mean :  0.06482962962962963
loss/policy :  0.0001667166591439375
loss/rnd :  1.5439828396004238e-06
loss/value :  6.76200946894559
loss/value_i :  5.737249638872472e-06
loss/value_e :  6.76200371800047
loss/entropy :  2.3644176866068984
reward/intrinsic_running :  0.0019983418352004303
reward/extrinsic_running :  0.06482962962962963
reward/intrinsic_std_running :  0.03069857247760455
reward/extrinsic_std_running :  1.3642162614523308
reward/intrinsic_batch_std :  3.556133637900095e-05
reward/intrinsic_batch_max :  0.0004866917442996055
reward/intrinsic_batch_min :  5.456553935800912e-06
reward/total_batch :  0.03243996220371779
time/iteration_time :  111.8624165058136
time/fps :  2413.6793074371662
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: 0.0002, Value Loss: 6.7620, Entropy: 2.3644
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=110.6
Extrinsic raw: Œº=0.06482962962962963

=== Iteration 307/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.95s
EPOCH 1 took 20.53s
update_step :  307
reward/intrinsic_batch_mean :  5.048682560851645e-05
reward/extrinsic_batch_mean :  0.06556296296296296
loss/policy :  -0.0003217075795736023
loss/rnd :  1.5472093667939948e-06
loss/value :  6.448970707980069
loss/value_i :  5.8239467252309565e-06
loss/value_e :  6.4489649064613115
loss/entropy :  2.363955667524627
reward/intrinsic_running :  0.0019922915028740434
reward/extrinsic_running :  0.06556296296296296
reward/intrinsic_std_running :  0.03064871688843993
reward/extrinsic_std_running :  1.3668948379036026
reward/intrinsic_batch_std :  3.540494878942207e-05
reward/intrinsic_batch_max :  0.0005445715505629778
reward/intrinsic_batch_min :  3.545245590430568e-06
reward/total_batch :  0.03280672489428574
time/iteration_time :  115.40868806838989
time/fps :  2339.511907803692
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2340
Policy Loss: -0.0003, Value Loss: 6.4490, Entropy: 2.3640
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=111.2
Extrinsic raw: Œº=0.06556296296296296

=== Iteration 308/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.44s
EPOCH 1 took 18.51s
update_step :  308
reward/intrinsic_batch_mean :  5.225821300826081e-05
reward/extrinsic_batch_mean :  0.05973333333333333
loss/policy :  -6.413613410779473e-05
loss/rnd :  1.596382338158781e-06
loss/value :  7.700176961494215
loss/value_i :  6.215404834041362e-06
loss/value_e :  7.7001707337119365
loss/entropy :  2.361343123696067
reward/intrinsic_running :  0.0019862969392238977
reward/extrinsic_running :  0.05973333333333333
reward/intrinsic_std_running :  0.030599102476882648
reward/extrinsic_std_running :  1.2953944355692222
reward/intrinsic_batch_std :  4.053440754714617e-05
reward/intrinsic_batch_max :  0.0006692084134556353
reward/intrinsic_batch_min :  4.226588316669222e-06
reward/total_batch :  0.029892795773170798
time/iteration_time :  111.01992559432983
time/fps :  2431.995865198002
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0001, Value Loss: 7.7002, Entropy: 2.3613
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=115.3
Extrinsic raw: Œº=0.05973333333333333

=== Iteration 309/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 20.59s
update_step :  309
reward/intrinsic_batch_mean :  5.4700681374749735e-05
reward/extrinsic_batch_mean :  0.06254814814814814
loss/policy :  -1.9783652422836784e-05
loss/rnd :  1.6685958488585928e-06
loss/value :  7.197322831009373
loss/value_i :  5.940179224842613e-06
loss/value_e :  7.197316921118534
loss/entropy :  2.363133257085627
reward/intrinsic_running :  0.001980361821656147
reward/extrinsic_running :  0.06254814814814814
reward/intrinsic_std_running :  0.03054972713573661
reward/extrinsic_std_running :  1.3117414024650649
reward/intrinsic_batch_std :  4.5314106430010055e-05
reward/intrinsic_batch_max :  0.0008982755243778229
reward/intrinsic_batch_min :  3.3223009268112946e-06
reward/total_batch :  0.03130142441476145
time/iteration_time :  121.3341052532196
time/fps :  2225.260568217983
data/episodes_collected :  60
data/frames_collected :  270000
Timer 121.3s | FPS: 2225
Policy Loss: -0.0000, Value Loss: 7.1973, Entropy: 2.3631
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=120.9
Extrinsic raw: Œº=0.06254814814814814

=== Iteration 310/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.60s
EPOCH 1 took 18.76s
update_step :  310
reward/intrinsic_batch_mean :  5.19510425926388e-05
reward/extrinsic_batch_mean :  0.06358518518518519
loss/policy :  0.00010251775551516789
loss/rnd :  2.9732562094261192e-06
loss/value :  6.87787972797047
loss/value_i :  5.918149010099252e-06
loss/value_e :  6.8778738036300195
loss/entropy :  2.3630750504407017
reward/intrinsic_running :  0.0019744427794713445
reward/extrinsic_running :  0.06358518518518519
reward/intrinsic_std_running :  0.030500591231889477
reward/extrinsic_std_running :  1.326795596109135
reward/intrinsic_batch_std :  4.068581216295251e-05
reward/intrinsic_batch_max :  0.000832996389362961
reward/intrinsic_batch_min :  2.585965830803616e-06
reward/total_batch :  0.03181856811388891
time/iteration_time :  112.44597625732422
time/fps :  2401.153060222672
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0001, Value Loss: 6.8779, Entropy: 2.3631
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=115.0
Extrinsic raw: Œº=0.06358518518518519

=== Iteration 311/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.91s
update_step :  311
reward/intrinsic_batch_mean :  6.244895424548573e-05
reward/extrinsic_batch_mean :  0.06425185185185185
loss/policy :  0.0005489050086136117
loss/rnd :  1.8517500624318817e-06
loss/value :  6.317382046670625
loss/value_i :  5.8058611543718586e-06
loss/value_e :  6.31737622347745
loss/entropy :  2.3679726954662437
reward/intrinsic_running :  0.0019686523579329944
reward/extrinsic_running :  0.06425185185185185
reward/intrinsic_std_running :  0.030451686288027403
reward/extrinsic_std_running :  1.372900901273939
reward/intrinsic_batch_std :  4.250843400953599e-05
reward/intrinsic_batch_max :  0.0009864949388429523
reward/intrinsic_batch_min :  8.782787517702673e-06
reward/total_batch :  0.032157150403048666
time/iteration_time :  113.64531898498535
time/fps :  2375.8127691618515
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2376
Policy Loss: 0.0005, Value Loss: 6.3174, Entropy: 2.3680
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=138.4
Extrinsic raw: Œº=0.06425185185185185

=== Iteration 312/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.52s
EPOCH 1 took 18.35s
update_step :  312
reward/intrinsic_batch_mean :  5.220306056671015e-05
reward/extrinsic_batch_mean :  0.06399259259259259
loss/policy :  -0.00025430358778755885
loss/rnd :  1.5761878196165278e-06
loss/value :  7.330083153464577
loss/value_i :  6.174018518791082e-06
loss/value_e :  7.330077026829575
loss/entropy :  2.357866417277943
reward/intrinsic_running :  0.001962807978012326
reward/extrinsic_running :  0.06399259259259259
reward/intrinsic_std_running :  0.03040302118447641
reward/extrinsic_std_running :  1.3396176015802606
reward/intrinsic_batch_std :  3.845135884268275e-05
reward/intrinsic_batch_max :  0.000602278218138963
reward/intrinsic_batch_min :  4.754443580168299e-06
reward/total_batch :  0.032022397826579646
time/iteration_time :  110.00796031951904
time/fps :  2454.367840434299
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.0s | FPS: 2454
Policy Loss: -0.0003, Value Loss: 7.3301, Entropy: 2.3579
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=115.9
Extrinsic raw: Œº=0.06399259259259259

=== Iteration 313/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.08s
EPOCH 1 took 18.87s
update_step :  313
reward/intrinsic_batch_mean :  5.320646737085621e-05
reward/extrinsic_batch_mean :  0.05973333333333333
loss/policy :  0.0003229867065921567
loss/rnd :  1.6113128581172063e-06
loss/value :  7.181155349269058
loss/value_i :  5.835489280963719e-06
loss/value_e :  7.181149504401467
loss/entropy :  2.3608426397497
reward/intrinsic_running :  0.001957008548177731
reward/extrinsic_running :  0.05973333333333333
reward/intrinsic_std_running :  0.030354588301128714
reward/extrinsic_std_running :  1.2547282733723664
reward/intrinsic_batch_std :  4.3891558098816676e-05
reward/intrinsic_batch_max :  0.0008178992429748178
reward/intrinsic_batch_min :  5.304222668200964e-06
reward/total_batch :  0.029893269900352095
time/iteration_time :  112.4931914806366
time/fps :  2400.145257204077
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0003, Value Loss: 7.1812, Entropy: 2.3608
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=118.3
Extrinsic raw: Œº=0.05973333333333333

=== Iteration 314/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.73s
EPOCH 1 took 19.01s
update_step :  314
reward/intrinsic_batch_mean :  5.063501007891184e-05
reward/extrinsic_batch_mean :  0.06722962962962963
loss/policy :  0.00022828178198048562
loss/rnd :  1.5307757414782166e-06
loss/value :  6.246195431911584
loss/value_i :  5.206103237882913e-06
loss/value_e :  6.246190244501287
loss/entropy :  2.3639660929188584
reward/intrinsic_running :  0.0019512240328357741
reward/extrinsic_running :  0.06722962962962963
reward/intrinsic_std_running :  0.030306387326338412
reward/extrinsic_std_running :  1.3941725911582468
reward/intrinsic_batch_std :  3.490418004395519e-05
reward/intrinsic_batch_max :  0.0005303635844029486
reward/intrinsic_batch_min :  5.814613359689247e-06
reward/total_batch :  0.03364013231985427
time/iteration_time :  111.80342268943787
time/fps :  2414.952901307797
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0002, Value Loss: 6.2462, Entropy: 2.3640
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=112.8
Extrinsic raw: Œº=0.06722962962962963

=== Iteration 315/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 19.66s
update_step :  315
reward/intrinsic_batch_mean :  5.255720442272394e-05
reward/extrinsic_batch_mean :  0.061362962962962966
loss/policy :  0.0001936486307496318
loss/rnd :  1.5890392725823128e-06
loss/value :  7.557253909833504
loss/value_i :  6.343291605651647e-06
loss/value_e :  7.557247588128755
loss/entropy :  2.3560029882373232
reward/intrinsic_running :  0.0019454900216755308
reward/extrinsic_running :  0.061362962962962966
reward/intrinsic_std_running :  0.03025841444957991
reward/extrinsic_std_running :  1.2843492925582682
reward/intrinsic_batch_std :  3.913478051242248e-05
reward/intrinsic_batch_max :  0.0008150297217071056
reward/intrinsic_batch_min :  6.116670647315914e-06
reward/total_batch :  0.030707760083692845
time/iteration_time :  113.39799380302429
time/fps :  2380.9945039151053
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2381
Policy Loss: 0.0002, Value Loss: 7.5573, Entropy: 2.3560
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=117.2
Extrinsic raw: Œº=0.061362962962962966

=== Iteration 316/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.77s
EPOCH 1 took 19.71s
update_step :  316
reward/intrinsic_batch_mean :  5.009405325070273e-05
reward/extrinsic_batch_mean :  0.06897037037037038
loss/policy :  -0.00012752626295850584
loss/rnd :  1.5113055579521726e-06
loss/value :  6.730058561671864
loss/value_i :  5.3088626759056226e-06
loss/value_e :  6.730053251439875
loss/entropy :  2.358657128883131
reward/intrinsic_running :  0.0019397715232807192
reward/extrinsic_running :  0.06897037037037038
reward/intrinsic_std_running :  0.03021066988148309
reward/extrinsic_std_running :  1.4214554796417525
reward/intrinsic_batch_std :  3.555398058288967e-05
reward/intrinsic_batch_max :  0.0005154042155481875
reward/intrinsic_batch_min :  5.9853578022739384e-06
reward/total_batch :  0.034510232211810536
time/iteration_time :  112.39489412307739
time/fps :  2402.244355551757
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: -0.0001, Value Loss: 6.7301, Entropy: 2.3587
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=111.9
Extrinsic raw: Œº=0.06897037037037038

=== Iteration 317/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 18.36s
update_step :  317
reward/intrinsic_batch_mean :  5.00271339958393e-05
reward/extrinsic_batch_mean :  0.06576296296296297
loss/policy :  0.00015674274640552926
loss/rnd :  1.5097694420712122e-06
loss/value :  6.18050808617563
loss/value_i :  1.793251850689227e-05
loss/value_e :  6.180490139758948
loss/entropy :  2.364448738820625
reward/intrinsic_running :  0.0019340897594269035
reward/extrinsic_running :  0.06576296296296297
reward/intrinsic_std_running :  0.030163150567786484
reward/extrinsic_std_running :  1.4100884038869352
reward/intrinsic_batch_std :  3.477791943413867e-05
reward/intrinsic_batch_max :  0.0004973932518623769
reward/intrinsic_batch_min :  4.74214220957947e-06
reward/total_batch :  0.0329064950484794
time/iteration_time :  111.64890432357788
time/fps :  2418.2951157092702
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2418
Policy Loss: 0.0002, Value Loss: 6.1805, Entropy: 2.3644
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.016, sum=112.0
Extrinsic raw: Œº=0.06576296296296297

=== Iteration 318/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 18.78s
update_step :  318
reward/intrinsic_batch_mean :  5.048483871321002e-05
reward/extrinsic_batch_mean :  0.06882962962962963
loss/policy :  0.00028985260128551585
loss/rnd :  1.5196489643489204e-06
loss/value :  6.613918795730129
loss/value_i :  6.399196935848467e-06
loss/value_e :  6.61391239455252
loss/entropy :  2.364972215710264
reward/intrinsic_running :  0.0019284469236415527
reward/extrinsic_running :  0.06882962962962963
reward/intrinsic_std_running :  0.03011585459647182
reward/extrinsic_std_running :  1.4416411303621006
reward/intrinsic_batch_std :  3.648545676738351e-05
reward/intrinsic_batch_max :  0.0005599342985078692
reward/intrinsic_batch_min :  4.859972250415012e-06
reward/total_batch :  0.03444005723417142
time/iteration_time :  111.26919317245483
time/fps :  2426.547657099752
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2427
Policy Loss: 0.0003, Value Loss: 6.6139, Entropy: 2.3650
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=113.2
Extrinsic raw: Œº=0.06882962962962963

=== Iteration 319/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.21s
EPOCH 1 took 18.69s
update_step :  319
reward/intrinsic_batch_mean :  5.383786872731704e-05
reward/extrinsic_batch_mean :  0.0666
loss/policy :  0.00031102177639364857
loss/rnd :  1.617435652240767e-06
loss/value :  6.603099425633748
loss/value_i :  6.809525950412728e-06
loss/value_e :  6.6030926343166465
loss/entropy :  2.355937372554432
reward/intrinsic_running :  0.0019228677817974018
reward/extrinsic_running :  0.0666
reward/intrinsic_std_running :  0.030068778752818732
reward/extrinsic_std_running :  1.3920826375002415
reward/intrinsic_batch_std :  3.8812855610294434e-05
reward/intrinsic_batch_max :  0.000818433822132647
reward/intrinsic_batch_min :  5.184205292607658e-06
reward/total_batch :  0.03332691893436366
time/iteration_time :  111.77662134170532
time/fps :  2415.531948980636
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0003, Value Loss: 6.6031, Entropy: 2.3559
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=120.9
Extrinsic raw: Œº=0.0666

=== Iteration 320/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 19.45s
update_step :  320
reward/intrinsic_batch_mean :  5.2073744830718e-05
reward/extrinsic_batch_mean :  0.06602962962962963
loss/policy :  0.00018970883860619682
loss/rnd :  1.561675191803233e-06
loss/value :  6.806781393108946
loss/value_i :  5.749653065791018e-06
loss/value_e :  6.806775678287853
loss/entropy :  2.360650571909818
reward/intrinsic_running :  0.00191730475270748
reward/extrinsic_running :  0.06602962962962963
reward/intrinsic_std_running :  0.030021924100681278
reward/extrinsic_std_running :  1.4005935564014265
reward/intrinsic_batch_std :  3.923262738211829e-05
reward/intrinsic_batch_max :  0.0008909687167033553
reward/intrinsic_batch_min :  5.248576144367689e-06
reward/total_batch :  0.03304085168723018
time/iteration_time :  112.97273278236389
time/fps :  2389.9572343721293
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0002, Value Loss: 6.8068, Entropy: 2.3607
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=117.1
Extrinsic raw: Œº=0.06602962962962963

=== Iteration 321/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.01s
update_step :  321
reward/intrinsic_batch_mean :  5.269102905522569e-05
reward/extrinsic_batch_mean :  0.06586666666666667
loss/policy :  -6.900056949675535e-06
loss/rnd :  1.5784954040430999e-06
loss/value :  6.635890808972445
loss/value_i :  5.461689301172913e-06
loss/value_e :  6.635885332569932
loss/entropy :  2.3578495726440893
reward/intrinsic_running :  0.0019117816952945144
reward/extrinsic_running :  0.06586666666666667
reward/intrinsic_std_running :  0.029975287449991436
reward/extrinsic_std_running :  1.378749604210682
reward/intrinsic_batch_std :  3.642774554786428e-05
reward/intrinsic_batch_max :  0.0006068305228836834
reward/intrinsic_batch_min :  5.1203091970819514e-06
reward/total_batch :  0.03295967884786095
time/iteration_time :  111.01621913909912
time/fps :  2432.0770612958836
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: -0.0000, Value Loss: 6.6359, Entropy: 2.3578
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=118.7
Extrinsic raw: Œº=0.06586666666666667

=== Iteration 322/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 20.27s
update_step :  322
reward/intrinsic_batch_mean :  5.163631414806231e-05
reward/extrinsic_batch_mean :  0.06409629629629629
loss/policy :  0.0002279764834604452
loss/rnd :  1.5613654261759429e-06
loss/value :  6.553837848432137
loss/value_i :  1.607607989419855e-05
loss/value_e :  6.5538218165888935
loss/entropy :  2.35799604473692
reward/intrinsic_running :  0.0019062837117466667
reward/extrinsic_running :  0.06409629629629629
reward/intrinsic_std_running :  0.02992886801590743
reward/extrinsic_std_running :  1.350552355446133
reward/intrinsic_batch_std :  3.572909679594617e-05
reward/intrinsic_batch_max :  0.000495236658025533
reward/intrinsic_batch_min :  5.725747541873716e-06
reward/total_batch :  0.032073966305222176
time/iteration_time :  112.24711799621582
time/fps :  2405.4069700845457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2405
Policy Loss: 0.0002, Value Loss: 6.5538, Entropy: 2.3580
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=116.5
Extrinsic raw: Œº=0.06409629629629629

=== Iteration 323/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.76s
update_step :  323
reward/intrinsic_batch_mean :  7.765313320495706e-05
reward/extrinsic_batch_mean :  0.06185185185185185
loss/policy :  0.00023710979748460832
loss/rnd :  1.66852197136188e-06
loss/value :  6.535256161834255
loss/value_i :  2.2077795854398353e-05
loss/value_e :  6.5352340539296465
loss/entropy :  2.3598730925357705
reward/intrinsic_running :  0.0019010349964166844
reward/extrinsic_running :  0.06185185185185185
reward/intrinsic_std_running :  0.02988265121746933
reward/extrinsic_std_running :  1.3534552135512885
reward/intrinsic_batch_std :  4.075608015578183e-05
reward/intrinsic_batch_max :  0.0005831615417264402
reward/intrinsic_batch_min :  1.9982906451332383e-05
reward/total_batch :  0.030964752492528405
time/iteration_time :  112.13278150558472
time/fps :  2407.859649736351
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: 0.0002, Value Loss: 6.5353, Entropy: 2.3599
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.020, sum=175.4
Extrinsic raw: Œº=0.06185185185185185

=== Iteration 324/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.80s
EPOCH 1 took 20.08s
update_step :  324
reward/intrinsic_batch_mean :  5.3134645295513445e-05
reward/extrinsic_batch_mean :  0.0658962962962963
loss/policy :  0.00024598206668584186
loss/rnd :  1.5847292719296424e-06
loss/value :  6.62478467912385
loss/value_i :  6.476961488894603e-06
loss/value_e :  6.624778191248576
loss/entropy :  2.3638548742641103
reward/intrinsic_running :  0.0018956179274348273
reward/extrinsic_running :  0.0658962962962963
reward/intrinsic_std_running :  0.02983665936297923
reward/extrinsic_std_running :  1.400068216719372
reward/intrinsic_batch_std :  3.7356791325378474e-05
reward/intrinsic_batch_max :  0.0005114901578053832
reward/intrinsic_batch_min :  4.9863388085213955e-06
reward/total_batch :  0.032974715470795904
time/iteration_time :  112.80253744125366
time/fps :  2393.5631779614273
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0002, Value Loss: 6.6248, Entropy: 2.3639
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=120.2
Extrinsic raw: Œº=0.0658962962962963

=== Iteration 325/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.41s
EPOCH 1 took 18.61s
update_step :  325
reward/intrinsic_batch_mean :  5.134411038101529e-05
reward/extrinsic_batch_mean :  0.06697777777777777
loss/policy :  0.0001109877132076883
loss/rnd :  1.5449075269977832e-06
loss/value :  5.261655670223814
loss/value_i :  5.335472251593301e-06
loss/value_e :  5.2616503310926035
loss/entropy :  2.3753358739795107
reward/intrinsic_running :  0.0018902156701910448
reward/extrinsic_running :  0.06697777777777777
reward/intrinsic_std_running :  0.02979088028542316
reward/extrinsic_std_running :  1.4757380750569664
reward/intrinsic_batch_std :  3.777955969644663e-05
reward/intrinsic_batch_max :  0.000713311368599534
reward/intrinsic_batch_min :  4.718822765426012e-06
reward/total_batch :  0.0335145609440794
time/iteration_time :  111.26004123687744
time/fps :  2426.7472580309254
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2427
Policy Loss: 0.0001, Value Loss: 5.2617, Entropy: 2.3753
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=116.3
Extrinsic raw: Œº=0.06697777777777777

=== Iteration 326/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 19.43s
update_step :  326
reward/intrinsic_batch_mean :  5.252699731074783e-05
reward/extrinsic_batch_mean :  0.06875555555555556
loss/policy :  0.0005297791693726939
loss/rnd :  1.7627776235878463e-06
loss/value :  6.038310238809297
loss/value_i :  4.958757651338326e-06
loss/value_e :  6.038305282592773
loss/entropy :  2.3740512493884927
reward/intrinsic_running :  0.0018848558965374816
reward/extrinsic_running :  0.06875555555555556
reward/intrinsic_std_running :  0.02974531074293564
reward/extrinsic_std_running :  1.4513615853253201
reward/intrinsic_batch_std :  3.847466315443835e-05
reward/intrinsic_batch_max :  0.0007969833677634597
reward/intrinsic_batch_min :  4.7973239816201385e-06
reward/total_batch :  0.03440404127643315
time/iteration_time :  112.60417652130127
time/fps :  2397.779623644104
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0005, Value Loss: 6.0383, Entropy: 2.3741
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=119.2
Extrinsic raw: Œº=0.06875555555555556

=== Iteration 327/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 18.75s
update_step :  327
reward/intrinsic_batch_mean :  5.465665817643e-05
reward/extrinsic_batch_mean :  0.057385185185185185
loss/policy :  0.0008287426616968305
loss/rnd :  1.615684719912348e-06
loss/value :  7.633315606550737
loss/value_i :  5.683061407112153e-06
loss/value_e :  7.633309978427309
loss/entropy :  2.3666588284752588
reward/intrinsic_running :  0.001879545922104948
reward/extrinsic_running :  0.057385185185185185
reward/intrinsic_std_running :  0.029699948697754462
reward/extrinsic_std_running :  1.245352655603046
reward/intrinsic_batch_std :  3.9884332789715726e-05
reward/intrinsic_batch_max :  0.0005289218388497829
reward/intrinsic_batch_min :  4.862248260906199e-06
reward/total_batch :  0.028719920921680808
time/iteration_time :  111.49313163757324
time/fps :  2421.673837969494
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: 0.0008, Value Loss: 7.6333, Entropy: 2.3667
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=124.2
Extrinsic raw: Œº=0.057385185185185185

=== Iteration 328/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 19.39s
update_step :  328
reward/intrinsic_batch_mean :  5.439521457790559e-05
reward/extrinsic_batch_mean :  0.06322962962962964
loss/policy :  -0.0001724686748771505
loss/rnd :  1.6674176019175018e-06
loss/value :  6.527585217446992
loss/value_i :  7.798519652968741e-06
loss/value_e :  6.527577385757908
loss/entropy :  2.36964919350364
reward/intrinsic_running :  0.0018742629375662224
reward/extrinsic_running :  0.06322962962962964
reward/intrinsic_std_running :  0.029654793861079908
reward/extrinsic_std_running :  1.3691637671748063
reward/intrinsic_batch_std :  4.094670768787866e-05
reward/intrinsic_batch_max :  0.000738579488825053
reward/intrinsic_batch_min :  5.314044756232761e-06
reward/total_batch :  0.03164201242210377
time/iteration_time :  112.59566974639893
time/fps :  2397.9607795586226
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: -0.0002, Value Loss: 6.5276, Entropy: 2.3696
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=123.8
Extrinsic raw: Œº=0.06322962962962964

=== Iteration 329/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 18.13s
update_step :  329
reward/intrinsic_batch_mean :  0.00010158544321230794
reward/extrinsic_batch_mean :  0.06305925925925926
loss/policy :  0.0001695055283507276
loss/rnd :  2.5774634230291475e-06
loss/value :  6.571496450539791
loss/value_i :  5.218659900878485e-06
loss/value_e :  6.571491205331051
loss/entropy :  2.3671429699117486
reward/intrinsic_running :  0.001869401428888844
reward/extrinsic_running :  0.06305925925925926
reward/intrinsic_std_running :  0.029609822671355732
reward/extrinsic_std_running :  1.3577668935531904
reward/intrinsic_batch_std :  4.338953607540937e-05
reward/intrinsic_batch_max :  0.0009195904131047428
reward/intrinsic_batch_min :  3.352058774908073e-05
reward/total_batch :  0.03158042235123578
time/iteration_time :  112.00960159301758
time/fps :  2410.5076364884703
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0002, Value Loss: 6.5715, Entropy: 2.3671
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=231.6
Extrinsic raw: Œº=0.06305925925925926

=== Iteration 330/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 20.24s
update_step :  330
reward/intrinsic_batch_mean :  5.2825292173980014e-05
reward/extrinsic_batch_mean :  0.06739259259259259
loss/policy :  0.0003267589235099766
loss/rnd :  1.5150516753347993e-06
loss/value :  6.142954219471324
loss/value_i :  4.758174396336086e-06
loss/value_e :  6.142949472774159
loss/entropy :  2.3711141203389023
reward/intrinsic_running :  0.0018641712987297952
reward/extrinsic_running :  0.06739259259259259
reward/intrinsic_std_running :  0.02956507759853511
reward/extrinsic_std_running :  1.44170131542844
reward/intrinsic_batch_std :  3.71543246362508e-05
reward/intrinsic_batch_max :  0.000594462500885129
reward/intrinsic_batch_min :  6.680767000943888e-06
reward/total_batch :  0.03372270894238329
time/iteration_time :  114.08212018013
time/fps :  2366.716182813603
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0003, Value Loss: 6.1430, Entropy: 2.3711
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=120.6
Extrinsic raw: Œº=0.06739259259259259

=== Iteration 331/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.73s
EPOCH 1 took 19.76s
update_step :  331
reward/intrinsic_batch_mean :  5.329026458114607e-05
reward/extrinsic_batch_mean :  0.06497037037037037
loss/policy :  -2.921918745745312e-07
loss/rnd :  1.5061003130705848e-06
loss/value :  6.786481965671886
loss/value_i :  4.864376478508348e-06
loss/value_e :  6.786477117827444
loss/entropy :  2.3626345829530195
reward/intrinsic_running :  0.001858975910110526
reward/extrinsic_running :  0.06497037037037037
reward/intrinsic_std_running :  0.0295205345826638
reward/extrinsic_std_running :  1.3862944075149655
reward/intrinsic_batch_std :  3.720673445704728e-05
reward/intrinsic_batch_max :  0.0005780347855761647
reward/intrinsic_batch_min :  6.922416559973499e-06
reward/total_batch :  0.03251183031747576
time/iteration_time :  112.14960622787476
time/fps :  2407.498421808026
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2407
Policy Loss: -0.0000, Value Loss: 6.7865, Entropy: 2.3626
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=121.9
Extrinsic raw: Œº=0.06497037037037037

=== Iteration 332/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.24s
EPOCH 1 took 18.85s
update_step :  332
reward/intrinsic_batch_mean :  5.061409946640736e-05
reward/extrinsic_batch_mean :  0.06794074074074075
loss/policy :  0.00012594350537807313
loss/rnd :  1.4890104167038358e-06
loss/value :  6.256491950063994
loss/value_i :  4.85384139486114e-06
loss/value_e :  6.2564870877699414
loss/entropy :  2.3685291572050615
reward/intrinsic_running :  0.001853788401313863
reward/extrinsic_running :  0.06794074074074075
reward/intrinsic_std_running :  0.029476193635657552
reward/extrinsic_std_running :  1.4488586760464275
reward/intrinsic_batch_std :  3.610411321544098e-05
reward/intrinsic_batch_max :  0.000551111763343215
reward/intrinsic_batch_min :  3.2302186809829436e-06
reward/total_batch :  0.03399567742010358
time/iteration_time :  113.28651356697083
time/fps :  2383.337535057833
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2383
Policy Loss: 0.0001, Value Loss: 6.2565, Entropy: 2.3685
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=115.9
Extrinsic raw: Œº=0.06794074074074075

=== Iteration 333/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.61s
update_step :  333
reward/intrinsic_batch_mean :  5.056936870404132e-05
reward/extrinsic_batch_mean :  0.06456296296296296
loss/policy :  0.0005386968683028085
loss/rnd :  1.4876957851756192e-06
loss/value :  6.484465266719009
loss/value_i :  4.640963921205681e-06
loss/value_e :  6.484460621169119
loss/entropy :  2.3700018615433662
reward/intrinsic_running :  0.001848631364457176
reward/extrinsic_running :  0.06456296296296296
reward/intrinsic_std_running :  0.02943205196417933
reward/extrinsic_std_running :  1.3953607504202785
reward/intrinsic_batch_std :  3.8124013295527585e-05
reward/intrinsic_batch_max :  0.0005693238344974816
reward/intrinsic_batch_min :  3.893986104230862e-06
reward/total_batch :  0.0323067661658335
time/iteration_time :  110.89596152305603
time/fps :  2434.7144502991223
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2435
Policy Loss: 0.0005, Value Loss: 6.4845, Entropy: 2.3700
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=116.0
Extrinsic raw: Œº=0.06456296296296296

=== Iteration 334/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 19.24s
update_step :  334
reward/intrinsic_batch_mean :  5.085466345751263e-05
reward/extrinsic_batch_mean :  0.068
loss/policy :  0.0005147966824924052
loss/rnd :  1.4872683605613983e-06
loss/value :  5.312678922306407
loss/value_i :  5.128319923063497e-06
loss/value_e :  5.312673803531762
loss/entropy :  2.3692440661517056
reward/intrinsic_running :  0.0018435077652271723
reward/extrinsic_running :  0.068
reward/intrinsic_std_running :  0.02938810782096923
reward/extrinsic_std_running :  1.4891851114943022
reward/intrinsic_batch_std :  3.521518613468194e-05
reward/intrinsic_batch_max :  0.0005291428533382714
reward/intrinsic_batch_min :  5.86956639381242e-06
reward/total_batch :  0.03402542733172876
time/iteration_time :  112.94959950447083
time/fps :  2390.446723003323
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2390
Policy Loss: 0.0005, Value Loss: 5.3127, Entropy: 2.3692
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=116.8
Extrinsic raw: Œº=0.068

=== Iteration 335/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.76s
EPOCH 1 took 18.99s
update_step :  335
reward/intrinsic_batch_mean :  5.0464126443417894e-05
reward/extrinsic_batch_mean :  0.06963703703703704
loss/policy :  8.272390219975601e-05
loss/rnd :  1.7090886785808834e-06
loss/value :  5.489081989635121
loss/value_i :  4.4759832497110246e-06
loss/value_e :  5.4890775174805615
loss/entropy :  2.366140163306034
reward/intrinsic_running :  0.0018384137861760456
reward/extrinsic_running :  0.06963703703703704
reward/intrinsic_std_running :  0.029344359985449278
reward/extrinsic_std_running :  1.4746119193544898
reward/intrinsic_batch_std :  3.558523528669653e-05
reward/intrinsic_batch_max :  0.00045325569226406515
reward/intrinsic_batch_min :  5.122933544043917e-06
reward/total_batch :  0.034843750581740225
time/iteration_time :  111.39423680305481
time/fps :  2423.823778938945
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0001, Value Loss: 5.4891, Entropy: 2.3661
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=116.1
Extrinsic raw: Œº=0.06963703703703704

=== Iteration 336/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.18s
EPOCH 1 took 18.19s
update_step :  336
reward/intrinsic_batch_mean :  5.862373423225546e-05
reward/extrinsic_batch_mean :  0.06853333333333333
loss/policy :  0.00031799209748648786
loss/rnd :  1.5809667267989647e-06
loss/value :  6.7765623367193975
loss/value_i :  4.919289880710879e-06
loss/value_e :  6.776557431076512
loss/entropy :  2.3516585104393237
reward/intrinsic_running :  0.0018334114951984194
reward/extrinsic_running :  0.06853333333333333
reward/intrinsic_std_running :  0.029300803430075087
reward/extrinsic_std_running :  1.4199111333695027
reward/intrinsic_batch_std :  3.931774273328918e-05
reward/intrinsic_batch_max :  0.000878930208273232
reward/intrinsic_batch_min :  8.281304872070905e-06
reward/total_batch :  0.034295978533782794
time/iteration_time :  112.43070673942566
time/fps :  2401.479167304034
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0003, Value Loss: 6.7766, Entropy: 2.3517
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=135.1
Extrinsic raw: Œº=0.06853333333333333

=== Iteration 337/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.75s
EPOCH 1 took 19.30s
update_step :  337
reward/intrinsic_batch_mean :  5.075570852934982e-05
reward/extrinsic_batch_mean :  0.06311111111111112
loss/policy :  0.0008759855920674675
loss/rnd :  1.5007816104474787e-06
loss/value :  6.284221540797841
loss/value_i :  2.0601973071252083e-05
loss/value_e :  6.284200913978346
loss/entropy :  2.354424570546006
reward/intrinsic_running :  0.001828377282422355
reward/extrinsic_running :  0.06311111111111112
reward/intrinsic_std_running :  0.029257443823921602
reward/extrinsic_std_running :  1.3588456248223215
reward/intrinsic_batch_std :  3.969250400349355e-05
reward/intrinsic_batch_max :  0.0009332843474112451
reward/intrinsic_batch_min :  4.661452294385526e-06
reward/total_batch :  0.03158093340982023
time/iteration_time :  112.74287700653076
time/fps :  2394.829785870729
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0009, Value Loss: 6.2842, Entropy: 2.3544
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=117.1
Extrinsic raw: Œº=0.06311111111111112

=== Iteration 338/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 18.97s
update_step :  338
reward/intrinsic_batch_mean :  6.395407831137331e-05
reward/extrinsic_batch_mean :  0.06471851851851852
loss/policy :  7.931428262963891e-05
loss/rnd :  3.343046490623568e-06
loss/value :  6.458590399135243
loss/value_i :  5.198819242953808e-05
loss/value_e :  6.458538416660193
loss/entropy :  2.3573967110026968
reward/intrinsic_running :  0.0018234761649673925
reward/extrinsic_running :  0.06471851851851852
reward/intrinsic_std_running :  0.02921427021542431
reward/extrinsic_std_running :  1.406456156717363
reward/intrinsic_batch_std :  3.8461852469999765e-05
reward/intrinsic_batch_max :  0.0008458895026706159
reward/intrinsic_batch_min :  1.2043420611007605e-05
reward/total_batch :  0.03239123629841495
time/iteration_time :  112.06617975234985
time/fps :  2409.290658400788
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0001, Value Loss: 6.4586, Entropy: 2.3574
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=147.8
Extrinsic raw: Œº=0.06471851851851852

=== Iteration 339/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.31s
EPOCH 1 took 19.88s
update_step :  339
reward/intrinsic_batch_mean :  6.651397088699687e-05
reward/extrinsic_batch_mean :  0.06948888888888889
loss/policy :  0.00029339746481238046
loss/rnd :  1.6768055543665965e-06
loss/value :  5.868212172479341
loss/value_i :  5.626240512025436e-06
loss/value_e :  5.868206558805523
loss/entropy :  2.3569412845553774
reward/intrinsic_running :  0.0018186255066909179
reward/extrinsic_running :  0.06948888888888889
reward/intrinsic_std_running :  0.029171285977602587
reward/extrinsic_std_running :  1.489115135546469
reward/intrinsic_batch_std :  4.004138569809569e-05
reward/intrinsic_batch_max :  0.0005386550910770893
reward/intrinsic_batch_min :  9.033242349687498e-06
reward/total_batch :  0.034777701429887946
time/iteration_time :  112.22213363647461
time/fps :  2405.9424932573565
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0003, Value Loss: 5.8682, Entropy: 2.3569
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=153.9
Extrinsic raw: Œº=0.06948888888888889

=== Iteration 340/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.46s
EPOCH 1 took 19.18s
update_step :  340
reward/intrinsic_batch_mean :  5.287591232722156e-05
reward/extrinsic_batch_mean :  0.06558518518518519
loss/policy :  0.0004496668327853761
loss/rnd :  1.5227478332814248e-06
loss/value :  7.192784294937596
loss/value_i :  4.694168279511911e-06
loss/value_e :  7.19277961326368
loss/entropy :  2.348601084766966
reward/intrinsic_running :  0.0018136942925721913
reward/extrinsic_running :  0.06558518518518519
reward/intrinsic_std_running :  0.029128497070902593
reward/extrinsic_std_running :  1.378760336304213
reward/intrinsic_batch_std :  3.831637589586654e-05
reward/intrinsic_batch_max :  0.0007102086092345417
reward/intrinsic_batch_min :  5.6608864724694286e-06
reward/total_batch :  0.032819030548756206
time/iteration_time :  112.56767868995667
time/fps :  2398.557056005895
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0004, Value Loss: 7.1928, Entropy: 2.3486
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=122.5
Extrinsic raw: Œº=0.06558518518518519

=== Iteration 341/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.89s
EPOCH 1 took 19.28s
update_step :  341
reward/intrinsic_batch_mean :  5.195385990954391e-05
reward/extrinsic_batch_mean :  0.06756296296296296
loss/policy :  0.00021420672926593176
loss/rnd :  1.5079588809964084e-06
loss/value :  5.859075343970097
loss/value_i :  4.7907730290854955e-06
loss/value_e :  5.859070568373709
loss/entropy :  2.3499304056167603
reward/intrinsic_running :  0.0018087847380285039
reward/extrinsic_running :  0.06756296296296296
reward/intrinsic_std_running :  0.02908589634732562
reward/extrinsic_std_running :  1.4267114692207512
reward/intrinsic_batch_std :  4.02485181025958e-05
reward/intrinsic_batch_max :  0.000899656442925334
reward/intrinsic_batch_min :  2.547936446717358e-06
reward/total_batch :  0.03380745841143625
time/iteration_time :  111.90975999832153
time/fps :  2412.6581989278643
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0002, Value Loss: 5.8591, Entropy: 2.3499
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=120.6
Extrinsic raw: Œº=0.06756296296296296

=== Iteration 342/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.60s
EPOCH 1 took 19.00s
update_step :  342
reward/intrinsic_batch_mean :  5.568801037237184e-05
reward/extrinsic_batch_mean :  0.05551111111111111
loss/policy :  -7.937941788413534e-05
loss/rnd :  1.614066086335008e-06
loss/value :  6.930515542174831
loss/value_i :  5.5997121914212284e-06
loss/value_e :  6.93050995017543
loss/entropy :  2.342683181618199
reward/intrinsic_running :  0.0018039302553445608
reward/extrinsic_running :  0.05551111111111111
reward/intrinsic_std_running :  0.02904348061821201
reward/extrinsic_std_running :  1.2134951043968254
reward/intrinsic_batch_std :  4.8002143167849794e-05
reward/intrinsic_batch_max :  0.0010003549978137016
reward/intrinsic_batch_min :  4.387145509099355e-06
reward/total_batch :  0.02778339956074174
time/iteration_time :  111.55367851257324
time/fps :  2420.3594502674177
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: -0.0001, Value Loss: 6.9305, Entropy: 2.3427
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.034, sum=129.4
Extrinsic raw: Œº=0.05551111111111111

=== Iteration 343/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.16s
EPOCH 1 took 20.01s
update_step :  343
reward/intrinsic_batch_mean :  5.234073440563036e-05
reward/extrinsic_batch_mean :  0.06877777777777777
loss/policy :  0.00023203257991223256
loss/rnd :  1.5152910119661211e-06
loss/value :  5.5235240531690195
loss/value_i :  4.5391731157106925e-06
loss/value_e :  5.523519508766405
loss/entropy :  2.357615434762203
reward/intrinsic_running :  0.0017990782753229094
reward/extrinsic_running :  0.06877777777777777
reward/intrinsic_std_running :  0.029001251206066538
reward/extrinsic_std_running :  1.471579897614033
reward/intrinsic_batch_std :  3.631361089521021e-05
reward/intrinsic_batch_max :  0.0005365053657442331
reward/intrinsic_batch_min :  4.900195108348271e-06
reward/total_batch :  0.0344150592560917
time/iteration_time :  113.1052668094635
time/fps :  2387.15674005562
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2387
Policy Loss: 0.0002, Value Loss: 5.5235, Entropy: 2.3576
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=121.8
Extrinsic raw: Œº=0.06877777777777777

=== Iteration 344/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.88s
EPOCH 1 took 18.57s
update_step :  344
reward/intrinsic_batch_mean :  4.910875517095216e-05
reward/extrinsic_batch_mean :  0.07086666666666666
loss/policy :  0.0001416923515727941
loss/rnd :  1.4217298037306825e-06
loss/value :  5.025617841518287
loss/value_i :  4.40499815285324e-06
loss/value_e :  5.025613456061392
loss/entropy :  2.361690485116207
reward/intrinsic_running :  0.0017942282436345094
reward/extrinsic_running :  0.07086666666666666
reward/intrinsic_std_running :  0.028959206958893733
reward/extrinsic_std_running :  1.4984646923014486
reward/intrinsic_batch_std :  3.4997885697608886e-05
reward/intrinsic_batch_max :  0.0007468334515579045
reward/intrinsic_batch_min :  4.723286565422313e-06
reward/total_batch :  0.0354578877109188
time/iteration_time :  112.27443361282349
time/fps :  2404.821750703197
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0001, Value Loss: 5.0256, Entropy: 2.3617
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=114.5
Extrinsic raw: Œº=0.07086666666666666

=== Iteration 345/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.08s
EPOCH 1 took 19.52s
update_step :  345
reward/intrinsic_batch_mean :  5.09503489925919e-05
reward/extrinsic_batch_mean :  0.06266666666666666
loss/policy :  0.0004514631847004321
loss/rnd :  1.4659289828352595e-06
loss/value :  6.446667396661007
loss/value_i :  4.533680291360449e-06
loss/value_e :  6.446662895607226
loss/entropy :  2.3517359748031152
reward/intrinsic_running :  0.0017894216966864902
reward/extrinsic_running :  0.06266666666666666
reward/intrinsic_std_running :  0.028917344156009935
reward/extrinsic_std_running :  1.36701849129979
reward/intrinsic_batch_std :  3.5064953998900956e-05
reward/intrinsic_batch_max :  0.0005426275893114507
reward/intrinsic_batch_min :  5.274565410218202e-06
reward/total_batch :  0.03135880850782963
time/iteration_time :  114.1020233631134
time/fps :  2366.303348896483
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0005, Value Loss: 6.4467, Entropy: 2.3517
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=118.9
Extrinsic raw: Œº=0.06266666666666666

=== Iteration 346/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 19.28s
update_step :  346
reward/intrinsic_batch_mean :  5.017173941743278e-05
reward/extrinsic_batch_mean :  0.0661925925925926
loss/policy :  0.0005051341537513177
loss/rnd :  1.446347356925275e-06
loss/value :  6.36452595392863
loss/value_i :  4.448566208090845e-06
loss/value_e :  6.364521496223681
loss/entropy :  2.3614405140732275
reward/intrinsic_running :  0.001784635451981629
reward/extrinsic_running :  0.0661925925925926
reward/intrinsic_std_running :  0.028875662809382065
reward/extrinsic_std_running :  1.4115935386872698
reward/intrinsic_batch_std :  3.538764979372296e-05
reward/intrinsic_batch_max :  0.0005094123771414161
reward/intrinsic_batch_min :  5.088143552711699e-06
reward/total_batch :  0.03312138216600501
time/iteration_time :  111.90872263908386
time/fps :  2412.680563522965
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0005, Value Loss: 6.3645, Entropy: 2.3614
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=117.3
Extrinsic raw: Œº=0.0661925925925926

=== Iteration 347/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 19.86s
update_step :  347
reward/intrinsic_batch_mean :  5.1707418484801125e-05
reward/extrinsic_batch_mean :  0.06973333333333333
loss/policy :  0.00010296910179683685
loss/rnd :  1.4889729568908066e-06
loss/value :  6.543245842962554
loss/value_i :  4.31263221357905e-06
loss/value_e :  6.54324155142813
loss/entropy :  2.3567441918633203
reward/intrinsic_running :  0.0017798884378141264
reward/extrinsic_running :  0.06973333333333333
reward/intrinsic_std_running :  0.028834160549260256
reward/extrinsic_std_running :  1.459975977478676
reward/intrinsic_batch_std :  3.9188897672307145e-05
reward/intrinsic_batch_max :  0.0008368380949832499
reward/intrinsic_batch_min :  4.290329343348276e-06
reward/total_batch :  0.034892520375909064
time/iteration_time :  112.76006603240967
time/fps :  2394.4647205367564
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0001, Value Loss: 6.5432, Entropy: 2.3567
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=121.0
Extrinsic raw: Œº=0.06973333333333333

=== Iteration 348/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 18.67s
update_step :  348
reward/intrinsic_batch_mean :  5.199623930672075e-05
reward/extrinsic_batch_mean :  0.0656
loss/policy :  2.6865294344271675e-05
loss/rnd :  1.4962521528573371e-06
loss/value :  6.198417555202138
loss/value_i :  4.512255545154348e-06
loss/value_e :  6.198413046923551
loss/entropy :  2.3545842531955605
reward/intrinsic_running :  0.001775169146475445
reward/extrinsic_running :  0.0656
reward/intrinsic_std_running :  0.028792836679386483
reward/extrinsic_std_running :  1.4200444604411613
reward/intrinsic_batch_std :  3.7534266223003823e-05
reward/intrinsic_batch_max :  0.0005608205683529377
reward/intrinsic_batch_min :  4.806357992492849e-06
reward/total_batch :  0.032825998119653366
time/iteration_time :  110.92413020133972
time/fps :  2434.096165639701
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2434
Policy Loss: 0.0000, Value Loss: 6.1984, Entropy: 2.3546
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=121.9
Extrinsic raw: Œº=0.0656

=== Iteration 349/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 19.38s
update_step :  349
reward/intrinsic_batch_mean :  5.0180112206685916e-05
reward/extrinsic_batch_mean :  0.06461481481481482
loss/policy :  0.0004294640419891838
loss/rnd :  1.478357167646512e-06
loss/value :  5.995384931564331
loss/value_i :  4.454284359753453e-06
loss/value_e :  5.9953805027586045
loss/entropy :  2.356984889868534
reward/intrinsic_running :  0.0017704647368352912
reward/extrinsic_running :  0.06461481481481482
reward/intrinsic_std_running :  0.02875169065266612
reward/extrinsic_std_running :  1.4058735651764713
reward/intrinsic_batch_std :  3.483777105938053e-05
reward/intrinsic_batch_max :  0.0005495927762240171
reward/intrinsic_batch_min :  5.173652880330337e-06
reward/total_batch :  0.03233249746351075
time/iteration_time :  111.95304298400879
time/fps :  2411.7254234756833
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2412
Policy Loss: 0.0004, Value Loss: 5.9954, Entropy: 2.3570
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=117.8
Extrinsic raw: Œº=0.06461481481481482

=== Iteration 350/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.24s
EPOCH 1 took 18.79s
update_step :  350
reward/intrinsic_batch_mean :  6.175381800156308e-05
reward/extrinsic_batch_mean :  0.06873333333333333
loss/policy :  0.00022409366713625124
loss/rnd :  1.5820034766902884e-06
loss/value :  6.324051329583833
loss/value_i :  4.868097662300428e-06
loss/value_e :  6.324046452840169
loss/entropy :  2.3550783901503594
reward/intrinsic_running :  0.0017658730113286282
reward/extrinsic_running :  0.06873333333333333
reward/intrinsic_std_running :  0.028710715713133092
reward/extrinsic_std_running :  1.4204139287154607
reward/intrinsic_batch_std :  3.9645600509376746e-05
reward/intrinsic_batch_max :  0.0006785611039958894
reward/intrinsic_batch_min :  1.1347909094183706e-05
reward/total_batch :  0.03439754357566745
time/iteration_time :  110.5858633518219
time/fps :  2441.5417289008465
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2442
Policy Loss: 0.0002, Value Loss: 6.3241, Entropy: 2.3551
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=145.2
Extrinsic raw: Œº=0.06873333333333333

=== Iteration 351/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.17s
EPOCH 1 took 18.79s
update_step :  351
reward/intrinsic_batch_mean :  5.366702620547046e-05
reward/extrinsic_batch_mean :  0.06739259259259259
loss/policy :  0.00019705487912605432
loss/rnd :  1.5533259787651221e-06
loss/value :  6.140704783526334
loss/value_i :  4.6661035536420634e-06
loss/value_e :  6.140700116302028
loss/entropy :  2.3558979829152427
reward/intrinsic_running :  0.0017612445803042397
reward/extrinsic_running :  0.06739259259259259
reward/intrinsic_std_running :  0.028669918974618364
reward/extrinsic_std_running :  1.4262041363225848
reward/intrinsic_batch_std :  3.782264180320521e-05
reward/intrinsic_batch_max :  0.0005763010703958571
reward/intrinsic_batch_min :  4.692467427958036e-06
reward/total_batch :  0.03372312980939903
time/iteration_time :  112.8271005153656
time/fps :  2393.0420862249266
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0002, Value Loss: 6.1407, Entropy: 2.3559
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=126.4
Extrinsic raw: Œº=0.06739259259259259

=== Iteration 352/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.68s
update_step :  352
reward/intrinsic_batch_mean :  5.619642796134064e-05
reward/extrinsic_batch_mean :  0.06555555555555556
loss/policy :  6.165703907203296e-05
loss/rnd :  1.8525952207186713e-06
loss/value :  7.516569469914292
loss/value_i :  6.607036236043011e-06
loss/value_e :  7.516562837542909
loss/entropy :  2.3506474205941865
reward/intrinsic_running :  0.0017566608409174827
reward/extrinsic_running :  0.06555555555555556
reward/intrinsic_std_running :  0.028629294620597826
reward/extrinsic_std_running :  1.3668965479653192
reward/intrinsic_batch_std :  3.706609746632471e-05
reward/intrinsic_batch_max :  0.0005180774605832994
reward/intrinsic_batch_min :  7.463847850885941e-06
reward/total_batch :  0.03280587599175845
time/iteration_time :  112.0746738910675
time/fps :  2409.108058279341
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0001, Value Loss: 7.5166, Entropy: 2.3506
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=132.5
Extrinsic raw: Œº=0.06555555555555556

=== Iteration 353/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.55s
EPOCH 1 took 19.81s
update_step :  353
reward/intrinsic_batch_mean :  5.4914920664183836e-05
reward/extrinsic_batch_mean :  0.0704074074074074
loss/policy :  0.00037883190805476977
loss/rnd :  1.5054862215589364e-06
loss/value :  5.155815247333411
loss/value_i :  4.6716748632510035e-06
loss/value_e :  5.1558105728843
loss/entropy :  2.352507674332821
reward/intrinsic_running :  0.001752095217449087
reward/extrinsic_running :  0.0704074074074074
reward/intrinsic_std_running :  0.02858884289505054
reward/extrinsic_std_running :  1.4970051030185734
reward/intrinsic_batch_std :  3.5583995465714865e-05
reward/intrinsic_batch_max :  0.0005773116135969758
reward/intrinsic_batch_min :  6.739750460837968e-06
reward/total_batch :  0.035231161164035796
time/iteration_time :  114.05202269554138
time/fps :  2367.3407416960704
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0004, Value Loss: 5.1558, Entropy: 2.3525
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=129.7
Extrinsic raw: Œº=0.0704074074074074

=== Iteration 354/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.22s
EPOCH 1 took 19.75s
update_step :  354
reward/intrinsic_batch_mean :  5.18566914211853e-05
reward/extrinsic_batch_mean :  0.06657037037037038
loss/policy :  0.0002029886747936182
loss/rnd :  1.48025692293562e-06
loss/value :  5.601200327728733
loss/value_i :  4.538944825650436e-06
loss/value_e :  5.60119578332612
loss/entropy :  2.3570560253027715
reward/intrinsic_running :  0.0017475287921396706
reward/extrinsic_running :  0.06657037037037038
reward/intrinsic_std_running :  0.02854856365940434
reward/extrinsic_std_running :  1.412662922970975
reward/intrinsic_batch_std :  3.824006793959093e-05
reward/intrinsic_batch_max :  0.00063596066320315
reward/intrinsic_batch_min :  3.957502485718578e-06
reward/total_batch :  0.03331111353089578
time/iteration_time :  111.40926742553711
time/fps :  2423.496772209373
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: 0.0002, Value Loss: 5.6012, Entropy: 2.3571
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=122.6
Extrinsic raw: Œº=0.06657037037037038

=== Iteration 355/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.64s
EPOCH 1 took 18.65s
update_step :  355
reward/intrinsic_batch_mean :  5.344847984676259e-05
reward/extrinsic_batch_mean :  0.06962962962962962
loss/policy :  0.00037257418063580354
loss/rnd :  1.527405288470618e-06
loss/value :  5.789622249025287
loss/value_i :  4.761853040580525e-06
loss/value_e :  5.789617466204094
loss/entropy :  2.347643736637
reward/intrinsic_running :  0.0017430029478711577
reward/extrinsic_running :  0.06962962962962962
reward/intrinsic_std_running :  0.02850845336911953
reward/extrinsic_std_running :  1.4645324914051387
reward/intrinsic_batch_std :  3.898130012348099e-05
reward/intrinsic_batch_max :  0.00088817736832425
reward/intrinsic_batch_min :  4.932312094751978e-06
reward/total_batch :  0.03484153905473819
time/iteration_time :  111.71258902549744
time/fps :  2416.9165029231826
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0004, Value Loss: 5.7896, Entropy: 2.3476
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=126.6
Extrinsic raw: Œº=0.06962962962962962

=== Iteration 356/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.94s
EPOCH 1 took 19.08s
update_step :  356
reward/intrinsic_batch_mean :  5.422822824678372e-05
reward/extrinsic_batch_mean :  0.06462222222222222
loss/policy :  0.0005553156529045241
loss/rnd :  3.117801192977574e-06
loss/value :  5.4799135598269375
loss/value_i :  4.942096135588751e-06
loss/value_e :  5.479908625284831
loss/entropy :  2.357883171601729
reward/intrinsic_running :  0.0017385073509256547
reward/extrinsic_running :  0.06462222222222222
reward/intrinsic_std_running :  0.0284685114080031
reward/extrinsic_std_running :  1.4059245955580484
reward/intrinsic_batch_std :  3.845496129927969e-05
reward/intrinsic_batch_max :  0.0005920171970501542
reward/intrinsic_batch_min :  5.969202447886346e-06
reward/total_batch :  0.0323382252252345
time/iteration_time :  111.73415565490723
time/fps :  2416.44999613099
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2416
Policy Loss: 0.0006, Value Loss: 5.4799, Entropy: 2.3579
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=128.6
Extrinsic raw: Œº=0.06462222222222222

=== Iteration 357/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 18.89s
update_step :  357
reward/intrinsic_batch_mean :  9.629250253072112e-05
reward/extrinsic_batch_mean :  0.06563703703703704
loss/policy :  0.0005799180935630857
loss/rnd :  1.892787837953096e-06
loss/value :  5.920801942998713
loss/value_i :  5.780556662240556e-06
loss/value_e :  5.92079614870476
loss/entropy :  2.349061965942383
reward/intrinsic_running :  0.0017343412552442573
reward/extrinsic_running :  0.06563703703703704
reward/intrinsic_std_running :  0.02842872054807747
reward/extrinsic_std_running :  1.4095649189911337
reward/intrinsic_batch_std :  4.719759622237825e-05
reward/intrinsic_batch_max :  0.0008742086356505752
reward/intrinsic_batch_min :  2.60073684330564e-05
reward/total_batch :  0.03286666476978388
time/iteration_time :  111.57857084274292
time/fps :  2419.8194864902307
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0006, Value Loss: 5.9208, Entropy: 2.3491
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=228.6
Extrinsic raw: Œº=0.06563703703703704

=== Iteration 358/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.42s
EPOCH 1 took 20.14s
update_step :  358
reward/intrinsic_batch_mean :  5.407651623415101e-05
reward/extrinsic_batch_mean :  0.06936296296296296
loss/policy :  -0.0002257571276541884
loss/rnd :  1.5118525087735069e-06
loss/value :  5.654223940589211
loss/value_i :  4.603597675888908e-06
loss/value_e :  5.654219331163349
loss/entropy :  2.3508352980469214
reward/intrinsic_running :  0.0017298923287894362
reward/extrinsic_running :  0.06936296296296296
reward/intrinsic_std_running :  0.028389112449220856
reward/extrinsic_std_running :  1.5181823567206565
reward/intrinsic_batch_std :  3.8644839668984914e-05
reward/intrinsic_batch_max :  0.0005929808830842376
reward/intrinsic_batch_min :  5.1930337576777674e-06
reward/total_batch :  0.034708519739598556
time/iteration_time :  113.62051248550415
time/fps :  2376.3314747805503
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2376
Policy Loss: -0.0002, Value Loss: 5.6542, Entropy: 2.3508
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=128.6
Extrinsic raw: Œº=0.06936296296296296

=== Iteration 359/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.95s
EPOCH 1 took 18.29s
update_step :  359
reward/intrinsic_batch_mean :  5.5267083276218425e-05
reward/extrinsic_batch_mean :  0.06524444444444444
loss/policy :  0.00016144792056310865
loss/rnd :  1.562821649492958e-06
loss/value :  5.291114814353712
loss/value_i :  4.715383759255267e-06
loss/value_e :  5.291110085718559
loss/entropy :  2.3524285699381973
reward/intrinsic_running :  0.0017254765406815229
reward/extrinsic_running :  0.06524444444444444
reward/intrinsic_std_running :  0.02834966919307919
reward/extrinsic_std_running :  1.4494732809192326
reward/intrinsic_batch_std :  5.090036177735402e-05
reward/intrinsic_batch_max :  0.0009465494658797979
reward/intrinsic_batch_min :  5.431271802081028e-06
reward/total_batch :  0.03264985576386033
time/iteration_time :  111.8169777393341
time/fps :  2414.6601478482057
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0002, Value Loss: 5.2911, Entropy: 2.3524
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=131.6
Extrinsic raw: Œº=0.06524444444444444

=== Iteration 360/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.99s
EPOCH 1 took 19.56s
update_step :  360
reward/intrinsic_batch_mean :  5.4869912667358964e-05
reward/extrinsic_batch_mean :  0.06486666666666667
loss/policy :  1.708051246224028e-05
loss/rnd :  1.5491401740925512e-06
loss/value :  6.53342392950347
loss/value_i :  5.604392099760871e-06
loss/value_e :  6.533418337504069
loss/entropy :  2.344588622902379
reward/intrinsic_running :  0.0017210822182479673
reward/extrinsic_running :  0.06486666666666667
reward/intrinsic_std_running :  0.02831039001257403
reward/extrinsic_std_running :  1.3963536180590737
reward/intrinsic_batch_std :  4.698840381748743e-05
reward/intrinsic_batch_max :  0.0013157366774976254
reward/intrinsic_batch_min :  6.19526917944313e-06
reward/total_batch :  0.032460768289667014
time/iteration_time :  114.05530858039856
time/fps :  2367.272539617695
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0000, Value Loss: 6.5334, Entropy: 2.3446
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.046, sum=130.8
Extrinsic raw: Œº=0.06486666666666667

=== Iteration 361/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 19.59s
update_step :  361
reward/intrinsic_batch_mean :  5.294247215938581e-05
reward/extrinsic_batch_mean :  0.06652592592592593
loss/policy :  0.00017008476601349133
loss/rnd :  1.4952929821750633e-06
loss/value :  6.0267721522938125
loss/value_i :  2.930385391085689e-05
loss/value_e :  6.026742855707805
loss/entropy :  2.347838445143266
reward/intrinsic_running :  0.0017166983594200536
reward/extrinsic_running :  0.06652592592592593
reward/intrinsic_std_running :  0.028271274244982592
reward/extrinsic_std_running :  1.4334936103133937
reward/intrinsic_batch_std :  3.841092490059265e-05
reward/intrinsic_batch_max :  0.0006164318765513599
reward/intrinsic_batch_min :  5.331984993972583e-06
reward/total_batch :  0.03328943419904266
time/iteration_time :  112.68322682380676
time/fps :  2396.0975169993685
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0002, Value Loss: 6.0268, Entropy: 2.3478
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=126.4
Extrinsic raw: Œº=0.06652592592592593

=== Iteration 362/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.59s
EPOCH 1 took 20.10s
update_step :  362
reward/intrinsic_batch_mean :  5.165498104802787e-05
reward/extrinsic_batch_mean :  0.06744444444444445
loss/policy :  9.881604857968561e-05
loss/rnd :  1.4576522847743367e-06
loss/value :  5.268469066330881
loss/value_i :  5.1082419076919905e-06
loss/value_e :  5.268463972843055
loss/entropy :  2.35240127101089
reward/intrinsic_running :  0.0017123266818124825
reward/extrinsic_running :  0.06744444444444445
reward/intrinsic_std_running :  0.028232320827346315
reward/extrinsic_std_running :  1.4772181521819325
reward/intrinsic_batch_std :  3.6951885607143086e-05
reward/intrinsic_batch_max :  0.0005643254262395203
reward/intrinsic_batch_min :  2.035368424913031e-06
reward/total_batch :  0.03374804971274624
time/iteration_time :  112.6121437549591
time/fps :  2397.6099823435784
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0001, Value Loss: 5.2685, Entropy: 2.3524
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=123.5
Extrinsic raw: Œº=0.06744444444444445

=== Iteration 363/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 18.96s
update_step :  363
reward/intrinsic_batch_mean :  5.156272089124859e-05
reward/extrinsic_batch_mean :  0.06916296296296297
loss/policy :  0.00010729542940900887
loss/rnd :  1.470847533627503e-06
loss/value :  6.358887448455349
loss/value_i :  4.237544758187582e-06
loss/value_e :  6.358883200269757
loss/entropy :  2.3496524167783335
reward/intrinsic_running :  0.0017079782187099848
reward/extrinsic_running :  0.06916296296296297
reward/intrinsic_std_running :  0.02819352804450219
reward/extrinsic_std_running :  1.4731315231689888
reward/intrinsic_batch_std :  3.9115257163566294e-05
reward/intrinsic_batch_max :  0.0011123052099719644
reward/intrinsic_batch_min :  4.20816604673746e-06
reward/total_batch :  0.03460726284192711
time/iteration_time :  110.95600461959839
time/fps :  2433.3969209297693
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: 0.0001, Value Loss: 6.3589, Entropy: 2.3497
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.039, sum=123.4
Extrinsic raw: Œº=0.06916296296296297

=== Iteration 364/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.87s
update_step :  364
reward/intrinsic_batch_mean :  5.221934968059132e-05
reward/extrinsic_batch_mean :  0.06780740740740741
loss/policy :  0.00023638440512568746
loss/rnd :  1.4653117098146828e-06
loss/value :  6.552781065305074
loss/value_i :  4.494527919026344e-06
loss/value_e :  6.552776596762917
loss/entropy :  2.3444569183118418
reward/intrinsic_running :  0.0017036572001993136
reward/extrinsic_running :  0.06780740740740741
reward/intrinsic_std_running :  0.028154894510787384
reward/extrinsic_std_running :  1.4277469715464097
reward/intrinsic_batch_std :  3.670636608434063e-05
reward/intrinsic_batch_max :  0.0008650730014778674
reward/intrinsic_batch_min :  5.26593112226692e-06
reward/total_batch :  0.033929813378544005
time/iteration_time :  113.06860399246216
time/fps :  2387.9307824301063
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0002, Value Loss: 6.5528, Entropy: 2.3445
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=125.2
Extrinsic raw: Œº=0.06780740740740741

=== Iteration 365/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.09s
EPOCH 1 took 18.56s
update_step :  365
reward/intrinsic_batch_mean :  5.162605078994939e-05
reward/extrinsic_batch_mean :  0.06995555555555556
loss/policy :  0.0004125743457045632
loss/rnd :  1.4495865326408062e-06
loss/value :  5.641321023305257
loss/value_i :  4.51595346793042e-06
loss/value_e :  5.641316493352254
loss/entropy :  2.3521212194905137
reward/intrinsic_running :  0.0016993555209727073
reward/extrinsic_running :  0.06995555555555556
reward/intrinsic_std_running :  0.028116419606000594
reward/extrinsic_std_running :  1.4755974050290261
reward/intrinsic_batch_std :  3.7407217677628956e-05
reward/intrinsic_batch_max :  0.0005395856569521129
reward/intrinsic_batch_min :  5.42850284546148e-06
reward/total_batch :  0.03500359080317276
time/iteration_time :  111.13208818435669
time/fps :  2429.5413180043715
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0004, Value Loss: 5.6413, Entropy: 2.3521
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=123.9
Extrinsic raw: Œº=0.06995555555555556

=== Iteration 366/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.61s
EPOCH 1 took 19.08s
update_step :  366
reward/intrinsic_batch_mean :  5.1880668575971933e-05
reward/extrinsic_batch_mean :  0.06728888888888888
loss/policy :  5.521255397153172e-05
loss/rnd :  1.4599613988056346e-06
loss/value :  6.012564702467485
loss/value_i :  1.2584751382085166e-05
loss/value_e :  6.012552124081236
loss/entropy :  2.3447563648223877
reward/intrinsic_running :  0.0016950816417035332
reward/extrinsic_running :  0.06728888888888888
reward/intrinsic_std_running :  0.028078101779345468
reward/extrinsic_std_running :  1.4360355606175024
reward/intrinsic_batch_std :  3.7937524768285066e-05
reward/intrinsic_batch_max :  0.0007514035678468645
reward/intrinsic_batch_min :  4.551122856355505e-06
reward/total_batch :  0.03367038477873243
time/iteration_time :  112.05706834793091
time/fps :  2409.486558774366
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0001, Value Loss: 6.0126, Entropy: 2.3448
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=124.7
Extrinsic raw: Œº=0.06728888888888888

=== Iteration 367/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.66s
EPOCH 1 took 18.63s
update_step :  367
reward/intrinsic_batch_mean :  5.12255705481106e-05
reward/extrinsic_batch_mean :  0.06934074074074074
loss/policy :  0.0005771741449610669
loss/rnd :  1.4317267748469242e-06
loss/value :  5.943420598001191
loss/value_i :  5.101947546350085e-06
loss/value_e :  5.943415482838948
loss/entropy :  2.3479098695697207
reward/intrinsic_running :  0.0016908230785051047
reward/extrinsic_running :  0.06934074074074074
reward/intrinsic_std_running :  0.02803994060017258
reward/extrinsic_std_running :  1.483640171325184
reward/intrinsic_batch_std :  3.599767215622901e-05
reward/intrinsic_batch_max :  0.0005518268444575369
reward/intrinsic_batch_min :  2.679181307030376e-06
reward/total_batch :  0.03469598315564443
time/iteration_time :  111.7572250366211
time/fps :  2415.9511826776766
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0006, Value Loss: 5.9434, Entropy: 2.3479
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=123.3
Extrinsic raw: Œº=0.06934074074074074

=== Iteration 368/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.70s
EPOCH 1 took 19.42s
update_step :  368
reward/intrinsic_batch_mean :  5.027695439117384e-05
reward/extrinsic_batch_mean :  0.07231111111111112
loss/policy :  0.0003100278395736082
loss/rnd :  1.4106877267405444e-06
loss/value :  5.7697521701003565
loss/value_i :  4.941722877585121e-06
loss/value_e :  5.76974723555825
loss/entropy :  2.355874935785929
reward/intrinsic_running :  0.0016865806293885211
reward/extrinsic_running :  0.07231111111111112
reward/intrinsic_std_running :  0.028001934997663364
reward/extrinsic_std_running :  1.5033372725578673
reward/intrinsic_batch_std :  3.7006420182219894e-05
reward/intrinsic_batch_max :  0.00048072909703478217
reward/intrinsic_batch_min :  4.799141152034281e-06
reward/total_batch :  0.03618069403275115
time/iteration_time :  112.78353810310364
time/fps :  2393.9663938647973
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0003, Value Loss: 5.7698, Entropy: 2.3559
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=121.2
Extrinsic raw: Œº=0.07231111111111112

=== Iteration 369/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.31s
EPOCH 1 took 19.63s
update_step :  369
reward/intrinsic_batch_mean :  5.030633099606887e-05
reward/extrinsic_batch_mean :  0.06802962962962963
loss/policy :  0.0002933135408304886
loss/rnd :  1.4044418648926225e-06
loss/value :  5.999571800231934
loss/value_i :  4.3431009544292465e-06
loss/value_e :  5.999567450899066
loss/entropy :  2.3557208451357754
reward/intrinsic_running :  0.001682360535736493
reward/extrinsic_running :  0.06802962962962963
reward/intrinsic_std_running :  0.027964083545429414
reward/extrinsic_std_running :  1.4282421619585939
reward/intrinsic_batch_std :  3.579862261000689e-05
reward/intrinsic_batch_max :  0.0004253939550835639
reward/intrinsic_batch_min :  4.8498900468985084e-06
reward/total_batch :  0.03403996798031285
time/iteration_time :  111.1318986415863
time/fps :  2429.5454617470577
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0003, Value Loss: 5.9996, Entropy: 2.3557
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.015, sum=121.4
Extrinsic raw: Œº=0.06802962962962963

=== Iteration 370/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 20.02s
update_step :  370
reward/intrinsic_batch_mean :  5.3523334153780725e-05
reward/extrinsic_batch_mean :  0.07017037037037037
loss/policy :  0.00047134166357643676
loss/rnd :  1.4900109246093163e-06
loss/value :  7.352948788440589
loss/value_i :  4.461611545345725e-06
loss/value_e :  7.352944337960445
loss/entropy :  2.343215227127075
reward/intrinsic_running :  0.0016781847835759247
reward/extrinsic_running :  0.07017037037037037
reward/intrinsic_std_running :  0.027926383991651958
reward/extrinsic_std_running :  1.446192385341031
reward/intrinsic_batch_std :  3.772870874502829e-05
reward/intrinsic_batch_max :  0.0005053757922723889
reward/intrinsic_batch_min :  5.3158364607952535e-06
reward/total_batch :  0.03511194685226207
time/iteration_time :  110.44524574279785
time/fps :  2444.6502715813526
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2445
Policy Loss: 0.0005, Value Loss: 7.3529, Entropy: 2.3432
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=129.4
Extrinsic raw: Œº=0.07017037037037037

=== Iteration 371/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.41s
EPOCH 1 took 18.49s
update_step :  371
reward/intrinsic_batch_mean :  5.2104074461412555e-05
reward/extrinsic_batch_mean :  0.06979259259259259
loss/policy :  0.00037667387567291206
loss/rnd :  1.4541482083917467e-06
loss/value :  6.140729463461674
loss/value_i :  4.878397655347451e-06
loss/value_e :  6.140724601167621
loss/entropy :  2.345816655592485
reward/intrinsic_running :  0.0016740208033416352
reward/extrinsic_running :  0.06979259259259259
reward/intrinsic_std_running :  0.027888837100315693
reward/extrinsic_std_running :  1.465027908197309
reward/intrinsic_batch_std :  3.9725537446039756e-05
reward/intrinsic_batch_max :  0.0007343480247072875
reward/intrinsic_batch_min :  5.233726824371843e-06
reward/total_batch :  0.034922348333527
time/iteration_time :  111.34331703186035
time/fps :  2424.932247372699
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: 0.0004, Value Loss: 6.1407, Entropy: 2.3458
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=126.1
Extrinsic raw: Œº=0.06979259259259259

=== Iteration 372/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.37s
EPOCH 1 took 18.75s
update_step :  372
reward/intrinsic_batch_mean :  5.126531538037482e-05
reward/extrinsic_batch_mean :  0.06936296296296296
loss/policy :  0.0005557139529352726
loss/rnd :  1.413784792186396e-06
loss/value :  5.736301458243168
loss/value_i :  4.243523562763585e-06
loss/value_e :  5.736297213669979
loss/entropy :  2.3498506437648428
reward/intrinsic_running :  0.0016698741770606491
reward/extrinsic_running :  0.06936296296296296
reward/intrinsic_std_running :  0.02785144151568847
reward/extrinsic_std_running :  1.4836353880095279
reward/intrinsic_batch_std :  3.677157653843021e-05
reward/intrinsic_batch_max :  0.0006816107779741287
reward/intrinsic_batch_min :  5.405540832725819e-06
reward/total_batch :  0.034707114139171664
time/iteration_time :  112.18142819404602
time/fps :  2406.815498310175
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0006, Value Loss: 5.7363, Entropy: 2.3499
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=124.2
Extrinsic raw: Œº=0.06936296296296296

=== Iteration 373/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.54s
EPOCH 1 took 18.94s
update_step :  373
reward/intrinsic_batch_mean :  5.101804541787311e-05
reward/extrinsic_batch_mean :  0.06846666666666666
loss/policy :  0.0001486311693125489
loss/rnd :  1.823581066784038e-06
loss/value :  5.993512789408366
loss/value_i :  4.62639875284808e-06
loss/value_e :  5.993508165532893
loss/entropy :  2.3469124273820356
reward/intrinsic_running :  0.0016657454948680289
reward/extrinsic_running :  0.06846666666666666
reward/intrinsic_std_running :  0.02781419618268456
reward/extrinsic_std_running :  1.4297776636272532
reward/intrinsic_batch_std :  3.7263291669877194e-05
reward/intrinsic_batch_max :  0.0005522870924323797
reward/intrinsic_batch_min :  4.706761956185801e-06
reward/total_batch :  0.03425884235604227
time/iteration_time :  111.14745116233826
time/fps :  2429.205502928241
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2429
Policy Loss: 0.0001, Value Loss: 5.9935, Entropy: 2.3469
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=123.8
Extrinsic raw: Œº=0.06846666666666666

=== Iteration 374/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.07s
EPOCH 1 took 19.06s
update_step :  374
reward/intrinsic_batch_mean :  0.0005056166839604784
reward/extrinsic_batch_mean :  0.0665111111111111
loss/policy :  0.00047077284839223
loss/rnd :  4.069289380395551e-06
loss/value :  6.518532875812415
loss/value_i :  2.2512355971312818e-05
loss/value_e :  6.518510366931106
loss/entropy :  2.354028925751195
reward/intrinsic_running :  0.0016647050480516927
reward/extrinsic_running :  0.0665111111111111
reward/intrinsic_std_running :  0.027776998234912854
reward/extrinsic_std_running :  1.4126762013556196
reward/intrinsic_batch_std :  9.856006945210138e-05
reward/intrinsic_batch_max :  0.0017585455207154155
reward/intrinsic_batch_min :  0.00029992751660756767
reward/total_batch :  0.03350836389753579
time/iteration_time :  112.75024962425232
time/fps :  2394.6731905232396
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2395
Policy Loss: 0.0005, Value Loss: 6.5185, Entropy: 2.3540
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.018, max=0.063, sum=1228.7
Extrinsic raw: Œº=0.0665111111111111

=== Iteration 375/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.81s
EPOCH 1 took 18.29s
update_step :  375
reward/intrinsic_batch_mean :  5.619247559640186e-05
reward/extrinsic_batch_mean :  0.06385925925925925
loss/policy :  -7.741370074764939e-05
loss/rnd :  1.479959419984053e-06
loss/value :  6.761904745390921
loss/value_i :  1.1446027594336721e-05
loss/value_e :  6.761893294074318
loss/entropy :  2.3580549558003745
reward/intrinsic_running :  0.001660648608727946
reward/extrinsic_running :  0.06385925925925925
reward/intrinsic_std_running :  0.0277400485688528
reward/extrinsic_std_running :  1.3820515328493734
reward/intrinsic_batch_std :  3.906184609953041e-05
reward/intrinsic_batch_max :  0.0006940399762243032
reward/intrinsic_batch_min :  7.166315754147945e-06
reward/total_batch :  0.03195772586742783
time/iteration_time :  111.44332122802734
time/fps :  2422.7562228475344
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: -0.0001, Value Loss: 6.7619, Entropy: 2.3581
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=136.7
Extrinsic raw: Œº=0.06385925925925925

=== Iteration 376/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.22s
EPOCH 1 took 19.06s
update_step :  376
reward/intrinsic_batch_mean :  5.683092566776866e-05
reward/extrinsic_batch_mean :  0.06652592592592593
loss/policy :  0.00041820214832885983
loss/rnd :  1.5518159247304455e-06
loss/value :  5.916746125076756
loss/value_i :  4.7566498696224615e-06
loss/value_e :  5.916741385604396
loss/entropy :  2.3631327224500254
reward/intrinsic_running :  0.0016566181046007013
reward/extrinsic_running :  0.06652592592592593
reward/intrinsic_std_running :  0.027703246367261698
reward/extrinsic_std_running :  1.4334936103133937
reward/intrinsic_batch_std :  6.274326984618376e-05
reward/intrinsic_batch_max :  0.0013637356460094452
reward/intrinsic_batch_min :  5.695762865798315e-06
reward/total_batch :  0.03329137842579685
time/iteration_time :  113.49696683883667
time/fps :  2378.918199491572
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: 0.0004, Value Loss: 5.9167, Entropy: 2.3631
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.049, sum=138.5
Extrinsic raw: Œº=0.06652592592592593

=== Iteration 377/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.61s
EPOCH 1 took 19.76s
update_step :  377
reward/intrinsic_batch_mean :  5.35560909849058e-05
reward/extrinsic_batch_mean :  0.07273333333333333
loss/policy :  0.0002256013218412232
loss/rnd :  1.4738981442199226e-06
loss/value :  5.7334177855289346
loss/value_i :  4.457254163119642e-06
loss/value_e :  5.733413335048791
loss/entropy :  2.357419729232788
reward/intrinsic_running :  0.0016525832418259158
reward/extrinsic_running :  0.07273333333333333
reward/intrinsic_std_running :  0.027666591121479282
reward/extrinsic_std_running :  1.4949206132768387
reward/intrinsic_batch_std :  4.56856327126323e-05
reward/intrinsic_batch_max :  0.0013694908702746034
reward/intrinsic_batch_min :  4.768468443216989e-06
reward/total_batch :  0.03639344471215912
time/iteration_time :  111.12478971481323
time/fps :  2429.700885760221
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0002, Value Loss: 5.7334, Entropy: 2.3574
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.049, sum=130.7
Extrinsic raw: Œº=0.07273333333333333

=== Iteration 378/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.52s
EPOCH 1 took 19.66s
update_step :  378
reward/intrinsic_batch_mean :  5.207906837334088e-05
reward/extrinsic_batch_mean :  0.06670370370370371
loss/policy :  0.00045554668163690207
loss/rnd :  1.4362420663680744e-06
loss/value :  5.319287834745465
loss/value_i :  4.542373575890396e-06
loss/value_e :  5.3192832939552535
loss/entropy :  2.3573530695655127
reward/intrinsic_running :  0.0016485622465397256
reward/extrinsic_running :  0.06670370370370371
reward/intrinsic_std_running :  0.027630081268864976
reward/extrinsic_std_running :  1.454512348338014
reward/intrinsic_batch_std :  3.555933975362321e-05
reward/intrinsic_batch_max :  0.0005854081246070564
reward/intrinsic_batch_min :  4.681607606471516e-06
reward/total_batch :  0.03337789138603853
time/iteration_time :  113.8780608177185
time/fps :  2370.95712783678
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2371
Policy Loss: 0.0005, Value Loss: 5.3193, Entropy: 2.3574
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=127.2
Extrinsic raw: Œº=0.06670370370370371

=== Iteration 379/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.44s
EPOCH 1 took 18.51s
update_step :  379
reward/intrinsic_batch_mean :  4.9982478193460676e-05
reward/extrinsic_batch_mean :  0.06948148148148148
loss/policy :  0.00022315397721037945
loss/rnd :  1.3768960677611397e-06
loss/value :  5.671390432299989
loss/value_i :  4.762245122368437e-06
loss/value_e :  5.671385660316005
loss/entropy :  2.3585758714964897
reward/intrinsic_running :  0.0016445460362826258
reward/extrinsic_running :  0.06948148148148148
reward/intrinsic_std_running :  0.027593716478275875
reward/extrinsic_std_running :  1.4841340253537147
reward/intrinsic_batch_std :  3.542881261168037e-05
reward/intrinsic_batch_max :  0.0007534447940997779
reward/intrinsic_batch_min :  4.455734142538859e-06
reward/total_batch :  0.03476573197983747
time/iteration_time :  111.84891724586487
time/fps :  2413.970619013588
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: 0.0002, Value Loss: 5.6714, Entropy: 2.3586
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=122.3
Extrinsic raw: Œº=0.06948148148148148

=== Iteration 380/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.46s
EPOCH 1 took 18.31s
update_step :  380
reward/intrinsic_batch_mean :  5.052391658815328e-05
reward/extrinsic_batch_mean :  0.07205925925925925
loss/policy :  -0.00020908340009169257
loss/rnd :  1.3956420609633136e-06
loss/value :  4.41996549837517
loss/value_i :  4.341334684712902e-06
loss/value_e :  4.419961156267108
loss/entropy :  2.357191721598307
reward/intrinsic_running :  0.0016405589547590542
reward/extrinsic_running :  0.07205925925925925
reward/intrinsic_std_running :  0.027557494511983974
reward/extrinsic_std_running :  1.512185094309325
reward/intrinsic_batch_std :  3.951012743158068e-05
reward/intrinsic_batch_max :  0.0008989940979517996
reward/intrinsic_batch_min :  2.9404936867649667e-06
reward/total_batch :  0.0360548915879237
time/iteration_time :  111.93138909339905
time/fps :  2412.1919882072007
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: -0.0002, Value Loss: 4.4200, Entropy: 2.3572
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=123.8
Extrinsic raw: Œº=0.07205925925925925

=== Iteration 381/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.80s
EPOCH 1 took 18.88s
update_step :  381
reward/intrinsic_batch_mean :  5.078797841660734e-05
reward/extrinsic_batch_mean :  0.07236296296296296
loss/policy :  0.00024268320659316623
loss/rnd :  1.3861325841748058e-06
loss/value :  4.280736496954253
loss/value_i :  4.218599628708916e-06
loss/value_e :  4.280732281280287
loss/entropy :  2.352033271934047
reward/intrinsic_running :  0.0016365922810698303
reward/extrinsic_running :  0.07236296296296296
reward/intrinsic_std_running :  0.02752141478846699
reward/extrinsic_std_running :  1.5131487557893228
reward/intrinsic_batch_std :  3.5360793107602135e-05
reward/intrinsic_batch_max :  0.0005398372304625809
reward/intrinsic_batch_min :  5.559384590014815e-06
reward/total_batch :  0.036206875470689785
time/iteration_time :  111.98520183563232
time/fps :  2411.0328469675474
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0002, Value Loss: 4.2807, Entropy: 2.3520
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=124.6
Extrinsic raw: Œº=0.07236296296296296

=== Iteration 382/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 18.72s
update_step :  382
reward/intrinsic_batch_mean :  4.89863116592123e-05
reward/extrinsic_batch_mean :  0.07114074074074074
loss/policy :  4.882767715378467e-05
loss/rnd :  1.3484153824224037e-06
loss/value :  5.065579338507219
loss/value_i :  4.7115546108629625e-06
loss/value_e :  5.065574635158885
loss/entropy :  2.353478438926466
reward/intrinsic_running :  0.0016326329871826672
reward/extrinsic_running :  0.07114074074074074
reward/intrinsic_std_running :  0.027485477134357245
reward/extrinsic_std_running :  1.4695042356899013
reward/intrinsic_batch_std :  3.4710695039563655e-05
reward/intrinsic_batch_max :  0.00046347055467776954
reward/intrinsic_batch_min :  4.033708592032781e-06
reward/total_batch :  0.03559486352619998
time/iteration_time :  112.31041359901428
time/fps :  2404.051337251684
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0000, Value Loss: 5.0656, Entropy: 2.3535
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=120.3
Extrinsic raw: Œº=0.07114074074074074

=== Iteration 383/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.77s
EPOCH 1 took 19.30s
update_step :  383
reward/intrinsic_batch_mean :  5.205475380827449e-05
reward/extrinsic_batch_mean :  0.07201481481481481
loss/policy :  0.00020830516851591793
loss/rnd :  1.4277410814016052e-06
loss/value :  5.055402582341975
loss/value_i :  4.445266461406198e-06
loss/value_e :  5.055398102962609
loss/entropy :  2.3503120559634585
reward/intrinsic_running :  0.001628717494620768
reward/extrinsic_running :  0.07201481481481481
reward/intrinsic_std_running :  0.02744967897259778
reward/extrinsic_std_running :  1.512194559230295
reward/intrinsic_batch_std :  5.065549362719894e-05
reward/intrinsic_batch_max :  0.0010242172284051776
reward/intrinsic_batch_min :  5.269207576930057e-06
reward/total_batch :  0.03603343478431154
time/iteration_time :  113.10947060585022
time/fps :  2387.068019625539
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2387
Policy Loss: 0.0002, Value Loss: 5.0554, Entropy: 2.3503
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=128.0
Extrinsic raw: Œº=0.07201481481481481

=== Iteration 384/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 19.54s
update_step :  384
reward/intrinsic_batch_mean :  5.015599313367905e-05
reward/extrinsic_batch_mean :  0.06948888888888889
loss/policy :  0.00023447048244468698
loss/rnd :  1.370537781688406e-06
loss/value :  5.841238498687744
loss/value_i :  4.363291254500809e-06
loss/value_e :  5.841234142130071
loss/entropy :  2.3482445189447114
reward/intrinsic_running :  0.001624806045212393
reward/extrinsic_running :  0.06948888888888889
reward/intrinsic_std_running :  0.02741402087789834
reward/extrinsic_std_running :  1.4436005006344717
reward/intrinsic_batch_std :  3.5903004449613406e-05
reward/intrinsic_batch_max :  0.0005481081898324192
reward/intrinsic_batch_min :  2.706595523704891e-06
reward/total_batch :  0.03476952244101129
time/iteration_time :  112.79038047790527
time/fps :  2393.821165031807
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0002, Value Loss: 5.8412, Entropy: 2.3482
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=123.5
Extrinsic raw: Œº=0.06948888888888889

=== Iteration 385/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.40s
EPOCH 1 took 20.06s
update_step :  385
reward/intrinsic_batch_mean :  5.1531577656802524e-05
reward/extrinsic_batch_mean :  0.06951851851851852
loss/policy :  0.0005286537872796708
loss/rnd :  1.4069956398888088e-06
loss/value :  5.397260105971134
loss/value_i :  4.125887719717205e-06
loss/value_e :  5.397255973382429
loss/entropy :  2.3592206348072398
reward/intrinsic_running :  0.0016209254657784972
reward/extrinsic_running :  0.06951851851851852
reward/intrinsic_std_running :  0.027378501066916295
reward/extrinsic_std_running :  1.4841260521080928
reward/intrinsic_batch_std :  4.7800703839085196e-05
reward/intrinsic_batch_max :  0.0009800345869734883
reward/intrinsic_batch_min :  4.736505616165232e-06
reward/total_batch :  0.03478502504808766
time/iteration_time :  112.06857395172119
time/fps :  2409.2391870384217
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0005, Value Loss: 5.3973, Entropy: 2.3592
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=127.0
Extrinsic raw: Œº=0.06951851851851852

=== Iteration 386/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 18.72s
update_step :  386
reward/intrinsic_batch_mean :  5.0320088758599015e-05
reward/extrinsic_batch_mean :  0.06934814814814814
loss/policy :  0.0003010803228596959
loss/rnd :  1.3928850672996442e-06
loss/value :  5.857990850101817
loss/value_i :  1.0985059788888037e-05
loss/value_e :  5.857979890071984
loss/entropy :  2.3545087575912476
reward/intrinsic_running :  0.0016170531167377415
reward/extrinsic_running :  0.06934814814814814
reward/intrinsic_std_running :  0.027343119343531692
reward/extrinsic_std_running :  1.4533735025973629
reward/intrinsic_batch_std :  3.473032446661032e-05
reward/intrinsic_batch_max :  0.000547864765394479
reward/intrinsic_batch_min :  5.323153345671017e-06
reward/total_batch :  0.034699234118453375
time/iteration_time :  111.15895414352417
time/fps :  2428.9541232223755
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2429
Policy Loss: 0.0003, Value Loss: 5.8580, Entropy: 2.3545
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=124.2
Extrinsic raw: Œº=0.06934814814814814

=== Iteration 387/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.83s
update_step :  387
reward/intrinsic_batch_mean :  5.0822229423714885e-05
reward/extrinsic_batch_mean :  0.07363703703703704
loss/policy :  0.00029483581205237317
loss/rnd :  1.4359968507492202e-06
loss/value :  5.739040779344963
loss/value_i :  2.049322229209572e-05
loss/value_e :  5.739020282571966
loss/entropy :  2.347047874421784
reward/intrinsic_running :  0.0016132082677697635
reward/extrinsic_running :  0.07363703703703704
reward/intrinsic_std_running :  0.02730787404478303
reward/extrinsic_std_running :  1.4978440659947434
reward/intrinsic_batch_std :  3.672921561125304e-05
reward/intrinsic_batch_max :  0.00046059268061071634
reward/intrinsic_batch_min :  5.576328021561494e-06
reward/total_batch :  0.036843929633230375
time/iteration_time :  111.50326991081238
time/fps :  2421.453650784983
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0003, Value Loss: 5.7390, Entropy: 2.3470
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=125.6
Extrinsic raw: Œº=0.07363703703703704

=== Iteration 388/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 19.10s
update_step :  388
reward/intrinsic_batch_mean :  5.140386661425712e-05
reward/extrinsic_batch_mean :  0.06905925925925926
loss/policy :  0.00031792340715500444
loss/rnd :  1.5897311379486574e-06
loss/value :  5.498669122204636
loss/value_i :  4.180901393710608e-06
loss/value_e :  5.498664942654696
loss/entropy :  2.356355764649131
reward/intrinsic_running :  0.0016093827293845442
reward/extrinsic_running :  0.06905925925925926
reward/intrinsic_std_running :  0.027272764717931934
reward/extrinsic_std_running :  1.4421297535651805
reward/intrinsic_batch_std :  3.710939350471892e-05
reward/intrinsic_batch_max :  0.0006973547860980034
reward/intrinsic_batch_min :  5.354813310987083e-06
reward/total_batch :  0.03455533156293676
time/iteration_time :  111.92867588996887
time/fps :  2412.250460868693
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: 0.0003, Value Loss: 5.4987, Entropy: 2.3564
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=127.2
Extrinsic raw: Œº=0.06905925925925926

=== Iteration 389/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.75s
update_step :  389
reward/intrinsic_batch_mean :  5.372871442780673e-05
reward/extrinsic_batch_mean :  0.07228888888888889
loss/policy :  0.0001996944651402759
loss/rnd :  2.339831529284173e-06
loss/value :  5.355182062495839
loss/value_i :  4.1008316436614915e-06
loss/value_e :  5.355177966031161
loss/entropy :  2.3542224349397602
reward/intrinsic_running :  0.0016055934100523553
reward/extrinsic_running :  0.07228888888888889
reward/intrinsic_std_running :  0.027237789591461795
reward/extrinsic_std_running :  1.5131645347204656
reward/intrinsic_batch_std :  3.781355850739946e-05
reward/intrinsic_batch_max :  0.000779959955252707
reward/intrinsic_batch_min :  6.810022568970453e-06
reward/total_batch :  0.03617130880165835
time/iteration_time :  112.97706747055054
time/fps :  2389.8655368301206
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0002, Value Loss: 5.3552, Entropy: 2.3542
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=133.1
Extrinsic raw: Œº=0.07228888888888889

=== Iteration 390/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.04s
EPOCH 1 took 18.92s
update_step :  390
reward/intrinsic_batch_mean :  5.583363648131328e-05
reward/extrinsic_batch_mean :  0.07188888888888889
loss/policy :  0.00018538136006982037
loss/rnd :  1.4528224786166295e-06
loss/value :  4.680661017244512
loss/value_i :  1.356992260587669e-05
loss/value_e :  4.6806474490599195
loss/entropy :  2.3553665479024253
reward/intrinsic_running :  0.001601836704527909
reward/extrinsic_running :  0.07188888888888889
reward/intrinsic_std_running :  0.027202947948256076
reward/extrinsic_std_running :  1.5117069536058392
reward/intrinsic_batch_std :  3.73549083794067e-05
reward/intrinsic_batch_max :  0.0005890629254281521
reward/intrinsic_batch_min :  8.818380592856556e-06
reward/total_batch :  0.035972361262685104
time/iteration_time :  112.5552990436554
time/fps :  2398.8208666682012
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0002, Value Loss: 4.6807, Entropy: 2.3554
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=138.5
Extrinsic raw: Œº=0.07188888888888889

=== Iteration 391/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.90s
EPOCH 1 took 19.35s
update_step :  391
reward/intrinsic_batch_mean :  5.376111441385513e-05
reward/extrinsic_batch_mean :  0.0689037037037037
loss/policy :  0.00024957484768520135
loss/rnd :  1.646199391967512e-06
loss/value :  4.996816147457469
loss/value_i :  1.600172468539368e-05
loss/value_e :  4.996800151738253
loss/entropy :  2.358303579417142
reward/intrinsic_running :  0.0015980853772486663
reward/extrinsic_running :  0.0689037037037037
reward/intrinsic_std_running :  0.027168240416888454
reward/extrinsic_std_running :  1.4721313793729247
reward/intrinsic_batch_std :  3.874007025891378e-05
reward/intrinsic_batch_max :  0.0006505507626570761
reward/intrinsic_batch_min :  6.51278924124199e-06
reward/total_batch :  0.03447873240905878
time/iteration_time :  112.95604348182678
time/fps :  2390.310351508015
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0002, Value Loss: 4.9968, Entropy: 2.3583
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=133.6
Extrinsic raw: Œº=0.0689037037037037

=== Iteration 392/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.47s
EPOCH 1 took 18.87s
update_step :  392
reward/intrinsic_batch_mean :  5.566214646554457e-05
reward/extrinsic_batch_mean :  0.0743925925925926
loss/policy :  0.0006897038617876894
loss/rnd :  1.5974718731933646e-06
loss/value :  5.218658295544711
loss/value_i :  4.457819434747128e-06
loss/value_e :  5.218653855901776
loss/entropy :  2.351139617688728
reward/intrinsic_running :  0.0015943635201033375
reward/extrinsic_running :  0.0743925925925926
reward/intrinsic_std_running :  0.027133664829245858
reward/extrinsic_std_running :  1.519847397779699
reward/intrinsic_batch_std :  3.5884700689508365e-05
reward/intrinsic_batch_max :  0.000474481494165957
reward/intrinsic_batch_min :  7.338314389926381e-06
reward/total_batch :  0.03722412736952907
time/iteration_time :  111.74265336990356
time/fps :  2416.266231894588
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2416
Policy Loss: 0.0007, Value Loss: 5.2187, Entropy: 2.3511
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=138.5
Extrinsic raw: Œº=0.0743925925925926

=== Iteration 393/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.81s
EPOCH 1 took 20.07s
update_step :  393
reward/intrinsic_batch_mean :  5.19181658811013e-05
reward/extrinsic_batch_mean :  0.07368148148148149
loss/policy :  0.0003359252434827133
loss/rnd :  1.4046252899926472e-06
loss/value :  4.056316112027024
loss/value_i :  4.636917599947827e-06
loss/value_e :  4.056311466477134
loss/entropy :  2.360981164556561
reward/intrinsic_running :  0.0015906365880742049
reward/extrinsic_running :  0.07368148148148149
reward/intrinsic_std_running :  0.027099222201610013
reward/extrinsic_std_running :  1.5464980518810487
reward/intrinsic_batch_std :  3.762816763161277e-05
reward/intrinsic_batch_max :  0.0011077026138082147
reward/intrinsic_batch_min :  4.903772605757695e-06
reward/total_batch :  0.03686669982368129
time/iteration_time :  113.23291349411011
time/fps :  2384.4657146797185
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: 0.0003, Value Loss: 4.0563, Entropy: 2.3610
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=129.3
Extrinsic raw: Œº=0.07368148148148149

=== Iteration 394/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.38s
EPOCH 1 took 18.50s
update_step :  394
reward/intrinsic_batch_mean :  5.389060983817655e-05
reward/extrinsic_batch_mean :  0.07502962962962963
loss/policy :  0.0005107080747124696
loss/rnd :  1.4545152015616072e-06
loss/value :  3.9355901118480796
loss/value_i :  4.372641176980158e-06
loss/value_e :  3.935585715553977
loss/entropy :  2.3552336259321733
reward/intrinsic_running :  0.001586942402146779
reward/extrinsic_running :  0.07502962962962963
reward/intrinsic_std_running :  0.027064909671608326
reward/extrinsic_std_running :  1.56972638540862
reward/intrinsic_batch_std :  3.829905965829539e-05
reward/intrinsic_batch_max :  0.0005542769213207066
reward/intrinsic_batch_min :  5.141002020536689e-06
reward/total_batch :  0.037541760119733904
time/iteration_time :  111.24961113929749
time/fps :  2426.9747753268866
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2427
Policy Loss: 0.0005, Value Loss: 3.9356, Entropy: 2.3552
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=134.4
Extrinsic raw: Œº=0.07502962962962963

=== Iteration 395/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 20.17s
update_step :  395
reward/intrinsic_batch_mean :  5.2626503560639795e-05
reward/extrinsic_batch_mean :  0.06638518518518519
loss/policy :  0.0005181092948822135
loss/rnd :  1.4218288404690886e-06
loss/value :  6.363018982338183
loss/value_i :  4.175141708456619e-06
loss/value_e :  6.363014799175841
loss/entropy :  2.3487020514228125
reward/intrinsic_running :  0.0015832577116682235
reward/extrinsic_running :  0.06638518518518519
reward/intrinsic_std_running :  0.027030727632255114
reward/extrinsic_std_running :  1.412153742470385
reward/intrinsic_batch_std :  3.677219013180262e-05
reward/intrinsic_batch_max :  0.0005542764556594193
reward/intrinsic_batch_min :  3.0755099942325614e-06
reward/total_batch :  0.03321890584437291
time/iteration_time :  112.93858695030212
time/fps :  2390.6798136124344
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: 0.0005, Value Loss: 6.3630, Entropy: 2.3487
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=131.4
Extrinsic raw: Œº=0.06638518518518519

=== Iteration 396/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.20s
EPOCH 1 took 18.23s
update_step :  396
reward/intrinsic_batch_mean :  5.216320325530601e-05
reward/extrinsic_batch_mean :  0.07525925925925926
loss/policy :  0.0005036066665497581
loss/rnd :  1.4043546843133685e-06
loss/value :  5.281707741997459
loss/value_i :  4.018025654686701e-06
loss/value_e :  5.281703714168433
loss/entropy :  2.354070862134298
reward/intrinsic_running :  0.0015795878746107616
reward/extrinsic_running :  0.07525925925925926
reward/intrinsic_std_running :  0.0269966749783682
reward/extrinsic_std_running :  1.5421134269804948
reward/intrinsic_batch_std :  3.684822374193559e-05
reward/intrinsic_batch_max :  0.0006434263195842505
reward/intrinsic_batch_min :  3.80898245566641e-06
reward/total_batch :  0.037655711231257286
time/iteration_time :  109.6464364528656
time/fps :  2462.4603291696267
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.6s | FPS: 2462
Policy Loss: 0.0005, Value Loss: 5.2817, Entropy: 2.3541
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=130.4
Extrinsic raw: Œº=0.07525925925925926

=== Iteration 397/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 19.63s
update_step :  397
reward/intrinsic_batch_mean :  5.397561294801697e-05
reward/extrinsic_batch_mean :  0.06578518518518518
loss/policy :  0.0002757734283946003
loss/rnd :  1.4543301383376026e-06
loss/value :  6.342730095892241
loss/value_i :  4.3684042339009466e-06
loss/value_e :  6.342725717660152
loss/entropy :  2.338932503353466
reward/intrinsic_running :  0.0015759430570780276
reward/extrinsic_running :  0.06578518518518518
reward/intrinsic_std_running :  0.02696275035197663
reward/extrinsic_std_running :  1.383568284653504
reward/intrinsic_batch_std :  3.677678827661983e-05
reward/intrinsic_batch_max :  0.0004772125103045255
reward/intrinsic_batch_min :  5.070319730293704e-06
reward/total_batch :  0.0329195803990666
time/iteration_time :  114.29892873764038
time/fps :  2362.2268640833277
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0003, Value Loss: 6.3427, Entropy: 2.3389
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=135.1
Extrinsic raw: Œº=0.06578518518518518

=== Iteration 398/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.23s
update_step :  398
reward/intrinsic_batch_mean :  5.4923956925752765e-05
reward/extrinsic_batch_mean :  0.06848148148148148
loss/policy :  0.0006557088897600559
loss/rnd :  1.4787399185010917e-06
loss/value :  5.754547054117376
loss/value_i :  4.099374991435043e-06
loss/value_e :  5.754542957652699
loss/entropy :  2.3421136791055854
reward/intrinsic_running :  0.001572324310535588
reward/extrinsic_running :  0.06848148148148148
reward/intrinsic_std_running :  0.02692895287177057
reward/extrinsic_std_running :  1.4605285413258569
reward/intrinsic_batch_std :  3.5934214827005955e-05
reward/intrinsic_batch_max :  0.000458915950730443
reward/intrinsic_batch_min :  5.711086487281136e-06
reward/total_batch :  0.03426820271920362
time/iteration_time :  112.17394924163818
time/fps :  2406.9759674626657
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0007, Value Loss: 5.7545, Entropy: 2.3421
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=137.7
Extrinsic raw: Œº=0.06848148148148148

=== Iteration 399/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 20.16s
update_step :  399
reward/intrinsic_batch_mean :  5.252888244631996e-05
reward/extrinsic_batch_mean :  0.07368888888888889
loss/policy :  0.00014403555101263478
loss/rnd :  2.661366519270924e-06
loss/value :  4.765927838556694
loss/value_i :  1.392796544526694e-05
loss/value_e :  4.765913901907025
loss/entropy :  2.3444891373316445
reward/intrinsic_running :  0.0015687104182750965
reward/extrinsic_running :  0.07368888888888889
reward/intrinsic_std_running :  0.026895282878683497
reward/extrinsic_std_running :  1.5368870483891042
reward/intrinsic_batch_std :  3.661704608796442e-05
reward/intrinsic_batch_max :  0.0006360750994645059
reward/intrinsic_batch_min :  3.898024260706734e-06
reward/total_batch :  0.036870708885667604
time/iteration_time :  114.11055111885071
time/fps :  2366.1265093600696
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0001, Value Loss: 4.7659, Entropy: 2.3445
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=131.8
Extrinsic raw: Œº=0.07368888888888889

=== Iteration 400/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 19.10s
update_step :  400
reward/intrinsic_batch_mean :  0.00010741351072156923
reward/extrinsic_batch_mean :  0.07574814814814815
loss/policy :  0.0005084522258998318
loss/rnd :  1.791405729749606e-06
loss/value :  5.076942386049213
loss/value_i :  4.363847562093394e-06
loss/value_e :  5.076938000592318
loss/entropy :  2.3423862529523447
reward/intrinsic_running :  0.0015654521683507049
reward/extrinsic_running :  0.07574814814814815
reward/intrinsic_std_running :  0.026861721785678194
reward/extrinsic_std_running :  1.543522665221385
reward/intrinsic_batch_std :  4.342412340316407e-05
reward/intrinsic_batch_max :  0.0006644147797487676
reward/intrinsic_batch_min :  3.865965118166059e-05
reward/total_batch :  0.037927780829434855
time/iteration_time :  111.19173049926758
time/fps :  2428.2381323472478
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0005, Value Loss: 5.0769, Entropy: 2.3424
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.025, sum=269.9
Extrinsic raw: Œº=0.07574814814814815

=== Iteration 401/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.30s
EPOCH 1 took 19.93s
update_step :  401
reward/intrinsic_batch_mean :  5.3643506675339096e-05
reward/extrinsic_batch_mean :  0.0695111111111111
loss/policy :  0.0006077497470841715
loss/rnd :  1.4155419101123037e-06
loss/value :  6.047937082521843
loss/value_i :  5.416586749230522e-06
loss/value_e :  6.047931692816994
loss/entropy :  2.350842139937661
reward/intrinsic_running :  0.0015618799627771071
reward/extrinsic_running :  0.0695111111111111
reward/intrinsic_std_running :  0.02682830271249677
reward/extrinsic_std_running :  1.4436468936621056
reward/intrinsic_batch_std :  4.086589283167971e-05
reward/intrinsic_batch_max :  0.0008828402496874332
reward/intrinsic_batch_min :  5.899652478547068e-06
reward/total_batch :  0.03478237730889322
time/iteration_time :  113.91217637062073
time/fps :  2370.2470499864503
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2370
Policy Loss: 0.0006, Value Loss: 6.0479, Entropy: 2.3508
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=135.0
Extrinsic raw: Œº=0.0695111111111111

=== Iteration 402/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.03s
EPOCH 1 took 19.20s
update_step :  402
reward/intrinsic_batch_mean :  5.115167384622812e-05
reward/extrinsic_batch_mean :  0.07238518518518519
loss/policy :  -0.00012413898763373834
loss/rnd :  1.3580734668556198e-06
loss/value :  3.7690850351796006
loss/value_i :  5.167082997214686e-06
loss/value_e :  3.7690798875057334
loss/entropy :  2.3616461609349106
reward/intrinsic_running :  0.001558308413028715
reward/extrinsic_running :  0.07238518518518519
reward/intrinsic_std_running :  0.026795008938955606
reward/extrinsic_std_running :  1.5229032993068807
reward/intrinsic_batch_std :  3.620884147066441e-05
reward/intrinsic_batch_max :  0.000594301731325686
reward/intrinsic_batch_min :  4.990007255400997e-06
reward/total_batch :  0.03621816842951571
time/iteration_time :  111.65012383460999
time/fps :  2418.268701608943
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: -0.0001, Value Loss: 3.7691, Entropy: 2.3616
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=128.9
Extrinsic raw: Œº=0.07238518518518519

=== Iteration 403/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 19.39s
update_step :  403
reward/intrinsic_batch_mean :  5.08005046086139e-05
reward/extrinsic_batch_mean :  0.07556296296296296
loss/policy :  0.00039787190458313984
loss/rnd :  1.355500587303113e-06
loss/value :  5.164582465634202
loss/value_i :  4.88545604391468e-06
loss/value_e :  5.164577588890538
loss/entropy :  2.359782594622988
reward/intrinsic_running :  0.0015547561186765766
reward/extrinsic_running :  0.07556296296296296
reward/intrinsic_std_running :  0.026761838752056413
reward/extrinsic_std_running :  1.5526290301597883
reward/intrinsic_batch_std :  3.866642428689177e-05
reward/intrinsic_batch_max :  0.0007255921955220401
reward/intrinsic_batch_min :  4.794497272087028e-06
reward/total_batch :  0.03780688173378578
time/iteration_time :  112.89779925346375
time/fps :  2391.5435179903766
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0004, Value Loss: 5.1646, Entropy: 2.3598
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=128.1
Extrinsic raw: Œº=0.07556296296296296

=== Iteration 404/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 18.25s
update_step :  404
reward/intrinsic_batch_mean :  5.361935261012318e-05
reward/extrinsic_batch_mean :  0.06994814814814815
loss/policy :  0.0005181094783245388
loss/rnd :  1.4297342390405405e-06
loss/value :  6.084088506120624
loss/value_i :  4.377060377285516e-06
loss/value_e :  6.084084135113341
loss/entropy :  2.3489377570874765
reward/intrinsic_running :  0.0015512323435216077
reward/extrinsic_running :  0.06994814814814815
reward/intrinsic_std_running :  0.026728790896510056
reward/extrinsic_std_running :  1.4553807689043343
reward/intrinsic_batch_std :  4.306463259907418e-05
reward/intrinsic_batch_max :  0.0007454144069924951
reward/intrinsic_batch_min :  4.791468654730124e-06
reward/total_batch :  0.03500088375037914
time/iteration_time :  111.5883948802948
time/fps :  2419.6064500223297
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0005, Value Loss: 6.0841, Entropy: 2.3489
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=135.4
Extrinsic raw: Œº=0.06994814814814815

=== Iteration 405/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.05s
EPOCH 1 took 18.67s
update_step :  405
reward/intrinsic_batch_mean :  5.5436758310245044e-05
reward/extrinsic_batch_mean :  0.06817777777777778
loss/policy :  0.0001260536541160422
loss/rnd :  1.488995647750099e-06
loss/value :  5.951320445898808
loss/value_i :  7.422793036119291e-06
loss/value_e :  5.95131304769805
loss/entropy :  2.344092257095106
reward/intrinsic_running :  0.0015477399097258402
reward/extrinsic_running :  0.06817777777777778
reward/intrinsic_std_running :  0.026695864463207743
reward/extrinsic_std_running :  1.4287536441956918
reward/intrinsic_batch_std :  4.5903286147310684e-05
reward/intrinsic_batch_max :  0.0008877420914359391
reward/intrinsic_batch_min :  2.496736897228402e-06
reward/total_batch :  0.03411660726804401
time/iteration_time :  113.33295798301697
time/fps :  2382.360831351986
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2382
Policy Loss: 0.0001, Value Loss: 5.9513, Entropy: 2.3441
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=140.2
Extrinsic raw: Œº=0.06817777777777778

=== Iteration 406/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 18.58s
update_step :  406
reward/intrinsic_batch_mean :  5.2866331738941545e-05
reward/extrinsic_batch_mean :  0.07052592592592592
loss/policy :  0.0005737928555445802
loss/rnd :  1.4044754903586705e-06
loss/value :  5.818911949793498
loss/value_i :  4.336286193310198e-06
loss/value_e :  5.818907593235825
loss/entropy :  2.350863879377192
reward/intrinsic_running :  0.0015442462111251384
reward/extrinsic_running :  0.07052592592592592
reward/intrinsic_std_running :  0.026663060330442495
reward/extrinsic_std_running :  1.4775806618559981
reward/intrinsic_batch_std :  3.8312464138636794e-05
reward/intrinsic_batch_max :  0.0006291712634265423
reward/intrinsic_batch_min :  5.658260306518059e-06
reward/total_batch :  0.03528939612883243
time/iteration_time :  111.97642207145691
time/fps :  2411.2218894411676
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0006, Value Loss: 5.8189, Entropy: 2.3509
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=133.8
Extrinsic raw: Œº=0.07052592592592592

=== Iteration 407/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 18.90s
update_step :  407
reward/intrinsic_batch_mean :  5.248883990752128e-05
reward/extrinsic_batch_mean :  0.07096296296296296
loss/policy :  0.00023049437467389825
loss/rnd :  1.3977250225914097e-06
loss/value :  6.099687865286162
loss/value_i :  4.32864032973157e-06
loss/value_e :  6.099683544852517
loss/entropy :  2.3482881892811167
reward/intrinsic_running :  0.0015407698371555385
reward/extrinsic_running :  0.07096296296296296
reward/intrinsic_std_running :  0.026630376829725338
reward/extrinsic_std_running :  1.4890468609764478
reward/intrinsic_batch_std :  4.1613343915182726e-05
reward/intrinsic_batch_max :  0.0008485604776069522
reward/intrinsic_batch_min :  4.592531695379876e-06
reward/total_batch :  0.03550772590143524
time/iteration_time :  112.65603733062744
time/fps :  2396.6758142539065
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: 0.0002, Value Loss: 6.0997, Entropy: 2.3483
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=133.0
Extrinsic raw: Œº=0.07096296296296296

=== Iteration 408/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 19.09s
update_step :  408
reward/intrinsic_batch_mean :  5.119538086457598e-05
reward/extrinsic_batch_mean :  0.07482222222222222
loss/policy :  0.00109259146528061
loss/rnd :  1.365153307784622e-06
loss/value :  5.773167165842923
loss/value_i :  3.749926005377457e-06
loss/value_e :  5.7731634197813095
loss/entropy :  2.3519316983945444
reward/intrinsic_running :  0.0015373027196690504
reward/extrinsic_running :  0.07482222222222222
reward/intrinsic_std_running :  0.026597813628770638
reward/extrinsic_std_running :  1.5406918136640295
reward/intrinsic_batch_std :  3.871561955985257e-05
reward/intrinsic_batch_max :  0.0005837311036884785
reward/intrinsic_batch_min :  5.3640683290723246e-06
reward/total_batch :  0.0374367088015434
time/iteration_time :  112.25703001022339
time/fps :  2405.19457868617
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0011, Value Loss: 5.7732, Entropy: 2.3519
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=129.9
Extrinsic raw: Œº=0.07482222222222222

=== Iteration 409/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 18.94s
update_step :  409
reward/intrinsic_batch_mean :  5.06341205636124e-05
reward/extrinsic_batch_mean :  0.07376296296296296
loss/policy :  0.0008675965177162377
loss/rnd :  1.585854599370302e-06
loss/value :  5.5458315502513535
loss/value_i :  8.382700305749799e-06
loss/value_e :  5.545823169477059
loss/entropy :  2.347449537479516
reward/intrinsic_running :  0.0015338471198607375
reward/extrinsic_running :  0.07376296296296296
reward/intrinsic_std_running :  0.026565369853155538
reward/extrinsic_std_running :  1.5179822582645806
reward/intrinsic_batch_std :  3.660035889348686e-05
reward/intrinsic_batch_max :  0.0005185460322536528
reward/intrinsic_batch_min :  4.222266852593748e-06
reward/total_batch :  0.036906798541763285
time/iteration_time :  112.47800159454346
time/fps :  2400.4693911017907
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0009, Value Loss: 5.5458, Entropy: 2.3474
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=128.7
Extrinsic raw: Œº=0.07376296296296296

=== Iteration 410/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.44s
EPOCH 1 took 19.33s
update_step :  410
reward/intrinsic_batch_mean :  5.854733163116045e-05
reward/extrinsic_batch_mean :  0.07214814814814814
loss/policy :  -8.695436884987761e-05
loss/rnd :  1.923727144127373e-06
loss/value :  6.027778892806082
loss/value_i :  1.3460531731928341e-05
loss/value_e :  6.027765411319154
loss/entropy :  2.3417089996915874
reward/intrinsic_running :  0.0015304548030230726
reward/extrinsic_running :  0.07214814814814814
reward/intrinsic_std_running :  0.026533042076041475
reward/extrinsic_std_running :  1.492964431212928
reward/intrinsic_batch_std :  3.885697662436038e-05
reward/intrinsic_batch_max :  0.0010778693249449134
reward/intrinsic_batch_min :  8.276144399133045e-06
reward/total_batch :  0.03610334773988965
time/iteration_time :  111.38410210609436
time/fps :  2424.044319563869
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0001, Value Loss: 6.0278, Entropy: 2.3417
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=148.9
Extrinsic raw: Œº=0.07214814814814814

=== Iteration 411/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 18.48s
update_step :  411
reward/intrinsic_batch_mean :  4.85853292814311e-05
reward/extrinsic_batch_mean :  0.07708888888888889
loss/policy :  4.334443964939e-05
loss/rnd :  1.2811436008495079e-06
loss/value :  4.704765558242798
loss/value_i :  5.466072693569444e-06
loss/value_e :  4.7047601035147
loss/entropy :  2.3554997371904776
reward/intrinsic_running :  0.0015270208415604277
reward/extrinsic_running :  0.07708888888888889
reward/intrinsic_std_running :  0.026500835080360614
reward/extrinsic_std_running :  1.59954677824766
reward/intrinsic_batch_std :  3.5555094711724365e-05
reward/intrinsic_batch_max :  0.0005078327376395464
reward/intrinsic_batch_min :  2.5131100755970692e-06
reward/total_batch :  0.038568737109085156
time/iteration_time :  111.07137632369995
time/fps :  2430.8693106775568
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0000, Value Loss: 4.7048, Entropy: 2.3555
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.019, sum=123.8
Extrinsic raw: Œº=0.07708888888888889

=== Iteration 412/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 18.24s
update_step :  412
reward/intrinsic_batch_mean :  4.963343187428782e-05
reward/extrinsic_batch_mean :  0.07368148148148149
loss/policy :  0.00033080505090765655
loss/rnd :  1.3090560948760619e-06
loss/value :  4.7294039292768995
loss/value_i :  3.646867388383588e-06
loss/value_e :  4.729400309649381
loss/entropy :  2.3518657612078115
reward/intrinsic_running :  0.0015236084705146152
reward/extrinsic_running :  0.07368148148148149
reward/intrinsic_std_running :  0.026468744819998696
reward/extrinsic_std_running :  1.5464980518810487
reward/intrinsic_batch_std :  3.579518683984951e-05
reward/intrinsic_batch_max :  0.00046274298802018166
reward/intrinsic_batch_min :  4.82840187032707e-06
reward/total_batch :  0.03686555745667789
time/iteration_time :  110.58160829544067
time/fps :  2441.635676690843
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2442
Policy Loss: 0.0003, Value Loss: 4.7294, Entropy: 2.3519
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=126.6
Extrinsic raw: Œº=0.07368148148148149

=== Iteration 413/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.41s
EPOCH 1 took 18.85s
update_step :  413
reward/intrinsic_batch_mean :  4.888834496605004e-05
reward/extrinsic_batch_mean :  0.07318518518518519
loss/policy :  0.0006537089070523948
loss/rnd :  1.2901341971304314e-06
loss/value :  5.575846440864332
loss/value_i :  3.871975412618088e-06
loss/value_e :  5.575842568368623
loss/entropy :  2.348850105748032
reward/intrinsic_running :  0.0015202072172693095
reward/extrinsic_running :  0.07318518518518519
reward/intrinsic_std_running :  0.02643677114172677
reward/extrinsic_std_running :  1.525795312640859
reward/intrinsic_batch_std :  3.581889033963206e-05
reward/intrinsic_batch_max :  0.00046453700633719563
reward/intrinsic_batch_min :  4.871170858677942e-06
reward/total_batch :  0.03661703676507562
time/iteration_time :  113.25248527526855
time/fps :  2384.0536421231286
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2384
Policy Loss: 0.0007, Value Loss: 5.5758, Entropy: 2.3489
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=124.8
Extrinsic raw: Œº=0.07318518518518519

=== Iteration 414/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 19.04s
update_step :  414
reward/intrinsic_batch_mean :  5.102086728451535e-05
reward/extrinsic_batch_mean :  0.07502962962962963
loss/policy :  0.0002457497599111362
loss/rnd :  1.3569952522740287e-06
loss/value :  4.272015708865541
loss/value_i :  2.4179841823228564e-05
loss/value_e :  4.271991549116192
loss/entropy :  2.3445999550096914
reward/intrinsic_running :  0.0015168379553978262
reward/extrinsic_running :  0.07502962962962963
reward/intrinsic_std_running :  0.02640491225562703
reward/extrinsic_std_running :  1.5507358465543875
reward/intrinsic_batch_std :  3.727583132631753e-05
reward/intrinsic_batch_max :  0.0006060150917619467
reward/intrinsic_batch_min :  4.107098448002944e-06
reward/total_batch :  0.037540325248457074
time/iteration_time :  112.25715160369873
time/fps :  2405.1919734537773
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0002, Value Loss: 4.2720, Entropy: 2.3446
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=130.4
Extrinsic raw: Œº=0.07502962962962963

=== Iteration 415/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.40s
EPOCH 1 took 19.37s
update_step :  415
reward/intrinsic_batch_mean :  4.8869073726820245e-05
reward/extrinsic_batch_mean :  0.07657777777777777
loss/policy :  0.0002509643187901626
loss/rnd :  1.2851314508996878e-06
loss/value :  5.835252451174187
loss/value_i :  4.3804732974945875e-06
loss/value_e :  5.835248065717293
loss/entropy :  2.344535383311185
reward/intrinsic_running :  0.0015134700885466093
reward/extrinsic_running :  0.07657777777777777
reward/intrinsic_std_running :  0.026373169034793677
reward/extrinsic_std_running :  1.5559190184899618
reward/intrinsic_batch_std :  3.617630866845236e-05
reward/intrinsic_batch_max :  0.0005813041352666914
reward/intrinsic_batch_min :  4.436025392351439e-06
reward/total_batch :  0.0383133234257523
time/iteration_time :  112.78901696205139
time/fps :  2393.8501041359664
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0003, Value Loss: 5.8353, Entropy: 2.3445
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=125.1
Extrinsic raw: Œº=0.07657777777777777

=== Iteration 416/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 18.60s
update_step :  416
reward/intrinsic_batch_mean :  5.028142549061967e-05
reward/extrinsic_batch_mean :  0.0736
loss/policy :  6.044539865494395e-05
loss/rnd :  1.333624574974899e-06
loss/value :  6.241198156819199
loss/value_i :  4.028857505766085e-06
loss/value_e :  6.2411941037033545
loss/entropy :  2.3426699674490727
reward/intrinsic_running :  0.0015101251339975231
reward/extrinsic_running :  0.0736
reward/intrinsic_std_running :  0.02634153966536204
reward/extrinsic_std_running :  1.5272359695432354
reward/intrinsic_batch_std :  3.523511517974608e-05
reward/intrinsic_batch_max :  0.0004868851392529905
reward/intrinsic_batch_min :  4.4068615352443885e-06
reward/total_batch :  0.036825140712745306
time/iteration_time :  111.3246898651123
time/fps :  2425.3379939988895
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: 0.0001, Value Loss: 6.2412, Entropy: 2.3427
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=128.8
Extrinsic raw: Œº=0.0736

=== Iteration 417/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 19.35s
update_step :  417
reward/intrinsic_batch_mean :  5.5508170787329115e-05
reward/extrinsic_batch_mean :  0.07243703703703704
loss/policy :  0.00029278763527558607
loss/rnd :  1.378481635693981e-06
loss/value :  6.123497226021507
loss/value_i :  3.836211073410761e-06
loss/value_e :  6.123493375200214
loss/entropy :  2.3392725063092783
reward/intrinsic_running :  0.0015068252600306767
reward/extrinsic_running :  0.07243703703703704
reward/intrinsic_std_running :  0.026310022320523038
reward/extrinsic_std_running :  1.5038275566399693
reward/intrinsic_batch_std :  4.018657737618431e-05
reward/intrinsic_batch_max :  0.0009320650715380907
reward/intrinsic_batch_min :  7.642463970114477e-06
reward/total_batch :  0.03624627260391218
time/iteration_time :  112.88750791549683
time/fps :  2391.761541960085
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0003, Value Loss: 6.1235, Entropy: 2.3393
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=142.4
Extrinsic raw: Œº=0.07243703703703704

=== Iteration 418/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 19.68s
update_step :  418
reward/intrinsic_batch_mean :  5.012256959551922e-05
reward/extrinsic_batch_mean :  0.07381481481481482
loss/policy :  0.0007268334342039783
loss/rnd :  1.3605503568214772e-06
loss/value :  4.9241915905114375
loss/value_i :  3.6958614270009673e-06
loss/value_e :  4.924187887798656
loss/entropy :  2.3477170106136436
reward/intrinsic_running :  0.0015035107531708224
reward/extrinsic_running :  0.07381481481481482
reward/intrinsic_std_running :  0.026278619418420104
reward/extrinsic_std_running :  1.537318337043486
reward/intrinsic_batch_std :  3.732826345833536e-05
reward/intrinsic_batch_max :  0.0007307644700631499
reward/intrinsic_batch_min :  3.116855168627808e-06
reward/total_batch :  0.03693246869220517
time/iteration_time :  112.06383752822876
time/fps :  2409.3410145086928
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0007, Value Loss: 4.9242, Entropy: 2.3477
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=128.7
Extrinsic raw: Œº=0.07381481481481482

=== Iteration 419/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.94s
EPOCH 1 took 18.35s
update_step :  419
reward/intrinsic_batch_mean :  6.688988444059052e-05
reward/extrinsic_batch_mean :  0.07189629629629629
loss/policy :  0.0006075860327462468
loss/rnd :  1.3866889503333368e-06
loss/value :  5.103383035370798
loss/value_i :  3.749280763672273e-06
loss/value_e :  5.103379264022365
loss/entropy :  2.329122557784572
reward/intrinsic_running :  0.001500305904158381
reward/extrinsic_running :  0.07189629629629629
reward/intrinsic_std_running :  0.026247323838357255
reward/extrinsic_std_running :  1.501873335262155
reward/intrinsic_batch_std :  3.890003733879576e-05
reward/intrinsic_batch_max :  0.0007167300209403038
reward/intrinsic_batch_min :  1.6510435671079904e-05
reward/total_batch :  0.03598159309036844
time/iteration_time :  112.54103374481201
time/fps :  2399.1249326199354
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0006, Value Loss: 5.1034, Entropy: 2.3291
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=172.0
Extrinsic raw: Œº=0.07189629629629629

=== Iteration 420/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.25s
EPOCH 1 took 18.79s
update_step :  420
reward/intrinsic_batch_mean :  5.0429131357965095e-05
reward/extrinsic_batch_mean :  0.07751111111111111
loss/policy :  0.0006386800351637331
loss/rnd :  1.2950836362919786e-06
loss/value :  4.574864261078112
loss/value_i :  3.5914308648099187e-06
loss/value_e :  4.574860670349815
loss/entropy :  2.3455207058877656
reward/intrinsic_running :  0.0014970240463076934
reward/extrinsic_running :  0.07751111111111111
reward/intrinsic_std_running :  0.026216144553988387
reward/extrinsic_std_running :  1.5869302389235254
reward/intrinsic_batch_std :  3.567013110411787e-05
reward/intrinsic_batch_max :  0.0004587569274008274
reward/intrinsic_batch_min :  7.27525184629485e-06
reward/total_batch :  0.03878077012123454
time/iteration_time :  112.48222517967224
time/fps :  2400.3792560888487
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0006, Value Loss: 4.5749, Entropy: 2.3455
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.017, sum=129.8
Extrinsic raw: Œº=0.07751111111111111

=== Iteration 421/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.36s
EPOCH 1 took 19.05s
update_step :  421
reward/intrinsic_batch_mean :  5.071311612069554e-05
reward/extrinsic_batch_mean :  0.07586666666666667
loss/policy :  0.0007667002377495395
loss/rnd :  1.3689420146681985e-06
loss/value :  4.965182159886216
loss/value_i :  4.003796951137977e-06
loss/value_e :  4.965178139281996
loss/entropy :  2.341142350977117
reward/intrinsic_running :  0.0014937592552002293
reward/extrinsic_running :  0.07586666666666667
reward/intrinsic_std_running :  0.026185076068127887
reward/extrinsic_std_running :  1.553566919966699
reward/intrinsic_batch_std :  3.9653479740600464e-05
reward/intrinsic_batch_max :  0.0005997063708491623
reward/intrinsic_batch_min :  4.791562332684407e-06
reward/total_batch :  0.03795868989139368
time/iteration_time :  111.7934980392456
time/fps :  2415.167292691882
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0008, Value Loss: 4.9652, Entropy: 2.3411
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=130.7
Extrinsic raw: Œº=0.07586666666666667

=== Iteration 422/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.08s
EPOCH 1 took 19.74s
update_step :  422
reward/intrinsic_batch_mean :  5.4603080015598e-05
reward/extrinsic_batch_mean :  0.07406666666666667
loss/policy :  0.0005828995825581704
loss/rnd :  1.6292091817321666e-06
loss/value :  5.789840098583337
loss/value_i :  4.085347699622092e-06
loss/value_e :  5.789836009343465
loss/entropy :  2.3285103277726606
reward/intrinsic_running :  0.0014905314650430878
reward/extrinsic_running :  0.07406666666666667
reward/intrinsic_std_running :  0.026154116823682922
reward/extrinsic_std_running :  1.5189419012125704
reward/intrinsic_batch_std :  5.122660260219885e-05
reward/intrinsic_batch_max :  0.0011031482135877013
reward/intrinsic_batch_min :  6.114813913882244e-06
reward/total_batch :  0.03706063487334113
time/iteration_time :  113.07855439186096
time/fps :  2387.7206553626916
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0006, Value Loss: 5.7898, Entropy: 2.3285
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.042, sum=140.9
Extrinsic raw: Œº=0.07406666666666667

=== Iteration 423/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.02s
EPOCH 1 took 18.64s
update_step :  423
reward/intrinsic_batch_mean :  5.0577875430617836e-05
reward/extrinsic_batch_mean :  0.07397037037037037
loss/policy :  0.0007914510259235448
loss/rnd :  1.3430182858345772e-06
loss/value :  5.3731270847898545
loss/value_i :  3.910806116657499e-06
loss/value_e :  5.3731231472708965
loss/entropy :  2.3434822631604746
reward/intrinsic_running :  0.0014872948638189067
reward/extrinsic_running :  0.07397037037037037
reward/intrinsic_std_running :  0.026123268200264997
reward/extrinsic_std_running :  1.537839590636648
reward/intrinsic_batch_std :  3.728108492650441e-05
reward/intrinsic_batch_max :  0.0005988074117340147
reward/intrinsic_batch_min :  5.054172561358428e-06
reward/total_batch :  0.03701047412290049
time/iteration_time :  112.42902827262878
time/fps :  2401.515019282012
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: 0.0008, Value Loss: 5.3731, Entropy: 2.3435
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=130.7
Extrinsic raw: Œº=0.07397037037037037

=== Iteration 424/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 19.39s
update_step :  424
reward/intrinsic_batch_mean :  5.13171701892942e-05
reward/extrinsic_batch_mean :  0.08254814814814815
loss/policy :  0.0006661426375627123
loss/rnd :  1.3426935738331822e-06
loss/value :  4.581152384931391
loss/value_i :  3.85317341831317e-06
loss/value_e :  4.5811485268852925
loss/entropy :  2.330693710934032
reward/intrinsic_running :  0.0014840773359518795
reward/extrinsic_running :  0.08254814814814815
reward/intrinsic_std_running :  0.02609252828059383
reward/extrinsic_std_running :  1.6209007176784904
reward/intrinsic_batch_std :  3.7862855651283684e-05
reward/intrinsic_batch_max :  0.000510566052980721
reward/intrinsic_batch_min :  4.5536762627307326e-06
reward/total_batch :  0.04129973265916872
time/iteration_time :  112.18361568450928
time/fps :  2406.7685673397546
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0007, Value Loss: 4.5812, Entropy: 2.3307
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=132.8
Extrinsic raw: Œº=0.08254814814814815

=== Iteration 425/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.77s
EPOCH 1 took 18.80s
update_step :  425
reward/intrinsic_batch_mean :  5.47863810131107e-05
reward/extrinsic_batch_mean :  0.0788
loss/policy :  4.129068579597074e-05
loss/rnd :  1.4082378684041472e-06
loss/value :  5.4118468689196035
loss/value_i :  4.326277882793158e-06
loss/value_e :  5.411842526811542
loss/entropy :  2.3263370087652495
reward/intrinsic_running :  0.001480895640820911
reward/extrinsic_running :  0.0788
reward/intrinsic_std_running :  0.026061895587354025
reward/extrinsic_std_running :  1.5817775411320107
reward/intrinsic_batch_std :  4.2768108808378446e-05
reward/intrinsic_batch_max :  0.001008434221148491
reward/intrinsic_batch_min :  6.967791705392301e-06
reward/total_batch :  0.03942739319050655
time/iteration_time :  110.74579572677612
time/fps :  2438.015802117889
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2438
Policy Loss: 0.0000, Value Loss: 5.4118, Entropy: 2.3263
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.039, sum=141.9
Extrinsic raw: Œº=0.0788

=== Iteration 426/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 19.14s
update_step :  426
reward/intrinsic_batch_mean :  5.389155539637108e-05
reward/extrinsic_batch_mean :  0.0717037037037037
loss/policy :  0.0012062660252647192
loss/rnd :  1.875399754791226e-06
loss/value :  6.123852664774114
loss/value_i :  3.195598913641857e-05
loss/value_e :  6.123820716684515
loss/entropy :  2.3351342100085635
reward/intrinsic_running :  0.0014777225079988397
reward/extrinsic_running :  0.0717037037037037
reward/intrinsic_std_running :  0.026031370819159544
reward/extrinsic_std_running :  1.4914966585879013
reward/intrinsic_batch_std :  3.6889774085174905e-05
reward/intrinsic_batch_max :  0.0005300517077557743
reward/intrinsic_batch_min :  9.126327313424554e-06
reward/total_batch :  0.035878797629550034
time/iteration_time :  110.99140000343323
time/fps :  2432.620905688623
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: 0.0012, Value Loss: 6.1239, Entropy: 2.3351
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=139.7
Extrinsic raw: Œº=0.0717037037037037

=== Iteration 427/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.37s
EPOCH 1 took 18.32s
update_step :  427
reward/intrinsic_batch_mean :  6.527851897652134e-05
reward/extrinsic_batch_mean :  0.07735555555555555
loss/policy :  0.0007124512710354545
loss/rnd :  1.411590136685294e-06
loss/value :  5.275958119016705
loss/value_i :  4.1677975180694675e-06
loss/value_e :  5.275953943079168
loss/entropy :  2.336140423110037
reward/intrinsic_running :  0.0014746280125548694
reward/extrinsic_running :  0.07735555555555555
reward/intrinsic_std_running :  0.026000949826288894
reward/extrinsic_std_running :  1.5677317323736728
reward/intrinsic_batch_std :  4.063196188839969e-05
reward/intrinsic_batch_max :  0.0007253949879668653
reward/intrinsic_batch_min :  1.5077229363669176e-05
reward/total_batch :  0.038710417037266034
time/iteration_time :  111.19114184379578
time/fps :  2428.2509876488457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0007, Value Loss: 5.2760, Entropy: 2.3361
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=169.5
Extrinsic raw: Œº=0.07735555555555555

=== Iteration 428/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.10s
EPOCH 1 took 19.09s
update_step :  428
reward/intrinsic_batch_mean :  5.318694669526007e-05
reward/extrinsic_batch_mean :  0.07824444444444445
loss/policy :  0.0009891677340915935
loss/rnd :  1.3768639942926795e-06
loss/value :  4.468642260089065
loss/value_i :  3.7825924506030404e-06
loss/value_e :  4.468638488740632
loss/entropy :  2.345118865822301
reward/intrinsic_running :  0.0014714803056471654
reward/extrinsic_running :  0.07824444444444445
reward/intrinsic_std_running :  0.025970638865303534
reward/extrinsic_std_running :  1.616997684171899
reward/intrinsic_batch_std :  5.000169673169355e-05
reward/intrinsic_batch_max :  0.0011190456571057439
reward/intrinsic_batch_min :  4.696141331805848e-06
reward/total_batch :  0.039148815695569855
time/iteration_time :  113.15438199043274
time/fps :  2386.1205836715067
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0010, Value Loss: 4.4686, Entropy: 2.3451
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.043, sum=138.2
Extrinsic raw: Œº=0.07824444444444445

=== Iteration 429/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.79s
EPOCH 1 took 18.55s
update_step :  429
reward/intrinsic_batch_mean :  5.0454869719033013e-05
reward/extrinsic_batch_mean :  0.07337777777777778
loss/policy :  0.0002655868560340781
loss/rnd :  1.3085687917489188e-06
loss/value :  5.026862682718219
loss/value_i :  3.5411204600787833e-06
loss/value_e :  5.02685910282713
loss/entropy :  2.3372063745151865
reward/intrinsic_running :  0.00146833082636833
reward/extrinsic_running :  0.07337777777777778
reward/intrinsic_std_running :  0.025940434310426686
reward/extrinsic_std_running :  1.5165265374418715
reward/intrinsic_batch_std :  3.6821375750646166e-05
reward/intrinsic_batch_max :  0.00046724179992452264
reward/intrinsic_batch_min :  5.1156389417883474e-06
reward/total_batch :  0.03671411632374841
time/iteration_time :  112.81677603721619
time/fps :  2393.261086550922
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0003, Value Loss: 5.0269, Entropy: 2.3372
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.018, sum=131.3
Extrinsic raw: Œº=0.07337777777777778

=== Iteration 430/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 19.79s
update_step :  430
reward/intrinsic_batch_mean :  5.04562391420593e-05
reward/extrinsic_batch_mean :  0.07442222222222222
loss/policy :  0.00040552050058701724
loss/rnd :  1.3080568047977674e-06
loss/value :  4.464318167079579
loss/value_i :  3.5174357607860602e-06
loss/value_e :  4.4643146377621274
loss/entropy :  2.3481826565482398
reward/intrinsic_running :  0.0014651956114497774
reward/extrinsic_running :  0.07442222222222222
reward/intrinsic_std_running :  0.025910334914558523
reward/extrinsic_std_running :  1.5583913356605037
reward/intrinsic_batch_std :  3.7089175877507474e-05
reward/intrinsic_batch_max :  0.0005836553173139691
reward/intrinsic_batch_min :  4.446935690793907e-06
reward/total_batch :  0.03723633923068214
time/iteration_time :  113.30811476707458
time/fps :  2382.883172622138
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2383
Policy Loss: 0.0004, Value Loss: 4.4643, Entropy: 2.3482
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=131.4
Extrinsic raw: Œº=0.07442222222222222

=== Iteration 431/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 18.68s
update_step :  431
reward/intrinsic_batch_mean :  4.9818317329172043e-05
reward/extrinsic_batch_mean :  0.07662962962962963
loss/policy :  0.00028051291133813334
loss/rnd :  1.2883739304236246e-06
loss/value :  4.37676046111367
loss/value_i :  3.120157109812929e-06
loss/value_e :  4.376757365284544
loss/entropy :  2.3500822854764536
reward/intrinsic_running :  0.0014620726725452647
reward/extrinsic_running :  0.07662962962962963
reward/intrinsic_std_running :  0.025880340177833052
reward/extrinsic_std_running :  1.5654008278120588
reward/intrinsic_batch_std :  3.947613057417343e-05
reward/intrinsic_batch_max :  0.0008179728174582124
reward/intrinsic_batch_min :  4.237287612340879e-06
reward/total_batch :  0.0383397239734794
time/iteration_time :  112.22127842903137
time/fps :  2405.960828282203
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0003, Value Loss: 4.3768, Entropy: 2.3501
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=129.9
Extrinsic raw: Œº=0.07662962962962963

=== Iteration 432/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.89s
EPOCH 1 took 19.04s
update_step :  432
reward/intrinsic_batch_mean :  5.221273325151506e-05
reward/extrinsic_batch_mean :  0.07914814814814815
loss/policy :  0.0004780356195458973
loss/rnd :  1.349667799689941e-06
loss/value :  4.316023407560406
loss/value_i :  3.295706719517043e-06
loss/value_e :  4.316020127498742
loss/entropy :  2.3437624555645566
reward/intrinsic_running :  0.0014589739653207603
reward/extrinsic_running :  0.07914814814814815
reward/intrinsic_std_running :  0.02585044886378201
reward/extrinsic_std_running :  1.5920213148513478
reward/intrinsic_batch_std :  3.864315464309362e-05
reward/intrinsic_batch_max :  0.0006431311485357583
reward/intrinsic_batch_min :  4.205486675346037e-06
reward/total_batch :  0.03960018044069983
time/iteration_time :  111.89054727554321
time/fps :  2413.0724764004794
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0005, Value Loss: 4.3160, Entropy: 2.3438
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=136.3
Extrinsic raw: Œº=0.07914814814814815

=== Iteration 433/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.95s
EPOCH 1 took 19.04s
update_step :  433
reward/intrinsic_batch_mean :  5.050186260616977e-05
reward/extrinsic_batch_mean :  0.07988888888888888
loss/policy :  -5.0885176857594736e-05
loss/rnd :  1.3031869739830708e-06
loss/value :  3.8452033057357324
loss/value_i :  3.1995563900140538e-06
loss/value_e :  3.8452000906973174
loss/entropy :  2.3460848078583227
reward/intrinsic_running :  0.0014558815955541392
reward/extrinsic_running :  0.07988888888888888
reward/intrinsic_std_running :  0.025820661285314638
reward/extrinsic_std_running :  1.612786634491699
reward/intrinsic_batch_std :  3.704221360977631e-05
reward/intrinsic_batch_max :  0.0006138838361948729
reward/intrinsic_batch_min :  4.5714123189100064e-06
reward/total_batch :  0.03996969537574753
time/iteration_time :  111.08608746528625
time/fps :  2430.547390413524
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: -0.0001, Value Loss: 3.8452, Entropy: 2.3461
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=132.0
Extrinsic raw: Œº=0.07988888888888888

=== Iteration 434/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.32s
EPOCH 1 took 19.70s
update_step :  434
reward/intrinsic_batch_mean :  5.1863505716816386e-05
reward/extrinsic_batch_mean :  0.08313333333333334
loss/policy :  0.00041391766298505843
loss/rnd :  1.3384523985030572e-06
loss/value :  4.308374271248326
loss/value_i :  3.2577635961801703e-06
loss/value_e :  4.30837100202387
loss/entropy :  2.341156359874841
reward/intrinsic_running :  0.0014528120803436971
reward/extrinsic_running :  0.08313333333333334
reward/intrinsic_std_running :  0.025790975996156023
reward/extrinsic_std_running :  1.6318031258339596
reward/intrinsic_batch_std :  3.742409740397914e-05
reward/intrinsic_batch_max :  0.0007959912763908505
reward/intrinsic_batch_min :  4.598461146088084e-06
reward/total_batch :  0.041592598419525076
time/iteration_time :  111.3220055103302
time/fps :  2425.3964772036484
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: 0.0004, Value Loss: 4.3084, Entropy: 2.3412
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=135.7
Extrinsic raw: Œº=0.08313333333333334

=== Iteration 435/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.58s
EPOCH 1 took 18.64s
update_step :  435
reward/intrinsic_batch_mean :  5.088804246342652e-05
reward/extrinsic_batch_mean :  0.08104444444444445
loss/policy :  0.0006020891362850582
loss/rnd :  1.3223629997066217e-06
loss/value :  4.840432481332258
loss/value_i :  4.199529564285705e-06
loss/value_e :  4.840428283720305
loss/entropy :  2.3455003210992524
reward/intrinsic_running :  0.001449750008117703
reward/extrinsic_running :  0.08104444444444445
reward/intrinsic_std_running :  0.025761393206747144
reward/extrinsic_std_running :  1.5979681374780481
reward/intrinsic_batch_std :  3.8755986194732103e-05
reward/intrinsic_batch_max :  0.0009375891531817615
reward/intrinsic_batch_min :  4.939905920764431e-06
reward/total_batch :  0.040547666243453934
time/iteration_time :  111.45364570617676
time/fps :  2422.5317914839334
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2423
Policy Loss: 0.0006, Value Loss: 4.8404, Entropy: 2.3455
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=133.3
Extrinsic raw: Œº=0.08104444444444445

=== Iteration 436/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.53s
EPOCH 1 took 18.94s
update_step :  436
reward/intrinsic_batch_mean :  5.178504975059089e-05
reward/extrinsic_batch_mean :  0.07705185185185186
loss/policy :  0.0007538504825347583
loss/rnd :  1.3263756696605098e-06
loss/value :  5.258692069487139
loss/value_i :  3.5048739336520103e-06
loss/value_e :  5.258688579906117
loss/entropy :  2.342127399011092
reward/intrinsic_running :  0.0014467041938392346
reward/extrinsic_running :  0.07705185185185186
reward/intrinsic_std_running :  0.0257319119461672
reward/extrinsic_std_running :  1.5572708954307948
reward/intrinsic_batch_std :  4.5768523875147445e-05
reward/intrinsic_batch_max :  0.0010536472545936704
reward/intrinsic_batch_min :  4.915854333376046e-06
reward/total_batch :  0.038551818450801224
time/iteration_time :  112.18086504936218
time/fps :  2406.8275804540617
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0008, Value Loss: 5.2587, Entropy: 2.3421
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=135.8
Extrinsic raw: Œº=0.07705185185185186

=== Iteration 437/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.00s
EPOCH 1 took 19.26s
update_step :  437
reward/intrinsic_batch_mean :  5.017078119385082e-05
reward/extrinsic_batch_mean :  0.07942962962962963
loss/policy :  0.0009490912286282489
loss/rnd :  1.3535960433865981e-06
loss/value :  4.9719242760629365
loss/value_i :  4.428078031279173e-06
loss/value_e :  4.9719198580944175
loss/entropy :  2.342787161017909
reward/intrinsic_running :  0.0014436648903653213
reward/extrinsic_running :  0.07942962962962963
reward/intrinsic_std_running :  0.02570253197533995
reward/extrinsic_std_running :  1.6022132287037194
reward/intrinsic_batch_std :  3.898623841628839e-05
reward/intrinsic_batch_max :  0.0009941053576767445
reward/intrinsic_batch_min :  4.939849986840272e-06
reward/total_batch :  0.03973990020541174
time/iteration_time :  113.17352390289307
time/fps :  2385.7170006623605
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0009, Value Loss: 4.9719, Entropy: 2.3428
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.039, sum=131.8
Extrinsic raw: Œº=0.07942962962962963

=== Iteration 438/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.35s
EPOCH 1 took 19.86s
update_step :  438
reward/intrinsic_batch_mean :  5.214828661953814e-05
reward/extrinsic_batch_mean :  0.07840740740740741
loss/policy :  -2.8351114561894175e-05
loss/rnd :  1.3252558250259785e-06
loss/value :  4.35191831444249
loss/value_i :  3.6455440253617284e-06
loss/value_e :  4.3519146767529575
loss/entropy :  2.3379741509755454
reward/intrinsic_running :  0.001440652077586697
reward/extrinsic_running :  0.07840740740740741
reward/intrinsic_std_running :  0.025673251773237985
reward/extrinsic_std_running :  1.5897299038995705
reward/intrinsic_batch_std :  4.022192236681036e-05
reward/intrinsic_batch_max :  0.0006947581423446536
reward/intrinsic_batch_min :  4.7976632231439e-06
reward/total_batch :  0.039229777847013474
time/iteration_time :  111.64803147315979
time/fps :  2418.314021639585
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2418
Policy Loss: -0.0000, Value Loss: 4.3519, Entropy: 2.3380
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=137.1
Extrinsic raw: Œº=0.07840740740740741

=== Iteration 439/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.24s
EPOCH 1 took 18.54s
update_step :  439
reward/intrinsic_batch_mean :  5.149782961146869e-05
reward/extrinsic_batch_mean :  0.0794
loss/policy :  -0.0001265482269721388
loss/rnd :  1.4111819664873164e-06
loss/value :  5.1882139046986895
loss/value_i :  3.318722730055566e-06
loss/value_e :  5.1882105776757905
loss/entropy :  2.331531297076832
reward/intrinsic_running :  0.0014376464587222584
reward/extrinsic_running :  0.0794
reward/intrinsic_std_running :  0.02564407172128116
reward/extrinsic_std_running :  1.5929460510266757
reward/intrinsic_batch_std :  3.647526408316068e-05
reward/intrinsic_batch_max :  0.0005983037990517914
reward/intrinsic_batch_min :  5.136901108926395e-06
reward/total_batch :  0.039725748914805736
time/iteration_time :  111.8583459854126
time/fps :  2413.7671411233864
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: -0.0001, Value Loss: 5.1882, Entropy: 2.3315
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=135.6
Extrinsic raw: Œº=0.0794

=== Iteration 440/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 18.67s
update_step :  440
reward/intrinsic_batch_mean :  5.4112220486543566e-05
reward/extrinsic_batch_mean :  0.07488148148148148
loss/policy :  0.00034167588896569657
loss/rnd :  8.560553567349416e-06
loss/value :  4.359805287736835
loss/value_i :  0.00015275296061989854
loss/value_e :  4.35965252645088
loss/entropy :  2.337358037630717
reward/intrinsic_running :  0.0014346706423636673
reward/extrinsic_running :  0.07488148148148148
reward/intrinsic_std_running :  0.025614990315286582
reward/extrinsic_std_running :  1.5502652654822557
reward/intrinsic_batch_std :  5.047791482112192e-05
reward/intrinsic_batch_max :  0.0013191996840760112
reward/intrinsic_batch_min :  5.445738679554779e-06
reward/total_batch :  0.03746779685098401
time/iteration_time :  111.53134107589722
time/fps :  2420.844198549219
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0003, Value Loss: 4.3598, Entropy: 2.3374
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.052, sum=142.6
Extrinsic raw: Œº=0.07488148148148148

=== Iteration 441/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.78s
EPOCH 1 took 18.45s
update_step :  441
reward/intrinsic_batch_mean :  7.114523131385794e-05
reward/extrinsic_batch_mean :  0.07797037037037037
loss/policy :  0.00045896120630486894
loss/rnd :  1.617895658469162e-06
loss/value :  4.357336232156465
loss/value_i :  2.4893978520319223e-05
loss/value_e :  4.357311328252156
loss/entropy :  2.337689576726971
reward/intrinsic_running :  0.0014317960833085362
reward/extrinsic_running :  0.07797037037037037
reward/intrinsic_std_running :  0.025586003080848532
reward/extrinsic_std_running :  1.5789970653726428
reward/intrinsic_batch_std :  4.492463079466038e-05
reward/intrinsic_batch_max :  0.0007145677809603512
reward/intrinsic_batch_min :  1.0075245882035233e-05
reward/total_batch :  0.03902075780084211
time/iteration_time :  110.89792275428772
time/fps :  2434.6713923418447
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.9s | FPS: 2435
Policy Loss: 0.0005, Value Loss: 4.3573, Entropy: 2.3377
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=187.7
Extrinsic raw: Œº=0.07797037037037037

=== Iteration 442/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.51s
EPOCH 1 took 18.94s
update_step :  442
reward/intrinsic_batch_mean :  5.326377131608482e-05
reward/extrinsic_batch_mean :  0.08044444444444444
loss/policy :  0.0007862782363328292
loss/rnd :  1.3460621475629027e-06
loss/value :  5.73489059823932
loss/value_i :  3.4213127126790686e-06
loss/value_e :  5.734887209805575
loss/entropy :  2.3389835502162124
reward/intrinsic_running :  0.0014288406023955473
reward/extrinsic_running :  0.08044444444444444
reward/intrinsic_std_running :  0.02555711871383775
reward/extrinsic_std_running :  1.6418967652243919
reward/intrinsic_batch_std :  4.134095543976402e-05
reward/intrinsic_batch_max :  0.000644215673673898
reward/intrinsic_batch_min :  5.195410722080851e-06
reward/total_batch :  0.04024885410788026
time/iteration_time :  111.2169578075409
time/fps :  2427.6873358398325
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0008, Value Loss: 5.7349, Entropy: 2.3390
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=140.7
Extrinsic raw: Œº=0.08044444444444444

=== Iteration 443/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.83s
EPOCH 1 took 18.27s
update_step :  443
reward/intrinsic_batch_mean :  5.179721393592276e-05
reward/extrinsic_batch_mean :  0.0764962962962963
loss/policy :  0.0005778996470105609
loss/rnd :  1.3110183538105269e-06
loss/value :  4.239268317367092
loss/value_i :  3.104873464756317e-06
loss/value_e :  4.239265221537965
loss/entropy :  2.3427609530362217
reward/intrinsic_running :  0.001425889347479085
reward/extrinsic_running :  0.0764962962962963
reward/intrinsic_std_running :  0.025528332405880316
reward/extrinsic_std_running :  1.5743700039207877
reward/intrinsic_batch_std :  3.9456784001491884e-05
reward/intrinsic_batch_max :  0.0008501605479978025
reward/intrinsic_batch_min :  5.130590125190793e-06
reward/total_batch :  0.03827404675511611
time/iteration_time :  111.08807373046875
time/fps :  2430.503931998108
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0006, Value Loss: 4.2393, Entropy: 2.3428
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=137.0
Extrinsic raw: Œº=0.0764962962962963

=== Iteration 444/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.23s
EPOCH 1 took 18.28s
update_step :  444
reward/intrinsic_batch_mean :  4.976751910039807e-05
reward/extrinsic_batch_mean :  0.07498518518518518
loss/policy :  0.0004205221877341638
loss/rnd :  1.2654258219327224e-06
loss/value :  5.592733845566258
loss/value_i :  3.157765046456585e-06
loss/value_e :  5.592730673876676
loss/entropy :  2.347591656627077
reward/intrinsic_running :  0.0014229421650312844
reward/extrinsic_running :  0.07498518518518518
reward/intrinsic_std_running :  0.025499643614854288
reward/extrinsic_std_running :  1.58382898667747
reward/intrinsic_batch_std :  3.84697107882429e-05
reward/intrinsic_batch_max :  0.0006810763152316213
reward/intrinsic_batch_min :  5.080048140371218e-06
reward/total_batch :  0.03751747635214279
time/iteration_time :  110.32837891578674
time/fps :  2447.239800433305
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.3s | FPS: 2447
Policy Loss: 0.0004, Value Loss: 5.5927, Entropy: 2.3476
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=131.7
Extrinsic raw: Œº=0.07498518518518518

=== Iteration 445/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 18.61s
update_step :  445
reward/intrinsic_batch_mean :  5.205384897502275e-05
reward/extrinsic_batch_mean :  0.08131111111111111
loss/policy :  0.0005004381453159801
loss/rnd :  1.323977127151121e-06
loss/value :  5.69563487443057
loss/value_i :  3.3886983429152733e-06
loss/value_e :  5.695631478772019
loss/entropy :  2.3359728437481504
reward/intrinsic_running :  0.001420019203414766
reward/extrinsic_running :  0.08131111111111111
reward/intrinsic_std_running :  0.025471050796306245
reward/extrinsic_std_running :  1.617265520089121
reward/intrinsic_batch_std :  4.2343072660858915e-05
reward/intrinsic_batch_max :  0.0006912763346917927
reward/intrinsic_batch_min :  4.607991741067963e-06
reward/total_batch :  0.04068158248004307
time/iteration_time :  111.54389929771423
time/fps :  2420.57164667842
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0005, Value Loss: 5.6956, Entropy: 2.3360
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=137.9
Extrinsic raw: Œº=0.08131111111111111

=== Iteration 446/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.25s
EPOCH 1 took 19.48s
update_step :  446
reward/intrinsic_batch_mean :  5.402199280996245e-05
reward/extrinsic_batch_mean :  0.0753111111111111
loss/policy :  0.0008098614551162234
loss/rnd :  1.3663316270718828e-06
loss/value :  4.007433157978636
loss/value_i :  3.213087573137521e-06
loss/value_e :  4.007429946552623
loss/entropy :  2.3414645158883296
reward/intrinsic_running :  0.0014171160365477919
reward/extrinsic_running :  0.0753111111111111
reward/intrinsic_std_running :  0.025442553826013018
reward/extrinsic_std_running :  1.5800628490391067
reward/intrinsic_batch_std :  5.445013601817504e-05
reward/intrinsic_batch_max :  0.001000687014311552
reward/intrinsic_batch_min :  5.017739113100106e-06
reward/total_batch :  0.037682566551960534
time/iteration_time :  110.73333692550659
time/fps :  2438.2901075367804
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2438
Policy Loss: 0.0008, Value Loss: 4.0074, Entropy: 2.3415
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.039, sum=143.3
Extrinsic raw: Œº=0.0753111111111111

=== Iteration 447/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.73s
EPOCH 1 took 18.38s
update_step :  447
reward/intrinsic_batch_mean :  5.1472583448937965e-05
reward/extrinsic_batch_mean :  0.07395555555555555
loss/policy :  0.00031401589248244733
loss/rnd :  1.3044453494744217e-06
loss/value :  4.716804948720065
loss/value_i :  3.184679730056263e-06
loss/value_e :  4.716801751743663
loss/entropy :  2.3427035375074907
reward/intrinsic_running :  0.001414215008259957
reward/extrinsic_running :  0.07395555555555555
reward/intrinsic_std_running :  0.02541415260355327
reward/extrinsic_std_running :  1.547446230103563
reward/intrinsic_batch_std :  4.058463055824617e-05
reward/intrinsic_batch_max :  0.0011387468548491597
reward/intrinsic_batch_min :  4.973921022610739e-06
reward/total_batch :  0.037003514069502245
time/iteration_time :  111.7359299659729
time/fps :  2416.4116241053657
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2416
Policy Loss: 0.0003, Value Loss: 4.7168, Entropy: 2.3427
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.045, sum=136.7
Extrinsic raw: Œº=0.07395555555555555

=== Iteration 448/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.40s
EPOCH 1 took 18.61s
update_step :  448
reward/intrinsic_batch_mean :  4.94909846539856e-05
reward/extrinsic_batch_mean :  0.07524444444444445
loss/policy :  0.0007297561608015023
loss/rnd :  1.2545070073125923e-06
loss/value :  5.96054618286364
loss/value_i :  3.1190834995482653e-06
loss/value_e :  5.960543097871723
loss/entropy :  2.332545291293751
reward/intrinsic_running :  0.0014113164713436238
reward/extrinsic_running :  0.07524444444444445
reward/intrinsic_std_running :  0.02538584680139503
reward/extrinsic_std_running :  1.5421165516151603
reward/intrinsic_batch_std :  3.9235831338313985e-05
reward/intrinsic_batch_max :  0.0012974037090316415
reward/intrinsic_batch_min :  3.934985215892084e-06
reward/total_batch :  0.037646967714549215
time/iteration_time :  110.74089288711548
time/fps :  2438.123740570039
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2438
Policy Loss: 0.0007, Value Loss: 5.9605, Entropy: 2.3325
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.051, sum=131.6
Extrinsic raw: Œº=0.07524444444444445

=== Iteration 449/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.45s
EPOCH 1 took 17.56s
update_step :  449
reward/intrinsic_batch_mean :  5.083611133128148e-05
reward/extrinsic_batch_mean :  0.08016296296296296
loss/policy :  0.0010904305752112784
loss/rnd :  1.2840508333917542e-06
loss/value :  4.762803883263559
loss/value_i :  3.101785544210791e-06
loss/value_e :  4.762800791046836
loss/entropy :  2.335868932984092
reward/intrinsic_running :  0.0014084362944825175
reward/extrinsic_running :  0.08016296296296296
reward/intrinsic_std_running :  0.0253576350946358
reward/extrinsic_std_running :  1.622849520453349
reward/intrinsic_batch_std :  3.991553072782042e-05
reward/intrinsic_batch_max :  0.0006014755927026272
reward/intrinsic_batch_min :  5.2269106163294055e-06
reward/total_batch :  0.04010689953714712
time/iteration_time :  109.74803948402405
time/fps :  2460.180621625626
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.7s | FPS: 2460
Policy Loss: 0.0011, Value Loss: 4.7628, Entropy: 2.3359
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=135.3
Extrinsic raw: Œº=0.08016296296296296

=== Iteration 450/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 18.77s
update_step :  450
reward/intrinsic_batch_mean :  5.072165380391164e-05
reward/extrinsic_batch_mean :  0.0827925925925926
loss/policy :  0.0004156899698445517
loss/rnd :  1.2842702076478887e-06
loss/value :  5.073173634933703
loss/value_i :  3.3171951579127135e-06
loss/value_e :  5.0731703115232065
loss/entropy :  2.32434157891707
reward/intrinsic_running :  0.001405570311333734
reward/extrinsic_running :  0.0827925925925926
reward/intrinsic_std_running :  0.025329517161234293
reward/extrinsic_std_running :  1.6309191391554787
reward/intrinsic_batch_std :  3.933030128698504e-05
reward/intrinsic_batch_max :  0.0005556092946790159
reward/intrinsic_batch_min :  3.4077943382726517e-06
reward/total_batch :  0.04142165712319826
time/iteration_time :  111.80853700637817
time/fps :  2414.8424371620004
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0004, Value Loss: 5.0732, Entropy: 2.3243
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=135.2
Extrinsic raw: Œº=0.0827925925925926

=== Iteration 451/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.13s
EPOCH 1 took 18.58s
update_step :  451
reward/intrinsic_batch_mean :  4.955478000379285e-05
reward/extrinsic_batch_mean :  0.07908888888888889
loss/policy :  0.0005606304788891451
loss/rnd :  1.2502428017851894e-06
loss/value :  6.319693485895793
loss/value_i :  3.2576448761160877e-06
loss/value_e :  6.319690213058934
loss/entropy :  2.3286957307295366
reward/intrinsic_running :  0.001402708177974266
reward/extrinsic_running :  0.07908888888888889
reward/intrinsic_std_running :  0.025301492997664033
reward/extrinsic_std_running :  1.5826538142633941
reward/intrinsic_batch_std :  3.7018401843444815e-05
reward/intrinsic_batch_max :  0.0006649049464613199
reward/intrinsic_batch_min :  5.149105163582135e-06
reward/total_batch :  0.03956922183444634
time/iteration_time :  113.03677201271057
time/fps :  2388.603241161553
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0006, Value Loss: 6.3197, Entropy: 2.3287
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=132.2
Extrinsic raw: Œº=0.07908888888888889

=== Iteration 452/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.11s
EPOCH 1 took 18.92s
update_step :  452
reward/intrinsic_batch_mean :  4.873961529406693e-05
reward/extrinsic_batch_mean :  0.07942222222222223
loss/policy :  0.0007039089987026246
loss/rnd :  1.2248703800458205e-06
loss/value :  4.341300343022202
loss/value_i :  3.0199808710070406e-06
loss/value_e :  4.341297355565158
loss/entropy :  2.3340249531196826
reward/intrinsic_running :  0.0013998552134227744
reward/extrinsic_running :  0.07942222222222223
reward/intrinsic_std_running :  0.025273561823262954
reward/extrinsic_std_running :  1.6022147517162872
reward/intrinsic_batch_std :  3.869523070121221e-05
reward/intrinsic_batch_max :  0.0011214260011911392
reward/intrinsic_batch_min :  4.097788860235596e-06
reward/total_batch :  0.03973548091875815
time/iteration_time :  111.6132423877716
time/fps :  2419.067793604223
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0007, Value Loss: 4.3413, Entropy: 2.3340
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.044, sum=130.2
Extrinsic raw: Œº=0.07942222222222223

=== Iteration 453/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.84s
EPOCH 1 took 19.48s
update_step :  453
reward/intrinsic_batch_mean :  4.9777543149374884e-05
reward/extrinsic_batch_mean :  0.07892592592592593
loss/policy :  0.0011827892290470613
loss/rnd :  1.2601617113845847e-06
loss/value :  5.712647019010602
loss/value_i :  3.0561553372039767e-06
loss/value_e :  5.712643941243489
loss/entropy :  2.327984192154624
reward/intrinsic_running :  0.0013970210031769006
reward/extrinsic_running :  0.07892592592592593
reward/intrinsic_std_running :  0.02524572263995961
reward/extrinsic_std_running :  1.5728519608689582
reward/intrinsic_batch_std :  3.8301395392007016e-05
reward/intrinsic_batch_max :  0.0008514648652635515
reward/intrinsic_batch_min :  5.058937404101016e-06
reward/total_batch :  0.03948785173453765
time/iteration_time :  113.49135637283325
time/fps :  2379.035801748781
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: 0.0012, Value Loss: 5.7126, Entropy: 2.3280
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.034, sum=133.1
Extrinsic raw: Œº=0.07892592592592593

=== Iteration 454/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.20s
EPOCH 1 took 19.41s
update_step :  454
reward/intrinsic_batch_mean :  4.808031113798616e-05
reward/extrinsic_batch_mean :  0.08057037037037038
loss/policy :  0.00040661443585342954
loss/rnd :  1.211075471019285e-06
loss/value :  5.888661124489524
loss/value_i :  3.199344384732037e-06
loss/value_e :  5.888657902226304
loss/entropy :  2.336495106870478
reward/intrinsic_running :  0.0013941887429878338
reward/extrinsic_running :  0.08057037037037038
reward/intrinsic_std_running :  0.02521797577277368
reward/extrinsic_std_running :  1.5966055105000487
reward/intrinsic_batch_std :  3.744915301895683e-05
reward/intrinsic_batch_max :  0.0005067000747658312
reward/intrinsic_batch_min :  4.511683982855175e-06
reward/total_batch :  0.04030922534075418
time/iteration_time :  111.50487542152405
time/fps :  2421.418785316012
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0004, Value Loss: 5.8887, Entropy: 2.3365
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.020, sum=128.7
Extrinsic raw: Œº=0.08057037037037038

=== Iteration 455/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 18.00s
update_step :  455
reward/intrinsic_batch_mean :  5.080375996251489e-05
reward/extrinsic_batch_mean :  0.07497037037037037
loss/policy :  0.0008646262021184983
loss/rnd :  1.2712976385817896e-06
loss/value :  5.369131966070696
loss/value_i :  3.2820041552082384e-06
loss/value_e :  5.369128678784226
loss/entropy :  2.335993792071487
reward/intrinsic_running :  0.0013913834419365578
reward/extrinsic_running :  0.07497037037037037
reward/intrinsic_std_running :  0.02519031968502894
reward/extrinsic_std_running :  1.5517033051683018
reward/intrinsic_batch_std :  5.0196043114537214e-05
reward/intrinsic_batch_max :  0.0010599030647426844
reward/intrinsic_batch_min :  4.471020474738907e-06
reward/total_batch :  0.03751058706516644
time/iteration_time :  111.48476529121399
time/fps :  2421.855571877662
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: 0.0009, Value Loss: 5.3691, Entropy: 2.3360
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.042, sum=136.1
Extrinsic raw: Œº=0.07497037037037037

=== Iteration 456/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.07s
EPOCH 1 took 18.87s
update_step :  456
reward/intrinsic_batch_mean :  5.020164335612747e-05
reward/extrinsic_batch_mean :  0.08085925925925926
loss/policy :  0.0010768653653830177
loss/rnd :  1.2627713359010655e-06
loss/value :  6.050411759000836
loss/value_i :  3.281210848454617e-06
loss/value_e :  6.0504084644895615
loss/entropy :  2.328518737446178
reward/intrinsic_running :  0.0013885853240437173
reward/extrinsic_running :  0.08085925925925926
reward/intrinsic_std_running :  0.0251627544272075
reward/extrinsic_std_running :  1.59751969865772
reward/intrinsic_batch_std :  3.969797154941114e-05
reward/intrinsic_batch_max :  0.0006218506023287773
reward/intrinsic_batch_min :  4.588039701047819e-06
reward/total_batch :  0.040454730451307694
time/iteration_time :  112.04384303092957
time/fps :  2409.7709672941764
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0011, Value Loss: 6.0504, Entropy: 2.3285
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=134.7
Extrinsic raw: Œº=0.08085925925925926

=== Iteration 457/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 19.38s
update_step :  457
reward/intrinsic_batch_mean :  5.0442369025417804e-05
reward/extrinsic_batch_mean :  0.07511851851851852
loss/policy :  0.001112148241990133
loss/rnd :  1.310023337323814e-06
loss/value :  5.738254070281982
loss/value_i :  3.0424412767443396e-06
loss/value_e :  5.738251039476106
loss/entropy :  2.339390906420621
reward/intrinsic_running :  0.0013858017201149836
reward/extrinsic_running :  0.07511851851851852
reward/intrinsic_std_running :  0.025135279348697716
reward/extrinsic_std_running :  1.5415906241995723
reward/intrinsic_batch_std :  3.788244766138188e-05
reward/intrinsic_batch_max :  0.0005974823143333197
reward/intrinsic_batch_min :  4.463797722564777e-06
reward/total_batch :  0.03758448044377197
time/iteration_time :  113.9426736831665
time/fps :  2369.612641798916
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2370
Policy Loss: 0.0011, Value Loss: 5.7383, Entropy: 2.3394
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=135.5
Extrinsic raw: Œº=0.07511851851851852

=== Iteration 458/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 19.87s
update_step :  458
reward/intrinsic_batch_mean :  5.364031092725512e-05
reward/extrinsic_batch_mean :  0.0835037037037037
loss/policy :  0.0003254338190538075
loss/rnd :  1.325425512966445e-06
loss/value :  5.769372694420092
loss/value_i :  3.203842070296091e-06
loss/value_e :  5.769369479381677
loss/entropy :  2.3156492710113525
reward/intrinsic_running :  0.0013830474209170264
reward/extrinsic_running :  0.0835037037037037
reward/intrinsic_std_running :  0.02510789321486648
reward/extrinsic_std_running :  1.620407271046497
reward/intrinsic_batch_std :  3.94038239241672e-05
reward/intrinsic_batch_max :  0.0006893910467624664
reward/intrinsic_batch_min :  5.098658220958896e-06
reward/total_batch :  0.04177867200731548
time/iteration_time :  113.49009037017822
time/fps :  2379.062340327009
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: 0.0003, Value Loss: 5.7694, Entropy: 2.3156
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=144.2
Extrinsic raw: Œº=0.0835037037037037

=== Iteration 459/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.87s
EPOCH 1 took 17.86s
update_step :  459
reward/intrinsic_batch_mean :  5.377097589096391e-05
reward/extrinsic_batch_mean :  0.07454814814814816
loss/policy :  0.00045133467717801756
loss/rnd :  1.5700093740633747e-06
loss/value :  5.391721021045338
loss/value_i :  3.0902841844539526e-06
loss/value_e :  5.391717928828615
loss/entropy :  2.3272043177575776
reward/intrinsic_running :  0.0013803051987925454
reward/extrinsic_running :  0.07454814814814816
reward/intrinsic_std_running :  0.025080596396061174
reward/extrinsic_std_running :  1.5300393300126178
reward/intrinsic_batch_std :  3.745611069593596e-05
reward/intrinsic_batch_max :  0.0005957346293143928
reward/intrinsic_batch_min :  6.386932909663301e-06
reward/total_batch :  0.03730095956201956
time/iteration_time :  111.35175466537476
time/fps :  2424.7484991267725
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2425
Policy Loss: 0.0005, Value Loss: 5.3917, Entropy: 2.3272
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=144.7
Extrinsic raw: Œº=0.07454814814814816

=== Iteration 460/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.30s
update_step :  460
reward/intrinsic_batch_mean :  5.8140645546006484e-05
reward/extrinsic_batch_mean :  0.07615555555555556
loss/policy :  0.0007546808646469744
loss/rnd :  2.853098902560856e-06
loss/value :  5.463021036350366
loss/value_i :  2.9531317219759026e-06
loss/value_e :  5.463018121141376
loss/entropy :  2.339418497952548
reward/intrinsic_running :  0.001377594272624632
reward/extrinsic_running :  0.07615555555555556
reward/intrinsic_std_running :  0.025053387459724383
reward/extrinsic_std_running :  1.554507292987272
reward/intrinsic_batch_std :  4.101132313629293e-05
reward/intrinsic_batch_max :  0.0007052062428556383
reward/intrinsic_batch_min :  9.669412065704819e-06
reward/total_batch :  0.03810684810055078
time/iteration_time :  112.02565121650696
time/fps :  2410.1622893330305
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0008, Value Loss: 5.4630, Entropy: 2.3394
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=156.6
Extrinsic raw: Œº=0.07615555555555556

=== Iteration 461/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 19.41s
update_step :  461
reward/intrinsic_batch_mean :  5.674096564440266e-05
reward/extrinsic_batch_mean :  0.07497037037037037
loss/policy :  0.00023301015872592953
loss/rnd :  1.3801719574351437e-06
loss/value :  6.30360725070491
loss/value_i :  2.9364143101977818e-06
loss/value_e :  6.303604342720726
loss/entropy :  2.3301993427854595
reward/intrinsic_running :  0.0013748890056757774
reward/extrinsic_running :  0.07497037037037037
reward/intrinsic_std_running :  0.02502626718633831
reward/extrinsic_std_running :  1.5411653236034217
reward/intrinsic_batch_std :  4.0072475352490096e-05
reward/intrinsic_batch_max :  0.000619945116341114
reward/intrinsic_batch_min :  6.064313311071601e-06
reward/total_batch :  0.03751355566800738
time/iteration_time :  111.5996606349945
time/fps :  2419.3621957604378
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0002, Value Loss: 6.3036, Entropy: 2.3302
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=153.0
Extrinsic raw: Œº=0.07497037037037037

=== Iteration 462/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.32s
EPOCH 1 took 20.10s
update_step :  462
reward/intrinsic_batch_mean :  5.354945213804496e-05
reward/extrinsic_batch_mean :  0.07044444444444445
loss/policy :  0.0009615608229950974
loss/rnd :  1.3176407395748715e-06
loss/value :  4.854935317328482
loss/value_i :  4.356472617694111e-06
loss/value_e :  4.854930967995615
loss/entropy :  2.332741040171999
reward/intrinsic_running :  0.0013721816561761402
reward/extrinsic_running :  0.07044444444444445
reward/intrinsic_std_running :  0.024999235479781157
reward/extrinsic_std_running :  1.4870678913823157
reward/intrinsic_batch_std :  3.8310212474614865e-05
reward/intrinsic_batch_max :  0.0007365898345597088
reward/intrinsic_batch_min :  6.1546220422314946e-06
reward/total_batch :  0.03524899694829125
time/iteration_time :  111.74341559410095
time/fps :  2416.2497500591307
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2416
Policy Loss: 0.0010, Value Loss: 4.8549, Entropy: 2.3327
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=144.6
Extrinsic raw: Œº=0.07044444444444445

=== Iteration 463/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.62s
EPOCH 1 took 18.19s
update_step :  463
reward/intrinsic_batch_mean :  5.253197916313015e-05
reward/extrinsic_batch_mean :  0.0788
loss/policy :  0.00043693599053023553
loss/rnd :  1.310162524463742e-06
loss/value :  6.456033070882161
loss/value_i :  3.985089974914004e-06
loss/value_e :  6.456029024991122
loss/entropy :  2.318959933338743
reward/intrinsic_running :  0.0013694794726890876
reward/extrinsic_running :  0.0788
reward/intrinsic_std_running :  0.02497229151173852
reward/extrinsic_std_running :  1.5438113624931522
reward/intrinsic_batch_std :  3.989908058043297e-05
reward/intrinsic_batch_max :  0.0005826309788972139
reward/intrinsic_batch_min :  4.521063146967208e-06
reward/total_batch :  0.039426265989581565
time/iteration_time :  111.93383884429932
time/fps :  2412.139195686585
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: 0.0004, Value Loss: 6.4560, Entropy: 2.3190
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=142.0
Extrinsic raw: Œº=0.0788

=== Iteration 464/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 18.77s
update_step :  464
reward/intrinsic_batch_mean :  5.1594912368515605e-05
reward/extrinsic_batch_mean :  0.07614814814814815
loss/policy :  0.00024108258995428596
loss/rnd :  1.2918897165504997e-06
loss/value :  5.992530559048508
loss/value_i :  3.141631647408896e-05
loss/value_e :  5.992499141982107
loss/entropy :  2.3240012472326104
reward/intrinsic_running :  0.0013667842942044308
reward/extrinsic_running :  0.07614814814814815
reward/intrinsic_std_running :  0.024945434693770793
reward/extrinsic_std_running :  1.5449492309458825
reward/intrinsic_batch_std :  3.812271672926312e-05
reward/intrinsic_batch_max :  0.0006514436681754887
reward/intrinsic_batch_min :  4.271107627573656e-06
reward/total_batch :  0.03809987153025833
time/iteration_time :  112.00143098831177
time/fps :  2410.6834851795475
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0002, Value Loss: 5.9925, Entropy: 2.3240
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=139.6
Extrinsic raw: Œº=0.07614814814814815

=== Iteration 465/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 19.22s
update_step :  465
reward/intrinsic_batch_mean :  5.2890166547156156e-05
reward/extrinsic_batch_mean :  0.07453333333333333
loss/policy :  0.000572054364690275
loss/rnd :  1.3248607098665326e-06
loss/value :  5.637687628919428
loss/value_i :  3.359174027219992e-05
loss/value_e :  5.637654066085815
loss/entropy :  2.321382117993904
reward/intrinsic_running :  0.0013641071375159299
reward/extrinsic_running :  0.07453333333333333
reward/intrinsic_std_running :  0.02491866403230647
reward/extrinsic_std_running :  1.5300908847370982
reward/intrinsic_batch_std :  3.9438681844792234e-05
reward/intrinsic_batch_max :  0.0005226508365012705
reward/intrinsic_batch_min :  5.060867351858178e-06
reward/total_batch :  0.03729311174994024
time/iteration_time :  112.62190222740173
time/fps :  2397.4022340239517
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2397
Policy Loss: 0.0006, Value Loss: 5.6377, Entropy: 2.3214
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=143.3
Extrinsic raw: Œº=0.07453333333333333

=== Iteration 466/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.58s
update_step :  466
reward/intrinsic_batch_mean :  5.080473987489111e-05
reward/extrinsic_batch_mean :  0.07706666666666667
loss/policy :  0.0010671854053009265
loss/rnd :  1.2821465719698057e-06
loss/value :  4.606317064978859
loss/value_i :  3.1744411864675577e-06
loss/value_e :  4.60631387161486
loss/entropy :  2.3349764383200444
reward/intrinsic_running :  0.0013614300009026018
reward/extrinsic_running :  0.07706666666666667
reward/intrinsic_std_running :  0.02489197993696344
reward/extrinsic_std_running :  1.5855976753729641
reward/intrinsic_batch_std :  3.963988636492267e-05
reward/intrinsic_batch_max :  0.0006260883528739214
reward/intrinsic_batch_min :  4.406928383104969e-06
reward/total_batch :  0.03855873570327078
time/iteration_time :  110.82472658157349
time/fps :  2436.2794146057668
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2436
Policy Loss: 0.0011, Value Loss: 4.6063, Entropy: 2.3350
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=137.8
Extrinsic raw: Œº=0.07706666666666667

=== Iteration 467/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.84s
EPOCH 1 took 18.80s
update_step :  467
reward/intrinsic_batch_mean :  5.368053125696153e-05
reward/extrinsic_batch_mean :  0.07629629629629629
loss/policy :  0.0005506538433440834
loss/rnd :  1.3300234375933404e-06
loss/value :  5.854489373438286
loss/value_i :  3.2169193914479832e-06
loss/value_e :  5.854486140337857
loss/entropy :  2.328742594429941
reward/intrinsic_running :  0.0013587779570591982
reward/extrinsic_running :  0.07629629629629629
reward/intrinsic_std_running :  0.02486538071851233
reward/extrinsic_std_running :  1.5738703136092107
reward/intrinsic_batch_std :  4.213127478435656e-05
reward/intrinsic_batch_max :  0.0009244445245712996
reward/intrinsic_batch_min :  5.057708676758921e-06
reward/total_batch :  0.038174988413776624
time/iteration_time :  112.51940774917603
time/fps :  2399.5860394312926
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0006, Value Loss: 5.8545, Entropy: 2.3287
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=145.7
Extrinsic raw: Œº=0.07629629629629629

=== Iteration 468/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 19.70s
update_step :  468
reward/intrinsic_batch_mean :  5.1450372834322616e-05
reward/extrinsic_batch_mean :  0.07558518518518519
loss/policy :  0.0005084410253347772
loss/rnd :  1.2998150585493324e-06
loss/value :  4.595480918884277
loss/value_i :  2.9141150607205364e-06
loss/value_e :  4.595478000062885
loss/entropy :  2.33511343869296
reward/intrinsic_running :  0.001356126518045668
reward/extrinsic_running :  0.07558518518518519
reward/intrinsic_std_running :  0.024838867110914608
reward/extrinsic_std_running :  1.5715920891234263
reward/intrinsic_batch_std :  3.903593249175324e-05
reward/intrinsic_batch_max :  0.0007160721579566598
reward/intrinsic_batch_min :  4.676170192396967e-06
reward/total_batch :  0.03781831777900976
time/iteration_time :  112.54647636413574
time/fps :  2399.0089136725624
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0005, Value Loss: 4.5955, Entropy: 2.3351
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=139.8
Extrinsic raw: Œº=0.07558518518518519

=== Iteration 469/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.23s
EPOCH 1 took 19.02s
update_step :  469
reward/intrinsic_batch_mean :  5.9207420515196175e-05
reward/extrinsic_batch_mean :  0.07587407407407408
loss/policy :  -7.980376143347133e-06
loss/rnd :  1.4392706682222276e-06
loss/value :  5.2422308488325635
loss/value_i :  3.2996055717210932e-06
loss/value_e :  5.242227536259276
loss/entropy :  2.3271446733763725
reward/intrinsic_running :  0.0013535230649957995
reward/extrinsic_running :  0.07587407407407408
reward/intrinsic_std_running :  0.024812436318545992
reward/extrinsic_std_running :  1.553517685434407
reward/intrinsic_batch_std :  3.9194535881648685e-05
reward/intrinsic_batch_max :  0.0005254031857475638
reward/intrinsic_batch_min :  9.613369002181571e-06
reward/total_batch :  0.03796664074729464
time/iteration_time :  111.40030694007874
time/fps :  2423.6917062107436
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: -0.0000, Value Loss: 5.2422, Entropy: 2.3271
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=161.1
Extrinsic raw: Œº=0.07587407407407408

=== Iteration 470/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 18.91s
update_step :  470
reward/intrinsic_batch_mean :  5.503924201234946e-05
reward/extrinsic_batch_mean :  0.07854074074074074
loss/policy :  0.0005923289449349271
loss/rnd :  1.7529574854575691e-06
loss/value :  5.036619782447815
loss/value_i :  3.1125305867769355e-06
loss/value_e :  5.036616675781481
loss/entropy :  2.314334338361567
reward/intrinsic_running :  0.0013509108675633112
reward/extrinsic_running :  0.07854074074074074
reward/intrinsic_std_running :  0.024786090698444126
reward/extrinsic_std_running :  1.5619923946462688
reward/intrinsic_batch_std :  3.9958236784616754e-05
reward/intrinsic_batch_max :  0.0006100953323766589
reward/intrinsic_batch_min :  5.682848950527841e-06
reward/total_batch :  0.039297889991376546
time/iteration_time :  110.37538075447083
time/fps :  2446.197677003832
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: 0.0006, Value Loss: 5.0366, Entropy: 2.3143
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=149.9
Extrinsic raw: Œº=0.07854074074074074

=== Iteration 471/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.41s
EPOCH 1 took 18.47s
update_step :  471
reward/intrinsic_batch_mean :  7.819824616173584e-05
reward/extrinsic_batch_mean :  0.07605925925925926
loss/policy :  0.0007277418899871973
loss/rnd :  6.0886841242101966e-06
loss/value :  4.150269862377282
loss/value_i :  5.573119962622458e-05
loss/value_e :  4.150214133840619
loss/entropy :  2.3238015138741694
reward/intrinsic_running :  0.0013484221997820442
reward/extrinsic_running :  0.07605925925925926
reward/intrinsic_std_running :  0.024759823438649815
reward/extrinsic_std_running :  1.5540270828612088
reward/intrinsic_batch_std :  4.3835475546802345e-05
reward/intrinsic_batch_max :  0.0008260596077889204
reward/intrinsic_batch_min :  2.3064665583660826e-05
reward/total_batch :  0.038068728752710494
time/iteration_time :  111.61845779418945
time/fps :  2418.954761925186
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0007, Value Loss: 4.1503, Entropy: 2.3238
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=213.2
Extrinsic raw: Œº=0.07605925925925926

=== Iteration 472/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 18.78s
update_step :  472
reward/intrinsic_batch_mean :  0.00029361747703752133
reward/extrinsic_batch_mean :  0.07442222222222222
loss/policy :  0.0004983888801220791
loss/rnd :  3.0443873473621243e-06
loss/value :  3.9907323880629106
loss/value_i :  5.422191562006033e-05
loss/value_e :  3.9906781658981787
loss/entropy :  2.339124235239896
reward/intrinsic_running :  0.0013469718027692404
reward/extrinsic_running :  0.07442222222222222
reward/intrinsic_std_running :  0.02473360175549066
reward/extrinsic_std_running :  1.5583913356605037
reward/intrinsic_batch_std :  5.330039423420384e-05
reward/intrinsic_batch_max :  0.0012147558154538274
reward/intrinsic_batch_min :  0.00016771706577856094
reward/total_batch :  0.03735791984962987
time/iteration_time :  112.46170282363892
time/fps :  2400.8172846485418
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0005, Value Loss: 3.9907, Entropy: 2.3391
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.012, max=0.049, sum=801.3
Extrinsic raw: Œº=0.07442222222222222

=== Iteration 473/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 18.96s
update_step :  473
reward/intrinsic_batch_mean :  5.561071480129208e-05
reward/extrinsic_batch_mean :  0.07765185185185185
loss/policy :  0.0008056074328564908
loss/rnd :  1.3196877175963009e-06
loss/value :  4.847856633590929
loss/value_i :  3.987274415824989e-06
loss/value_e :  4.8478526671727495
loss/entropy :  2.333994970177159
reward/intrinsic_running :  0.0013443917048576667
reward/extrinsic_running :  0.07765185185185185
reward/intrinsic_std_running :  0.02470750614341747
reward/extrinsic_std_running :  1.5686145706914303
reward/intrinsic_batch_std :  4.257025907379477e-05
reward/intrinsic_batch_max :  0.0005932516069151461
reward/intrinsic_batch_min :  6.634344572375994e-06
reward/total_batch :  0.038853731283326566
time/iteration_time :  112.32333159446716
time/fps :  2403.774853961861
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0008, Value Loss: 4.8479, Entropy: 2.3340
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=151.9
Extrinsic raw: Œº=0.07765185185185185

=== Iteration 474/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 19.46s
update_step :  474
reward/intrinsic_batch_mean :  5.201596991816957e-05
reward/extrinsic_batch_mean :  0.07926666666666667
loss/policy :  0.0002929746983819782
loss/rnd :  1.2788527628386377e-06
loss/value :  5.482440836501844
loss/value_i :  3.2100445761181726e-06
loss/value_e :  5.482437617851026
loss/entropy :  2.332315939845461
reward/intrinsic_running :  0.0013418047734349067
reward/extrinsic_running :  0.07926666666666667
reward/intrinsic_std_running :  0.024681493820197294
reward/extrinsic_std_running :  1.610983751441152
reward/intrinsic_batch_std :  3.9827075577130685e-05
reward/intrinsic_batch_max :  0.0007683825679123402
reward/intrinsic_batch_min :  4.605520189215895e-06
reward/total_batch :  0.03965934131829242
time/iteration_time :  112.06091165542603
time/fps :  2409.4039215941584
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0003, Value Loss: 5.4824, Entropy: 2.3323
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=142.3
Extrinsic raw: Œº=0.07926666666666667

=== Iteration 475/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 18.91s
update_step :  475
reward/intrinsic_batch_mean :  5.30095193414632e-05
reward/extrinsic_batch_mean :  0.07574814814814815
loss/policy :  0.0009141457690434022
loss/rnd :  1.3030407141438143e-06
loss/value :  4.296667922626842
loss/value_i :  3.264052762378097e-06
loss/value_e :  4.296664649789983
loss/entropy :  2.339623100829847
reward/intrinsic_running :  0.0013392334323668992
reward/extrinsic_running :  0.07574814814814815
reward/intrinsic_std_running :  0.02465556326439847
reward/extrinsic_std_running :  1.5720531501641464
reward/intrinsic_batch_std :  4.2552306885656226e-05
reward/intrinsic_batch_max :  0.0006719770608469844
reward/intrinsic_batch_min :  5.175250862521352e-06
reward/total_batch :  0.03790057883374481
time/iteration_time :  111.92786955833435
time/fps :  2412.26783879132
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: 0.0009, Value Loss: 4.2967, Entropy: 2.3396
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=145.1
Extrinsic raw: Œº=0.07574814814814815

=== Iteration 476/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.60s
update_step :  476
reward/intrinsic_batch_mean :  5.2002121559093616e-05
reward/extrinsic_batch_mean :  0.08017037037037036
loss/policy :  0.00030938911941396356
loss/rnd :  1.2790323932098213e-06
loss/value :  4.21463177059636
loss/value_i :  2.9023607994256024e-06
loss/value_e :  4.214628858999773
loss/entropy :  2.3387951814767085
reward/intrinsic_running :  0.0013366672046348205
reward/extrinsic_running :  0.08017037037037036
reward/intrinsic_std_running :  0.024629714538085924
reward/extrinsic_std_running :  1.6136932933640185
reward/intrinsic_batch_std :  4.175517395844065e-05
reward/intrinsic_batch_max :  0.0007620800170116127
reward/intrinsic_batch_min :  5.279473043628968e-06
reward/total_batch :  0.04011118624596473
time/iteration_time :  111.96419930458069
time/fps :  2411.485114679454
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0003, Value Loss: 4.2146, Entropy: 2.3388
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=142.5
Extrinsic raw: Œº=0.08017037037037036

=== Iteration 477/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 19.07s
update_step :  477
reward/intrinsic_batch_mean :  5.2224722919783274e-05
reward/extrinsic_batch_mean :  0.07735555555555555
loss/policy :  0.0010202648629660182
loss/rnd :  1.2824149848711386e-06
loss/value :  5.218428026546132
loss/value_i :  2.890788953829377e-06
loss/value_e :  5.2184251474611685
loss/entropy :  2.339848200480143
reward/intrinsic_running :  0.0013341105147896591
reward/extrinsic_running :  0.07735555555555555
reward/intrinsic_std_running :  0.02460394699976559
reward/extrinsic_std_running :  1.5771532627874145
reward/intrinsic_batch_std :  4.0716986341408635e-05
reward/intrinsic_batch_max :  0.0005929803592152894
reward/intrinsic_batch_min :  4.898123734164983e-06
reward/total_batch :  0.03870389013923767
time/iteration_time :  111.73330950737
time/fps :  2416.468295716155
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2416
Policy Loss: 0.0010, Value Loss: 5.2184, Entropy: 2.3398
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=143.3
Extrinsic raw: Œº=0.07735555555555555

=== Iteration 478/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.27s
EPOCH 1 took 19.00s
update_step :  478
reward/intrinsic_batch_mean :  5.193526286463263e-05
reward/extrinsic_batch_mean :  0.07984444444444444
loss/policy :  0.00043366405368556804
loss/rnd :  1.2754458146336027e-06
loss/value :  4.990091605619951
loss/value_i :  3.0956907342745885e-06
loss/value_e :  4.990088520628033
loss/entropy :  2.3305242422855263
reward/intrinsic_running :  0.0013315666417261802
reward/extrinsic_running :  0.07984444444444444
reward/intrinsic_std_running :  0.024578260065800883
reward/extrinsic_std_running :  1.5943182839750925
reward/intrinsic_batch_std :  4.0048587563961535e-05
reward/intrinsic_batch_max :  0.0005610401858575642
reward/intrinsic_batch_min :  4.576324499794282e-06
reward/total_batch :  0.03994818985365454
time/iteration_time :  109.76379156112671
time/fps :  2459.827563897871
data/episodes_collected :  60
data/frames_collected :  270000
Timer 109.8s | FPS: 2460
Policy Loss: 0.0004, Value Loss: 4.9901, Entropy: 2.3305
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=142.6
Extrinsic raw: Œº=0.07984444444444444

=== Iteration 479/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 18.31s
update_step :  479
reward/intrinsic_batch_mean :  4.969497693827078e-05
reward/extrinsic_batch_mean :  0.07705925925925926
loss/policy :  0.0007128379092495325
loss/rnd :  1.2184998175171406e-06
loss/value :  4.561141017711524
loss/value_i :  2.943463035383805e-06
loss/value_e :  4.56113806999091
loss/entropy :  2.3410350156552866
reward/intrinsic_running :  0.001329020457048139
reward/extrinsic_running :  0.07705925925925926
reward/intrinsic_std_running :  0.02455265404199382
reward/extrinsic_std_running :  1.5949151899568228
reward/intrinsic_batch_std :  3.93184504443849e-05
reward/intrinsic_batch_max :  0.0005740014603361487
reward/intrinsic_batch_min :  4.676921435020631e-06
reward/total_batch :  0.038554477118098764
time/iteration_time :  111.79037404060364
time/fps :  2415.234784901361
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0007, Value Loss: 4.5611, Entropy: 2.3410
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=136.6
Extrinsic raw: Œº=0.07705925925925926

=== Iteration 480/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.25s
EPOCH 1 took 18.55s
update_step :  480
reward/intrinsic_batch_mean :  4.865564040167859e-05
reward/extrinsic_batch_mean :  0.0756074074074074
loss/policy :  0.0006884399547495625
loss/rnd :  1.1933215935669343e-06
loss/value :  4.270974603566256
loss/value_i :  2.666409989504962e-06
loss/value_e :  4.2709719303882485
loss/entropy :  2.34660707098065
reward/intrinsic_running :  0.0013264815700888156
reward/extrinsic_running :  0.0756074074074074
reward/intrinsic_std_running :  0.024527128046378143
reward/extrinsic_std_running :  1.5809860382933383
reward/intrinsic_batch_std :  3.74136807838732e-05
reward/intrinsic_batch_max :  0.0006729387678205967
reward/intrinsic_batch_min :  4.736506070912583e-06
reward/total_batch :  0.03782803152390454
time/iteration_time :  111.08230686187744
time/fps :  2430.630112279941
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0007, Value Loss: 4.2710, Entropy: 2.3466
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=133.9
Extrinsic raw: Œº=0.0756074074074074

=== Iteration 481/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.76s
update_step :  481
reward/intrinsic_batch_mean :  4.994138916377038e-05
reward/extrinsic_batch_mean :  0.07602962962962963
loss/policy :  0.0008411160846607703
loss/rnd :  1.224978658146111e-06
loss/value :  4.637558456623193
loss/value_i :  2.660478278840222e-06
loss/value_e :  4.637555819569212
loss/entropy :  2.3387066306489888
reward/intrinsic_running :  0.0013239569359566896
reward/extrinsic_running :  0.07602962962962963
reward/intrinsic_std_running :  0.02450168131835859
reward/extrinsic_std_running :  1.5823742870469273
reward/intrinsic_batch_std :  4.0452050182346625e-05
reward/intrinsic_batch_max :  0.0009516832651570439
reward/intrinsic_batch_min :  5.180310381547315e-06
reward/total_batch :  0.0380397855093967
time/iteration_time :  112.6587507724762
time/fps :  2396.6180891290696
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: 0.0008, Value Loss: 4.6376, Entropy: 2.3387
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.039, sum=137.6
Extrinsic raw: Œº=0.07602962962962963

=== Iteration 482/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.26s
EPOCH 1 took 19.35s
update_step :  482
reward/intrinsic_batch_mean :  5.051072101779802e-05
reward/extrinsic_batch_mean :  0.07946666666666667
loss/policy :  0.00032254957403148927
loss/rnd :  1.3987800019949095e-06
loss/value :  3.5885267077070293
loss/value_i :  2.6062113172222534e-06
loss/value_e :  3.588524077877854
loss/entropy :  2.342935435699694
reward/intrinsic_running :  0.0013214469080901198
reward/extrinsic_running :  0.07946666666666667
reward/intrinsic_std_running :  0.024476313428360992
reward/extrinsic_std_running :  1.611425597505605
reward/intrinsic_batch_std :  4.093781854249613e-05
reward/intrinsic_batch_max :  0.0006211255094967782
reward/intrinsic_batch_min :  3.5260939057479845e-06
reward/total_batch :  0.03975858869384224
time/iteration_time :  112.03667163848877
time/fps :  2409.925215122554
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0003, Value Loss: 3.5885, Entropy: 2.3429
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=139.3
Extrinsic raw: Œº=0.07946666666666667

=== Iteration 483/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.59s
EPOCH 1 took 19.20s
update_step :  483
reward/intrinsic_batch_mean :  5.3419619732408645e-05
reward/extrinsic_batch_mean :  0.0762074074074074
loss/policy :  0.00045766013984878856
loss/rnd :  1.258684309587724e-06
loss/value :  4.0416223569349805
loss/value_i :  2.7426754747990123e-06
loss/value_e :  4.041619593446905
loss/entropy :  2.3344017086607036
reward/intrinsic_running :  0.0013189588482239297
reward/extrinsic_running :  0.0762074074074074
reward/intrinsic_std_running :  0.024451023611219237
reward/extrinsic_std_running :  1.5639976749830988
reward/intrinsic_batch_std :  4.176510420498614e-05
reward/intrinsic_batch_max :  0.0010283837327733636
reward/intrinsic_batch_min :  6.4247647060255986e-06
reward/total_batch :  0.038130413513569904
time/iteration_time :  112.35381174087524
time/fps :  2403.1227407104675
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: 0.0005, Value Loss: 4.0416, Entropy: 2.3344
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.042, sum=147.5
Extrinsic raw: Œº=0.0762074074074074

=== Iteration 484/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.93s
EPOCH 1 took 18.84s
update_step :  484
reward/intrinsic_batch_mean :  4.992553060850763e-05
reward/extrinsic_batch_mean :  0.08311111111111111
loss/policy :  0.00037827129849712503
loss/rnd :  1.2172080318757226e-06
loss/value :  4.973577087575739
loss/value_i :  2.7893367869734047e-06
loss/value_e :  4.973574277126428
loss/entropy :  2.3253241018815474
reward/intrinsic_running :  0.0013164661602286655
reward/extrinsic_running :  0.08311111111111111
reward/intrinsic_std_running :  0.02442581273555183
reward/extrinsic_std_running :  1.6318076623528828
reward/intrinsic_batch_std :  3.9667837148938534e-05
reward/intrinsic_batch_max :  0.00053659628611058
reward/intrinsic_batch_min :  4.719454864243744e-06
reward/total_batch :  0.04158051832085981
time/iteration_time :  111.03194880485535
time/fps :  2431.732513986038
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2432
Policy Loss: 0.0004, Value Loss: 4.9736, Entropy: 2.3253
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=138.0
Extrinsic raw: Œº=0.08311111111111111

=== Iteration 485/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.05s
EPOCH 1 took 19.01s
update_step :  485
reward/intrinsic_batch_mean :  5.2033344972665805e-05
reward/extrinsic_batch_mean :  0.07896296296296296
loss/policy :  0.0013039922429897795
loss/rnd :  1.2689936232329109e-06
loss/value :  5.393690781159834
loss/value_i :  3.0728909423211888e-06
loss/value_e :  5.39368771422993
loss/entropy :  2.315795157894944
reward/intrinsic_running :  0.0013139922204313606
reward/extrinsic_running :  0.07896296296296296
reward/intrinsic_std_running :  0.024400679279894526
reward/extrinsic_std_running :  1.5728442149666901
reward/intrinsic_batch_std :  4.2466873051649614e-05
reward/intrinsic_batch_max :  0.0007047795807011425
reward/intrinsic_batch_min :  4.650145456253085e-06
reward/total_batch :  0.03950749815396781
time/iteration_time :  112.25632905960083
time/fps :  2405.209597194716
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0013, Value Loss: 5.3937, Entropy: 2.3158
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=143.9
Extrinsic raw: Œº=0.07896296296296296

=== Iteration 486/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.55s
EPOCH 1 took 19.72s
update_step :  486
reward/intrinsic_batch_mean :  5.189537916349191e-05
reward/extrinsic_batch_mean :  0.08094074074074074
loss/policy :  0.0009618572499179704
loss/rnd :  1.265331181085375e-06
loss/value :  4.032267967859904
loss/value_i :  2.9164577261491846e-06
loss/value_e :  4.032265056263316
loss/entropy :  2.3195079817916406
reward/intrinsic_running :  0.001311527915075042
reward/extrinsic_running :  0.08094074074074074
reward/intrinsic_std_running :  0.024375623299156834
reward/extrinsic_std_running :  1.5975028210162912
reward/intrinsic_batch_std :  4.403526301481196e-05
reward/intrinsic_batch_max :  0.0009049974614754319
reward/intrinsic_batch_min :  4.756705038744258e-06
reward/total_batch :  0.040496318059952116
time/iteration_time :  112.06716084480286
time/fps :  2409.2695662551114
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0010, Value Loss: 4.0323, Entropy: 2.3195
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=143.7
Extrinsic raw: Œº=0.08094074074074074

=== Iteration 487/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.79s
EPOCH 1 took 18.08s
update_step :  487
reward/intrinsic_batch_mean :  4.921274664774736e-05
reward/extrinsic_batch_mean :  0.08020740740740741
loss/policy :  0.000413768372681895
loss/rnd :  1.1858285698839277e-06
loss/value :  3.111499705097892
loss/value_i :  2.5287246699284e-06
loss/value_e :  3.1114971854469995
loss/entropy :  2.331850871895299
reward/intrinsic_running :  0.0013090611961870527
reward/extrinsic_running :  0.08020740740740741
reward/intrinsic_std_running :  0.02435064491733303
reward/extrinsic_std_running :  1.63194388563794
reward/intrinsic_batch_std :  3.8195321808052804e-05
reward/intrinsic_batch_max :  0.0006567951058968902
reward/intrinsic_batch_min :  5.243722625891678e-06
reward/total_batch :  0.04012831007702758
time/iteration_time :  112.24830365180969
time/fps :  2405.3815622686875
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2405
Policy Loss: 0.0004, Value Loss: 3.1115, Entropy: 2.3319
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=136.4
Extrinsic raw: Œº=0.08020740740740741

=== Iteration 488/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.55s
EPOCH 1 took 18.51s
update_step :  488
reward/intrinsic_batch_mean :  5.267707086434341e-05
reward/extrinsic_batch_mean :  0.07778518518518518
loss/policy :  0.0007501508366796329
loss/rnd :  1.3779431924376695e-06
loss/value :  5.263104897556883
loss/value_i :  2.854560806774702e-06
loss/value_e :  5.263102025696726
loss/entropy :  2.3168218713818174
reward/intrinsic_running :  0.001306617715165964
reward/extrinsic_running :  0.07778518518518518
reward/intrinsic_std_running :  0.02432574252336954
reward/extrinsic_std_running :  1.569129689823064
reward/intrinsic_batch_std :  3.847773074758273e-05
reward/intrinsic_batch_max :  0.0006352614145725965
reward/intrinsic_batch_min :  6.260442205530126e-06
reward/total_batch :  0.03891893112802476
time/iteration_time :  111.6178719997406
time/fps :  2418.967457116791
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0008, Value Loss: 5.2631, Entropy: 2.3168
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=146.2
Extrinsic raw: Œº=0.07778518518518518

=== Iteration 489/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.72s
EPOCH 1 took 19.57s
update_step :  489
reward/intrinsic_batch_mean :  5.292033356532489e-05
reward/extrinsic_batch_mean :  0.07597037037037037
loss/policy :  0.0007339876302108733
loss/rnd :  1.2758310321480553e-06
loss/value :  6.45342374570442
loss/value_i :  3.000626265654291e-06
loss/value_e :  6.453420754634973
loss/entropy :  2.3133133360833833
reward/intrinsic_running :  0.0013041863191921306
reward/extrinsic_running :  0.07597037037037037
reward/intrinsic_std_running :  0.024300916487685786
reward/extrinsic_std_running :  1.5635497312477933
reward/intrinsic_batch_std :  5.415749785575833e-05
reward/intrinsic_batch_max :  0.0012641260400414467
reward/intrinsic_batch_min :  4.714368515124079e-06
reward/total_batch :  0.03801164535196785
time/iteration_time :  113.02601170539856
time/fps :  2388.830641071835
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0007, Value Loss: 6.4534, Entropy: 2.3133
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.052, sum=147.0
Extrinsic raw: Œº=0.07597037037037037

=== Iteration 490/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 20.11s
update_step :  490
reward/intrinsic_batch_mean :  4.943442538050375e-05
reward/extrinsic_batch_mean :  0.08077037037037037
loss/policy :  0.0006079552765709884
loss/rnd :  1.1996503744602236e-06
loss/value :  4.416821042696635
loss/value_i :  2.737416249339841e-06
loss/value_e :  4.416818318944989
loss/entropy :  2.3152689428040474
reward/intrinsic_running :  0.0013017501843154955
reward/extrinsic_running :  0.08077037037037037
reward/intrinsic_std_running :  0.02427616683896133
reward/extrinsic_std_running :  1.5886805144206508
reward/intrinsic_batch_std :  4.4076407386644326e-05
reward/intrinsic_batch_max :  0.0010397052392363548
reward/intrinsic_batch_min :  4.62818661617348e-06
reward/total_batch :  0.04040990239787544
time/iteration_time :  113.23111176490784
time/fps :  2384.5036562087116
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0006, Value Loss: 4.4168, Entropy: 2.3153
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.043, sum=137.5
Extrinsic raw: Œº=0.08077037037037037

=== Iteration 491/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 18.87s
update_step :  491
reward/intrinsic_batch_mean :  5.334582481794954e-05
reward/extrinsic_batch_mean :  0.08587407407407407
loss/policy :  0.0008311803861888069
loss/rnd :  1.3117523367051918e-06
loss/value :  6.211587096705581
loss/value_i :  3.2596003792963475e-06
loss/value_e :  6.2115838491555415
loss/entropy :  2.3049165082700327
reward/intrinsic_running :  0.0012993410108742096
reward/extrinsic_running :  0.08587407407407407
reward/intrinsic_std_running :  0.024251492085444453
reward/extrinsic_std_running :  1.6582408390939352
reward/intrinsic_batch_std :  5.651964021426637e-05
reward/intrinsic_batch_max :  0.001137303770519793
reward/intrinsic_batch_min :  4.124513907299843e-06
reward/total_batch :  0.04296370994944601
time/iteration_time :  112.56002831459045
time/fps :  2398.7200789021263
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0008, Value Loss: 6.2116, Entropy: 2.3049
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.047, sum=148.5
Extrinsic raw: Œº=0.08587407407407407

=== Iteration 492/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 18.94s
update_step :  492
reward/intrinsic_batch_mean :  5.1023690309847115e-05
reward/extrinsic_batch_mean :  0.07914074074074075
loss/policy :  0.0006556051931428639
loss/rnd :  1.2423685878578301e-06
loss/value :  4.983006365371473
loss/value_i :  3.008067954562483e-06
loss/value_e :  4.983003363464817
loss/entropy :  2.312267932024869
reward/intrinsic_running :  0.0012969273634868836
reward/extrinsic_running :  0.07914074074074075
reward/intrinsic_std_running :  0.02422689284842818
reward/extrinsic_std_running :  1.6013014621815087
reward/intrinsic_batch_std :  4.28962229236704e-05
reward/intrinsic_batch_max :  0.0006483030738309026
reward/intrinsic_batch_min :  5.211503776081372e-06
reward/total_batch :  0.0395958822155253
time/iteration_time :  111.86506652832031
time/fps :  2413.6221286888117
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: 0.0007, Value Loss: 4.9830, Entropy: 2.3123
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=142.2
Extrinsic raw: Œº=0.07914074074074075

=== Iteration 493/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 18.99s
update_step :  493
reward/intrinsic_batch_mean :  5.2756029952561896e-05
reward/extrinsic_batch_mean :  0.08012592592592592
loss/policy :  0.00035191919816883677
loss/rnd :  1.2795783191270884e-06
loss/value :  6.38205640966242
loss/value_i :  3.488740021291023e-06
loss/value_e :  6.382052891182177
loss/entropy :  2.3052441640333696
reward/intrinsic_running :  0.001294530360537548
reward/extrinsic_running :  0.08012592592592592
reward/intrinsic_std_running :  0.0242023680077672
reward/extrinsic_std_running :  1.56712706676961
reward/intrinsic_batch_std :  4.698876612409189e-05
reward/intrinsic_batch_max :  0.0009924747282639146
reward/intrinsic_batch_min :  5.448860520118615e-06
reward/total_batch :  0.04008934097793924
time/iteration_time :  112.42404079437256
time/fps :  2401.6215579178415
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: 0.0004, Value Loss: 6.3821, Entropy: 2.3052
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=147.1
Extrinsic raw: Œº=0.08012592592592592

=== Iteration 494/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.01s
EPOCH 1 took 19.09s
update_step :  494
reward/intrinsic_batch_mean :  5.112737635924229e-05
reward/extrinsic_batch_mean :  0.08314814814814815
loss/policy :  0.001335208884539139
loss/rnd :  1.4152649500278076e-06
loss/value :  4.5963153694615215
loss/value_i :  3.8250614848452225e-06
loss/value_e :  4.596311525865034
loss/entropy :  2.319162531332536
reward/intrinsic_running :  0.0012921372774353757
reward/extrinsic_running :  0.08314814814814815
reward/intrinsic_std_running :  0.024177917730944007
reward/extrinsic_std_running :  1.6318001013128778
reward/intrinsic_batch_std :  3.996030318056059e-05
reward/intrinsic_batch_max :  0.0005074086366221309
reward/intrinsic_batch_min :  7.116278084140504e-06
reward/total_batch :  0.0415996377622537
time/iteration_time :  113.1009316444397
time/fps :  2387.2482399067294
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2387
Policy Loss: 0.0013, Value Loss: 4.5963, Entropy: 2.3192
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=142.7
Extrinsic raw: Œº=0.08314814814814815

=== Iteration 495/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.18s
update_step :  495
reward/intrinsic_batch_mean :  5.096224301828274e-05
reward/extrinsic_batch_mean :  0.08283703703703704
loss/policy :  8.672581558736663e-05
loss/rnd :  6.468382087570552e-06
loss/value :  4.4754963643623125
loss/value_i :  0.00019140998448840423
loss/value_e :  4.475304953979723
loss/entropy :  2.3185745152560147
reward/intrinsic_running :  0.0012897539992980838
reward/extrinsic_running :  0.08283703703703704
reward/intrinsic_std_running :  0.02415354139815846
reward/extrinsic_std_running :  1.6309100695392598
reward/intrinsic_batch_std :  3.907474279076219e-05
reward/intrinsic_batch_max :  0.000508126977365464
reward/intrinsic_batch_min :  5.144492206454743e-06
reward/total_batch :  0.041443999640027665
time/iteration_time :  112.31497621536255
time/fps :  2403.953676509519
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0001, Value Loss: 4.4755, Entropy: 2.3186
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=142.4
Extrinsic raw: Œº=0.08283703703703704

=== Iteration 496/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.55s
EPOCH 1 took 19.15s
update_step :  496
reward/intrinsic_batch_mean :  0.0004108279040057419
reward/extrinsic_batch_mean :  0.08206666666666666
loss/policy :  0.0002634536444516429
loss/rnd :  3.7726953051429573e-06
loss/value :  5.931468613219984
loss/value_i :  2.2401545148761326e-05
loss/value_e :  5.931446201873548
loss/entropy :  2.3195589744683467
reward/intrinsic_running :  0.0012889713453364002
reward/extrinsic_running :  0.08206666666666666
reward/intrinsic_std_running :  0.024129188564477426
reward/extrinsic_std_running :  1.6103859289002744
reward/intrinsic_batch_std :  7.332624102869645e-05
reward/intrinsic_batch_max :  0.0016795394476503134
reward/intrinsic_batch_min :  0.0002551445213612169
reward/total_batch :  0.041238747285336205
time/iteration_time :  112.79348111152649
time/fps :  2393.7553601438444
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0003, Value Loss: 5.9315, Entropy: 2.3196
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.017, max=0.070, sum=1149.3
Extrinsic raw: Œº=0.08206666666666666

=== Iteration 497/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.53s
EPOCH 1 took 18.66s
update_step :  497
reward/intrinsic_batch_mean :  5.836591242878731e-05
reward/extrinsic_batch_mean :  0.08064444444444445
loss/policy :  0.0008901594150246996
loss/rnd :  1.3138647380566744e-06
loss/value :  4.449211424047297
loss/value_i :  3.3670828956515337e-06
loss/value_e :  4.449208057287968
loss/entropy :  2.3230944871902466
reward/intrinsic_running :  0.0012866351308365553
reward/extrinsic_running :  0.08064444444444445
reward/intrinsic_std_running :  0.02410495776330351
reward/extrinsic_std_running :  1.6057962693833336
reward/intrinsic_batch_std :  4.7219082399186625e-05
reward/intrinsic_batch_max :  0.0010742630111053586
reward/intrinsic_batch_min :  6.083472726459149e-06
reward/total_batch :  0.04035140517843662
time/iteration_time :  112.27572512626648
time/fps :  2404.794087914864
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2405
Policy Loss: 0.0009, Value Loss: 4.4492, Entropy: 2.3231
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.045, sum=163.4
Extrinsic raw: Œº=0.08064444444444445

=== Iteration 498/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.65s
EPOCH 1 took 19.70s
update_step :  498
reward/intrinsic_batch_mean :  5.2845541814733426e-05
reward/extrinsic_batch_mean :  0.08003703703703703
loss/policy :  0.0008563054421260445
loss/rnd :  1.2570250415785378e-06
loss/value :  4.191176643877318
loss/value_i :  3.173887393765626e-06
loss/value_e :  4.191173450513319
loss/entropy :  2.327310132257866
reward/intrinsic_running :  0.0012842849937310828
reward/extrinsic_running :  0.08003703703703703
reward/intrinsic_std_running :  0.024080800911580578
reward/extrinsic_std_running :  1.613238518368185
reward/intrinsic_batch_std :  4.154737970516473e-05
reward/intrinsic_batch_max :  0.000657921948004514
reward/intrinsic_batch_min :  4.270408680895343e-06
reward/total_batch :  0.04004494128942588
time/iteration_time :  112.35310006141663
time/fps :  2403.1379628368722
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: 0.0009, Value Loss: 4.1912, Entropy: 2.3273
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=148.1
Extrinsic raw: Œº=0.08003703703703703

=== Iteration 499/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.94s
EPOCH 1 took 18.78s
update_step :  499
reward/intrinsic_batch_mean :  5.2125760059580323e-05
reward/extrinsic_batch_mean :  0.07841481481481481
loss/policy :  0.0015631424338966044
loss/rnd :  1.2495599745224437e-06
loss/value :  4.832977811495463
loss/value_i :  2.8563176404835153e-06
loss/value_e :  4.832974928798097
loss/entropy :  2.3331840435663858
reward/intrinsic_running :  0.0012819390777826878
reward/extrinsic_running :  0.07841481481481481
reward/intrinsic_std_running :  0.0240567167927831
reward/extrinsic_std_running :  1.589728373654677
reward/intrinsic_batch_std :  4.423398073979898e-05
reward/intrinsic_batch_max :  0.0007017143652774394
reward/intrinsic_batch_min :  4.8300112212018576e-06
reward/total_batch :  0.0392334702874372
time/iteration_time :  111.61384201049805
time/fps :  2419.0547976531857
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0016, Value Loss: 4.8330, Entropy: 2.3332
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=146.3
Extrinsic raw: Œº=0.07841481481481481

=== Iteration 500/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.10s
EPOCH 1 took 18.90s
update_step :  500
reward/intrinsic_batch_mean :  5.3812338165308004e-05
reward/extrinsic_batch_mean :  0.0826888888888889
loss/policy :  0.0005200781390268469
loss/rnd :  1.289297157117372e-06
loss/value :  4.05001894271735
loss/value_i :  3.0398024881089274e-06
loss/value_e :  4.050015890237057
loss/entropy :  2.3131564638831397
reward/intrinsic_running :  0.0012796133346536745
reward/extrinsic_running :  0.0826888888888889
reward/intrinsic_std_running :  0.024032704296379697
reward/extrinsic_std_running :  1.6121424528853092
reward/intrinsic_batch_std :  4.6524874878717436e-05
reward/intrinsic_batch_max :  0.0007500913343392313
reward/intrinsic_batch_min :  4.0922354855865706e-06
reward/total_batch :  0.0413713506135271
time/iteration_time :  110.24160099029541
time/fps :  2449.1661729746484
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.2s | FPS: 2449
Policy Loss: 0.0005, Value Loss: 4.0500, Entropy: 2.3132
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=151.1
Extrinsic raw: Œº=0.0826888888888889

=== Iteration 501/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.25s
EPOCH 1 took 18.86s
update_step :  501
reward/intrinsic_batch_mean :  5.212404545558524e-05
reward/extrinsic_batch_mean :  0.0784
loss/policy :  0.00015640584134609637
loss/rnd :  1.250307379354071e-06
loss/value :  4.471691048506535
loss/value_i :  2.904200645196287e-06
loss/value_e :  4.47168814052235
loss/entropy :  2.3229617241657143
reward/intrinsic_running :  0.0012772891689535873
reward/extrinsic_running :  0.0784
reward/intrinsic_std_running :  0.024008763914152645
reward/extrinsic_std_running :  1.5990233463655943
reward/intrinsic_batch_std :  4.244977946895326e-05
reward/intrinsic_batch_max :  0.0006106188520789146
reward/intrinsic_batch_min :  4.7848352551227435e-06
reward/total_batch :  0.03922606202272779
time/iteration_time :  111.20993733406067
time/fps :  2427.8405911600685
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0002, Value Loss: 4.4717, Entropy: 2.3230
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=146.5
Extrinsic raw: Œº=0.0784

=== Iteration 502/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.53s
EPOCH 1 took 18.88s
update_step :  502
reward/intrinsic_batch_mean :  5.31136103528735e-05
reward/extrinsic_batch_mean :  0.07882962962962962
loss/policy :  0.000666121777612716
loss/rnd :  1.2715929453103552e-06
loss/value :  5.168463392691179
loss/value_i :  2.9771967519715843e-06
loss/value_e :  5.168460430520954
loss/entropy :  2.316087487972144
reward/intrinsic_running :  0.0012749760652281087
reward/extrinsic_running :  0.07882962962962962
reward/intrinsic_std_running :  0.023984894849539824
reward/extrinsic_std_running :  1.600393690179554
reward/intrinsic_batch_std :  4.2776516167101836e-05
reward/intrinsic_batch_max :  0.0007601011311635375
reward/intrinsic_batch_min :  4.410657766129589e-06
reward/total_batch :  0.03944137161999125
time/iteration_time :  111.53111147880554
time/fps :  2420.8491820805407
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0007, Value Loss: 5.1685, Entropy: 2.3161
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=149.5
Extrinsic raw: Œº=0.07882962962962962

=== Iteration 503/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 18.49s
update_step :  503
reward/intrinsic_batch_mean :  5.051602468441464e-05
reward/extrinsic_batch_mean :  0.07713333333333333
loss/policy :  0.000686023825299785
loss/rnd :  1.2091539757062546e-06
loss/value :  2.9651258316907017
loss/value_i :  2.690038703197691e-06
loss/value_e :  2.9651231296134717
loss/entropy :  2.3191294200492627
reward/intrinsic_running :  0.0012726611517440234
reward/extrinsic_running :  0.07713333333333333
reward/intrinsic_std_running :  0.023961097359242435
reward/extrinsic_std_running :  1.5948999982583367
reward/intrinsic_batch_std :  4.12428092915499e-05
reward/intrinsic_batch_max :  0.0006597563624382019
reward/intrinsic_batch_min :  3.868357453029603e-06
reward/total_batch :  0.03859192467900887
time/iteration_time :  111.85195732116699
time/fps :  2413.905008606451
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2414
Policy Loss: 0.0007, Value Loss: 2.9651, Entropy: 2.3191
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=142.3
Extrinsic raw: Œº=0.07713333333333333

=== Iteration 504/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.08s
EPOCH 1 took 19.35s
update_step :  504
reward/intrinsic_batch_mean :  5.115287675797407e-05
reward/extrinsic_batch_mean :  0.07637037037037037
loss/policy :  0.0007223486957930921
loss/rnd :  1.2385262741852123e-06
loss/value :  3.8148695519476226
loss/value_i :  2.887503018372985e-06
loss/value_e :  3.8148666620254517
loss/entropy :  2.3125686862251977
reward/intrinsic_running :  0.0012703594990450147
reward/extrinsic_running :  0.07637037037037037
reward/intrinsic_std_running :  0.02393737036833357
reward/extrinsic_std_running :  1.574748942909999
reward/intrinsic_batch_std :  4.071884679179274e-05
reward/intrinsic_batch_max :  0.0005707032396458089
reward/intrinsic_batch_min :  4.653016731026582e-06
reward/total_batch :  0.03821076162356417
time/iteration_time :  112.74451947212219
time/fps :  2394.7948979175135
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0007, Value Loss: 3.8149, Entropy: 2.3126
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=144.2
Extrinsic raw: Œº=0.07637037037037037

=== Iteration 505/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.06s
EPOCH 1 took 19.34s
update_step :  505
reward/intrinsic_batch_mean :  5.134282317742839e-05
reward/extrinsic_batch_mean :  0.07708148148148149
loss/policy :  0.00028100633150615704
loss/rnd :  1.2326417039399862e-06
loss/value :  4.528111945499074
loss/value_i :  2.764469331161694e-06
loss/value_e :  4.528109167561387
loss/entropy :  2.316680565024867
reward/intrinsic_running :  0.0012680640520704573
reward/extrinsic_running :  0.07708148148148149
reward/intrinsic_std_running :  0.023913713863282494
reward/extrinsic_std_running :  1.5762235461490997
reward/intrinsic_batch_std :  4.219952359151377e-05
reward/intrinsic_batch_max :  0.0006182215292938054
reward/intrinsic_batch_min :  4.248309778631665e-06
reward/total_batch :  0.038566412152329456
time/iteration_time :  114.12763547897339
time/fps :  2365.7723115602807
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0003, Value Loss: 4.5281, Entropy: 2.3167
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=144.9
Extrinsic raw: Œº=0.07708148148148149

=== Iteration 506/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.56s
update_step :  506
reward/intrinsic_batch_mean :  5.112722899291974e-05
reward/extrinsic_batch_mean :  0.07822962962962964
loss/policy :  0.0013976436422319348
loss/rnd :  1.219984257562773e-06
loss/value :  5.777121695605191
loss/value_i :  2.8157013537455704e-06
loss/value_e :  5.777118834582242
loss/entropy :  2.3130641742186113
reward/intrinsic_running :  0.0012657795420098355
reward/extrinsic_running :  0.07822962962962964
reward/intrinsic_std_running :  0.023890127267426977
reward/extrinsic_std_running :  1.57052318926241
reward/intrinsic_batch_std :  4.135382285891853e-05
reward/intrinsic_batch_max :  0.0006276085623539984
reward/intrinsic_batch_min :  3.944257059629308e-06
reward/total_batch :  0.03914037842931128
time/iteration_time :  112.75521349906921
time/fps :  2394.5677687198813
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2395
Policy Loss: 0.0014, Value Loss: 5.7771, Entropy: 2.3131
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=144.5
Extrinsic raw: Œº=0.07822962962962964

=== Iteration 507/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 19.26s
update_step :  507
reward/intrinsic_batch_mean :  5.1507857594704005e-05
reward/extrinsic_batch_mean :  0.07605185185185186
loss/policy :  0.0008564840911386648
loss/rnd :  1.2281248690338875e-06
loss/value :  4.261969544670799
loss/value_i :  2.6805710562753533e-06
loss/value_e :  4.261966846205971
loss/entropy :  2.3169238603476323
reward/intrinsic_running :  0.0012635059770211934
reward/extrinsic_running :  0.07605185185185186
reward/intrinsic_std_running :  0.023866610228854127
reward/extrinsic_std_running :  1.5729794226174894
reward/intrinsic_batch_std :  4.03117235718781e-05
reward/intrinsic_batch_max :  0.0005933642969466746
reward/intrinsic_batch_min :  4.7443895709875505e-06
reward/total_batch :  0.03805167985472328
time/iteration_time :  113.15148115158081
time/fps :  2386.1817561035778
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0009, Value Loss: 4.2620, Entropy: 2.3169
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=145.7
Extrinsic raw: Œº=0.07605185185185186

=== Iteration 508/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 19.39s
update_step :  508
reward/intrinsic_batch_mean :  5.1132652362799425e-05
reward/extrinsic_batch_mean :  0.07798518518518519
loss/policy :  0.0006006429426964711
loss/rnd :  1.2191406116554306e-06
loss/value :  3.9689864498196226
loss/value_i :  2.5745823815227733e-06
loss/value_e :  3.9689838958509043
loss/entropy :  2.3172403357245703
reward/intrinsic_running :  0.001261238611287496
reward/extrinsic_running :  0.07798518518518519
reward/intrinsic_std_running :  0.023843162632554146
reward/extrinsic_std_running :  1.5883487161908008
reward/intrinsic_batch_std :  4.0367318271998486e-05
reward/intrinsic_batch_max :  0.0006018011481501162
reward/intrinsic_batch_min :  4.892379365628585e-06
reward/total_batch :  0.03901815891877399
time/iteration_time :  112.47978901863098
time/fps :  2400.431245077083
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0006, Value Loss: 3.9690, Entropy: 2.3172
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=144.8
Extrinsic raw: Œº=0.07798518518518519

=== Iteration 509/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.39s
EPOCH 1 took 18.89s
update_step :  509
reward/intrinsic_batch_mean :  5.1262310817791906e-05
reward/extrinsic_batch_mean :  0.07575555555555556
loss/policy :  0.001087675902950154
loss/rnd :  1.2204060219504975e-06
loss/value :  4.983362327922475
loss/value_i :  2.710576650728895e-06
loss/value_e :  4.983359600558425
loss/entropy :  2.3145182132720947
reward/intrinsic_running :  0.0012589823429907708
reward/extrinsic_running :  0.07575555555555556
reward/intrinsic_std_running :  0.023819783918008423
reward/extrinsic_std_running :  1.5338930088076994
reward/intrinsic_batch_std :  4.254255080571223e-05
reward/intrinsic_batch_max :  0.0008495573420077562
reward/intrinsic_batch_min :  4.8210117711278144e-06
reward/total_batch :  0.03790340893318668
time/iteration_time :  111.8494770526886
time/fps :  2413.958537086516
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: 0.0011, Value Loss: 4.9834, Entropy: 2.3145
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=145.3
Extrinsic raw: Œº=0.07575555555555556

=== Iteration 510/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 18.93s
update_step :  510
reward/intrinsic_batch_mean :  5.16122491937764e-05
reward/extrinsic_batch_mean :  0.07617037037037037
loss/policy :  0.0010894789796139141
loss/rnd :  1.2263787597834326e-06
loss/value :  5.469406030394814
loss/value_i :  2.624900892469944e-06
loss/value_e :  5.469403386116028
loss/entropy :  2.315051981897065
reward/intrinsic_running :  0.0012567333991767174
reward/extrinsic_running :  0.07617037037037037
reward/intrinsic_std_running :  0.02379647389663628
reward/extrinsic_std_running :  1.5545041845755276
reward/intrinsic_batch_std :  3.986667722622436e-05
reward/intrinsic_batch_max :  0.0005807247944176197
reward/intrinsic_batch_min :  4.719505341199692e-06
reward/total_batch :  0.03811099130978208
time/iteration_time :  112.19938921928406
time/fps :  2406.4302121316205
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0011, Value Loss: 5.4694, Entropy: 2.3151
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=146.4
Extrinsic raw: Œº=0.07617037037037037

=== Iteration 511/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.02s
EPOCH 1 took 18.85s
update_step :  511
reward/intrinsic_batch_mean :  5.4139963246672304e-05
reward/extrinsic_batch_mean :  0.07412592592592593
loss/policy :  0.0006129295745102519
loss/rnd :  1.2850657347399013e-06
loss/value :  4.83621100584666
loss/value_i :  2.7150782567663225e-06
loss/value_e :  4.836208260420597
loss/entropy :  2.3095668373685894
reward/intrinsic_running :  0.00125450297981172
reward/extrinsic_running :  0.07412592592592593
reward/intrinsic_std_running :  0.023773231790638106
reward/extrinsic_std_running :  1.5383124998210294
reward/intrinsic_batch_std :  5.119262225639616e-05
reward/intrinsic_batch_max :  0.001064314623363316
reward/intrinsic_batch_min :  4.542166607279796e-06
reward/total_batch :  0.0370900329445863
time/iteration_time :  112.84951138496399
time/fps :  2392.5668501917385
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0006, Value Loss: 4.8362, Entropy: 2.3096
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.045, sum=153.7
Extrinsic raw: Œº=0.07412592592592593

=== Iteration 512/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.25s
EPOCH 1 took 19.27s
update_step :  512
reward/intrinsic_batch_mean :  5.474343144661462e-05
reward/extrinsic_batch_mean :  0.07705185185185186
loss/policy :  0.000542295320580403
loss/rnd :  1.2959916461747498e-06
loss/value :  6.104464697115349
loss/value_i :  3.0352707240540027e-06
loss/value_e :  6.104461677146681
loss/entropy :  2.2898791847806987
reward/intrinsic_running :  0.0012522856037225124
reward/extrinsic_running :  0.07705185185185186
reward/intrinsic_std_running :  0.02375005738124407
reward/extrinsic_std_running :  1.5381747399579533
reward/intrinsic_batch_std :  4.431843682183771e-05
reward/intrinsic_batch_max :  0.000731831940356642
reward/intrinsic_batch_min :  4.897410690318793e-06
reward/total_batch :  0.038553297641649234
time/iteration_time :  112.80619645118713
time/fps :  2393.485539748988
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0005, Value Loss: 6.1045, Entropy: 2.2899
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=155.6
Extrinsic raw: Œº=0.07705185185185186

=== Iteration 513/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.29s
EPOCH 1 took 18.85s
update_step :  513
reward/intrinsic_batch_mean :  5.450901177549962e-05
reward/extrinsic_batch_mean :  0.07622222222222222
loss/policy :  0.0009930023083914862
loss/rnd :  1.290011208642351e-06
loss/value :  4.01312916206591
loss/value_i :  3.0255836477546394e-06
loss/value_e :  4.013126142097242
loss/entropy :  2.3049119927666406
reward/intrinsic_running :  0.001250077885773235
reward/extrinsic_running :  0.07622222222222222
reward/intrinsic_std_running :  0.02372695075004486
reward/extrinsic_std_running :  1.5639945849421588
reward/intrinsic_batch_std :  5.3227820734579844e-05
reward/intrinsic_batch_max :  0.0011165827745571733
reward/intrinsic_batch_min :  3.939862835977692e-06
reward/total_batch :  0.03813836561699886
time/iteration_time :  113.54099655151367
time/fps :  2377.9956861440855
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2378
Policy Loss: 0.0010, Value Loss: 4.0131, Entropy: 2.3049
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.047, sum=155.1
Extrinsic raw: Œº=0.07622222222222222

=== Iteration 514/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 19.83s
update_step :  514
reward/intrinsic_batch_mean :  5.051664314345274e-05
reward/extrinsic_batch_mean :  0.08005185185185185
loss/policy :  0.0008600047881235228
loss/rnd :  1.1964717645462246e-06
loss/value :  4.490444017179085
loss/value_i :  2.6826250467076367e-06
loss/value_e :  4.490441304264647
loss/entropy :  2.3121139244599775
reward/intrinsic_running :  0.001247858695976777
reward/extrinsic_running :  0.08005185185185185
reward/intrinsic_std_running :  0.02370391217711577
reward/extrinsic_std_running :  1.6141535555872892
reward/intrinsic_batch_std :  3.804864927281984e-05
reward/intrinsic_batch_max :  0.000533153535798192
reward/intrinsic_batch_min :  4.447456831258023e-06
reward/total_batch :  0.04005118424749765
time/iteration_time :  113.27585124969482
time/fps :  2383.561871495778
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2384
Policy Loss: 0.0009, Value Loss: 4.4904, Entropy: 2.3121
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=143.9
Extrinsic raw: Œº=0.08005185185185185

=== Iteration 515/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.24s
EPOCH 1 took 19.69s
update_step :  515
reward/intrinsic_batch_mean :  5.099184147116089e-05
reward/extrinsic_batch_mean :  0.08257777777777778
loss/policy :  0.0008313049250070683
loss/rnd :  1.2050615475455935e-06
loss/value :  3.4545035578987817
loss/value_i :  2.961882907556807e-06
loss/value_e :  3.454500588503751
loss/entropy :  2.309135335864443
reward/intrinsic_running :  0.0012456500088748376
reward/extrinsic_running :  0.08257777777777778
reward/intrinsic_std_running :  0.023680940501144814
reward/extrinsic_std_running :  1.63907250858376
reward/intrinsic_batch_std :  4.158201588636872e-05
reward/intrinsic_batch_max :  0.000784662610385567
reward/intrinsic_batch_min :  4.068805083079496e-06
reward/total_batch :  0.04131438480962447
time/iteration_time :  113.05876612663269
time/fps :  2388.138569437275
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0008, Value Loss: 3.4545, Entropy: 2.3091
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=145.3
Extrinsic raw: Œº=0.08257777777777778

=== Iteration 516/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.68s
EPOCH 1 took 18.66s
update_step :  516
reward/intrinsic_batch_mean :  5.037477222906967e-05
reward/extrinsic_batch_mean :  0.07856296296296296
loss/policy :  0.00044763635003508887
loss/rnd :  1.1918423366075854e-06
loss/value :  4.355353763609221
loss/value_i :  2.937006246556297e-06
loss/value_e :  4.355350826725815
loss/entropy :  2.3148005225441675
reward/intrinsic_running :  0.0012434462326176249
reward/extrinsic_running :  0.07856296296296296
reward/intrinsic_std_running :  0.02365803566403419
reward/extrinsic_std_running :  1.5901869473483758
reward/intrinsic_batch_std :  4.1653542790431934e-05
reward/intrinsic_batch_max :  0.0009451304213143885
reward/intrinsic_batch_min :  4.706787422037451e-06
reward/total_batch :  0.03930666886759601
time/iteration_time :  111.397958278656
time/fps :  2423.7428061707333
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0004, Value Loss: 4.3554, Entropy: 2.3148
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.040, sum=143.7
Extrinsic raw: Œº=0.07856296296296296

=== Iteration 517/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.03s
EPOCH 1 took 18.76s
update_step :  517
reward/intrinsic_batch_mean :  4.9358238942214583e-05
reward/extrinsic_batch_mean :  0.08063703703703703
loss/policy :  0.0004862163138265411
loss/rnd :  1.1630443616399355e-06
loss/value :  4.2263756882060655
loss/value_i :  2.9152872994845067e-06
loss/value_e :  4.2263727549350625
loss/entropy :  2.311495640061118
reward/intrinsic_running :  0.001241248312627089
reward/extrinsic_running :  0.08063703703703703
reward/intrinsic_std_running :  0.02363519727462604
reward/extrinsic_std_running :  1.5965917059991555
reward/intrinsic_batch_std :  3.964546030241529e-05
reward/intrinsic_batch_max :  0.0006805313169024885
reward/intrinsic_batch_min :  4.484008968574926e-06
reward/total_batch :  0.040343197637989624
time/iteration_time :  112.3457202911377
time/fps :  2403.2958202618665
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2403
Policy Loss: 0.0005, Value Loss: 4.2264, Entropy: 2.3115
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=141.0
Extrinsic raw: Œº=0.08063703703703703

=== Iteration 518/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.08s
EPOCH 1 took 18.80s
update_step :  518
reward/intrinsic_batch_mean :  5.224404758232089e-05
reward/extrinsic_batch_mean :  0.0837037037037037
loss/policy :  0.001038238263307986
loss/rnd :  1.2327959235804111e-06
loss/value :  5.120842146150993
loss/value_i :  2.9488116875985395e-06
loss/value_e :  5.120839216492393
loss/entropy :  2.2960614110484268
reward/intrinsic_running :  0.0012390694914814096
reward/extrinsic_running :  0.0837037037037037
reward/intrinsic_std_running :  0.023612424392724013
reward/extrinsic_std_running :  1.6153067548328106
reward/intrinsic_batch_std :  4.0460902309673744e-05
reward/intrinsic_batch_max :  0.0008272242266684771
reward/intrinsic_batch_min :  4.799784619535785e-06
reward/total_batch :  0.04187797387564301
time/iteration_time :  111.28739547729492
time/fps :  2426.1507679464557
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: 0.0010, Value Loss: 5.1208, Entropy: 2.2961
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=149.3
Extrinsic raw: Œº=0.0837037037037037

=== Iteration 519/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.54s
EPOCH 1 took 18.98s
update_step :  519
reward/intrinsic_batch_mean :  5.193408432982391e-05
reward/extrinsic_batch_mean :  0.0804962962962963
loss/policy :  0.0011947915164372798
loss/rnd :  1.2228671662893302e-06
loss/value :  4.08335002263387
loss/value_i :  2.865373172619112e-06
loss/value_e :  4.083347161610921
loss/entropy :  2.298850366563508
reward/intrinsic_running :  0.0012368988460821036
reward/extrinsic_running :  0.0804962962962963
reward/intrinsic_std_running :  0.023589717227201507
reward/extrinsic_std_running :  1.6144985387010313
reward/intrinsic_batch_std :  3.97404918598472e-05
reward/intrinsic_batch_max :  0.0005564456223510206
reward/intrinsic_batch_min :  4.96542634209618e-06
reward/total_batch :  0.04027411519031306
time/iteration_time :  112.59605574607849
time/fps :  2397.952558914601
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0012, Value Loss: 4.0834, Entropy: 2.2989
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=148.6
Extrinsic raw: Œº=0.0804962962962963

=== Iteration 520/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.64s
EPOCH 1 took 18.86s
update_step :  520
reward/intrinsic_batch_mean :  5.416845136722393e-05
reward/extrinsic_batch_mean :  0.07797777777777777
loss/policy :  0.0007280283131298016
loss/rnd :  1.2759757951106152e-06
loss/value :  4.831550359725952
loss/value_i :  3.1110996105505335e-06
loss/value_e :  4.831547234997605
loss/entropy :  2.288183797489513
reward/intrinsic_running :  0.0012347451449444197
reward/extrinsic_running :  0.07797777777777777
reward/intrinsic_std_running :  0.023567075067399187
reward/extrinsic_std_running :  1.5600703401362515
reward/intrinsic_batch_std :  4.551545442554518e-05
reward/intrinsic_batch_max :  0.0010320553556084633
reward/intrinsic_batch_min :  4.809633992408635e-06
reward/total_batch :  0.0390159731145725
time/iteration_time :  112.58884263038635
time/fps :  2398.1061861198164
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0007, Value Loss: 4.8316, Entropy: 2.2882
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.044, sum=155.1
Extrinsic raw: Œº=0.07797777777777777

=== Iteration 521/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.51s
EPOCH 1 took 18.61s
update_step :  521
reward/intrinsic_batch_mean :  5.321048856027725e-05
reward/extrinsic_batch_mean :  0.0784
loss/policy :  0.0007315939380505094
loss/rnd :  1.2748457255508006e-06
loss/value :  5.376197876352252
loss/value_i :  2.9470516637681583e-06
loss/value_e :  5.376194925019235
loss/entropy :  2.286187276695714
reward/intrinsic_running :  0.001232596600201598
reward/extrinsic_running :  0.0784
reward/intrinsic_std_running :  0.023544498108809795
reward/extrinsic_std_running :  1.5615239811490902
reward/intrinsic_batch_std :  4.226072872365999e-05
reward/intrinsic_batch_max :  0.0008397222845815122
reward/intrinsic_batch_min :  5.2097598199907225e-06
reward/total_batch :  0.039226605244280136
time/iteration_time :  111.55223894119263
time/fps :  2420.390684783448
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0007, Value Loss: 5.3762, Entropy: 2.2862
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=152.5
Extrinsic raw: Œº=0.0784

=== Iteration 522/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.10s
EPOCH 1 took 19.20s
update_step :  522
reward/intrinsic_batch_mean :  5.328911711089016e-05
reward/extrinsic_batch_mean :  0.07547407407407407
loss/policy :  0.0008142808960242705
loss/rnd :  1.2519360914418278e-06
loss/value :  4.815743587233803
loss/value_i :  2.7840057527734614e-06
loss/value_e :  4.815740791234103
loss/entropy :  2.291533401518157
reward/intrinsic_running :  0.0012304564704433243
reward/extrinsic_running :  0.07547407407407407
reward/intrinsic_std_running :  0.023521985896713758
reward/extrinsic_std_running :  1.5329383420212825
reward/intrinsic_batch_std :  4.0558002982876946e-05
reward/intrinsic_batch_max :  0.0006805621087551117
reward/intrinsic_batch_min :  4.303355581214419e-06
reward/total_batch :  0.03776368159559248
time/iteration_time :  111.05698895454407
time/fps :  2431.184228401076
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0008, Value Loss: 4.8157, Entropy: 2.2915
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=152.9
Extrinsic raw: Œº=0.07547407407407407

=== Iteration 523/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 19.40s
update_step :  523
reward/intrinsic_batch_mean :  5.451832387166009e-05
reward/extrinsic_batch_mean :  0.08107407407407408
loss/policy :  0.0005927692797161977
loss/rnd :  1.328111166416916e-06
loss/value :  4.78502150737878
loss/value_i :  2.955947035264795e-06
loss/value_e :  4.78501855243336
loss/entropy :  2.2941501790826972
reward/intrinsic_running :  0.0012283277850907313
reward/extrinsic_running :  0.08107407407407408
reward/intrinsic_std_running :  0.023499538041952442
reward/extrinsic_std_running :  1.5886638789998841
reward/intrinsic_batch_std :  4.688328894758042e-05
reward/intrinsic_batch_max :  0.0008770654094405472
reward/intrinsic_batch_min :  4.982965947419871e-06
reward/total_batch :  0.040564296198972866
time/iteration_time :  113.20667576789856
time/fps :  2385.018358401109
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0006, Value Loss: 4.7850, Entropy: 2.2942
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=156.6
Extrinsic raw: Œº=0.08107407407407408

=== Iteration 524/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.89s
EPOCH 1 took 18.29s
update_step :  524
reward/intrinsic_batch_mean :  5.29498786019758e-05
reward/extrinsic_batch_mean :  0.07460740740740741
loss/policy :  0.00025151853035574527
loss/rnd :  1.2496173157518515e-06
loss/value :  3.856397206133062
loss/value_i :  2.8511094535243693e-06
loss/value_e :  3.8563943414977104
loss/entropy :  2.2983635302745933
reward/intrinsic_running :  0.0012262021264696204
reward/extrinsic_running :  0.07460740740740741
reward/intrinsic_std_running :  0.02347715454283382
reward/extrinsic_std_running :  1.5493189762974893
reward/intrinsic_batch_std :  4.295295033118132e-05
reward/intrinsic_batch_max :  0.0007513956516049802
reward/intrinsic_batch_min :  5.15271904077963e-06
reward/total_batch :  0.0373301786430047
time/iteration_time :  110.81146955490112
time/fps :  2436.5708810154306
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: 0.0003, Value Loss: 3.8564, Entropy: 2.2984
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=152.2
Extrinsic raw: Œº=0.07460740740740741

=== Iteration 525/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.03s
EPOCH 1 took 18.50s
update_step :  525
reward/intrinsic_batch_mean :  5.2565846656007465e-05
reward/extrinsic_batch_mean :  0.07574814814814815
loss/policy :  0.0013153557251136976
loss/rnd :  1.2306272007360046e-06
loss/value :  5.439825346975615
loss/value_i :  2.872917234802144e-06
loss/value_e :  5.439822460665847
loss/entropy :  2.2846434080239497
reward/intrinsic_running :  0.0012240824099792119
reward/extrinsic_running :  0.07574814814814815
reward/intrinsic_std_running :  0.023454834952127655
reward/extrinsic_std_running :  1.5530910622631748
reward/intrinsic_batch_std :  4.025697651041877e-05
reward/intrinsic_batch_max :  0.0007323668105527759
reward/intrinsic_batch_min :  5.095764663565205e-06
reward/total_batch :  0.03790035699740208
time/iteration_time :  111.96845388412476
time/fps :  2411.3934830199655
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0013, Value Loss: 5.4398, Entropy: 2.2846
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=151.3
Extrinsic raw: Œº=0.07574814814814815

=== Iteration 526/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.70s
EPOCH 1 took 18.42s
update_step :  526
reward/intrinsic_batch_mean :  5.018307484540317e-05
reward/extrinsic_batch_mean :  0.07947407407407407
loss/policy :  0.0013884576716615509
loss/rnd :  1.1773377219938221e-06
loss/value :  4.083528991901513
loss/value_i :  2.627350041124869e-06
loss/value_e :  4.08352635123513
loss/entropy :  2.307108936887799
reward/intrinsic_running :  0.001221959189101189
reward/extrinsic_running :  0.07947407407407407
reward/intrinsic_std_running :  0.023432579441475046
reward/extrinsic_std_running :  1.6022040898787338
reward/intrinsic_batch_std :  3.8670354622201234e-05
reward/intrinsic_batch_max :  0.000580197898671031
reward/intrinsic_batch_min :  4.7492681005678605e-06
reward/total_batch :  0.03976212857445974
time/iteration_time :  110.7831916809082
time/fps :  2437.1928259450065
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: 0.0014, Value Loss: 4.0835, Entropy: 2.3071
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=144.6
Extrinsic raw: Œº=0.07947407407407407

=== Iteration 527/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 18.38s
update_step :  527
reward/intrinsic_batch_mean :  5.459303535647417e-05
reward/extrinsic_batch_mean :  0.0771037037037037
loss/policy :  0.0012464964441305985
loss/rnd :  1.2783986114823853e-06
loss/value :  4.016443285075101
loss/value_i :  2.8958187868104717e-06
loss/value_e :  4.016440373478514
loss/entropy :  2.3055147618958443
reward/intrinsic_running :  0.0012198629395677126
reward/extrinsic_running :  0.0771037037037037
reward/intrinsic_std_running :  0.02341038648062257
reward/extrinsic_std_running :  1.5855900351654302
reward/intrinsic_batch_std :  5.35647858518771e-05
reward/intrinsic_batch_max :  0.001017561531625688
reward/intrinsic_batch_min :  4.9213767852052115e-06
reward/total_batch :  0.03857914836953009
time/iteration_time :  112.63390016555786
time/fps :  2397.146859010773
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2397
Policy Loss: 0.0012, Value Loss: 4.0164, Entropy: 2.3055
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.043, sum=157.4
Extrinsic raw: Œº=0.0771037037037037

=== Iteration 528/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.08s
EPOCH 1 took 18.50s
update_step :  528
reward/intrinsic_batch_mean :  5.140978367780917e-05
reward/extrinsic_batch_mean :  0.08285925925925926
loss/policy :  0.0006869996326382865
loss/rnd :  2.1318992435915405e-06
loss/value :  4.04811079935594
loss/value_i :  4.276980193866841e-05
loss/value_e :  4.0480680176706025
loss/entropy :  2.2911933516011094
reward/intrinsic_running :  0.0012177613317789213
reward/extrinsic_running :  0.08285925925925926
reward/intrinsic_std_running :  0.02338825687541417
reward/extrinsic_std_running :  1.6399190050593986
reward/intrinsic_batch_std :  3.953570597292424e-05
reward/intrinsic_batch_max :  0.0005397626664489508
reward/intrinsic_batch_min :  5.316535407473566e-06
reward/total_batch :  0.04145533452146853
time/iteration_time :  112.81521773338318
time/fps :  2393.2941443954173
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0007, Value Loss: 4.0481, Entropy: 2.2912
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=148.4
Extrinsic raw: Œº=0.08285925925925926

=== Iteration 529/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.64s
EPOCH 1 took 19.43s
update_step :  529
reward/intrinsic_batch_mean :  8.762762550220402e-05
reward/extrinsic_batch_mean :  0.08034074074074074
loss/policy :  0.001241281502933072
loss/rnd :  1.4695839113163387e-06
loss/value :  4.46983211329489
loss/value_i :  1.5347792079658326e-05
loss/value_e :  4.469816785870177
loss/entropy :  2.2784451426881733
reward/intrinsic_running :  0.0012158125086994794
reward/extrinsic_running :  0.08034074074074074
reward/intrinsic_std_running :  0.02336618333077884
reward/extrinsic_std_running :  1.5956784794631014
reward/intrinsic_batch_std :  4.19061972895067e-05
reward/intrinsic_batch_max :  0.000820544024463743
reward/intrinsic_batch_min :  3.2647029001964256e-05
reward/total_batch :  0.04021418418312147
time/iteration_time :  112.75827121734619
time/fps :  2394.5028341163897
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2395
Policy Loss: 0.0012, Value Loss: 4.4698, Entropy: 2.2784
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.035, sum=253.1
Extrinsic raw: Œº=0.08034074074074074

=== Iteration 530/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 19.26s
update_step :  530
reward/intrinsic_batch_mean :  5.293907189305308e-05
reward/extrinsic_batch_mean :  0.07573333333333333
loss/policy :  0.00011919181225962485
loss/rnd :  1.231471830206746e-06
loss/value :  5.467979485338384
loss/value_i :  3.0556840949264536e-06
loss/value_e :  5.467976447307702
loss/entropy :  2.267121600382256
reward/intrinsic_running :  0.0012137325663428454
reward/extrinsic_running :  0.07573333333333333
reward/intrinsic_std_running :  0.02334417844004772
reward/extrinsic_std_running :  1.5338977280118775
reward/intrinsic_batch_std :  3.974407200548738e-05
reward/intrinsic_batch_max :  0.0010920725762844086
reward/intrinsic_batch_min :  5.244610292720608e-06
reward/total_batch :  0.03789313620261319
time/iteration_time :  112.04666662216187
time/fps :  2409.7102407381776
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0001, Value Loss: 5.4680, Entropy: 2.2671
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.047, sum=153.1
Extrinsic raw: Œº=0.07573333333333333

=== Iteration 531/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 18.74s
update_step :  531
reward/intrinsic_batch_mean :  5.139511691743084e-05
reward/extrinsic_batch_mean :  0.07974814814814815
loss/policy :  0.0007091221579519862
loss/rnd :  1.2011978004590096e-06
loss/value :  4.820750857844497
loss/value_i :  2.84104881261142e-06
loss/value_e :  4.820748011271159
loss/entropy :  2.2792610544146914
reward/intrinsic_running :  0.0012116545045474587
reward/extrinsic_running :  0.07974814814814815
reward/intrinsic_std_running :  0.023322235878742756
reward/extrinsic_std_running :  1.584528043852752
reward/intrinsic_batch_std :  3.957438529475182e-05
reward/intrinsic_batch_max :  0.0005590533837676048
reward/intrinsic_batch_min :  5.020494427299127e-06
reward/total_batch :  0.03989977163253279
time/iteration_time :  111.17164421081543
time/fps :  2428.6768619522927
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2429
Policy Loss: 0.0007, Value Loss: 4.8208, Entropy: 2.2793
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=148.7
Extrinsic raw: Œº=0.07974814814814815

=== Iteration 532/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.52s
EPOCH 1 took 18.31s
update_step :  532
reward/intrinsic_batch_mean :  5.17905702919018e-05
reward/extrinsic_batch_mean :  0.08062962962962963
loss/policy :  0.0007171133995253706
loss/rnd :  1.2238563881923752e-06
loss/value :  4.625472365003644
loss/value_i :  3.0313830786161073e-06
loss/value_e :  4.625469323360559
loss/entropy :  2.2832481680494365
reward/intrinsic_running :  0.0012095839793628122
reward/extrinsic_running :  0.08062962962962963
reward/intrinsic_std_running :  0.023300355087192907
reward/extrinsic_std_running :  1.59659323997595
reward/intrinsic_batch_std :  3.950035562393511e-05
reward/intrinsic_batch_max :  0.0006023159367032349
reward/intrinsic_batch_min :  4.891214757662965e-06
reward/total_batch :  0.04034071009996077
time/iteration_time :  110.57794666290283
time/fps :  2441.716528008028
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2442
Policy Loss: 0.0007, Value Loss: 4.6255, Entropy: 2.2832
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=150.0
Extrinsic raw: Œº=0.08062962962962963

=== Iteration 533/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.30s
EPOCH 1 took 18.42s
update_step :  533
reward/intrinsic_batch_mean :  5.336338957425108e-05
reward/extrinsic_batch_mean :  0.07743703703703704
loss/policy :  0.0003130706825300656
loss/rnd :  2.183470283770558e-06
loss/value :  3.366191307703654
loss/value_i :  2.865431583538311e-06
loss/value_e :  3.3661884466807046
loss/entropy :  2.2853035565578574
reward/intrinsic_running :  0.001207529465050463
reward/extrinsic_running :  0.07743703703703704
reward/intrinsic_std_running :  0.023278535397432656
reward/extrinsic_std_running :  1.5771363482116818
reward/intrinsic_batch_std :  4.1429809853642046e-05
reward/intrinsic_batch_max :  0.0009470378281548619
reward/intrinsic_batch_min :  5.181320830160985e-06
reward/total_batch :  0.038745200213305644
time/iteration_time :  112.95951271057129
time/fps :  2390.2369399539034
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0003, Value Loss: 3.3662, Entropy: 2.2853
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=154.7
Extrinsic raw: Œº=0.07743703703703704

=== Iteration 534/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.03s
update_step :  534
reward/intrinsic_batch_mean :  0.0001814913516468584
reward/extrinsic_batch_mean :  0.07844444444444444
loss/policy :  0.0014858611728854928
loss/rnd :  1.5610414135208526e-06
loss/value :  4.208793791857633
loss/value_i :  3.0945538865677063e-06
loss/value_e :  4.208790703253313
loss/entropy :  2.268566290537516
reward/intrinsic_running :  0.0012059898964965163
reward/extrinsic_running :  0.07844444444444444
reward/intrinsic_std_running :  0.023256756242633205
reward/extrinsic_std_running :  1.5897222523152188
reward/intrinsic_batch_std :  4.842291572124792e-05
reward/intrinsic_batch_max :  0.0008793429005891085
reward/intrinsic_batch_min :  9.468635107623413e-05
reward/total_batch :  0.03931296789804565
time/iteration_time :  112.34297227859497
time/fps :  2403.3546070904863
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2403
Policy Loss: 0.0015, Value Loss: 4.2088, Entropy: 2.2686
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.008, max=0.038, sum=526.8
Extrinsic raw: Œº=0.07844444444444444

=== Iteration 535/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.00s
EPOCH 1 took 18.66s
update_step :  535
reward/intrinsic_batch_mean :  5.8892372768739865e-05
reward/extrinsic_batch_mean :  0.07517777777777777
loss/policy :  0.0009457884440934956
loss/rnd :  1.2896935572825896e-06
loss/value :  4.789183912855206
loss/value_i :  3.210431366300547e-06
loss/value_e :  4.789180690591985
loss/entropy :  2.2700231183658945
reward/intrinsic_running :  0.0012039715145512346
reward/extrinsic_running :  0.07517777777777777
reward/intrinsic_std_running :  0.02323505769111059
reward/extrinsic_std_running :  1.5319861732606237
reward/intrinsic_batch_std :  4.218962506860332e-05
reward/intrinsic_batch_max :  0.0009512073593214154
reward/intrinsic_batch_min :  7.406107670249185e-06
reward/total_batch :  0.037618335075273256
time/iteration_time :  112.56753253936768
time/fps :  2398.560170141193
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0009, Value Loss: 4.7892, Entropy: 2.2700
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.041, sum=171.1
Extrinsic raw: Œº=0.07517777777777777

=== Iteration 536/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 18.70s
update_step :  536
reward/intrinsic_batch_mean :  5.622506795387178e-05
reward/extrinsic_batch_mean :  0.07445185185185185
loss/policy :  0.0002969120784352223
loss/rnd :  1.3057248069840584e-06
loss/value :  4.942569313627301
loss/value_i :  1.0092853795923116e-05
loss/value_e :  4.942559188062495
loss/entropy :  2.2631618759848853
reward/intrinsic_running :  0.0012019520423854912
reward/extrinsic_running :  0.07445185185185185
reward/intrinsic_std_running :  0.023213420179587645
reward/extrinsic_std_running :  1.510104692071079
reward/intrinsic_batch_std :  4.498695756056477e-05
reward/intrinsic_batch_max :  0.0009509623050689697
reward/intrinsic_batch_min :  4.976948730472941e-06
reward/total_batch :  0.03725403845990286
time/iteration_time :  110.97812938690186
time/fps :  2432.9117952484307
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: 0.0003, Value Loss: 4.9426, Entropy: 2.2632
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=163.5
Extrinsic raw: Œº=0.07445185185185185

=== Iteration 537/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.22s
EPOCH 1 took 19.56s
update_step :  537
reward/intrinsic_batch_mean :  5.554120801288836e-05
reward/extrinsic_batch_mean :  0.07472592592592593
loss/policy :  0.0015187239129745374
loss/rnd :  1.2796858789332681e-06
loss/value :  5.117567889618151
loss/value_i :  3.1424194834140837e-06
loss/value_e :  5.117564721540972
loss/entropy :  2.274036331610246
reward/intrinsic_running :  0.0011999347188468745
reward/extrinsic_running :  0.07472592592592593
reward/intrinsic_std_running :  0.02319184323999323
reward/extrinsic_std_running :  1.5305582735025498
reward/intrinsic_batch_std :  4.389802771750128e-05
reward/intrinsic_batch_max :  0.0008737532189115882
reward/intrinsic_batch_min :  5.449308901006589e-06
reward/total_batch :  0.03739073356696941
time/iteration_time :  113.57969212532043
time/fps :  2377.1855245222014
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2377
Policy Loss: 0.0015, Value Loss: 5.1176, Entropy: 2.2740
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.038, sum=161.7
Extrinsic raw: Œº=0.07472592592592593

=== Iteration 538/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.42s
EPOCH 1 took 19.21s
update_step :  538
reward/intrinsic_batch_mean :  5.4561898856216565e-05
reward/extrinsic_batch_mean :  0.07726666666666666
loss/policy :  0.0009210126238141322
loss/rnd :  1.2623895169340495e-06
loss/value :  3.848411029035395
loss/value_i :  2.8499127789804004e-06
loss/value_e :  3.848408168012446
loss/entropy :  2.271463000413143
reward/intrinsic_running :  0.0011979222695991565
reward/extrinsic_running :  0.07726666666666666
reward/intrinsic_std_running :  0.02317032646987664
reward/extrinsic_std_running :  1.5766784857438143
reward/intrinsic_batch_std :  4.0568213374958485e-05
reward/intrinsic_batch_max :  0.0005377212073653936
reward/intrinsic_batch_min :  4.938774054608075e-06
reward/total_batch :  0.03866061428276144
time/iteration_time :  111.63417649269104
time/fps :  2418.6141599537623
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2419
Policy Loss: 0.0009, Value Loss: 3.8484, Entropy: 2.2715
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=159.0
Extrinsic raw: Œº=0.07726666666666666

=== Iteration 539/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.59s
EPOCH 1 took 19.37s
update_step :  539
reward/intrinsic_batch_mean :  5.6925858909798314e-05
reward/extrinsic_batch_mean :  0.07871851851851852
loss/policy :  0.0007167048769946577
loss/rnd :  1.316078377537148e-06
loss/value :  4.881794272047101
loss/value_i :  2.982825769708363e-06
loss/value_e :  4.881791295427265
loss/entropy :  2.2752044995625815
reward/intrinsic_running :  0.001195926634706395
reward/extrinsic_running :  0.07871851851851852
reward/intrinsic_std_running :  0.02314886905586838
reward/extrinsic_std_running :  1.5906438442614026
reward/intrinsic_batch_std :  4.3083761402973704e-05
reward/intrinsic_batch_max :  0.0005862879334017634
reward/intrinsic_batch_min :  4.3874356379092205e-06
reward/total_batch :  0.03938772218871416
time/iteration_time :  113.45819854736328
time/fps :  2379.7310679782045
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2380
Policy Loss: 0.0007, Value Loss: 4.8818, Entropy: 2.2752
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=166.0
Extrinsic raw: Œº=0.07871851851851852

=== Iteration 540/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.78s
EPOCH 1 took 18.43s
update_step :  540
reward/intrinsic_batch_mean :  5.531474087922645e-05
reward/extrinsic_batch_mean :  0.07918518518518519
loss/policy :  0.0004930103653653836
loss/rnd :  1.2851163167700481e-06
loss/value :  3.5641943144075796
loss/value_i :  4.80609081464398e-06
loss/value_e :  3.5641895315863867
loss/entropy :  2.2751462784680454
reward/intrinsic_running :  0.0011939317245039534
reward/extrinsic_running :  0.07918518518518519
reward/intrinsic_std_running :  0.023127471446460324
reward/extrinsic_std_running :  1.5920136570472525
reward/intrinsic_batch_std :  4.195739430303449e-05
reward/intrinsic_batch_max :  0.0006161853671073914
reward/intrinsic_batch_min :  4.901041393168271e-06
reward/total_batch :  0.039620249963032206
time/iteration_time :  111.30349802970886
time/fps :  2425.799770712797
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: 0.0005, Value Loss: 3.5642, Entropy: 2.2751
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=161.4
Extrinsic raw: Œº=0.07918518518518519

=== Iteration 541/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.99s
EPOCH 1 took 18.42s
update_step :  541
reward/intrinsic_batch_mean :  5.650250917641878e-05
reward/extrinsic_batch_mean :  0.07605185185185186
loss/policy :  0.0006432571178513833
loss/rnd :  1.3095580722179103e-06
loss/value :  4.976159764058663
loss/value_i :  4.759918197743735e-05
loss/value_e :  4.976112167040507
loss/entropy :  2.274191733562585
reward/intrinsic_running :  0.0011919457891501023
reward/extrinsic_running :  0.07605185185185186
reward/intrinsic_std_running :  0.02310613299499545
reward/extrinsic_std_running :  1.5444660485388344
reward/intrinsic_batch_std :  4.422581067200653e-05
reward/intrinsic_batch_max :  0.0006204417441040277
reward/intrinsic_batch_min :  5.292347395879915e-06
reward/total_batch :  0.03805417718051414
time/iteration_time :  112.33435463905334
time/fps :  2403.5389785034986
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0006, Value Loss: 4.9762, Entropy: 2.2742
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=165.1
Extrinsic raw: Œº=0.07605185185185186

=== Iteration 542/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 19.49s
update_step :  542
reward/intrinsic_batch_mean :  5.5164728636198024e-05
reward/extrinsic_batch_mean :  0.07648148148148148
loss/policy :  0.000370081246012088
loss/rnd :  1.2478122099227304e-06
loss/value :  4.9298006332281865
loss/value_i :  3.551727397252486e-06
loss/value_e :  4.929797082236319
loss/entropy :  2.294917583465576
reward/intrinsic_running :  0.0011899631909533417
reward/extrinsic_running :  0.07648148148148148
reward/intrinsic_std_running :  0.02308485367622786
reward/extrinsic_std_running :  1.5553916470082356
reward/intrinsic_batch_std :  4.2391390755404584e-05
reward/intrinsic_batch_max :  0.0009241746156476438
reward/intrinsic_batch_min :  6.079681043047458e-06
reward/total_batch :  0.038268323105058843
time/iteration_time :  113.17232084274292
time/fps :  2385.7423616431342
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0004, Value Loss: 4.9298, Entropy: 2.2949
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.040, sum=161.3
Extrinsic raw: Œº=0.07648148148148148

=== Iteration 543/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.86s
EPOCH 1 took 19.28s
update_step :  543
reward/intrinsic_batch_mean :  5.620275867915081e-05
reward/extrinsic_batch_mean :  0.07957037037037037
loss/policy :  0.0009999286212956631
loss/rnd :  1.2963987501279917e-06
loss/value :  6.104790517778108
loss/value_i :  3.028564420178141e-06
loss/value_e :  6.104787519483855
loss/entropy :  2.283957788438508
reward/intrinsic_running :  0.0011879900530124326
reward/extrinsic_running :  0.07957037037037037
reward/intrinsic_std_running :  0.023063632939712184
reward/extrinsic_std_running :  1.5652103280306884
reward/intrinsic_batch_std :  4.2722556855149796e-05
reward/intrinsic_batch_max :  0.0006013927049934864
reward/intrinsic_batch_min :  4.166761755186599e-06
reward/total_batch :  0.039813286564524764
time/iteration_time :  112.60654640197754
time/fps :  2397.729160755599
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0010, Value Loss: 6.1048, Entropy: 2.2840
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=164.5
Extrinsic raw: Œº=0.07957037037037037

=== Iteration 544/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.76s
EPOCH 1 took 18.35s
update_step :  544
reward/intrinsic_batch_mean :  5.29808578358387e-05
reward/extrinsic_batch_mean :  0.08285925925925926
loss/policy :  0.0008056771052493291
loss/rnd :  1.229886524098137e-06
loss/value :  4.091453812339089
loss/value_i :  2.8272498143037823e-06
loss/value_e :  4.091450972990557
loss/entropy :  2.295974698933688
reward/intrinsic_running :  0.0011860099258362614
reward/extrinsic_running :  0.08285925925925926
reward/intrinsic_std_running :  0.023042471276636372
reward/extrinsic_std_running :  1.6227095226832373
reward/intrinsic_batch_std :  4.313978502032694e-05
reward/intrinsic_batch_max :  0.0006800398114137352
reward/intrinsic_batch_min :  4.52188487543026e-06
reward/total_batch :  0.04145612005854755
time/iteration_time :  110.78090238571167
time/fps :  2437.243190707428
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2437
Policy Loss: 0.0008, Value Loss: 4.0915, Entropy: 2.2960
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=155.2
Extrinsic raw: Œº=0.08285925925925926

=== Iteration 545/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.63s
EPOCH 1 took 19.60s
update_step :  545
reward/intrinsic_batch_mean :  5.4586958458080686e-05
reward/extrinsic_batch_mean :  0.07871851851851852
loss/policy :  0.0006784376070727101
loss/rnd :  1.2425789894664239e-06
loss/value :  4.211210059397148
loss/value_i :  2.6567612222248553e-06
loss/value_e :  4.211207411505959
loss/entropy :  2.3004466222994253
reward/intrinsic_running :  0.001184045729051872
reward/extrinsic_running :  0.07871851851851852
reward/intrinsic_std_running :  0.023021367365547885
reward/extrinsic_std_running :  1.571906034096006
reward/intrinsic_batch_std :  4.324042970502841e-05
reward/intrinsic_batch_max :  0.0008070280309766531
reward/intrinsic_batch_min :  5.67536380913225e-06
reward/total_batch :  0.039386552738488304
time/iteration_time :  113.37720346450806
time/fps :  2381.431114452577
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2381
Policy Loss: 0.0007, Value Loss: 4.2112, Entropy: 2.3004
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=160.1
Extrinsic raw: Œº=0.07871851851851852

=== Iteration 546/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.21s
EPOCH 1 took 19.03s
update_step :  546
reward/intrinsic_batch_mean :  5.5271161069834275e-05
reward/extrinsic_batch_mean :  0.08474074074074074
loss/policy :  0.0009465035929513925
loss/rnd :  1.2703772885095421e-06
loss/value :  5.765169096715523
loss/value_i :  2.627330042576597e-06
loss/value_e :  5.765166488560763
loss/entropy :  2.2807050148646035
reward/intrinsic_running :  0.0011820922790742338
reward/extrinsic_running :  0.08474074074074074
reward/intrinsic_std_running :  0.02300032116963686
reward/extrinsic_std_running :  1.641229362908648
reward/intrinsic_batch_std :  4.454022717659603e-05
reward/intrinsic_batch_max :  0.0007449706317856908
reward/intrinsic_batch_min :  5.012454948882805e-06
reward/total_batch :  0.04239800595090529
time/iteration_time :  111.68138718605042
time/fps :  2417.591747407346
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: 0.0009, Value Loss: 5.7652, Entropy: 2.2807
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=162.2
Extrinsic raw: Œº=0.08474074074074074

=== Iteration 547/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.45s
EPOCH 1 took 19.09s
update_step :  547
reward/intrinsic_batch_mean :  5.3187896461221734e-05
reward/extrinsic_batch_mean :  0.08076296296296297
loss/policy :  0.00027961331723032123
loss/rnd :  1.2202638221093698e-06
loss/value :  4.721593192129424
loss/value_i :  2.568187279862424e-06
loss/value_e :  4.721590641773108
loss/entropy :  2.293092709599119
reward/intrinsic_running :  0.0011801361109886315
reward/extrinsic_running :  0.08076296296296297
reward/intrinsic_std_running :  0.022979333039941898
reward/extrinsic_std_running :  1.597006322988514
reward/intrinsic_batch_std :  4.3651084446315235e-05
reward/intrinsic_batch_max :  0.0008267338271252811
reward/intrinsic_batch_min :  4.873474608757533e-06
reward/total_batch :  0.040408075429712094
time/iteration_time :  112.14723610877991
time/fps :  2407.5493018669404
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: 0.0003, Value Loss: 4.7216, Entropy: 2.2931
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=156.2
Extrinsic raw: Œº=0.08076296296296297

=== Iteration 548/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.20s
update_step :  548
reward/intrinsic_batch_mean :  4.9924473431518115e-05
reward/extrinsic_batch_mean :  0.07708148148148149
loss/policy :  0.00043813843424714196
loss/rnd :  1.1459574883095531e-06
loss/value :  5.137814503727538
loss/value_i :  2.5003301936632134e-06
loss/value_e :  5.137812000332457
loss/entropy :  2.3057882966417256
reward/intrinsic_running :  0.0011781726369435306
reward/extrinsic_running :  0.07708148148148149
reward/intrinsic_std_running :  0.0229584029159105
reward/extrinsic_std_running :  1.5667964251316167
reward/intrinsic_batch_std :  4.071092422228917e-05
reward/intrinsic_batch_max :  0.0007250451017171144
reward/intrinsic_batch_min :  4.739698397315806e-06
reward/total_batch :  0.038565702977456505
time/iteration_time :  111.55047464370728
time/fps :  2420.4289660118548
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0004, Value Loss: 5.1378, Entropy: 2.3058
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.032, sum=146.8
Extrinsic raw: Œº=0.07708148148148149

=== Iteration 549/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.89s
EPOCH 1 took 19.74s
update_step :  549
reward/intrinsic_batch_mean :  5.201344145255091e-05
reward/extrinsic_batch_mean :  0.07752592592592593
loss/policy :  0.0004869080366916023
loss/rnd :  1.330064003124073e-06
loss/value :  4.532952362840826
loss/value_i :  4.099562464475501e-06
loss/value_e :  4.532948284438162
loss/entropy :  2.3103390101230508
reward/intrinsic_running :  0.0011762261181130814
reward/extrinsic_running :  0.07752592592592593
reward/intrinsic_std_running :  0.022937529430640816
reward/extrinsic_std_running :  1.5776109778636789
reward/intrinsic_batch_std :  4.159723068783919e-05
reward/intrinsic_batch_max :  0.0007780817686580122
reward/intrinsic_batch_min :  4.914520104648545e-06
reward/total_batch :  0.03878896968368924
time/iteration_time :  113.34180474281311
time/fps :  2382.1748790101246
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2382
Policy Loss: 0.0005, Value Loss: 4.5330, Entropy: 2.3103
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.034, sum=153.1
Extrinsic raw: Œº=0.07752592592592593

=== Iteration 550/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.28s
EPOCH 1 took 18.99s
update_step :  550
reward/intrinsic_batch_mean :  0.00010552489885524631
reward/extrinsic_batch_mean :  0.08
loss/policy :  0.0010609511360102756
loss/rnd :  1.3532492761386852e-06
loss/value :  5.584824442863464
loss/value_i :  3.47330921723562e-06
loss/value_e :  5.584820964119651
loss/entropy :  2.304148981065461
reward/intrinsic_running :  0.0011744883326380272
reward/extrinsic_running :  0.08
reward/intrinsic_std_running :  0.02291670395030594
reward/extrinsic_std_running :  1.594773872278984
reward/intrinsic_batch_std :  4.4139746725213054e-05
reward/intrinsic_batch_max :  0.0006793267093598843
reward/intrinsic_batch_min :  4.725862527266145e-05
reward/total_batch :  0.040052762449427626
time/iteration_time :  112.5485372543335
time/fps :  2398.964985123377
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0011, Value Loss: 5.5848, Entropy: 2.3041
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.030, sum=310.8
Extrinsic raw: Œº=0.08

=== Iteration 551/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.46s
EPOCH 1 took 19.29s
update_step :  551
reward/intrinsic_batch_mean :  5.4259064063646495e-05
reward/extrinsic_batch_mean :  0.08248888888888889
loss/policy :  0.0007589450802752805
loss/rnd :  1.2092143899253367e-06
loss/value :  6.069466269377506
loss/value_i :  2.7036621242421628e-06
loss/value_e :  6.069463534788652
loss/entropy :  2.3010782220146875
reward/intrinsic_running :  0.0011725621264854294
reward/extrinsic_running :  0.08248888888888889
reward/intrinsic_std_running :  0.022895943577178564
reward/extrinsic_std_running :  1.611747162722246
reward/intrinsic_batch_std :  3.931580205346089e-05
reward/intrinsic_batch_max :  0.0005776910693384707
reward/intrinsic_batch_min :  7.083303898980375e-06
reward/total_batch :  0.04127157397647627
time/iteration_time :  112.36390256881714
time/fps :  2402.9069285364026
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: 0.0008, Value Loss: 6.0695, Entropy: 2.3011
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=160.0
Extrinsic raw: Œº=0.08248888888888889

=== Iteration 552/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 19.26s
update_step :  552
reward/intrinsic_batch_mean :  5.270178240674189e-05
reward/extrinsic_batch_mean :  0.08605185185185185
loss/policy :  0.0010276196566833692
loss/rnd :  1.203963851174084e-06
loss/value :  5.474656599940675
loss/value_i :  2.8071417029257812e-06
loss/value_e :  5.474653749754935
loss/entropy :  2.299221714337667
reward/intrinsic_running :  0.0011706371297474304
reward/extrinsic_running :  0.08605185185185185
reward/intrinsic_std_running :  0.022875239799529833
reward/extrinsic_std_running :  1.650615677809315
reward/intrinsic_batch_std :  4.1502881858023633e-05
reward/intrinsic_batch_max :  0.0008132757502608001
reward/intrinsic_batch_min :  4.859144155489048e-06
reward/total_batch :  0.043052276817129295
time/iteration_time :  112.34053540229797
time/fps :  2403.4067403463437
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2403
Policy Loss: 0.0010, Value Loss: 5.4747, Entropy: 2.2992
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=155.5
Extrinsic raw: Œº=0.08605185185185185

=== Iteration 553/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.55s
EPOCH 1 took 20.37s
update_step :  553
reward/intrinsic_batch_mean :  5.131749202600649e-05
reward/extrinsic_batch_mean :  0.08162962962962964
loss/policy :  0.0009180960094344107
loss/rnd :  1.189354176142043e-06
loss/value :  4.778696677901528
loss/value_i :  4.688400984129905e-06
loss/value_e :  4.778691974553195
loss/entropy :  2.318461764942516
reward/intrinsic_running :  0.0011687117579299907
reward/extrinsic_running :  0.08162962962962964
reward/intrinsic_std_running :  0.02285459242143745
reward/extrinsic_std_running :  1.627336932677255
reward/intrinsic_batch_std :  4.256110958533624e-05
reward/intrinsic_batch_max :  0.0009305860148742795
reward/intrinsic_batch_min :  3.463074790488463e-06
reward/total_batch :  0.040840473560827824
time/iteration_time :  112.70045685768127
time/fps :  2395.731193361154
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0009, Value Loss: 4.7787, Entropy: 2.3185
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=151.6
Extrinsic raw: Œº=0.08162962962962964

=== Iteration 554/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.15s
EPOCH 1 took 19.30s
update_step :  554
reward/intrinsic_batch_mean :  5.6527087855149014e-05
reward/extrinsic_batch_mean :  0.07883703703703704
loss/policy :  0.0006454045916060833
loss/rnd :  1.2303017928333606e-06
loss/value :  4.429543906992132
loss/value_i :  2.6458020143267773e-06
loss/value_e :  4.429541262713346
loss/entropy :  2.3249111500653354
reward/intrinsic_running :  0.001166813589402352
reward/extrinsic_running :  0.07883703703703704
reward/intrinsic_std_running :  0.022833999920316574
reward/extrinsic_std_running :  1.591108249721546
reward/intrinsic_batch_std :  4.066508166767941e-05
reward/intrinsic_batch_max :  0.0005597389535978436
reward/intrinsic_batch_min :  7.380432180070784e-06
reward/total_batch :  0.0394467820624461
time/iteration_time :  110.37949562072754
time/fps :  2446.106484557067
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.4s | FPS: 2446
Policy Loss: 0.0006, Value Loss: 4.4295, Entropy: 2.3249
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=167.1
Extrinsic raw: Œº=0.07883703703703704

=== Iteration 555/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 18.98s
update_step :  555
reward/intrinsic_batch_mean :  5.01953743515346e-05
reward/extrinsic_batch_mean :  0.08212592592592592
loss/policy :  0.000518555654487114
loss/rnd :  1.145181709999275e-06
loss/value :  3.5703164537747702
loss/value_i :  2.367838412669009e-06
loss/value_e :  3.570314075007583
loss/entropy :  2.3085734952579844
reward/intrinsic_running :  0.0011648994878127057
reward/extrinsic_running :  0.08212592592592592
reward/intrinsic_std_running :  0.022813464021707534
reward/extrinsic_std_running :  1.6195471929118292
reward/intrinsic_batch_std :  3.976723436353137e-05
reward/intrinsic_batch_max :  0.0005412036553025246
reward/intrinsic_batch_min :  3.940830083593028e-06
reward/total_batch :  0.04108806065013873
time/iteration_time :  111.43186140060425
time/fps :  2423.0053828979285
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2423
Policy Loss: 0.0005, Value Loss: 3.5703, Entropy: 2.3086
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=148.5
Extrinsic raw: Œº=0.08212592592592592

=== Iteration 556/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.25s
update_step :  556
reward/intrinsic_batch_mean :  5.1766271916279e-05
reward/extrinsic_batch_mean :  0.08222962962962962
loss/policy :  0.0009070133770971248
loss/rnd :  1.18265934774668e-06
loss/value :  4.982245401902632
loss/value_i :  2.429618014117075e-06
loss/value_e :  4.982242985205217
loss/entropy :  2.312838305126537
reward/intrinsic_running :  0.0011629967673624508
reward/extrinsic_running :  0.08222962962962962
reward/intrinsic_std_running :  0.02279298326108433
reward/extrinsic_std_running :  1.6108352305132965
reward/intrinsic_batch_std :  4.651165695787941e-05
reward/intrinsic_batch_max :  0.0010876135202124715
reward/intrinsic_batch_min :  4.505791366682388e-06
reward/total_batch :  0.04114069795077295
time/iteration_time :  112.2972776889801
time/fps :  2404.3325497862493
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0009, Value Loss: 4.9822, Entropy: 2.3128
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.048, sum=153.3
Extrinsic raw: Œº=0.08222962962962962

=== Iteration 557/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.06s
EPOCH 1 took 20.16s
update_step :  557
reward/intrinsic_batch_mean :  5.1517686416951214e-05
reward/extrinsic_batch_mean :  0.08032592592592593
loss/policy :  0.0009067952409113235
loss/rnd :  1.174288756415494e-06
loss/value :  5.437067963860252
loss/value_i :  2.353844851396306e-06
loss/value_e :  5.437065576062058
loss/entropy :  2.306108239925269
reward/intrinsic_running :  0.0011610998219776759
reward/extrinsic_running :  0.08032592592592593
reward/intrinsic_std_running :  0.022772557579881326
reward/extrinsic_std_running :  1.6278523585324614
reward/intrinsic_batch_std :  4.078320434002417e-05
reward/intrinsic_batch_max :  0.0005908776074647903
reward/intrinsic_batch_min :  4.6516543079633266e-06
reward/total_batch :  0.04018872180617144
time/iteration_time :  113.41911768913269
time/fps :  2380.5510526015155
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2381
Policy Loss: 0.0009, Value Loss: 5.4371, Entropy: 2.3061
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=152.7
Extrinsic raw: Œº=0.08032592592592593

=== Iteration 558/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 18.68s
update_step :  558
reward/intrinsic_batch_mean :  5.206386886498809e-05
reward/extrinsic_batch_mean :  0.08237777777777777
loss/policy :  0.0007210914839313111
loss/rnd :  1.1544097395182524e-06
loss/value :  4.4469494566772925
loss/value_i :  4.915785235894101e-06
loss/value_e :  4.446944518522783
loss/entropy :  2.3052492828080147
reward/intrinsic_running :  0.0011592135893909467
reward/extrinsic_running :  0.08237777777777777
reward/intrinsic_std_running :  0.022752186539279573
reward/extrinsic_std_running :  1.6295724882069496
reward/intrinsic_batch_std :  4.240240919268402e-05
reward/intrinsic_batch_max :  0.0010836974252015352
reward/intrinsic_batch_min :  5.679044534190325e-06
reward/total_batch :  0.04121492082332138
time/iteration_time :  112.30982613563538
time/fps :  2404.0639122165844
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0007, Value Loss: 4.4469, Entropy: 2.3052
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.048, sum=154.5
Extrinsic raw: Œº=0.08237777777777777

=== Iteration 559/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.16s
EPOCH 1 took 19.50s
update_step :  559
reward/intrinsic_batch_mean :  5.178275039570171e-05
reward/extrinsic_batch_mean :  0.089
loss/policy :  0.0008777304831186705
loss/rnd :  1.1352653118454767e-06
loss/value :  5.450693683190779
loss/value_i :  4.866723171207096e-06
loss/value_e :  5.450688817284324
loss/entropy :  2.303334467338793
reward/intrinsic_running :  0.0011573317831097114
reward/extrinsic_running :  0.089
reward/intrinsic_std_running :  0.02273187015607699
reward/extrinsic_std_running :  1.6859839747052647
reward/intrinsic_batch_std :  3.818258347558307e-05
reward/intrinsic_batch_max :  0.0005133570521138608
reward/intrinsic_batch_min :  6.067411959520541e-06
reward/total_batch :  0.04452589137519785
time/iteration_time :  113.07219576835632
time/fps :  2387.854929014835
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0009, Value Loss: 5.4507, Entropy: 2.3033
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.023, sum=153.8
Extrinsic raw: Œº=0.089

=== Iteration 560/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.35s
EPOCH 1 took 19.54s
update_step :  560
reward/intrinsic_batch_mean :  4.856988122989639e-05
reward/extrinsic_batch_mean :  0.0817925925925926
loss/policy :  0.0011945133667199336
loss/rnd :  1.104533878608918e-06
loss/value :  5.105263822006457
loss/value_i :  3.0968198857270623e-06
loss/value_e :  5.10526075146415
loss/entropy :  2.3001508315404258
reward/intrinsic_running :  0.0011554445264488297
reward/extrinsic_running :  0.0817925925925926
reward/intrinsic_std_running :  0.022711608659047245
reward/extrinsic_std_running :  1.609476211536128
reward/intrinsic_batch_std :  3.6929135611458564e-05
reward/intrinsic_batch_max :  0.0004998897202312946
reward/intrinsic_batch_min :  5.305763806973118e-06
reward/total_batch :  0.040920581236911245
time/iteration_time :  112.23725080490112
time/fps :  2405.6184382966885
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0012, Value Loss: 5.1053, Entropy: 2.3002
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=144.4
Extrinsic raw: Œº=0.0817925925925926

=== Iteration 561/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.34s
EPOCH 1 took 19.88s
update_step :  561
reward/intrinsic_batch_mean :  5.0231233306099226e-05
reward/extrinsic_batch_mean :  0.08265185185185185
loss/policy :  0.0005607794819470104
loss/rnd :  1.1395789745923441e-06
loss/value :  5.602258563041687
loss/value_i :  2.3981588645421486e-06
loss/value_e :  5.6022561246698555
loss/entropy :  2.297711704716538
reward/intrinsic_running :  0.0011535700231150299
reward/extrinsic_running :  0.08265185185185185
reward/intrinsic_std_running :  0.022691400972879465
reward/extrinsic_std_running :  1.6029804893270656
reward/intrinsic_batch_std :  3.838709809835063e-05
reward/intrinsic_batch_max :  0.0005056685185991228
reward/intrinsic_batch_min :  4.432650712260511e-06
reward/total_batch :  0.04135104154257897
time/iteration_time :  111.30922222137451
time/fps :  2425.6750214552517
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2426
Policy Loss: 0.0006, Value Loss: 5.6023, Entropy: 2.2977
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=149.4
Extrinsic raw: Œº=0.08265185185185185

=== Iteration 562/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.83s
EPOCH 1 took 18.69s
update_step :  562
reward/intrinsic_batch_mean :  5.233751973278736e-05
reward/extrinsic_batch_mean :  0.07914814814814815
loss/policy :  0.0014330255252196257
loss/rnd :  1.6256414717259537e-06
loss/value :  4.376448851643187
loss/value_i :  2.7182645439869235e-06
loss/value_e :  4.376446167627971
loss/entropy :  2.28580371538798
reward/intrinsic_running :  0.0011517098317714277
reward/extrinsic_running :  0.07914814814814815
reward/intrinsic_std_running :  0.022671246785569293
reward/extrinsic_std_running :  1.582688294425464
reward/intrinsic_batch_std :  4.063818776292065e-05
reward/intrinsic_batch_max :  0.0009054170222952962
reward/intrinsic_batch_min :  4.313644240028225e-06
reward/total_batch :  0.039600242833940466
time/iteration_time :  110.54767489433289
time/fps :  2442.3851542610896
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2442
Policy Loss: 0.0014, Value Loss: 4.3764, Entropy: 2.2858
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.040, sum=155.8
Extrinsic raw: Œº=0.07914814814814815

=== Iteration 563/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.76s
EPOCH 1 took 18.44s
update_step :  563
reward/intrinsic_batch_mean :  7.529592401888631e-05
reward/extrinsic_batch_mean :  0.08184444444444444
loss/policy :  0.0010284865621184563
loss/rnd :  1.2197954702335692e-06
loss/value :  3.3873512600407456
loss/value_i :  2.5480642307229573e-06
loss/value_e :  3.3873487096844297
loss/entropy :  2.2870197693506875
reward/intrinsic_running :  0.0011499406385329064
reward/extrinsic_running :  0.08184444444444444
reward/intrinsic_std_running :  0.022651142435225355
reward/extrinsic_std_running :  1.627725522255663
reward/intrinsic_batch_std :  4.3678285920718976e-05
reward/intrinsic_batch_max :  0.0008420003578066826
reward/intrinsic_batch_min :  2.0676849089795724e-05
reward/total_batch :  0.04095987018423167
time/iteration_time :  111.07094192504883
time/fps :  2430.878817811748
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0010, Value Loss: 3.3874, Entropy: 2.2870
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=224.4
Extrinsic raw: Œº=0.08184444444444444

=== Iteration 564/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.64s
update_step :  564
reward/intrinsic_batch_mean :  5.3716874100212376e-05
reward/extrinsic_batch_mean :  0.08236296296296296
loss/policy :  0.001305788715950312
loss/rnd :  1.2201226678426433e-06
loss/value :  6.004328135288123
loss/value_i :  2.8729350733004995e-06
loss/value_e :  6.004325270652771
loss/entropy :  2.2662529222892993
reward/intrinsic_running :  0.0011480982815335386
reward/extrinsic_running :  0.08236296296296296
reward/intrinsic_std_running :  0.022631095020447373
reward/extrinsic_std_running :  1.6020697405054107
reward/intrinsic_batch_std :  4.1250024642436136e-05
reward/intrinsic_batch_max :  0.000821569177787751
reward/intrinsic_batch_min :  4.417024229041999e-06
reward/total_batch :  0.04120833991853159
time/iteration_time :  112.7376561164856
time/fps :  2394.94069063334
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0013, Value Loss: 6.0043, Entropy: 2.2663
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.036, sum=160.2
Extrinsic raw: Œº=0.08236296296296296

=== Iteration 565/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 19.24s
update_step :  565
reward/intrinsic_batch_mean :  5.1269799497633895e-05
reward/extrinsic_batch_mean :  0.07844444444444444
loss/policy :  0.0010736073317909331
loss/rnd :  1.1642945912971108e-06
loss/value :  3.838401263410395
loss/value_i :  2.3790774658857226e-06
loss/value_e :  3.8383988611625903
loss/entropy :  2.305525870034189
reward/intrinsic_running :  0.0011462525429150727
reward/extrinsic_running :  0.07844444444444444
reward/intrinsic_std_running :  0.02261110119512045
reward/extrinsic_std_running :  1.5803756546709213
reward/intrinsic_batch_std :  4.192474637091849e-05
reward/intrinsic_batch_max :  0.0007682486320845783
reward/intrinsic_batch_min :  4.228413217788329e-06
reward/total_batch :  0.039247857121971035
time/iteration_time :  113.17954921722412
time/fps :  2385.5899927803416
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0011, Value Loss: 3.8384, Entropy: 2.3055
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.034, sum=153.1
Extrinsic raw: Œº=0.07844444444444444

=== Iteration 566/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 19.38s
update_step :  566
reward/intrinsic_batch_mean :  5.548154700764927e-05
reward/extrinsic_batch_mean :  0.08708888888888888
loss/policy :  0.00137654349920481
loss/rnd :  1.2520615913755053e-06
loss/value :  5.41610434922305
loss/value_i :  2.62143827388751e-06
loss/value_e :  5.416101733843486
loss/entropy :  2.2734047210577764
reward/intrinsic_running :  0.0011444305636240427
reward/extrinsic_running :  0.08708888888888888
reward/intrinsic_std_running :  0.02259115949825836
reward/extrinsic_std_running :  1.6447167851061402
reward/intrinsic_batch_std :  4.578761896171055e-05
reward/intrinsic_batch_max :  0.0009997229790315032
reward/intrinsic_batch_min :  3.842456862912513e-06
reward/total_batch :  0.04357218521794826
time/iteration_time :  112.85640287399292
time/fps :  2392.420749945946
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0014, Value Loss: 5.4161, Entropy: 2.2734
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.044, sum=165.8
Extrinsic raw: Œº=0.08708888888888888

=== Iteration 567/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.61s
update_step :  567
reward/intrinsic_batch_mean :  5.354331388670188e-05
reward/extrinsic_batch_mean :  0.08441481481481482
loss/policy :  0.0010284167467144664
loss/rnd :  1.2092128448178603e-06
loss/value :  5.842373689015706
loss/value_i :  3.286758952168439e-06
loss/value_e :  5.842370423403653
loss/entropy :  2.2798783562400122
reward/intrinsic_running :  0.0011426066283813214
reward/extrinsic_running :  0.08441481481481482
reward/intrinsic_std_running :  0.02257127082242287
reward/extrinsic_std_running :  1.6175656349849374
reward/intrinsic_batch_std :  3.988206680035434e-05
reward/intrinsic_batch_max :  0.0005842488026246428
reward/intrinsic_batch_min :  4.036555765196681e-06
reward/total_batch :  0.04223417906435076
time/iteration_time :  111.09429836273193
time/fps :  2430.367750453115
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0010, Value Loss: 5.8424, Entropy: 2.2799
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=160.1
Extrinsic raw: Œº=0.08441481481481482

=== Iteration 568/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.89s
EPOCH 1 took 18.93s
update_step :  568
reward/intrinsic_batch_mean :  5.021723047419881e-05
reward/extrinsic_batch_mean :  0.08123703703703704
loss/policy :  0.00151061729499788
loss/rnd :  1.1351850231001277e-06
loss/value :  3.826895594596863
loss/value_i :  2.572359679823311e-06
loss/value_e :  3.826893033403339
loss/entropy :  2.2926040851708613
reward/intrinsic_running :  0.0011407790815713367
reward/extrinsic_running :  0.08123703703703704
reward/intrinsic_std_running :  0.022551435037715263
reward/extrinsic_std_running :  1.616845519121209
reward/intrinsic_batch_std :  3.739026906464535e-05
reward/intrinsic_batch_max :  0.0005324778612703085
reward/intrinsic_batch_min :  4.718508535006549e-06
reward/total_batch :  0.04064362713375562
time/iteration_time :  112.14632439613342
time/fps :  2407.5688744490767
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: 0.0015, Value Loss: 3.8269, Entropy: 2.2926
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.024, sum=150.3
Extrinsic raw: Œº=0.08123703703703704

=== Iteration 569/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.38s
EPOCH 1 took 18.97s
update_step :  569
reward/intrinsic_batch_mean :  5.166372614909994e-05
reward/extrinsic_batch_mean :  0.08254074074074073
loss/policy :  0.0007673350368294808
loss/rnd :  1.158705114186997e-06
loss/value :  4.926716157884309
loss/value_i :  2.397933440768225e-06
loss/value_e :  4.926713737574491
loss/entropy :  2.2837803797288374
reward/intrinsic_running :  0.001138962807639336
reward/extrinsic_running :  0.08254074074074073
reward/intrinsic_std_running :  0.022531651240696376
reward/extrinsic_std_running :  1.6116905054560657
reward/intrinsic_batch_std :  3.996401868906781e-05
reward/intrinsic_batch_max :  0.0005962236318737268
reward/intrinsic_batch_min :  4.809818619833095e-06
reward/total_batch :  0.04129620223344492
time/iteration_time :  112.2415361404419
time/fps :  2405.5265927772343
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0008, Value Loss: 4.9267, Entropy: 2.2838
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=154.8
Extrinsic raw: Œº=0.08254074074074073

=== Iteration 570/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 18.80s
update_step :  570
reward/intrinsic_batch_mean :  5.370644877517339e-05
reward/extrinsic_batch_mean :  0.08078518518518518
loss/policy :  0.0008809002225241398
loss/rnd :  1.215099023904093e-06
loss/value :  4.368284933494799
loss/value_i :  2.4831366269581574e-06
loss/value_e :  4.36828244454933
loss/entropy :  2.2739841974142827
reward/intrinsic_running :  0.0011371602020294417
reward/extrinsic_running :  0.08078518518518518
reward/intrinsic_std_running :  0.02251191908324854
reward/extrinsic_std_running :  1.6062976910812992
reward/intrinsic_batch_std :  3.816031308719745e-05
reward/intrinsic_batch_max :  0.0005064250435680151
reward/intrinsic_batch_min :  4.727648502012016e-06
reward/total_batch :  0.040419445816980176
time/iteration_time :  111.05522632598877
time/fps :  2431.2228152815487
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2431
Policy Loss: 0.0009, Value Loss: 4.3683, Entropy: 2.2740
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=161.0
Extrinsic raw: Œº=0.08078518518518518

=== Iteration 571/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 18.42s
update_step :  571
reward/intrinsic_batch_mean :  5.433176492311355e-05
reward/extrinsic_batch_mean :  0.08548148148148148
loss/policy :  0.0009976577003368275
loss/rnd :  1.2248101294668838e-06
loss/value :  5.134761723605069
loss/value_i :  2.551877345826087e-06
loss/value_e :  5.1347592021479755
loss/entropy :  2.257621078780203
reward/intrinsic_running :  0.0011353652485442773
reward/extrinsic_running :  0.08548148148148148
reward/intrinsic_std_running :  0.022492238633411085
reward/extrinsic_std_running :  1.6115406562336865
reward/intrinsic_batch_std :  4.194848606216063e-05
reward/intrinsic_batch_max :  0.0008433174225501716
reward/intrinsic_batch_min :  3.944903710362269e-06
reward/total_batch :  0.0427679066232023
time/iteration_time :  111.04423236846924
time/fps :  2431.4635190063764
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2431
Policy Loss: 0.0010, Value Loss: 5.1348, Entropy: 2.2576
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=163.1
Extrinsic raw: Œº=0.08548148148148148

=== Iteration 572/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.20s
EPOCH 1 took 18.67s
update_step :  572
reward/intrinsic_batch_mean :  5.62166206038792e-05
reward/extrinsic_batch_mean :  0.08132592592592593
loss/policy :  0.001263351514794384
loss/rnd :  1.2244706915749481e-06
loss/value :  5.836926973227299
loss/value_i :  3.2312209200289077e-06
loss/value_e :  5.836923736514467
loss/entropy :  2.2572879682887685
reward/intrinsic_running :  0.0011335836393755263
reward/extrinsic_running :  0.08132592592592593
reward/intrinsic_std_running :  0.022472609404342953
reward/extrinsic_std_running :  1.5895902632072842
reward/intrinsic_batch_std :  4.300354032040298e-05
reward/intrinsic_batch_max :  0.0005662412149831653
reward/intrinsic_batch_min :  4.86186900161556e-06
reward/total_batch :  0.040691071273264906
time/iteration_time :  113.46752214431763
time/fps :  2379.535526091696
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2380
Policy Loss: 0.0013, Value Loss: 5.8369, Entropy: 2.2573
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.025, sum=168.9
Extrinsic raw: Œº=0.08132592592592593

=== Iteration 573/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.91s
update_step :  573
reward/intrinsic_batch_mean :  5.1402968688577215e-05
reward/extrinsic_batch_mean :  0.08254814814814815
loss/policy :  0.0010244532243108772
loss/rnd :  1.1533314336426856e-06
loss/value :  5.225361903508504
loss/value_i :  2.628022715808501e-06
loss/value_e :  5.225359277291731
loss/entropy :  2.2758552666866416
reward/intrinsic_running :  0.001131789923966397
reward/extrinsic_running :  0.08254814814814815
reward/intrinsic_std_running :  0.022453032272899555
reward/extrinsic_std_running :  1.62090071767849
reward/intrinsic_batch_std :  3.8510027990181755e-05
reward/intrinsic_batch_max :  0.0005730676930397749
reward/intrinsic_batch_min :  4.652211828215513e-06
reward/total_batch :  0.041299775558418364
time/iteration_time :  111.955322265625
time/fps :  2411.6763235194703
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2412
Policy Loss: 0.0010, Value Loss: 5.2254, Entropy: 2.2759
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=154.5
Extrinsic raw: Œº=0.08254814814814815

=== Iteration 574/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.66s
EPOCH 1 took 19.50s
update_step :  574
reward/intrinsic_batch_mean :  5.228339372062894e-05
reward/extrinsic_batch_mean :  0.0840074074074074
loss/policy :  0.0011051326371009716
loss/rnd :  1.1830845726928436e-06
loss/value :  5.455385656067819
loss/value_i :  2.726246252264404e-06
loss/value_e :  5.4553829395409785
loss/entropy :  2.2698104309313223
reward/intrinsic_running :  0.001130005459933879
reward/extrinsic_running :  0.0840074074074074
reward/intrinsic_std_running :  0.02243350608803628
reward/extrinsic_std_running :  1.6070602837170376
reward/intrinsic_batch_std :  4.134112612470678e-05
reward/intrinsic_batch_max :  0.0009165362571366131
reward/intrinsic_batch_min :  4.263624759914819e-06
reward/total_batch :  0.042029845400564016
time/iteration_time :  113.6710593700409
time/fps :  2375.2747752710848
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: 0.0011, Value Loss: 5.4554, Entropy: 2.2698
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.041, sum=157.3
Extrinsic raw: Œº=0.0840074074074074

=== Iteration 575/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 20.07s
update_step :  575
reward/intrinsic_batch_mean :  5.285450905434522e-05
reward/extrinsic_batch_mean :  0.08113333333333334
loss/policy :  0.001416614584079732
loss/rnd :  1.2010164458374537e-06
loss/value :  2.6459580966920564
loss/value_i :  2.389762688504892e-06
loss/value_e :  2.6459557125062654
loss/entropy :  2.287431583260045
reward/intrinsic_running :  0.0011282293918205386
reward/extrinsic_running :  0.08113333333333334
reward/intrinsic_std_running :  0.022414030660507445
reward/extrinsic_std_running :  1.6346136628165897
reward/intrinsic_batch_std :  4.140113482247823e-05
reward/intrinsic_batch_max :  0.0007893001893535256
reward/intrinsic_batch_min :  4.463667210075073e-06
reward/total_batch :  0.04059309392119384
time/iteration_time :  113.01552033424377
time/fps :  2389.052399187953
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0014, Value Loss: 2.6460, Entropy: 2.2874
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=159.2
Extrinsic raw: Œº=0.08113333333333334

=== Iteration 576/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.90s
EPOCH 1 took 19.90s
update_step :  576
reward/intrinsic_batch_mean :  5.5387876682686546e-05
reward/extrinsic_batch_mean :  0.08108148148148148
loss/policy :  0.0003461593455127017
loss/rnd :  1.2343703174751268e-06
loss/value :  3.999047774257082
loss/value_i :  2.5142276826679306e-06
loss/value_e :  3.9990452672495986
loss/entropy :  2.267397302569765
reward/intrinsic_running :  0.0011264684362072806
reward/extrinsic_running :  0.08108148148148148
reward/intrinsic_std_running :  0.022394605484729015
reward/extrinsic_std_running :  1.5979604642207572
reward/intrinsic_batch_std :  4.4340819632461497e-05
reward/intrinsic_batch_max :  0.0008931859047152102
reward/intrinsic_batch_min :  5.399721430876525e-06
reward/total_batch :  0.04056843467908208
time/iteration_time :  114.05955934524536
time/fps :  2367.1843162460464
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0003, Value Loss: 3.9990, Entropy: 2.2674
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.040, sum=166.9
Extrinsic raw: Œº=0.08108148148148148

=== Iteration 577/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 19.39s
update_step :  577
reward/intrinsic_batch_mean :  5.2485177005615294e-05
reward/extrinsic_batch_mean :  0.08080740740740741
loss/policy :  0.0003915120129628728
loss/rnd :  1.1961162847524753e-06
loss/value :  3.547632184895602
loss/value_i :  2.3763011161766676e-06
loss/value_e :  3.5476298187718247
loss/entropy :  2.284274509458831
reward/intrinsic_running :  0.0011247031633571077
reward/extrinsic_running :  0.08080740740740741
reward/intrinsic_std_running :  0.022375231176814524
reward/extrinsic_std_running :  1.597043499935387
reward/intrinsic_batch_std :  4.051123904889847e-05
reward/intrinsic_batch_max :  0.0006522907642647624
reward/intrinsic_batch_min :  5.023465746489819e-06
reward/total_batch :  0.04042994629220651
time/iteration_time :  112.15168404579163
time/fps :  2407.453818435386
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0004, Value Loss: 3.5476, Entropy: 2.2843
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=158.3
Extrinsic raw: Œº=0.08080740740740741

=== Iteration 578/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 19.46s
update_step :  578
reward/intrinsic_batch_mean :  5.3345766861032945e-05
reward/extrinsic_batch_mean :  0.08154814814814815
loss/policy :  0.000763013889258163
loss/rnd :  1.2131612076397384e-06
loss/value :  3.8662442077289927
loss/value_i :  2.2824355441612583e-06
loss/value_e :  3.8662419138532695
loss/entropy :  2.2912391496427134
reward/intrinsic_running :  0.0011229459451052575
reward/extrinsic_running :  0.08154814814814815
reward/intrinsic_std_running :  0.022355906969419567
reward/extrinsic_std_running :  1.6085598261638954
reward/intrinsic_batch_std :  3.834407804894911e-05
reward/intrinsic_batch_max :  0.0005591835943050683
reward/intrinsic_batch_min :  5.033588422520552e-06
reward/total_batch :  0.04080074695750459
time/iteration_time :  112.99647307395935
time/fps :  2389.455110012836
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0008, Value Loss: 3.8662, Entropy: 2.2912
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=161.1
Extrinsic raw: Œº=0.08154814814814815

=== Iteration 579/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 18.19s
update_step :  579
reward/intrinsic_batch_mean :  5.30715887836912e-05
reward/extrinsic_batch_mean :  0.07742222222222223
loss/policy :  0.0009859483036438398
loss/rnd :  1.2169201750800835e-06
loss/value :  3.3364589376883074
loss/value_i :  3.4644588174959416e-06
loss/value_e :  3.336455464363098
loss/entropy :  2.292671041055159
reward/intrinsic_running :  0.0011211958863765008
reward/extrinsic_running :  0.07742222222222223
reward/intrinsic_std_running :  0.022336632693679206
reward/extrinsic_std_running :  1.5865050873220559
reward/intrinsic_batch_std :  3.7131785980159315e-05
reward/intrinsic_batch_max :  0.0005502293934114277
reward/intrinsic_batch_min :  5.895280992262997e-06
reward/total_batch :  0.03873764690550296
time/iteration_time :  110.9720823764801
time/fps :  2433.044367717704
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2433
Policy Loss: 0.0010, Value Loss: 3.3365, Entropy: 2.2927
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=160.4
Extrinsic raw: Œº=0.07742222222222223

=== Iteration 580/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.78s
EPOCH 1 took 19.57s
update_step :  580
reward/intrinsic_batch_mean :  6.102271031737069e-05
reward/extrinsic_batch_mean :  0.08185925925925926
loss/policy :  0.0008381520667833022
loss/rnd :  2.4516119713718414e-06
loss/value :  4.01486924200347
loss/value_i :  1.2594011771012227e-05
loss/value_e :  4.01485664916761
loss/entropy :  2.2928992726586084
reward/intrinsic_running :  0.0011194795629179439
reward/extrinsic_running :  0.08185925925925926
reward/intrinsic_std_running :  0.02231740695395246
reward/extrinsic_std_running :  1.6503644341106085
reward/intrinsic_batch_std :  4.141307012548395e-05
reward/intrinsic_batch_max :  0.0008492300403304398
reward/intrinsic_batch_min :  1.0713894880609587e-05
reward/total_batch :  0.04096014098478831
time/iteration_time :  113.53749489784241
time/fps :  2378.0690268262288
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2378
Policy Loss: 0.0008, Value Loss: 4.0149, Entropy: 2.2929
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.038, sum=184.6
Extrinsic raw: Œº=0.08185925925925926

=== Iteration 581/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.36s
EPOCH 1 took 19.07s
update_step :  581
reward/intrinsic_batch_mean :  6.368801587327821e-05
reward/extrinsic_batch_mean :  0.08117777777777778
loss/policy :  0.0006902648160713866
loss/rnd :  1.3977802123835401e-06
loss/value :  6.3704975193197075
loss/value_i :  4.411322541300526e-06
loss/value_e :  6.370493119413203
loss/entropy :  2.2864577481240937
reward/intrinsic_running :  0.0011177737652191366
reward/extrinsic_running :  0.08117777777777778
reward/intrinsic_std_running :  0.022298230581322232
reward/extrinsic_std_running :  1.598427173084317
reward/intrinsic_batch_std :  4.4243056856186103e-05
reward/intrinsic_batch_max :  0.0008427861030213535
reward/intrinsic_batch_min :  1.1486245966807473e-05
reward/total_batch :  0.04062073289682553
time/iteration_time :  112.34169411659241
time/fps :  2403.3819511372503
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2403
Policy Loss: 0.0007, Value Loss: 6.3705, Entropy: 2.2865
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.038, sum=192.8
Extrinsic raw: Œº=0.08117777777777778

=== Iteration 582/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.42s
EPOCH 1 took 18.80s
update_step :  582
reward/intrinsic_batch_mean :  5.083386925169314e-05
reward/extrinsic_batch_mean :  0.08017777777777778
loss/policy :  0.0009455549588892609
loss/rnd :  1.1289573700940474e-06
loss/value :  4.569359927466421
loss/value_i :  2.4350961418597514e-05
loss/value_e :  4.569335569034923
loss/entropy :  2.3027530186104053
reward/intrinsic_running :  0.0011160316705733223
reward/extrinsic_running :  0.08017777777777778
reward/intrinsic_std_running :  0.02227910541622057
reward/extrinsic_std_running :  1.6044848157432392
reward/intrinsic_batch_std :  3.85790702948314e-05
reward/intrinsic_batch_max :  0.0006907953065820038
reward/intrinsic_batch_min :  4.804640411748551e-06
reward/total_batch :  0.04011430582351474
time/iteration_time :  112.83106207847595
time/fps :  2392.9580651488536
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2393
Policy Loss: 0.0009, Value Loss: 4.5694, Entropy: 2.3028
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=154.0
Extrinsic raw: Œº=0.08017777777777778

=== Iteration 583/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.75s
EPOCH 1 took 18.76s
update_step :  583
reward/intrinsic_batch_mean :  5.140017414588429e-05
reward/extrinsic_batch_mean :  0.08391111111111112
loss/policy :  0.0012123290507588536
loss/rnd :  1.1385934285637191e-06
loss/value :  3.1153915289676553
loss/value_i :  5.4400910550722266e-06
loss/value_e :  3.1153860796581614
loss/entropy :  2.31491575457833
reward/intrinsic_running :  0.0011142969408200688
reward/extrinsic_running :  0.08391111111111112
reward/intrinsic_std_running :  0.022260029319792565
reward/extrinsic_std_running :  1.6520592199351811
reward/intrinsic_batch_std :  3.876713310273044e-05
reward/intrinsic_batch_max :  0.0006503620534203947
reward/intrinsic_batch_min :  4.589029686030699e-06
reward/total_batch :  0.0419812556426285
time/iteration_time :  111.56294322013855
time/fps :  2420.1584523207657
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.6s | FPS: 2420
Policy Loss: 0.0012, Value Loss: 3.1154, Entropy: 2.3149
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=155.9
Extrinsic raw: Œº=0.08391111111111112

=== Iteration 584/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 20.59s
update_step :  584
reward/intrinsic_batch_mean :  5.138275639559045e-05
reward/extrinsic_batch_mean :  0.07724444444444445
loss/policy :  0.0003691030160001846
loss/rnd :  1.1440431776601614e-06
loss/value :  4.236345009370283
loss/value_i :  2.0612328763959478e-06
loss/value_e :  4.236342971975153
loss/entropy :  2.3078060511386758
reward/intrinsic_running :  0.0011125677471334524
reward/extrinsic_running :  0.07724444444444445
reward/intrinsic_std_running :  0.022241002162761613
reward/extrinsic_std_running :  1.5672587413918397
reward/intrinsic_batch_std :  4.052455817692359e-05
reward/intrinsic_batch_max :  0.0006750474567525089
reward/intrinsic_batch_min :  5.076007255411241e-06
reward/total_batch :  0.03864791360042002
time/iteration_time :  113.36220335960388
time/fps :  2381.746225799042
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2382
Policy Loss: 0.0004, Value Loss: 4.2363, Entropy: 2.3078
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=155.9
Extrinsic raw: Œº=0.07724444444444445

=== Iteration 585/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 17.99s
EPOCH 1 took 18.78s
update_step :  585
reward/intrinsic_batch_mean :  5.4148987209306074e-05
reward/extrinsic_batch_mean :  0.07591111111111111
loss/policy :  0.00032594837654015106
loss/rnd :  1.2688230481906044e-06
loss/value :  4.536185510230787
loss/value_i :  2.8061342067248365e-06
loss/value_e :  4.536182714231087
loss/entropy :  2.300327019257979
reward/intrinsic_running :  0.0011108538223510956
reward/extrinsic_running :  0.07591111111111111
reward/intrinsic_std_running :  0.022222023306921582
reward/extrinsic_std_running :  1.5535575969089725
reward/intrinsic_batch_std :  4.257628915811286e-05
reward/intrinsic_batch_max :  0.0008196362177841365
reward/intrinsic_batch_min :  4.857517978962278e-06
reward/total_batch :  0.03798263004916021
time/iteration_time :  110.62196183204651
time/fps :  2440.7449979049516
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.6s | FPS: 2441
Policy Loss: 0.0003, Value Loss: 4.5362, Entropy: 2.3003
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=164.5
Extrinsic raw: Œº=0.07591111111111111

=== Iteration 586/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.31s
EPOCH 1 took 21.07s
update_step :  586
reward/intrinsic_batch_mean :  6.0539758594165536e-05
reward/extrinsic_batch_mean :  0.0746962962962963
loss/policy :  0.0007909283740445971
loss/rnd :  1.2781095678650618e-06
loss/value :  5.823758399847782
loss/value_i :  4.982458080755323e-06
loss/value_e :  5.823753421956843
loss/entropy :  2.2919024012305518
reward/intrinsic_running :  0.0011091687291865345
reward/extrinsic_running :  0.0746962962962963
reward/intrinsic_std_running :  0.02220309191760524
reward/extrinsic_std_running :  1.5208544444151757
reward/intrinsic_batch_std :  4.060170707789152e-05
reward/intrinsic_batch_max :  0.0005704588256776333
reward/intrinsic_batch_min :  8.992030416266061e-06
reward/total_batch :  0.03737841802744524
time/iteration_time :  115.80240893363953
time/fps :  2331.557715303861
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.8s | FPS: 2332
Policy Loss: 0.0008, Value Loss: 5.8238, Entropy: 2.2919
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.026, sum=184.0
Extrinsic raw: Œº=0.0746962962962963

=== Iteration 587/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 17.68s
EPOCH 1 took 18.15s
update_step :  587
reward/intrinsic_batch_mean :  5.830348718337956e-05
reward/extrinsic_batch_mean :  0.07161481481481481
loss/policy :  0.0009184549474439611
loss/rnd :  1.3097929940103672e-06
loss/value :  4.632650816079342
loss/value_i :  6.446706783153235e-05
loss/value_e :  4.632586338303306
loss/entropy :  2.3007703188693887
reward/intrinsic_running :  0.0011074826183201563
reward/extrinsic_running :  0.07161481481481481
reward/intrinsic_std_running :  0.022184209150601236
reward/extrinsic_std_running :  1.520510703606036
reward/intrinsic_batch_std :  4.321252282036432e-05
reward/intrinsic_batch_max :  0.0007886780076660216
reward/intrinsic_batch_min :  7.3208470894314814e-06
reward/total_batch :  0.03583655915099909
time/iteration_time :  114.50719237327576
time/fps :  2357.9304880678737
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2358
Policy Loss: 0.0009, Value Loss: 4.6327, Entropy: 2.3008
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=177.4
Extrinsic raw: Œº=0.07161481481481481

=== Iteration 588/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.65s
EPOCH 1 took 19.75s
update_step :  588
reward/intrinsic_batch_mean :  5.393737667805841e-05
reward/extrinsic_batch_mean :  0.07728148148148148
loss/policy :  0.001042195652244669
loss/rnd :  1.514571518975682e-06
loss/value :  3.176115541747122
loss/value_i :  1.593742160821421e-05
loss/value_e :  3.176099596601544
loss/entropy :  2.2989745862556226
reward/intrinsic_running :  0.001105786249806685
reward/extrinsic_running :  0.07728148148148148
reward/intrinsic_std_running :  0.022165375181668837
reward/extrinsic_std_running :  1.5860438140314526
reward/intrinsic_batch_std :  4.1241565004203803e-05
reward/intrinsic_batch_max :  0.0004975273041054606
reward/intrinsic_batch_min :  5.1473571147653274e-06
reward/total_batch :  0.038667709429079766
time/iteration_time :  112.66110491752625
time/fps :  2396.5680098526814
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: 0.0010, Value Loss: 3.1761, Entropy: 2.2990
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=164.3
Extrinsic raw: Œº=0.07728148148148148

=== Iteration 589/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 21.22s
EPOCH 1 took 20.85s
update_step :  589
reward/intrinsic_batch_mean :  5.5184203872394626e-05
reward/extrinsic_batch_mean :  0.07638518518518518
loss/policy :  0.0005649032868721847
loss/rnd :  1.2028982472188408e-06
loss/value :  3.4633873303731284
loss/value_i :  3.2195305610719407e-06
loss/value_e :  3.4633841297843238
loss/entropy :  2.2955245393695254
reward/intrinsic_running :  0.0011040996809302856
reward/extrinsic_running :  0.07638518518518518
reward/intrinsic_std_running :  0.02214658890608865
reward/extrinsic_std_running :  1.573898947225271
reward/intrinsic_batch_std :  4.015416739251741e-05
reward/intrinsic_batch_max :  0.0005928044556640089
reward/intrinsic_batch_min :  5.2929062803741544e-06
reward/total_batch :  0.038220184694528786
time/iteration_time :  118.23962450027466
time/fps :  2283.498456131961
data/episodes_collected :  60
data/frames_collected :  270000
Timer 118.2s | FPS: 2283
Policy Loss: 0.0006, Value Loss: 3.4634, Entropy: 2.2955
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=168.2
Extrinsic raw: Œº=0.07638518518518518

=== Iteration 590/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.21s
EPOCH 1 took 20.20s
update_step :  590
reward/intrinsic_batch_mean :  5.482436968171964e-05
reward/extrinsic_batch_mean :  0.08108148148148148
loss/policy :  0.0014427735322070393
loss/rnd :  1.3180936059253519e-06
loss/value :  4.230893265117299
loss/value_i :  2.5767987236494347e-06
loss/value_e :  4.230890689474164
loss/entropy :  2.2935712409741953
reward/intrinsic_running :  0.0011024165996821715
reward/extrinsic_running :  0.08108148148148148
reward/intrinsic_std_running :  0.022127850431258877
reward/extrinsic_std_running :  1.6173125447590027
reward/intrinsic_batch_std :  4.201168397054635e-05
reward/intrinsic_batch_max :  0.0006932786200195551
reward/intrinsic_batch_min :  5.298205906001385e-06
reward/total_batch :  0.0405681529255816
time/iteration_time :  115.32938647270203
time/fps :  2341.120578699236
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2341
Policy Loss: 0.0014, Value Loss: 4.2309, Entropy: 2.2936
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=167.2
Extrinsic raw: Œº=0.08108148148148148

=== Iteration 591/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.55s
EPOCH 1 took 18.47s
update_step :  591
reward/intrinsic_batch_mean :  5.993760741481243e-05
reward/extrinsic_batch_mean :  0.07842222222222223
loss/policy :  0.0010336024085214983
loss/rnd :  1.2404111692266078e-06
loss/value :  4.519573995561311
loss/value_i :  2.3228517696252586e-06
loss/value_e :  4.519571669173963
loss/entropy :  2.2961432753187236
reward/intrinsic_running :  0.0011007579926817618
reward/extrinsic_running :  0.07842222222222223
reward/intrinsic_std_running :  0.022109158590899458
reward/extrinsic_std_running :  1.5897268433737948
reward/intrinsic_batch_std :  3.9934737855331793e-05
reward/intrinsic_batch_max :  0.0006098091835156083
reward/intrinsic_batch_min :  8.894607162801549e-06
reward/total_batch :  0.03924107991481852
time/iteration_time :  111.22494053840637
time/fps :  2427.5130981685534
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0010, Value Loss: 4.5196, Entropy: 2.2961
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=183.0
Extrinsic raw: Œº=0.07842222222222223

=== Iteration 592/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.71s
EPOCH 1 took 19.58s
update_step :  592
reward/intrinsic_batch_mean :  5.1492855553806295e-05
reward/extrinsic_batch_mean :  0.07831851851851852
loss/policy :  0.00046852352005027404
loss/rnd :  1.4231584321516328e-06
loss/value :  2.8123578067981834
loss/value_i :  2.124693020794604e-06
loss/value_e :  2.8123556556123677
loss/entropy :  2.3164007772098887
reward/intrinsic_running :  0.0010990751086559767
reward/extrinsic_running :  0.07831851851851852
reward/intrinsic_std_running :  0.022090515373952454
reward/extrinsic_std_running :  1.5892589428519328
reward/intrinsic_batch_std :  3.921643905884444e-05
reward/intrinsic_batch_max :  0.0005562903243117034
reward/intrinsic_batch_min :  4.790253115061205e-06
reward/total_batch :  0.039185005687036166
time/iteration_time :  113.55675482749939
time/fps :  2377.6656915755366
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2378
Policy Loss: 0.0005, Value Loss: 2.8124, Entropy: 2.3164
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=157.3
Extrinsic raw: Œº=0.07831851851851852

=== Iteration 593/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.90s
EPOCH 1 took 19.31s
update_step :  593
reward/intrinsic_batch_mean :  5.1359540266653146e-05
reward/extrinsic_batch_mean :  0.07930370370370371
loss/policy :  0.0008969172221523794
loss/rnd :  1.1272003417395877e-06
loss/value :  4.589827642296299
loss/value_i :  2.138021062764341e-06
loss/value_e :  4.589825532653115
loss/entropy :  2.3018272898413916
reward/intrinsic_running :  0.0010973969160270052
reward/extrinsic_running :  0.07930370370370371
reward/intrinsic_std_running :  0.02207191927904289
reward/extrinsic_std_running :  1.6017536097298422
reward/intrinsic_batch_std :  4.0026137332581646e-05
reward/intrinsic_batch_max :  0.0006084634806029499
reward/intrinsic_batch_min :  4.3763052417489234e-06
reward/total_batch :  0.03967753162198518
time/iteration_time :  113.09353113174438
time/fps :  2387.404454508303
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2387
Policy Loss: 0.0009, Value Loss: 4.5898, Entropy: 2.3018
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=157.1
Extrinsic raw: Œº=0.07930370370370371

=== Iteration 594/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.33s
EPOCH 1 took 19.76s
update_step :  594
reward/intrinsic_batch_mean :  5.26154056424275e-05
reward/extrinsic_batch_mean :  0.07708888888888889
loss/policy :  0.00043333859216407734
loss/rnd :  1.1582940277493794e-06
loss/value :  4.612529415072816
loss/value_i :  2.2171550237241413e-06
loss/value_e :  4.612527193445148
loss/entropy :  2.2915581537015512
reward/intrinsic_running :  0.0010957280101588564
reward/extrinsic_running :  0.07708888888888889
reward/intrinsic_std_running :  0.0220533699128586
reward/extrinsic_std_running :  1.5761750136264205
reward/intrinsic_batch_std :  4.1165449637952146e-05
reward/intrinsic_batch_max :  0.0006528123049065471
reward/intrinsic_batch_min :  4.409876964928117e-06
reward/total_batch :  0.03857075214726566
time/iteration_time :  112.5346794128418
time/fps :  2399.2604005160492
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0004, Value Loss: 4.6125, Entropy: 2.2916
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=161.0
Extrinsic raw: Œº=0.07708888888888889

=== Iteration 595/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.93s
EPOCH 1 took 19.20s
update_step :  595
reward/intrinsic_batch_mean :  5.341115404310215e-05
reward/extrinsic_batch_mean :  0.08139259259259259
loss/policy :  0.0015629195188397937
loss/rnd :  1.1753701731763475e-06
loss/value :  4.315836635502902
loss/value_i :  2.2010756655425103e-06
loss/value_e :  4.315834439162052
loss/entropy :  2.292203769539342
reward/intrinsic_running :  0.0010940684834672963
reward/extrinsic_running :  0.08139259259259259
reward/intrinsic_std_running :  0.022034867078289607
reward/extrinsic_std_running :  1.6490438490960233
reward/intrinsic_batch_std :  4.286636589246004e-05
reward/intrinsic_batch_max :  0.0007242081337608397
reward/intrinsic_batch_min :  4.983121471013874e-06
reward/total_batch :  0.04072300187331784
time/iteration_time :  113.70589447021484
time/fps :  2374.5470826996243
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: 0.0016, Value Loss: 4.3158, Entropy: 2.2922
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=163.6
Extrinsic raw: Œº=0.08139259259259259

=== Iteration 596/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.17s
EPOCH 1 took 19.13s
update_step :  596
reward/intrinsic_batch_mean :  5.378710689716105e-05
reward/extrinsic_batch_mean :  0.07931851851851852
loss/policy :  0.0010680639190302993
loss/rnd :  1.1836522110735876e-06
loss/value :  4.457176078449596
loss/value_i :  2.3080937057095454e-06
loss/value_e :  4.457173744837443
loss/entropy :  2.292238394419352
reward/intrinsic_running :  0.0010924152110483858
reward/extrinsic_running :  0.07931851851851852
reward/intrinsic_std_running :  0.022016410708053734
reward/extrinsic_std_running :  1.5643165761436542
reward/intrinsic_batch_std :  4.4577824471796705e-05
reward/intrinsic_batch_max :  0.0009334975620731711
reward/intrinsic_batch_min :  4.33082686868147e-06
reward/total_batch :  0.03968615281270784
time/iteration_time :  111.1018738746643
time/fps :  2430.20203515731
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.1s | FPS: 2430
Policy Loss: 0.0011, Value Loss: 4.4572, Entropy: 2.2922
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.042, sum=164.9
Extrinsic raw: Œº=0.07931851851851852

=== Iteration 597/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.56s
EPOCH 1 took 18.80s
update_step :  597
reward/intrinsic_batch_mean :  5.371194200322659e-05
reward/extrinsic_batch_mean :  0.08197037037037037
loss/policy :  0.0011456802877188293
loss/rnd :  1.1793929870967104e-06
loss/value :  4.299053994092074
loss/value_i :  2.1782864981408543e-06
loss/value_e :  4.2990518230380435
loss/entropy :  2.2864451986370664
reward/intrinsic_running :  0.0010907681901830744
reward/extrinsic_running :  0.08197037037037037
reward/intrinsic_std_running :  0.021998000600014854
reward/extrinsic_std_running :  1.6099227399945986
reward/intrinsic_batch_std :  4.380990700198305e-05
reward/intrinsic_batch_max :  0.0007781879976391792
reward/intrinsic_batch_min :  4.754780093207955e-06
reward/total_batch :  0.0410120411561868
time/iteration_time :  112.4709210395813
time/fps :  2400.620511545205
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0011, Value Loss: 4.2991, Entropy: 2.2864
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=164.8
Extrinsic raw: Œº=0.08197037037037037

=== Iteration 598/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.10s
EPOCH 1 took 18.51s
update_step :  598
reward/intrinsic_batch_mean :  5.053169200922706e-05
reward/extrinsic_batch_mean :  0.08022222222222222
loss/policy :  0.0012053065125435364
loss/rnd :  1.110756093594594e-06
loss/value :  3.668487660812609
loss/value_i :  2.0792235101329095e-06
loss/value_e :  3.668485583681049
loss/entropy :  2.2951858693903144
reward/intrinsic_running :  0.0010891141477664536
reward/extrinsic_running :  0.08022222222222222
reward/intrinsic_std_running :  0.021979637142315024
reward/extrinsic_std_running :  1.6044756691329123
reward/intrinsic_batch_std :  3.950900719468613e-05
reward/intrinsic_batch_max :  0.0006728920852765441
reward/intrinsic_batch_min :  3.951162398152519e-06
reward/total_batch :  0.04013637695711572
time/iteration_time :  111.3722779750824
time/fps :  2424.3016746088983
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0012, Value Loss: 3.6685, Entropy: 2.2952
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=155.2
Extrinsic raw: Œº=0.08022222222222222

=== Iteration 599/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.28s
EPOCH 1 took 18.08s
update_step :  599
reward/intrinsic_batch_mean :  5.250364238843893e-05
reward/extrinsic_batch_mean :  0.08328888888888888
loss/policy :  0.0006978666404558515
loss/rnd :  1.1584270740775426e-06
loss/value :  4.871566273949363
loss/value_i :  2.266795919777823e-06
loss/value_e :  4.871564001748056
loss/entropy :  2.2837053645740855
reward/intrinsic_running :  0.0010874712022902078
reward/extrinsic_running :  0.08328888888888888
reward/intrinsic_std_running :  0.0219613193470056
reward/extrinsic_std_running :  1.6231462354724528
reward/intrinsic_batch_std :  4.111856337375622e-05
reward/intrinsic_batch_max :  0.0005441898829303682
reward/intrinsic_batch_min :  4.491304935072549e-06
reward/total_batch :  0.041670696265638664
time/iteration_time :  112.46252679824829
time/fps :  2400.7996946784365
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0007, Value Loss: 4.8716, Entropy: 2.2837
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=161.4
Extrinsic raw: Œº=0.08328888888888888

=== Iteration 600/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.81s
EPOCH 1 took 18.56s
update_step :  600
reward/intrinsic_batch_mean :  5.42691701800356e-05
reward/extrinsic_batch_mean :  0.0805037037037037
loss/policy :  0.0008539857031295965
loss/rnd :  1.1963665525454967e-06
loss/value :  4.063014998580471
loss/value_i :  2.572392387182018e-06
loss/value_e :  4.063012426549738
loss/entropy :  2.271989034883904
reward/intrinsic_running :  0.0010858406875506766
reward/extrinsic_running :  0.0805037037037037
reward/intrinsic_std_running :  0.021943046977427577
reward/extrinsic_std_running :  1.605386963270268
reward/intrinsic_batch_std :  4.2031184314542766e-05
reward/intrinsic_batch_max :  0.0006344668800011277
reward/intrinsic_batch_min :  5.6080607464537024e-06
reward/total_batch :  0.04027898643694187
time/iteration_time :  113.07246541976929
time/fps :  2387.8492345387026
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0009, Value Loss: 4.0630, Entropy: 2.2720
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=166.9
Extrinsic raw: Œº=0.0805037037037037

=== Iteration 601/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 19.66s
update_step :  601
reward/intrinsic_batch_mean :  5.605428439840681e-05
reward/extrinsic_batch_mean :  0.08783703703703703
loss/policy :  0.0015591146933399034
loss/rnd :  1.215681064340143e-06
loss/value :  5.799779360944575
loss/value_i :  2.4956089343201406e-06
loss/value_e :  5.799776846712286
loss/entropy :  2.256757136547204
reward/intrinsic_running :  0.001084220237961304
reward/extrinsic_running :  0.08783703703703703
reward/intrinsic_std_running :  0.02192481992231952
reward/extrinsic_std_running :  1.65495759913194
reward/intrinsic_batch_std :  4.249662907674359e-05
reward/intrinsic_batch_max :  0.0005829391302540898
reward/intrinsic_batch_min :  4.539658220892306e-06
reward/total_batch :  0.04394654566071772
time/iteration_time :  113.6292622089386
time/fps :  2376.1484916053655
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2376
Policy Loss: 0.0016, Value Loss: 5.7998, Entropy: 2.2568
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=172.6
Extrinsic raw: Œº=0.08783703703703703

=== Iteration 602/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.37s
update_step :  602
reward/intrinsic_batch_mean :  5.242854021379807e-05
reward/extrinsic_batch_mean :  0.08164444444444445
loss/policy :  0.0007972185787476712
loss/rnd :  1.1426470188890754e-06
loss/value :  5.63883714242415
loss/value_i :  2.6602499991151323e-06
loss/value_e :  5.638834508982572
loss/entropy :  2.2636483004598906
reward/intrinsic_running :  0.0010825925139939677
reward/extrinsic_running :  0.08164444444444445
reward/intrinsic_std_running :  0.021906638777165595
reward/extrinsic_std_running :  1.5905021683903238
reward/intrinsic_batch_std :  4.043558307160399e-05
reward/intrinsic_batch_max :  0.0006016014376655221
reward/intrinsic_batch_min :  4.499002443481004e-06
reward/total_batch :  0.040848436492329124
time/iteration_time :  113.0841314792633
time/fps :  2387.602897666601
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0008, Value Loss: 5.6388, Entropy: 2.2636
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=161.5
Extrinsic raw: Œº=0.08164444444444445

=== Iteration 603/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.82s
EPOCH 1 took 19.49s
update_step :  603
reward/intrinsic_batch_mean :  5.107520545645659e-05
reward/extrinsic_batch_mean :  0.08463703703703704
loss/policy :  0.0011933266774356139
loss/rnd :  1.1203114791952071e-06
loss/value :  3.743309169104605
loss/value_i :  2.1583292285261752e-05
loss/value_e :  3.7432875886107935
loss/entropy :  2.2829328522537695
reward/intrinsic_running :  0.0010809685009114916
reward/extrinsic_running :  0.08463703703703704
reward/intrinsic_std_running :  0.021888502857901972
reward/extrinsic_std_running :  1.6470398524824152
reward/intrinsic_batch_std :  3.9201964681137895e-05
reward/intrinsic_batch_max :  0.0006288741715252399
reward/intrinsic_batch_min :  4.380369773571147e-06
reward/total_batch :  0.04234405612124675
time/iteration_time :  113.05838108062744
time/fps :  2388.146702785792
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0012, Value Loss: 3.7433, Entropy: 2.2829
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=157.5
Extrinsic raw: Œº=0.08463703703703704

=== Iteration 604/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.32s
EPOCH 1 took 18.80s
update_step :  604
reward/intrinsic_batch_mean :  5.1149415006417524e-05
reward/extrinsic_batch_mean :  0.08712592592592593
loss/policy :  0.0009342417893507941
loss/rnd :  1.140585616419478e-06
loss/value :  4.8689363978125835
loss/value_i :  0.00021543342010814243
loss/value_e :  4.868720961339546
loss/entropy :  2.2757860602754536
reward/intrinsic_running :  0.0010793478749910929
reward/extrinsic_running :  0.08712592592592593
reward/intrinsic_std_running :  0.02187041199459384
reward/extrinsic_std_running :  1.6617354267713937
reward/intrinsic_batch_std :  3.9721236319678095e-05
reward/intrinsic_batch_max :  0.0007195842335931957
reward/intrinsic_batch_min :  4.270723820809508e-06
reward/total_batch :  0.04358853767046617
time/iteration_time :  110.53051137924194
time/fps :  2442.7644152807843
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2443
Policy Loss: 0.0009, Value Loss: 4.8689, Entropy: 2.2758
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=157.9
Extrinsic raw: Œº=0.08712592592592593

=== Iteration 605/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.63s
EPOCH 1 took 18.48s
update_step :  605
reward/intrinsic_batch_mean :  5.156185340178194e-05
reward/extrinsic_batch_mean :  0.0828962962962963
loss/policy :  0.0006011101262023052
loss/rnd :  1.1283349656630228e-06
loss/value :  2.8860495596221
loss/value_i :  2.99109788584522e-06
loss/value_e :  2.8860465667464514
loss/entropy :  2.2830312035300513
reward/intrinsic_running :  0.0010777331893436837
reward/extrinsic_running :  0.0828962962962963
reward/intrinsic_std_running :  0.02185236588722191
reward/extrinsic_std_running :  1.6126279623028674
reward/intrinsic_batch_std :  4.027789743717034e-05
reward/intrinsic_batch_max :  0.0005733034340664744
reward/intrinsic_batch_min :  4.974722287443001e-06
reward/total_batch :  0.04147392907484904
time/iteration_time :  113.07047724723816
time/fps :  2387.8912212391406
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0006, Value Loss: 2.8860, Entropy: 2.2830
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=159.3
Extrinsic raw: Œº=0.0828962962962963

=== Iteration 606/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.65s
EPOCH 1 took 18.48s
update_step :  606
reward/intrinsic_batch_mean :  5.24145242198655e-05
reward/extrinsic_batch_mean :  0.0833037037037037
loss/policy :  0.00045614579302668005
loss/rnd :  1.1430880755886557e-06
loss/value :  3.9267705064831357
loss/value_i :  2.8756200876931404e-06
loss/value_e :  3.926767627398173
loss/entropy :  2.2847140774582373
reward/intrinsic_running :  0.0010761273108000832
reward/extrinsic_running :  0.0833037037037037
reward/intrinsic_std_running :  0.021834364227896946
reward/extrinsic_std_running :  1.632244912968703
reward/intrinsic_batch_std :  4.0538124597581585e-05
reward/intrinsic_batch_max :  0.0005732487770728767
reward/intrinsic_batch_min :  4.692768015956972e-06
reward/total_batch :  0.04167805911396178
time/iteration_time :  111.5380437374115
time/fps :  2420.6987226317833
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2421
Policy Loss: 0.0005, Value Loss: 3.9268, Entropy: 2.2847
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=162.0
Extrinsic raw: Œº=0.0833037037037037

=== Iteration 607/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.04s
EPOCH 1 took 20.14s
update_step :  607
reward/intrinsic_batch_mean :  5.373734303761416e-05
reward/extrinsic_batch_mean :  0.08180740740740741
loss/policy :  0.0006870137718082829
loss/rnd :  1.1481697583803907e-06
loss/value :  4.885892936677644
loss/value_i :  2.4084511131039825e-06
loss/value_e :  4.885890501918214
loss/entropy :  2.288963617700519
reward/intrinsic_running :  0.001074531211780109
reward/extrinsic_running :  0.08180740740740741
reward/intrinsic_std_running :  0.02181640678637447
reward/extrinsic_std_running :  1.6277785794292892
reward/intrinsic_batch_std :  3.9737730640889224e-05
reward/intrinsic_batch_max :  0.0005644527263939381
reward/intrinsic_batch_min :  5.481393145601032e-06
reward/total_batch :  0.04093057237522251
time/iteration_time :  113.94729208946228
time/fps :  2369.516598850086
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2370
Policy Loss: 0.0007, Value Loss: 4.8859, Entropy: 2.2890
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=166.3
Extrinsic raw: Œº=0.08180740740740741

=== Iteration 608/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.94s
EPOCH 1 took 19.11s
update_step :  608
reward/intrinsic_batch_mean :  5.432187979602329e-05
reward/extrinsic_batch_mean :  0.0843037037037037
loss/policy :  0.0008856926332086776
loss/rnd :  1.1749581686313886e-06
loss/value :  5.277952353159587
loss/value_i :  2.322057036618582e-06
loss/value_e :  5.277950012322628
loss/entropy :  2.2757145166397095
reward/intrinsic_running :  0.0010729426818577416
reward/extrinsic_running :  0.0843037037037037
reward/intrinsic_std_running :  0.02179849348439178
reward/extrinsic_std_running :  1.6171535109983932
reward/intrinsic_batch_std :  4.092054624237142e-05
reward/intrinsic_batch_max :  0.00048312084982171655
reward/intrinsic_batch_min :  5.787050668004667e-06
reward/total_batch :  0.04217901279174986
time/iteration_time :  112.30183362960815
time/fps :  2404.235009114001
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0009, Value Loss: 5.2780, Entropy: 2.2757
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.022, sum=168.2
Extrinsic raw: Œº=0.0843037037037037

=== Iteration 609/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 19.73s
update_step :  609
reward/intrinsic_batch_mean :  5.337140641812665e-05
reward/extrinsic_batch_mean :  0.0807925925925926
loss/policy :  0.000988266704194812
loss/rnd :  1.1631459770025245e-06
loss/value :  4.481168309847514
loss/value_i :  2.2623242840023576e-06
loss/value_e :  4.481166026808999
loss/entropy :  2.28213682680419
reward/intrinsic_running :  0.0010713548365460712
reward/extrinsic_running :  0.0807925925925926
reward/intrinsic_std_running :  0.021780624433335723
reward/extrinsic_std_running :  1.5970465685656612
reward/intrinsic_batch_std :  4.123162269893896e-05
reward/intrinsic_batch_max :  0.0005997413536533713
reward/intrinsic_batch_min :  4.234848347550724e-06
reward/total_batch :  0.040422981999505364
time/iteration_time :  113.60385227203369
time/fps :  2376.679968153395
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2377
Policy Loss: 0.0010, Value Loss: 4.4812, Entropy: 2.2821
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=165.4
Extrinsic raw: Œº=0.0807925925925926

=== Iteration 610/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.34s
update_step :  610
reward/intrinsic_batch_mean :  5.2541219141568475e-05
reward/extrinsic_batch_mean :  0.07964444444444445
loss/policy :  0.001043136815441716
loss/rnd :  1.1597919827484777e-06
loss/value :  3.374440382827412
loss/value_i :  2.0991098649987676e-06
loss/value_e :  3.3744383111144556
loss/entropy :  2.2826894521713257
reward/intrinsic_running :  0.0010697701485329122
reward/extrinsic_running :  0.07964444444444445
reward/intrinsic_std_running :  0.021762799334663192
reward/extrinsic_std_running :  1.6026544252937316
reward/intrinsic_batch_std :  3.975247871983353e-05
reward/intrinsic_batch_max :  0.0006496928399428725
reward/intrinsic_batch_min :  4.504121989157284e-06
reward/total_batch :  0.03984849283179301
time/iteration_time :  111.78469467163086
time/fps :  2415.3574940928083
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0010, Value Loss: 3.3744, Entropy: 2.2827
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=163.0
Extrinsic raw: Œº=0.07964444444444445

=== Iteration 611/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 20.49s
update_step :  611
reward/intrinsic_batch_mean :  5.261307474327758e-05
reward/extrinsic_batch_mean :  0.08297777777777778
loss/policy :  0.0013528266739960986
loss/rnd :  1.1817631078966686e-06
loss/value :  5.69742294513818
loss/value_i :  2.203335237950479e-06
loss/value_e :  5.6974207632469405
loss/entropy :  2.2744729374394272
reward/intrinsic_running :  0.001068191151139673
reward/extrinsic_running :  0.08297777777777778
reward/intrinsic_std_running :  0.02174501793061705
reward/extrinsic_std_running :  1.6321752877300106
reward/intrinsic_batch_std :  4.4818954268270615e-05
reward/intrinsic_batch_max :  0.0009874777169898152
reward/intrinsic_batch_min :  5.065853201813297e-06
reward/total_batch :  0.041515195426260525
time/iteration_time :  114.05340194702148
time/fps :  2367.3121133678824
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0014, Value Loss: 5.6974, Entropy: 2.2745
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.045, sum=163.3
Extrinsic raw: Œº=0.08297777777777778

=== Iteration 612/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.53s
EPOCH 1 took 18.82s
update_step :  612
reward/intrinsic_batch_mean :  6.006367130996498e-05
reward/extrinsic_batch_mean :  0.08183703703703704
loss/policy :  0.0007748743964563773
loss/rnd :  1.1732744631196759e-06
loss/value :  3.7787544438333223
loss/value_i :  2.060790653545017e-06
loss/value_e :  3.778752402825789
loss/entropy :  2.2679886456691856
reward/intrinsic_running :  0.0010666425125202843
reward/extrinsic_running :  0.08183703703703704
reward/intrinsic_std_running :  0.02172727891167938
reward/extrinsic_std_running :  1.6368485176519447
reward/intrinsic_batch_std :  3.919965213879594e-05
reward/intrinsic_batch_max :  0.0005562757141888142
reward/intrinsic_batch_min :  9.667652193456888e-06
reward/total_batch :  0.0409485503541735
time/iteration_time :  113.44035744667053
time/fps :  2380.1053353250386
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2380
Policy Loss: 0.0008, Value Loss: 3.7788, Entropy: 2.2680
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.026, sum=186.6
Extrinsic raw: Œº=0.08183703703703704

=== Iteration 613/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.07s
EPOCH 1 took 19.43s
update_step :  613
reward/intrinsic_batch_mean :  5.296799733315075e-05
reward/extrinsic_batch_mean :  0.08273333333333334
loss/policy :  0.0006733890975627935
loss/rnd :  1.1515911585940393e-06
loss/value :  3.3881922617103113
loss/value_i :  2.0611495129383965e-06
loss/value_e :  3.3881902116717715
loss/entropy :  2.255774407675772
reward/intrinsic_running :  0.0010650758467923643
reward/extrinsic_running :  0.08273333333333334
reward/intrinsic_std_running :  0.021709584259825918
reward/extrinsic_std_running :  1.630454268442228
reward/intrinsic_batch_std :  4.1790250435373114e-05
reward/intrinsic_batch_max :  0.0007114506443031132
reward/intrinsic_batch_min :  4.473488388612168e-06
reward/total_batch :  0.04139315066533324
time/iteration_time :  112.21870946884155
time/fps :  2406.0159065986027
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2406
Policy Loss: 0.0007, Value Loss: 3.3882, Entropy: 2.2558
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=164.7
Extrinsic raw: Œº=0.08273333333333334

=== Iteration 614/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.70s
EPOCH 1 took 19.21s
update_step :  614
reward/intrinsic_batch_mean :  5.268550795122051e-05
reward/extrinsic_batch_mean :  0.07978518518518518
loss/policy :  0.0006204791836187889
loss/rnd :  1.2670354742498824e-06
loss/value :  3.743294184858149
loss/value_i :  2.1099987059118797e-06
loss/value_e :  3.7432920896645747
loss/entropy :  2.2475068027322944
reward/intrinsic_running :  0.0010635127961114825
reward/extrinsic_running :  0.07978518518518518
reward/intrinsic_std_running :  0.02169193281877385
reward/extrinsic_std_running :  1.5845203358099689
reward/intrinsic_batch_std :  3.881666990983492e-05
reward/intrinsic_batch_max :  0.0006184261292219162
reward/intrinsic_batch_min :  4.376458946353523e-06
reward/total_batch :  0.0399189353465682
time/iteration_time :  112.61628937721252
time/fps :  2397.5217217078143
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0006, Value Loss: 3.7433, Entropy: 2.2475
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=163.9
Extrinsic raw: Œº=0.07978518518518518

=== Iteration 615/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.80s
EPOCH 1 took 19.22s
update_step :  615
reward/intrinsic_batch_mean :  6.01744893247087e-05
reward/extrinsic_batch_mean :  0.0787037037037037
loss/policy :  0.0013636885463104893
loss/rnd :  2.0389126585872543e-06
loss/value :  5.458913564682007
loss/value_i :  2.137862645323559e-06
loss/value_e :  5.4589114731008355
loss/entropy :  2.242460352001768
reward/intrinsic_running :  0.0010619797903542495
reward/extrinsic_running :  0.0787037037037037
reward/intrinsic_std_running :  0.021674323282835497
reward/extrinsic_std_running :  1.581258929175546
reward/intrinsic_batch_std :  3.994006595462652e-05
reward/intrinsic_batch_max :  0.0005488824099302292
reward/intrinsic_batch_min :  8.58128896652488e-06
reward/total_batch :  0.039381939096514204
time/iteration_time :  113.46220922470093
time/fps :  2379.646948926326
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2380
Policy Loss: 0.0014, Value Loss: 5.4589, Entropy: 2.2425
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.025, sum=187.4
Extrinsic raw: Œº=0.0787037037037037

=== Iteration 616/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 18.39s
update_step :  616
reward/intrinsic_batch_mean :  7.118928709309397e-05
reward/extrinsic_batch_mean :  0.07633333333333334
loss/policy :  0.00039735624291510743
loss/rnd :  1.2901145293075056e-06
loss/value :  5.216010371843974
loss/value_i :  2.2324903566737757e-06
loss/value_e :  5.216008106867473
loss/entropy :  2.2506854823141387
reward/intrinsic_running :  0.0010604842726349491
reward/extrinsic_running :  0.07633333333333334
reward/intrinsic_std_running :  0.021656755190886872
reward/extrinsic_std_running :  1.564468635387463
reward/intrinsic_batch_std :  4.576849550840755e-05
reward/intrinsic_batch_max :  0.0008604019531048834
reward/intrinsic_batch_min :  1.4684384950669482e-05
reward/total_batch :  0.03820226131021322
time/iteration_time :  112.15677785873413
time/fps :  2407.344479350821
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0004, Value Loss: 5.2160, Entropy: 2.2507
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=221.9
Extrinsic raw: Œº=0.07633333333333334

=== Iteration 617/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 19.86s
update_step :  617
reward/intrinsic_batch_mean :  5.540105843813055e-05
reward/extrinsic_batch_mean :  0.08018518518518518
loss/policy :  0.0008955157069122475
loss/rnd :  1.1754171689035227e-06
loss/value :  5.446132609338472
loss/value_i :  2.105411157792718e-06
loss/value_e :  5.4461305358193135
loss/entropy :  2.258288275111805
reward/intrinsic_running :  0.0010589435702979483
reward/extrinsic_running :  0.08018518518518518
reward/intrinsic_std_running :  0.021639231884006547
reward/extrinsic_std_running :  1.5765398007929339
reward/intrinsic_batch_std :  4.24952817646145e-05
reward/intrinsic_batch_max :  0.0006556553998962045
reward/intrinsic_batch_min :  5.3968042266205885e-06
reward/total_batch :  0.04012029312181165
time/iteration_time :  112.53355264663696
time/fps :  2399.28442362269
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0009, Value Loss: 5.4461, Entropy: 2.2583
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=172.8
Extrinsic raw: Œº=0.08018518518518518

=== Iteration 618/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 19.84s
update_step :  618
reward/intrinsic_batch_mean :  5.401859743000117e-05
reward/extrinsic_batch_mean :  0.08063703703703703
loss/policy :  0.0008747349180118887
loss/rnd :  1.1677543918239914e-06
loss/value :  4.670052365823225
loss/value_i :  1.989976388386188e-06
loss/value_e :  4.670050440412579
loss/entropy :  2.2596667246385054
reward/intrinsic_running :  0.0010574048785755108
reward/extrinsic_running :  0.08063703703703703
reward/intrinsic_std_running :  0.02162175116920874
reward/extrinsic_std_running :  1.596498913049739
reward/intrinsic_batch_std :  3.9333974589274305e-05
reward/intrinsic_batch_max :  0.0006034718826413155
reward/intrinsic_batch_min :  4.419095148477936e-06
reward/total_batch :  0.040345527817233516
time/iteration_time :  112.5022919178009
time/fps :  2399.9511067496633
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0009, Value Loss: 4.6701, Entropy: 2.2597
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=168.6
Extrinsic raw: Œº=0.08063703703703703

=== Iteration 619/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.50s
EPOCH 1 took 18.77s
update_step :  619
reward/intrinsic_batch_mean :  5.246251746730532e-05
reward/extrinsic_batch_mean :  0.08372592592592593
loss/policy :  0.0017157943908717823
loss/rnd :  1.1313141189103506e-06
loss/value :  5.310017152266069
loss/value_i :  2.0602041862124074e-06
loss/value_e :  5.310015107646133
loss/entropy :  2.2791551170927105
reward/intrinsic_running :  0.001055862975671447
reward/extrinsic_running :  0.08372592592592593
reward/intrinsic_std_running :  0.02160431310441989
reward/extrinsic_std_running :  1.6335876125406816
reward/intrinsic_batch_std :  3.9347058574748474e-05
reward/intrinsic_batch_max :  0.0004633655771613121
reward/intrinsic_batch_min :  4.402677859616233e-06
reward/total_batch :  0.04188919422169662
time/iteration_time :  111.18722653388977
time/fps :  2428.3364952691236
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0017, Value Loss: 5.3100, Entropy: 2.2792
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.021, sum=163.9
Extrinsic raw: Œº=0.08372592592592593

=== Iteration 620/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.50s
EPOCH 1 took 18.41s
update_step :  620
reward/intrinsic_batch_mean :  5.458167970280354e-05
reward/extrinsic_batch_mean :  0.07462222222222223
loss/policy :  0.0007447548656879613
loss/rnd :  1.1815079705174316e-06
loss/value :  3.3227354396473276
loss/value_i :  2.0506319732372833e-06
loss/value_e :  3.3227333950273916
loss/entropy :  2.2854096058643227
reward/intrinsic_running :  0.001054332980289527
reward/extrinsic_running :  0.07462222222222223
reward/intrinsic_std_running :  0.021586916886474905
reward/extrinsic_std_running :  1.5397240150329332
reward/intrinsic_batch_std :  4.617615386263105e-05
reward/intrinsic_batch_max :  0.0008681980543769896
reward/intrinsic_batch_min :  4.692886705015553e-06
reward/total_batch :  0.03733840195096252
time/iteration_time :  112.44743752479553
time/fps :  2401.1218569606167
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0007, Value Loss: 3.3227, Entropy: 2.2854
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=170.7
Extrinsic raw: Œº=0.07462222222222223

=== Iteration 621/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 19.08s
update_step :  621
reward/intrinsic_batch_mean :  5.5378488528158753e-05
reward/extrinsic_batch_mean :  0.0748888888888889
loss/policy :  0.0006435063604096121
loss/rnd :  1.281555824155503e-06
loss/value :  4.878232370723378
loss/value_i :  2.0152421804844134e-06
loss/value_e :  4.87823039112669
loss/entropy :  2.268225402543039
reward/intrinsic_running :  0.0010528132188608633
reward/extrinsic_running :  0.0748888888888889
reward/intrinsic_std_running :  0.02156956239161453
reward/extrinsic_std_running :  1.5222981489580112
reward/intrinsic_batch_std :  4.315748287512388e-05
reward/intrinsic_batch_max :  0.000545114919077605
reward/intrinsic_batch_min :  4.847049694944872e-06
reward/total_batch :  0.037472133688708525
time/iteration_time :  112.29801774024963
time/fps :  2404.3167050777524
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0006, Value Loss: 4.8782, Entropy: 2.2682
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.025, sum=173.3
Extrinsic raw: Œº=0.0748888888888889

=== Iteration 622/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.81s
EPOCH 1 took 19.16s
update_step :  622
reward/intrinsic_batch_mean :  5.92783477895123e-05
reward/extrinsic_batch_mean :  0.07505925925925926
loss/policy :  0.0009363219873965577
loss/rnd :  1.267765832945963e-06
loss/value :  3.3971371361703584
loss/value_i :  2.041344268463669e-06
loss/value_e :  3.397135089744221
loss/entropy :  2.2766285628983467
reward/intrinsic_running :  0.0010513100825193659
reward/extrinsic_running :  0.07505925925925926
reward/intrinsic_std_running :  0.021552249163973622
reward/extrinsic_std_running :  1.5697202499665368
reward/intrinsic_batch_std :  4.2399251652684854e-05
reward/intrinsic_batch_max :  0.0007596178911626339
reward/intrinsic_batch_min :  7.305070539587177e-06
reward/total_batch :  0.037559268803524386
time/iteration_time :  111.39734029769897
time/fps :  2423.756251975588
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0009, Value Loss: 3.3971, Entropy: 2.2766
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=185.7
Extrinsic raw: Œº=0.07505925925925926

=== Iteration 623/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.65s
EPOCH 1 took 19.07s
update_step :  623
reward/intrinsic_batch_mean :  5.754931253702832e-05
reward/extrinsic_batch_mean :  0.07772592592592592
loss/policy :  0.0006077929336408323
loss/rnd :  1.213566168768342e-06
loss/value :  3.347558530894193
loss/value_i :  2.0187040067040387e-06
loss/value_e :  3.3475565187858813
loss/entropy :  2.2582676446799077
reward/intrinsic_running :  0.001049807486075871
reward/extrinsic_running :  0.07772592592592592
reward/intrinsic_std_running :  0.021534977751885155
reward/extrinsic_std_running :  1.5780623887100218
reward/intrinsic_batch_std :  4.394733390038169e-05
reward/intrinsic_batch_max :  0.0007063302909955382
reward/intrinsic_batch_min :  5.602122200798476e-06
reward/total_batch :  0.038891737619231474
time/iteration_time :  112.61360287666321
time/fps :  2397.5789167824573
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0006, Value Loss: 3.3476, Entropy: 2.2583
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=180.4
Extrinsic raw: Œº=0.07772592592592592

=== Iteration 624/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.84s
EPOCH 1 took 18.96s
update_step :  624
reward/intrinsic_batch_mean :  5.7824806612114585e-05
reward/extrinsic_batch_mean :  0.07725185185185185
loss/policy :  0.0012118153240545794
loss/rnd :  3.429430814156314e-06
loss/value :  4.561405384179317
loss/value_i :  1.2430082196343308e-05
loss/value_e :  4.561392968351191
loss/entropy :  2.248903245636911
reward/intrinsic_running :  0.0010483105569749748
reward/extrinsic_running :  0.07725185185185185
reward/intrinsic_std_running :  0.021517747757141523
reward/extrinsic_std_running :  1.5482363692566983
reward/intrinsic_batch_std :  4.184961264292512e-05
reward/intrinsic_batch_max :  0.0005643752519972622
reward/intrinsic_batch_min :  6.1094560805941e-06
reward/total_batch :  0.03865483832923198
time/iteration_time :  112.02478814125061
time/fps :  2410.1808580040383
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0012, Value Loss: 4.5614, Entropy: 2.2489
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.026, sum=181.4
Extrinsic raw: Œº=0.07725185185185185

=== Iteration 625/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.81s
EPOCH 1 took 19.78s
update_step :  625
reward/intrinsic_batch_mean :  9.134823056948436e-05
reward/extrinsic_batch_mean :  0.07564444444444444
loss/policy :  0.0006609087982779425
loss/rnd :  1.5646310702543291e-06
loss/value :  4.113337361451351
loss/value_i :  2.5970201153485863e-06
loss/value_e :  4.113334785808217
loss/entropy :  2.2668643322857944
reward/intrinsic_running :  0.0010469238741098409
reward/extrinsic_running :  0.07564444444444444
reward/intrinsic_std_running :  0.02150055468885452
reward/extrinsic_std_running :  1.5526119424861504
reward/intrinsic_batch_std :  4.6185023972070876e-05
reward/intrinsic_batch_max :  0.000882939319126308
reward/intrinsic_batch_min :  2.1016201571910642e-05
reward/total_batch :  0.037867896337506965
time/iteration_time :  112.43057775497437
time/fps :  2401.4819223683494
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0007, Value Loss: 4.1133, Entropy: 2.2669
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.041, sum=286.8
Extrinsic raw: Œº=0.07564444444444444

=== Iteration 626/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.77s
EPOCH 1 took 19.93s
update_step :  626
reward/intrinsic_batch_mean :  7.488052093979571e-05
reward/extrinsic_batch_mean :  0.0771037037037037
loss/policy :  0.00040473826194294924
loss/rnd :  1.3543776214481278e-06
loss/value :  4.279713417544509
loss/value_i :  7.644728946092293e-06
loss/value_e :  4.279705759250756
loss/entropy :  2.259127060572306
reward/intrinsic_running :  0.0010454889863942803
reward/extrinsic_running :  0.0771037037037037
reward/intrinsic_std_running :  0.02148340495543439
reward/extrinsic_std_running :  1.566791785897747
reward/intrinsic_batch_std :  5.1500486851810316e-05
reward/intrinsic_batch_max :  0.0011694063432514668
reward/intrinsic_batch_min :  1.34075617097551e-05
reward/total_batch :  0.038589292112321746
time/iteration_time :  111.80395126342773
time/fps :  2414.941484168457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0004, Value Loss: 4.2797, Entropy: 2.2591
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.054, sum=235.3
Extrinsic raw: Œº=0.0771037037037037

=== Iteration 627/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.44s
EPOCH 1 took 18.44s
update_step :  627
reward/intrinsic_batch_mean :  5.667978009522038e-05
reward/extrinsic_batch_mean :  0.0786
loss/policy :  0.0008515761318531903
loss/rnd :  1.325318655951626e-06
loss/value :  3.809513619451812
loss/value_i :  2.3267667722503767e-06
loss/value_e :  3.8095112966768667
loss/entropy :  2.2743554584907764
reward/intrinsic_running :  0.001044001550286233
reward/extrinsic_running :  0.0786
reward/intrinsic_std_running :  0.021466298554672452
reward/extrinsic_std_running :  1.5901327114426647
reward/intrinsic_batch_std :  4.316411853574972e-05
reward/intrinsic_batch_max :  0.0008623804897069931
reward/intrinsic_batch_min :  4.34561661677435e-06
reward/total_batch :  0.03932833989004761
time/iteration_time :  110.13744854927063
time/fps :  2451.482248376345
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.1s | FPS: 2451
Policy Loss: 0.0009, Value Loss: 3.8095, Entropy: 2.2744
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=178.2
Extrinsic raw: Œº=0.0786

=== Iteration 628/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.27s
EPOCH 1 took 19.32s
update_step :  628
reward/intrinsic_batch_mean :  5.823546156594535e-05
reward/extrinsic_batch_mean :  0.07666666666666666
loss/policy :  0.0005360696816227794
loss/rnd :  1.2141269652684885e-06
loss/value :  3.892778010079355
loss/value_i :  2.9573085901740175e-06
loss/value_e :  3.89277504790913
loss/entropy :  2.2622034296844946
reward/intrinsic_running :  0.0010425237018177101
reward/extrinsic_running :  0.07666666666666666
reward/intrinsic_std_running :  0.021449232747242145
reward/extrinsic_std_running :  1.5653930993701088
reward/intrinsic_batch_std :  4.4303449173985176e-05
reward/intrinsic_batch_max :  0.0006261630333028734
reward/intrinsic_batch_min :  5.933494776400039e-06
reward/total_batch :  0.0383624510641163
time/iteration_time :  111.8865077495575
time/fps :  2413.1595974409865
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0005, Value Loss: 3.8928, Entropy: 2.2622
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=183.3
Extrinsic raw: Œº=0.07666666666666666

=== Iteration 629/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.65s
EPOCH 1 took 18.98s
update_step :  629
reward/intrinsic_batch_mean :  5.785068018522671e-05
reward/extrinsic_batch_mean :  0.07364444444444444
loss/policy :  0.0011349362030159682
loss/rnd :  1.2351409109765936e-06
loss/value :  6.152916323054921
loss/value_i :  2.136172187502697e-06
loss/value_e :  6.152914235086152
loss/entropy :  2.251100439013857
reward/intrinsic_running :  0.0010410481781633302
reward/extrinsic_running :  0.07364444444444444
reward/intrinsic_std_running :  0.021432207682429007
reward/extrinsic_std_running :  1.5272265517096386
reward/intrinsic_batch_std :  4.620975442403523e-05
reward/intrinsic_batch_max :  0.0008486280567012727
reward/intrinsic_batch_min :  4.678948243963532e-06
reward/total_batch :  0.036851147562314834
time/iteration_time :  112.17841482162476
time/fps :  2406.8801509570967
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0011, Value Loss: 6.1529, Entropy: 2.2511
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=182.2
Extrinsic raw: Œº=0.07364444444444444

=== Iteration 630/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.19s
EPOCH 1 took 19.90s
update_step :  630
reward/intrinsic_batch_mean :  5.798494293292741e-05
reward/extrinsic_batch_mean :  0.07559259259259259
loss/policy :  0.0013287511385373584
loss/rnd :  1.240814065044326e-06
loss/value :  5.26569177165176
loss/value_i :  2.047567194853345e-06
loss/value_e :  5.265689799279878
loss/entropy :  2.2613364313588
reward/intrinsic_running :  0.0010395766585372462
reward/extrinsic_running :  0.07559259259259259
reward/intrinsic_std_running :  0.02141522312305232
reward/extrinsic_std_running :  1.5621354747353415
reward/intrinsic_batch_std :  4.54329699057965e-05
reward/intrinsic_batch_max :  0.0007426135125569999
reward/intrinsic_batch_min :  4.510241524258163e-06
reward/total_batch :  0.037825288767762755
time/iteration_time :  112.66684222221375
time/fps :  2396.4459700350594
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0013, Value Loss: 5.2657, Entropy: 2.2613
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=182.8
Extrinsic raw: Œº=0.07559259259259259

=== Iteration 631/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.66s
EPOCH 1 took 17.83s
update_step :  631
reward/intrinsic_batch_mean :  5.478630331725543e-05
reward/extrinsic_batch_mean :  0.07694074074074074
loss/policy :  0.00044633942183502245
loss/rnd :  1.1731164676982162e-06
loss/value :  4.377473506060514
loss/value_i :  2.7455021946672895e-06
loss/value_e :  4.377470746184841
loss/entropy :  2.2676755515011875
reward/intrinsic_running :  0.001038101266386297
reward/extrinsic_running :  0.07694074074074074
reward/intrinsic_std_running :  0.021398279235823808
reward/extrinsic_std_running :  1.575759232703811
reward/intrinsic_batch_std :  4.112290759049144e-05
reward/intrinsic_batch_max :  0.000630409165751189
reward/intrinsic_batch_min :  3.984695467806887e-06
reward/total_batch :  0.038497763522029
time/iteration_time :  111.690269947052
time/fps :  2417.399475603349
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0004, Value Loss: 4.3775, Entropy: 2.2677
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=172.8
Extrinsic raw: Œº=0.07694074074074074

=== Iteration 632/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.16s
EPOCH 1 took 19.49s
update_step :  632
reward/intrinsic_batch_mean :  5.445821764034109e-05
reward/extrinsic_batch_mean :  0.07607407407407407
loss/policy :  0.0012106393754065996
loss/rnd :  1.161525843103432e-06
loss/value :  4.012847351305412
loss/value_i :  2.0239852202311424e-06
loss/value_e :  4.012845346421907
loss/entropy :  2.271719152277166
reward/intrinsic_running :  0.0010366294692115469
reward/extrinsic_running :  0.07607407407407407
reward/intrinsic_std_running :  0.021381375542764487
reward/extrinsic_std_running :  1.5729748161654749
reward/intrinsic_batch_std :  3.9987016556797764e-05
reward/intrinsic_batch_max :  0.0006738027441315353
reward/intrinsic_batch_min :  4.31088164987159e-06
reward/total_batch :  0.03806426614585721
time/iteration_time :  111.7612144947052
time/fps :  2415.864942240687
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0012, Value Loss: 4.0128, Entropy: 2.2717
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=171.9
Extrinsic raw: Œº=0.07607407407407407

=== Iteration 633/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.02s
EPOCH 1 took 19.69s
update_step :  633
reward/intrinsic_batch_mean :  5.228899887670532e-05
reward/extrinsic_batch_mean :  0.07765185185185185
loss/policy :  0.0006734632602963371
loss/rnd :  1.116234738095624e-06
loss/value :  5.196090557358482
loss/value_i :  2.018696398298551e-06
loss/value_e :  5.196088509126143
loss/entropy :  2.2734272010398633
reward/intrinsic_running :  0.0010351553463334247
reward/extrinsic_running :  0.07765185185185185
reward/intrinsic_std_running :  0.021364512148189546
reward/extrinsic_std_running :  1.5780777703152777
reward/intrinsic_batch_std :  3.948472453647492e-05
reward/intrinsic_batch_max :  0.0005964528536424041
reward/intrinsic_batch_min :  4.744528268929571e-06
reward/total_batch :  0.038852070425364274
time/iteration_time :  112.65477585792542
time/fps :  2396.7026514748964
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: 0.0007, Value Loss: 5.1961, Entropy: 2.2734
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=165.2
Extrinsic raw: Œº=0.07765185185185185

=== Iteration 634/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 19.76s
update_step :  634
reward/intrinsic_batch_mean :  5.3786727420454014e-05
reward/extrinsic_batch_mean :  0.07841481481481481
loss/policy :  0.0002555433470247821
loss/rnd :  1.14546943416027e-06
loss/value :  4.392115260615493
loss/value_i :  1.9862775423351913e-06
loss/value_e :  4.392113270181598
loss/entropy :  2.280587470892704
reward/intrinsic_running :  0.001033688704856908
reward/extrinsic_running :  0.07841481481481481
reward/intrinsic_std_running :  0.021347688463161305
reward/extrinsic_std_running :  1.5897283736546768
reward/intrinsic_batch_std :  4.0189378910293784e-05
reward/intrinsic_batch_max :  0.0005690035759471357
reward/intrinsic_batch_min :  4.7036955947987735e-06
reward/total_batch :  0.039234300771117635
time/iteration_time :  110.69032502174377
time/fps :  2439.237575162615
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2439
Policy Loss: 0.0003, Value Loss: 4.3921, Entropy: 2.2806
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=170.1
Extrinsic raw: Œº=0.07841481481481481

=== Iteration 635/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.95s
EPOCH 1 took 18.45s
update_step :  635
reward/intrinsic_batch_mean :  5.2202552920257234e-05
reward/extrinsic_batch_mean :  0.08323703703703704
loss/policy :  0.0007324264081420772
loss/rnd :  1.112520938780411e-06
loss/value :  5.570367693901062
loss/value_i :  1.8522557311509005e-06
loss/value_e :  5.570365829901262
loss/entropy :  2.2824664657766167
reward/intrinsic_running :  0.0010322200057929012
reward/extrinsic_running :  0.08323703703703704
reward/intrinsic_std_running :  0.021330904759887165
reward/extrinsic_std_running :  1.641309697038076
reward/intrinsic_batch_std :  4.337191430433204e-05
reward/intrinsic_batch_max :  0.001065465621650219
reward/intrinsic_batch_min :  4.182078100711806e-06
reward/total_batch :  0.041644619794978646
time/iteration_time :  111.22291159629822
time/fps :  2427.557381162698
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2428
Policy Loss: 0.0007, Value Loss: 5.5704, Entropy: 2.2825
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.050, sum=165.2
Extrinsic raw: Œº=0.08323703703703704

=== Iteration 636/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 18.41s
update_step :  636
reward/intrinsic_batch_mean :  5.236443933988118e-05
reward/extrinsic_batch_mean :  0.0794
loss/policy :  0.0013698462650857189
loss/rnd :  1.1140125927726552e-06
loss/value :  5.529477162794634
loss/value_i :  1.8830646057942817e-06
loss/value_e :  5.529475233771584
loss/entropy :  2.2919776692534937
reward/intrinsic_running :  0.0010307553868790051
reward/extrinsic_running :  0.0794
reward/intrinsic_std_running :  0.0213141606105398
reward/extrinsic_std_running :  1.5836184805223292
reward/intrinsic_batch_std :  4.326311593017915e-05
reward/intrinsic_batch_max :  0.0006510484381578863
reward/intrinsic_batch_min :  4.229189016768942e-06
reward/total_batch :  0.03972618221966994
time/iteration_time :  110.0187349319458
time/fps :  2454.1274735345182
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.0s | FPS: 2454
Policy Loss: 0.0014, Value Loss: 5.5295, Entropy: 2.2920
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=165.8
Extrinsic raw: Œº=0.0794

=== Iteration 637/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.15s
EPOCH 1 took 19.45s
update_step :  637
reward/intrinsic_batch_mean :  5.144563724980226e-05
reward/extrinsic_batch_mean :  0.0792888888888889
loss/policy :  0.0013559807786915565
loss/rnd :  1.096156219745987e-06
loss/value :  4.813349749102737
loss/value_i :  1.9243372876052023e-06
loss/value_e :  4.813347802017674
loss/entropy :  2.289234659888528
reward/intrinsic_running :  0.0010292941424456593
reward/extrinsic_running :  0.0792888888888889
reward/intrinsic_std_running :  0.021297455874807907
reward/extrinsic_std_running :  1.5924806917448782
reward/intrinsic_batch_std :  4.1094909269733186e-05
reward/intrinsic_batch_max :  0.0006410148344002664
reward/intrinsic_batch_min :  3.880683834722731e-06
reward/total_batch :  0.03967016726306935
time/iteration_time :  114.01254630088806
time/fps :  2368.160424094457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.0s | FPS: 2368
Policy Loss: 0.0014, Value Loss: 4.8133, Entropy: 2.2892
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=163.1
Extrinsic raw: Œº=0.0792888888888889

=== Iteration 638/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 18.54s
update_step :  638
reward/intrinsic_batch_mean :  5.337149321181237e-05
reward/extrinsic_batch_mean :  0.08664444444444444
loss/policy :  0.0009141057830261575
loss/rnd :  1.1341703422355447e-06
loss/value :  5.200567158785733
loss/value_i :  2.64323997808705e-06
loss/value_e :  5.200564547018572
loss/entropy :  2.2705196647933037
reward/intrinsic_running :  0.001027841025463252
reward/extrinsic_running :  0.08664444444444444
reward/intrinsic_std_running :  0.021280790199948413
reward/extrinsic_std_running :  1.6604283693904247
reward/intrinsic_batch_std :  4.2487500220187444e-05
reward/intrinsic_batch_max :  0.0006468146457336843
reward/intrinsic_batch_min :  4.001697107014479e-06
reward/total_batch :  0.04334890796882813
time/iteration_time :  110.4561414718628
time/fps :  2444.4091238582587
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.5s | FPS: 2444
Policy Loss: 0.0009, Value Loss: 5.2006, Entropy: 2.2705
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=169.3
Extrinsic raw: Œº=0.08664444444444444

=== Iteration 639/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 19.50s
update_step :  639
reward/intrinsic_batch_mean :  5.155442934217852e-05
reward/extrinsic_batch_mean :  0.08271111111111111
loss/policy :  0.0008367356816906425
loss/rnd :  1.3438418849628677e-06
loss/value :  3.889720461585305
loss/value_i :  1.7965986826724971e-06
loss/value_e :  3.8897186445467398
loss/entropy :  2.29841368487387
reward/intrinsic_running :  0.0010263882617123257
reward/extrinsic_running :  0.08271111111111111
reward/intrinsic_std_running :  0.021264163783476744
reward/extrinsic_std_running :  1.6304588032623832
reward/intrinsic_batch_std :  4.462650147621325e-05
reward/intrinsic_batch_max :  0.0009456360712647438
reward/intrinsic_batch_min :  4.240655016474193e-06
reward/total_batch :  0.041381332770226646
time/iteration_time :  112.76315999031067
time/fps :  2394.3990220139285
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0008, Value Loss: 3.8897, Entropy: 2.2984
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.044, sum=163.7
Extrinsic raw: Œº=0.08271111111111111

=== Iteration 640/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.11s
EPOCH 1 took 18.91s
update_step :  640
reward/intrinsic_batch_mean :  6.186001030867004e-05
reward/extrinsic_batch_mean :  0.0801925925925926
loss/policy :  0.0009182583360763437
loss/rnd :  1.651037152758804e-06
loss/value :  4.543000138167179
loss/value_i :  1.864461382589952e-06
loss/value_e :  4.542998266942574
loss/entropy :  2.2871556390415537
reward/intrinsic_running :  0.0010249699216562898
reward/extrinsic_running :  0.0801925925925926
reward/intrinsic_std_running :  0.021247574970753545
reward/extrinsic_std_running :  1.604481767015715
reward/intrinsic_batch_std :  4.172763136588005e-05
reward/intrinsic_batch_max :  0.0007501777727156878
reward/intrinsic_batch_min :  1.053757659974508e-05
reward/total_batch :  0.04012722630145063
time/iteration_time :  112.03964972496033
time/fps :  2409.861157749131
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0009, Value Loss: 4.5430, Entropy: 2.2872
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=196.5
Extrinsic raw: Œº=0.0801925925925926

=== Iteration 641/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.23s
EPOCH 1 took 20.12s
update_step :  641
reward/intrinsic_batch_mean :  5.980819363565523e-05
reward/extrinsic_batch_mean :  0.08225925925925925
loss/policy :  0.000925788781993712
loss/rnd :  1.171090600978046e-06
loss/value :  4.294701912186363
loss/value_i :  5.132069969532137e-06
loss/value_e :  4.294696760900093
loss/entropy :  2.275704672842315
reward/intrinsic_running :  0.0010235523140799717
reward/extrinsic_running :  0.08225925925925925
reward/intrinsic_std_running :  0.021231025124176916
reward/extrinsic_std_running :  1.6200000249792537
reward/intrinsic_batch_std :  4.847415241862865e-05
reward/intrinsic_batch_max :  0.0007341419695876539
reward/intrinsic_batch_min :  7.878412361606024e-06
reward/total_batch :  0.041159533726447456
time/iteration_time :  112.3303918838501
time/fps :  2403.6237697735505
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.3s | FPS: 2404
Policy Loss: 0.0009, Value Loss: 4.2947, Entropy: 2.2757
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=190.1
Extrinsic raw: Œº=0.08225925925925925

=== Iteration 642/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.11s
EPOCH 1 took 18.67s
update_step :  642
reward/intrinsic_batch_mean :  5.2774351377849126e-05
reward/extrinsic_batch_mean :  0.08271851851851852
loss/policy :  0.0010518464559660943
loss/rnd :  1.1191182083662583e-06
loss/value :  3.863493283589681
loss/value_i :  9.477847348107664e-06
loss/value_e :  3.8634838190945713
loss/entropy :  2.2890060020215586
reward/intrinsic_running :  0.0010221166268160893
reward/extrinsic_running :  0.08271851851851852
reward/intrinsic_std_running :  0.021214514815658694
reward/extrinsic_std_running :  1.6304572916907187
reward/intrinsic_batch_std :  4.180200955780746e-05
reward/intrinsic_batch_max :  0.0007774958503432572
reward/intrinsic_batch_min :  4.079591690242523e-06
reward/total_batch :  0.04138564643494819
time/iteration_time :  109.9988157749176
time/fps :  2454.5718796871497
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.0s | FPS: 2455
Policy Loss: 0.0011, Value Loss: 3.8635, Entropy: 2.2890
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=167.9
Extrinsic raw: Œº=0.08271851851851852

=== Iteration 643/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.89s
EPOCH 1 took 19.76s
update_step :  643
reward/intrinsic_batch_mean :  5.3712845438800555e-05
reward/extrinsic_batch_mean :  0.08052592592592593
loss/policy :  0.0006288713960781355
loss/rnd :  1.141773533631887e-06
loss/value :  3.27000046860088
loss/value_i :  2.1987796875085528e-06
loss/value_e :  3.2699982903220435
loss/entropy :  2.291125369794441
reward/intrinsic_running :  0.0010206869875211927
reward/extrinsic_running :  0.08052592592592593
reward/intrinsic_std_running :  0.02119804290851493
reward/extrinsic_std_running :  1.6053823881838278
reward/intrinsic_batch_std :  4.382215338923759e-05
reward/intrinsic_batch_max :  0.0006223046220839024
reward/intrinsic_batch_min :  4.1919483919627964e-06
reward/total_batch :  0.040289819385682366
time/iteration_time :  112.0745370388031
time/fps :  2409.110999999215
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0006, Value Loss: 3.2700, Entropy: 2.2911
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=171.0
Extrinsic raw: Œº=0.08052592592592593

=== Iteration 644/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 18.20s
update_step :  644
reward/intrinsic_batch_mean :  5.193063266383601e-05
reward/extrinsic_batch_mean :  0.08242962962962963
loss/policy :  0.0007201312198021421
loss/rnd :  1.0942475383175902e-06
loss/value :  3.7970860329541294
loss/value_i :  1.9411263927147293e-06
loss/value_e :  3.797084087675268
loss/entropy :  2.292270364183368
reward/intrinsic_running :  0.001019255971122402
reward/extrinsic_running :  0.08242962962962963
reward/intrinsic_std_running :  0.021181609549464207
reward/extrinsic_std_running :  1.6204451219329086
reward/intrinsic_batch_std :  4.265126407402259e-05
reward/intrinsic_batch_max :  0.0006453173118643463
reward/intrinsic_batch_min :  3.9973660932446364e-06
reward/total_batch :  0.04124078013114673
time/iteration_time :  112.38367676734924
time/fps :  2402.484130848822
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: 0.0007, Value Loss: 3.7971, Entropy: 2.2923
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=165.5
Extrinsic raw: Œº=0.08242962962962963

=== Iteration 645/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.56s
EPOCH 1 took 19.17s
update_step :  645
reward/intrinsic_batch_mean :  5.315865555212103e-05
reward/extrinsic_batch_mean :  0.08282962962962963
loss/policy :  0.0004898094304018852
loss/rnd :  1.1245845385157296e-06
loss/value :  4.567075339230624
loss/value_i :  2.0549029793046154e-06
loss/value_e :  4.567073298223091
loss/entropy :  2.2857418891155357
reward/intrinsic_running :  0.001017833436371318
reward/extrinsic_running :  0.08282962962962963
reward/intrinsic_std_running :  0.02116521417124461
reward/extrinsic_std_running :  1.6309115812295747
reward/intrinsic_batch_std :  4.1086809683831666e-05
reward/intrinsic_batch_max :  0.0006512398249469697
reward/intrinsic_batch_min :  3.934640517400112e-06
reward/total_batch :  0.041441394142590876
time/iteration_time :  113.3602020740509
time/fps :  2381.7882736626248
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2382
Policy Loss: 0.0005, Value Loss: 4.5671, Entropy: 2.2857
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=169.5
Extrinsic raw: Œº=0.08282962962962963

=== Iteration 646/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.08s
EPOCH 1 took 19.24s
update_step :  646
reward/intrinsic_batch_mean :  5.149625098384368e-05
reward/extrinsic_batch_mean :  0.08549629629629629
loss/policy :  0.0016178549637764015
loss/rnd :  1.0882233830285037e-06
loss/value :  4.634078878344911
loss/value_i :  2.120165926512665e-06
loss/value_e :  4.6340767470273105
loss/entropy :  2.2897106300700796
reward/intrinsic_running :  0.0010164086541095887
reward/extrinsic_running :  0.08549629629629629
reward/intrinsic_std_running :  0.021148857091907114
reward/extrinsic_std_running :  1.6569096663906797
reward/intrinsic_batch_std :  4.1509550548699496e-05
reward/intrinsic_batch_max :  0.0006929899100214243
reward/intrinsic_batch_min :  4.0987642933032475e-06
reward/total_batch :  0.04277389627364007
time/iteration_time :  113.17068243026733
time/fps :  2385.7769008892087
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2386
Policy Loss: 0.0016, Value Loss: 4.6341, Entropy: 2.2897
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=164.4
Extrinsic raw: Œº=0.08549629629629629

=== Iteration 647/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.57s
EPOCH 1 took 19.32s
update_step :  647
reward/intrinsic_batch_mean :  5.256882773796355e-05
reward/extrinsic_batch_mean :  0.07751851851851851
loss/policy :  0.00023740833840389368
loss/rnd :  1.1125610702341267e-06
loss/value :  5.166154847000584
loss/value_i :  7.897231870574064e-06
loss/value_e :  5.166146953900655
loss/entropy :  2.2828467578598945
reward/intrinsic_running :  0.0010149936987807085
reward/extrinsic_running :  0.07751851851851851
reward/intrinsic_std_running :  0.02113253767167154
reward/extrinsic_std_running :  1.5587180599447115
reward/intrinsic_batch_std :  4.4457063955500345e-05
reward/intrinsic_batch_max :  0.0009887494379654527
reward/intrinsic_batch_min :  3.999803084298037e-06
reward/total_batch :  0.03878554367312824
time/iteration_time :  112.5102469921112
time/fps :  2399.781417411086
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0002, Value Loss: 5.1662, Entropy: 2.2828
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.047, sum=167.9
Extrinsic raw: Œº=0.07751851851851851

=== Iteration 648/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 19.51s
update_step :  648
reward/intrinsic_batch_mean :  5.160735519087515e-05
reward/extrinsic_batch_mean :  0.08312592592592592
loss/policy :  0.0009627343264803516
loss/rnd :  1.103244714654879e-06
loss/value :  5.381131490071614
loss/value_i :  1.0293530353368569e-05
loss/value_e :  5.381121205561088
loss/entropy :  2.2787944078445435
reward/intrinsic_running :  0.0010135789170353186
reward/extrinsic_running :  0.08312592592592592
reward/intrinsic_std_running :  0.021116256124342085
reward/extrinsic_std_running :  1.6135448916829043
reward/intrinsic_batch_std :  4.030106398575262e-05
reward/intrinsic_batch_max :  0.000549595570191741
reward/intrinsic_batch_min :  4.209397502563661e-06
reward/total_batch :  0.0415887666405584
time/iteration_time :  112.74231195449829
time/fps :  2394.841788493475
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0010, Value Loss: 5.3811, Entropy: 2.2788
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.026, sum=165.0
Extrinsic raw: Œº=0.08312592592592592

=== Iteration 649/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.09s
EPOCH 1 took 18.90s
update_step :  649
reward/intrinsic_batch_mean :  5.211578188335369e-05
reward/extrinsic_batch_mean :  0.08328148148148148
loss/policy :  0.0019351816445123404
loss/rnd :  1.0741215798285946e-06
loss/value :  4.704231843803868
loss/value_i :  1.0674325603138806e-05
loss/value_e :  4.704221163735245
loss/entropy :  2.271666649616126
reward/intrinsic_running :  0.0010121702272765773
reward/extrinsic_running :  0.08328148148148148
reward/intrinsic_std_running :  0.02110001207921924
reward/extrinsic_std_running :  1.6231477564555528
reward/intrinsic_batch_std :  4.110782853814475e-05
reward/intrinsic_batch_max :  0.0006630909629166126
reward/intrinsic_batch_min :  4.727982741314918e-06
reward/total_batch :  0.04166679863168242
time/iteration_time :  111.45723962783813
time/fps :  2422.4536773164746
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.5s | FPS: 2422
Policy Loss: 0.0019, Value Loss: 4.7042, Entropy: 2.2717
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=166.7
Extrinsic raw: Œº=0.08328148148148148

=== Iteration 650/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.78s
EPOCH 1 took 18.41s
update_step :  650
reward/intrinsic_batch_mean :  5.145935268013731e-05
reward/extrinsic_batch_mean :  0.08388148148148149
loss/policy :  0.0006159066331086003
loss/rnd :  1.083722643422582e-06
loss/value :  4.4611258687395035
loss/value_i :  1.9901971199942636e-06
loss/value_e :  4.461123878305608
loss/entropy :  2.2721064524217085
reward/intrinsic_running :  0.0010107641154350276
reward/extrinsic_running :  0.08388148148148149
reward/intrinsic_std_running :  0.02108380555402858
reward/extrinsic_std_running :  1.6430732859463082
reward/intrinsic_batch_std :  4.493456279344843e-05
reward/intrinsic_batch_max :  0.0010370343225076795
reward/intrinsic_batch_min :  3.977718733949587e-06
reward/total_batch :  0.04196647041708081
time/iteration_time :  112.53264117240906
time/fps :  2399.3038569701594
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0006, Value Loss: 4.4611, Entropy: 2.2721
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.049, sum=164.7
Extrinsic raw: Œº=0.08388148148148149

=== Iteration 651/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 18.15s
update_step :  651
reward/intrinsic_batch_mean :  5.341049117788754e-05
reward/extrinsic_batch_mean :  0.08401481481481482
loss/policy :  0.0011168263136465666
loss/rnd :  1.1306359476403678e-06
loss/value :  4.853985945383708
loss/value_i :  2.007078940165009e-06
loss/value_e :  4.853983958562215
loss/entropy :  2.2687931096915044
reward/intrinsic_running :  0.001009366619538277
reward/extrinsic_running :  0.08401481481481482
reward/intrinsic_std_running :  0.021067636142387592
reward/extrinsic_std_running :  1.634480558488481
reward/intrinsic_batch_std :  4.705393057682876e-05
reward/intrinsic_batch_max :  0.0010185041464865208
reward/intrinsic_batch_min :  3.7025490655651083e-06
reward/total_batch :  0.04203411265299636
time/iteration_time :  111.33352398872375
time/fps :  2425.145547601157
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.3s | FPS: 2425
Policy Loss: 0.0011, Value Loss: 4.8540, Entropy: 2.2688
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.048, sum=171.1
Extrinsic raw: Œº=0.08401481481481482

=== Iteration 652/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 19.52s
update_step :  652
reward/intrinsic_batch_mean :  5.1995628604217255e-05
reward/extrinsic_batch_mean :  0.08374074074074074
loss/policy :  0.0010402518911922182
loss/rnd :  1.0957771740488005e-06
loss/value :  4.140423344843315
loss/value_i :  1.9015401173391817e-06
loss/value_e :  4.1404214085954605
loss/entropy :  2.2895151123856055
reward/intrinsic_running :  0.0010079689531951395
reward/extrinsic_running :  0.08374074074074074
reward/intrinsic_std_running :  0.021051504047707968
reward/extrinsic_std_running :  1.651622795528859
reward/intrinsic_batch_std :  4.275448126867399e-05
reward/intrinsic_batch_max :  0.0006580788176506758
reward/intrinsic_batch_min :  4.419498964125523e-06
reward/total_batch :  0.04189636818467248
time/iteration_time :  112.49517846107483
time/fps :  2400.1028639056244
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0010, Value Loss: 4.1404, Entropy: 2.2895
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=166.7
Extrinsic raw: Œº=0.08374074074074074

=== Iteration 653/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.02s
EPOCH 1 took 18.56s
update_step :  653
reward/intrinsic_batch_mean :  5.337954390642052e-05
reward/extrinsic_batch_mean :  0.08442222222222222
loss/policy :  0.0011263787336330015
loss/rnd :  1.1190093015433045e-06
loss/value :  5.083127368580211
loss/value_i :  2.9825453008346483e-06
loss/value_e :  5.0831244027975835
loss/entropy :  2.251136873707627
reward/intrinsic_running :  0.0010065828022413
reward/extrinsic_running :  0.08442222222222222
reward/intrinsic_std_running :  0.021035408650692113
reward/extrinsic_std_running :  1.6267425754905354
reward/intrinsic_batch_std :  4.487108121729851e-05
reward/intrinsic_batch_max :  0.000924707914236933
reward/intrinsic_batch_min :  4.817517037736252e-06
reward/total_batch :  0.04223780088306432
time/iteration_time :  111.93269801139832
time/fps :  2412.1637805291302
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2412
Policy Loss: 0.0011, Value Loss: 5.0831, Entropy: 2.2511
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=171.3
Extrinsic raw: Œº=0.08442222222222222

=== Iteration 654/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.34s
EPOCH 1 took 19.17s
update_step :  654
reward/intrinsic_batch_mean :  5.1201700172505634e-05
reward/extrinsic_batch_mean :  0.08711851851851851
loss/policy :  0.0008170653282749382
loss/rnd :  1.085380652263914e-06
loss/value :  4.181110143661499
loss/value_i :  2.5656503253506373e-06
loss/value_e :  4.181107571630767
loss/entropy :  2.2586690187454224
reward/intrinsic_running :  0.0010051937350425788
reward/extrinsic_running :  0.08711851851851851
reward/intrinsic_std_running :  0.021019350408612518
reward/extrinsic_std_running :  1.670584060881666
reward/intrinsic_batch_std :  4.067825060819807e-05
reward/intrinsic_batch_max :  0.0008045691647566855
reward/intrinsic_batch_min :  4.316169452067697e-06
reward/total_batch :  0.04358486010934551
time/iteration_time :  112.36197328567505
time/fps :  2402.948187048457
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: 0.0008, Value Loss: 4.1811, Entropy: 2.2587
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.038, sum=164.4
Extrinsic raw: Œº=0.08711851851851851

=== Iteration 655/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 19.34s
update_step :  655
reward/intrinsic_batch_mean :  5.772483323924933e-05
reward/extrinsic_batch_mean :  0.08122222222222222
loss/policy :  0.0008249386750817807
loss/rnd :  1.1391532208301325e-06
loss/value :  4.930395505645058
loss/value_i :  2.5128429563141474e-06
loss/value_e :  4.9303930239243945
loss/entropy :  2.2772535772034614
reward/intrinsic_running :  0.0010038264010018086
reward/extrinsic_running :  0.08122222222222222
reward/intrinsic_std_running :  0.0210033281592097
reward/extrinsic_std_running :  1.5984179640051353
reward/intrinsic_batch_std :  4.543973881106178e-05
reward/intrinsic_batch_max :  0.0011196625418961048
reward/intrinsic_batch_min :  8.50277046993142e-06
reward/total_batch :  0.04063997352773074
time/iteration_time :  112.86930465698242
time/fps :  2392.147278842096
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0008, Value Loss: 4.9304, Entropy: 2.2773
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.053, sum=185.5
Extrinsic raw: Œº=0.08122222222222222

=== Iteration 656/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 20.58s
update_step :  656
reward/intrinsic_batch_mean :  5.98442661184284e-05
reward/extrinsic_batch_mean :  0.09016296296296296
loss/policy :  0.0012477186572857936
loss/rnd :  1.137374707385871e-06
loss/value :  5.9887181123097735
loss/value_i :  7.584184448784402e-06
loss/value_e :  5.988710526264075
loss/entropy :  2.2508637074268227
reward/intrinsic_running :  0.00100247040888151
reward/extrinsic_running :  0.09016296296296296
reward/intrinsic_std_running :  0.02098734216520377
reward/extrinsic_std_running :  1.6718065996928009
reward/intrinsic_batch_std :  4.040150405897843e-05
reward/intrinsic_batch_max :  0.0010580332018435001
reward/intrinsic_batch_min :  1.1041742254747078e-05
reward/total_batch :  0.04511140361454069
time/iteration_time :  113.2478973865509
time/fps :  2384.1502246916302
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: 0.0012, Value Loss: 5.9887, Entropy: 2.2509
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.050, sum=192.5
Extrinsic raw: Œº=0.09016296296296296

=== Iteration 657/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.64s
EPOCH 1 took 19.14s
update_step :  657
reward/intrinsic_batch_mean :  5.453612092774333e-05
reward/extrinsic_batch_mean :  0.08431111111111111
loss/policy :  0.0015522312932069217
loss/rnd :  1.135035909032233e-06
loss/value :  5.193191846211751
loss/value_i :  2.5680040132349613e-06
loss/value_e :  5.193189299467838
loss/entropy :  2.261057355187156
reward/intrinsic_running :  0.0010011024134092689
reward/extrinsic_running :  0.08431111111111111
reward/intrinsic_std_running :  0.020971393310059136
reward/extrinsic_std_running :  1.6353714515948226
reward/intrinsic_batch_std :  4.124880519126918e-05
reward/intrinsic_batch_max :  0.0006477466085925698
reward/intrinsic_batch_min :  6.2486269598593935e-06
reward/total_batch :  0.04218282361601943
time/iteration_time :  111.71995210647583
time/fps :  2416.7572122003216
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2417
Policy Loss: 0.0016, Value Loss: 5.1932, Entropy: 2.2611
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=175.5
Extrinsic raw: Œº=0.08431111111111111

=== Iteration 658/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 19.30s
update_step :  658
reward/intrinsic_batch_mean :  5.068169144258179e-05
reward/extrinsic_batch_mean :  0.08082962962962963
loss/policy :  0.0012567991066272511
loss/rnd :  1.062867096207452e-06
loss/value :  3.093029699542306
loss/value_i :  2.5472530182923947e-06
loss/value_e :  3.093027140154983
loss/entropy :  2.273842453956604
reward/intrinsic_running :  0.0009997299185954805
reward/extrinsic_running :  0.08082962962962963
reward/intrinsic_std_running :  0.020955481117148237
reward/extrinsic_std_running :  1.615485220266612
reward/intrinsic_batch_std :  3.723796448155077e-05
reward/intrinsic_batch_max :  0.0005271909176371992
reward/intrinsic_batch_min :  5.069662165624322e-06
reward/total_batch :  0.0404401556605361
time/iteration_time :  112.57308459281921
time/fps :  2398.44187424196
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2398
Policy Loss: 0.0013, Value Loss: 3.0930, Entropy: 2.2738
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=163.3
Extrinsic raw: Œº=0.08082962962962963

=== Iteration 659/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.15s
EPOCH 1 took 18.33s
update_step :  659
reward/intrinsic_batch_mean :  5.091612762643544e-05
reward/extrinsic_batch_mean :  0.08122222222222222
loss/policy :  0.0007779126260147402
loss/rnd :  1.0923892942270013e-06
loss/value :  5.113443042292739
loss/value_i :  5.658432807346496e-06
loss/value_e :  5.1134373491460625
loss/entropy :  2.2639896580667207
reward/intrinsic_running :  0.0009983615542302922
reward/extrinsic_running :  0.08122222222222222
reward/intrinsic_std_running :  0.020939605093173764
reward/extrinsic_std_running :  1.607659670851997
reward/intrinsic_batch_std :  3.8867066117949344e-05
reward/intrinsic_batch_max :  0.0005809180438518524
reward/intrinsic_batch_min :  5.124862582306378e-06
reward/total_batch :  0.04063656917492433
time/iteration_time :  111.96726512908936
time/fps :  2411.419084754026
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2411
Policy Loss: 0.0008, Value Loss: 5.1134, Entropy: 2.2640
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=164.1
Extrinsic raw: Œº=0.08122222222222222

=== Iteration 660/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.78s
EPOCH 1 took 18.95s
update_step :  660
reward/intrinsic_batch_mean :  5.344103156687736e-05
reward/extrinsic_batch_mean :  0.08198518518518519
loss/policy :  0.0009649590360685111
loss/rnd :  1.213194748701922e-06
loss/value :  3.6106365702368994
loss/value_i :  1.0223205311955429e-05
loss/value_e :  3.6106263507496226
loss/entropy :  2.2527314641258935
reward/intrinsic_running :  0.0009970034104886249
reward/extrinsic_running :  0.08198518518518519
reward/intrinsic_std_running :  0.020923764838424327
reward/extrinsic_std_running :  1.6190957420741814
reward/intrinsic_batch_std :  3.960260578731432e-05
reward/intrinsic_batch_max :  0.0006964100175537169
reward/intrinsic_batch_min :  5.899348252569325e-06
reward/total_batch :  0.04101931310837603
time/iteration_time :  112.55942606925964
time/fps :  2398.7329131712577
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0010, Value Loss: 3.6106, Entropy: 2.2527
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=172.4
Extrinsic raw: Œº=0.08198518518518519

=== Iteration 661/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.80s
EPOCH 1 took 18.61s
update_step :  661
reward/intrinsic_batch_mean :  0.00016123826866947907
reward/extrinsic_batch_mean :  0.08372592592592593
loss/policy :  0.000698915166801519
loss/rnd :  2.0574757331125895e-06
loss/value :  4.651570027524775
loss/value_i :  5.486401057692781e-06
loss/value_e :  4.651564518610637
loss/entropy :  2.221895615259806
reward/intrinsic_running :  0.0009959594076233184
reward/extrinsic_running :  0.08372592592592593
reward/intrinsic_std_running :  0.020907948860764306
reward/extrinsic_std_running :  1.6161732256332462
reward/intrinsic_batch_std :  4.4131278089662776e-05
reward/intrinsic_batch_max :  0.0010408643865957856
reward/intrinsic_batch_min :  8.925343718146905e-05
reward/total_batch :  0.041943582097297705
time/iteration_time :  112.90621590614319
time/fps :  2391.3652391330334
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: 0.0007, Value Loss: 4.6516, Entropy: 2.2219
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.008, max=0.050, sum=520.5
Extrinsic raw: Œº=0.08372592592592593

=== Iteration 662/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.48s
EPOCH 1 took 19.09s
update_step :  662
reward/intrinsic_batch_mean :  5.5576657567575306e-05
reward/extrinsic_batch_mean :  0.08138518518518519
loss/policy :  0.0014884694352407348
loss/rnd :  1.0711936252763818e-06
loss/value :  4.454950506036932
loss/value_i :  4.019792010529438e-06
loss/value_e :  4.454946492657517
loss/entropy :  2.2509131828943887
reward/intrinsic_running :  0.000994615830799169
reward/extrinsic_running :  0.08138518518518519
reward/intrinsic_std_running :  0.020892179999659536
reward/extrinsic_std_running :  1.6081098197489856
reward/intrinsic_batch_std :  3.948537385075076e-05
reward/intrinsic_batch_max :  0.0006301205139607191
reward/intrinsic_batch_min :  8.325703674927354e-06
reward/total_batch :  0.04072038092137638
time/iteration_time :  113.1878650188446
time/fps :  2385.4147258193075
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0015, Value Loss: 4.4550, Entropy: 2.2509
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=179.6
Extrinsic raw: Œº=0.08138518518518519

=== Iteration 663/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.39s
EPOCH 1 took 19.23s
update_step :  663
reward/intrinsic_batch_mean :  5.0677164344206514e-05
reward/extrinsic_batch_mean :  0.07931111111111111
loss/policy :  0.001045482454532193
loss/rnd :  1.0535404054611386e-06
loss/value :  4.641315615538395
loss/value_i :  3.3668644825659366e-06
loss/value_e :  4.641312270453482
loss/entropy :  2.242624217813665
reward/intrinsic_running :  0.0009932620279383215
reward/extrinsic_running :  0.07931111111111111
reward/intrinsic_std_running :  0.020876447370957306
reward/extrinsic_std_running :  1.58314575715411
reward/intrinsic_batch_std :  3.94052014873985e-05
reward/intrinsic_batch_max :  0.0007821797044016421
reward/intrinsic_batch_min :  4.411253939906601e-06
reward/total_batch :  0.03968089413772766
time/iteration_time :  113.56301975250244
time/fps :  2377.5345230202047
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2378
Policy Loss: 0.0010, Value Loss: 4.6413, Entropy: 2.2426
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.037, sum=163.9
Extrinsic raw: Œº=0.07931111111111111

=== Iteration 664/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.63s
EPOCH 1 took 19.60s
update_step :  664
reward/intrinsic_batch_mean :  5.055987203204495e-05
reward/extrinsic_batch_mean :  0.08154074074074075
loss/policy :  0.0008713512806659282
loss/rnd :  1.0590537571757026e-06
loss/value :  3.706849641872175
loss/value_i :  6.0437061833771155e-06
loss/value_e :  3.706843589291428
loss/entropy :  2.2599196723013213
reward/intrinsic_running :  0.0009919122071267651
reward/extrinsic_running :  0.08154074074074075
reward/intrinsic_std_running :  0.02086075023741332
reward/extrinsic_std_running :  1.6177451145800437
reward/intrinsic_batch_std :  4.0440673390901206e-05
reward/intrinsic_batch_max :  0.0007826766232028604
reward/intrinsic_batch_min :  3.471146783340373e-06
reward/total_batch :  0.0407956503063864
time/iteration_time :  113.33948087692261
time/fps :  2382.2237221396654
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2382
Policy Loss: 0.0009, Value Loss: 3.7068, Entropy: 2.2599
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.038, sum=163.6
Extrinsic raw: Œº=0.08154074074074075

=== Iteration 665/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.06s
EPOCH 1 took 19.27s
update_step :  665
reward/intrinsic_batch_mean :  5.1057632219083274e-05
reward/extrinsic_batch_mean :  0.08080740740740741
loss/policy :  0.0014399576607640042
loss/rnd :  1.0557931135956482e-06
loss/value :  3.774817026022709
loss/value_i :  2.7605711472984473e-06
loss/value_e :  3.774814253503626
loss/entropy :  2.2533056410876187
reward/intrinsic_running :  0.0009905661207312818
reward/extrinsic_running :  0.08080740740740741
reward/intrinsic_std_running :  0.020845088477390347
reward/extrinsic_std_running :  1.597043499935387
reward/intrinsic_batch_std :  4.265253663657438e-05
reward/intrinsic_batch_max :  0.0011569358175620437
reward/intrinsic_batch_min :  4.350642484496348e-06
reward/total_batch :  0.04042923251981325
time/iteration_time :  113.62152099609375
time/fps :  2376.310382337537
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2376
Policy Loss: 0.0014, Value Loss: 3.7748, Entropy: 2.2533
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.056, sum=165.3
Extrinsic raw: Œº=0.08080740740740741

=== Iteration 666/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.87s
EPOCH 1 took 18.59s
update_step :  666
reward/intrinsic_batch_mean :  5.0014689030319494e-05
reward/extrinsic_batch_mean :  0.08213333333333334
loss/policy :  0.0019414284818622311
loss/rnd :  1.035946866068116e-06
loss/value :  4.492138392997511
loss/value_i :  4.051466984230611e-06
loss/value_e :  4.492134343494069
loss/entropy :  2.251240267898097
reward/intrinsic_running :  0.0009892199469423782
reward/extrinsic_running :  0.08213333333333334
reward/intrinsic_std_running :  0.02082946210528633
reward/extrinsic_std_running :  1.6195456738325202
reward/intrinsic_batch_std :  3.949367220687791e-05
reward/intrinsic_batch_max :  0.0006777124362997711
reward/intrinsic_batch_min :  4.673903276852798e-06
reward/total_batch :  0.04109167401118183
time/iteration_time :  111.24759101867676
time/fps :  2427.0188462298584
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.2s | FPS: 2427
Policy Loss: 0.0019, Value Loss: 4.4921, Entropy: 2.2512
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=162.1
Extrinsic raw: Œº=0.08213333333333334

=== Iteration 667/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.62s
EPOCH 1 took 19.88s
update_step :  667
reward/intrinsic_batch_mean :  5.4997402816102464e-05
reward/extrinsic_batch_mean :  0.08566666666666667
loss/policy :  0.0009971522764923673
loss/rnd :  1.1482798468574456e-06
loss/value :  4.540660666696953
loss/value_i :  4.632057968220496e-06
loss/value_e :  4.540656024759466
loss/entropy :  2.2099075678623086
reward/intrinsic_running :  0.0009878944210217548
reward/extrinsic_running :  0.08566666666666667
reward/intrinsic_std_running :  0.020813870149050565
reward/extrinsic_std_running :  1.63936926669759
reward/intrinsic_batch_std :  4.713403453591872e-05
reward/intrinsic_batch_max :  0.0010030718985944986
reward/intrinsic_batch_min :  4.110257577849552e-06
reward/total_batch :  0.042860832034741385
time/iteration_time :  113.39917397499084
time/fps :  2380.9697243433716
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2381
Policy Loss: 0.0010, Value Loss: 4.5407, Entropy: 2.2099
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.048, sum=178.4
Extrinsic raw: Œº=0.08566666666666667

=== Iteration 668/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 18.43s
update_step :  668
reward/intrinsic_batch_mean :  5.2092435868602206e-05
reward/extrinsic_batch_mean :  0.08361481481481481
loss/policy :  0.0008360714683393863
loss/rnd :  1.076984410770599e-06
loss/value :  3.5863284035162493
loss/value_i :  1.8592991423385243e-06
loss/value_e :  3.5863265268730395
loss/entropy :  2.2459655566649004
reward/intrinsic_running :  0.000986563940063572
reward/extrinsic_running :  0.08361481481481481
reward/intrinsic_std_running :  0.02079831351254594
reward/extrinsic_std_running :  1.6331341283746426
reward/intrinsic_batch_std :  4.3371668751371875e-05
reward/intrinsic_batch_max :  0.0008723969804123044
reward/intrinsic_batch_min :  4.992288268113043e-06
reward/total_batch :  0.04183345362534171
time/iteration_time :  110.8184506893158
time/fps :  2436.417386459917
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.8s | FPS: 2436
Policy Loss: 0.0008, Value Loss: 3.5863, Entropy: 2.2460
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.042, sum=169.1
Extrinsic raw: Œº=0.08361481481481481

=== Iteration 669/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.60s
EPOCH 1 took 18.87s
update_step :  669
reward/intrinsic_batch_mean :  5.403695226107596e-05
reward/extrinsic_batch_mean :  0.07901481481481482
loss/policy :  0.0011771938809419446
loss/rnd :  1.1820417991216483e-06
loss/value :  4.367398726217674
loss/value_i :  2.033307137852799e-06
loss/value_e :  4.367396712303162
loss/entropy :  2.229775157841769
reward/intrinsic_running :  0.0009852419328208414
reward/extrinsic_running :  0.07901481481481482
reward/intrinsic_std_running :  0.02078279154434374
reward/extrinsic_std_running :  1.5728333691742202
reward/intrinsic_batch_std :  4.7449674044048e-05
reward/intrinsic_batch_max :  0.0007709846249781549
reward/intrinsic_batch_min :  4.013043508166447e-06
reward/total_batch :  0.03953442588353795
time/iteration_time :  113.60083222389221
time/fps :  2376.74315156306
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2377
Policy Loss: 0.0012, Value Loss: 4.3674, Entropy: 2.2298
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=175.5
Extrinsic raw: Œº=0.07901481481481482

=== Iteration 670/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 18.50s
update_step :  670
reward/intrinsic_batch_mean :  5.402849122027773e-05
reward/extrinsic_batch_mean :  0.08301481481481482
loss/policy :  0.0008964273914567788
loss/rnd :  1.1164830404843749e-06
loss/value :  3.6230935418244563
loss/value_i :  2.0867818331239643e-06
loss/value_e :  3.623091444824681
loss/entropy :  2.2331796125932173
reward/intrinsic_running :  0.0009839232101036383
reward/extrinsic_running :  0.08301481481481482
reward/intrinsic_std_running :  0.02076730427798182
reward/extrinsic_std_running :  1.6313506173773793
reward/intrinsic_batch_std :  4.309217865652875e-05
reward/intrinsic_batch_max :  0.0005912291235290468
reward/intrinsic_batch_min :  5.305932063492946e-06
reward/total_batch :  0.04153442165301755
time/iteration_time :  112.0563280582428
time/fps :  2409.502476822762
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2410
Policy Loss: 0.0009, Value Loss: 3.6231, Entropy: 2.2332
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=175.6
Extrinsic raw: Œº=0.08301481481481482

=== Iteration 671/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.80s
EPOCH 1 took 19.95s
update_step :  671
reward/intrinsic_batch_mean :  5.091590899259986e-05
reward/extrinsic_batch_mean :  0.0850962962962963
loss/policy :  0.0011061002951464616
loss/rnd :  1.0927262551238968e-06
loss/value :  3.2431198015357507
loss/value_i :  1.971776367609533e-06
loss/value_e :  3.24311781652046
loss/entropy :  2.2522967222965127
reward/intrinsic_running :  0.0009826011146827562
reward/extrinsic_running :  0.0850962962962963
reward/intrinsic_std_running :  0.020751851881755223
reward/extrinsic_std_running :  1.6555818351713227
reward/intrinsic_batch_std :  4.104308340222227e-05
reward/intrinsic_batch_max :  0.0006830571219325066
reward/intrinsic_batch_min :  4.1410248741158284e-06
reward/total_batch :  0.04257360610264445
time/iteration_time :  112.70468020439148
time/fps :  2395.641418886521
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0011, Value Loss: 3.2431, Entropy: 2.2523
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=165.6
Extrinsic raw: Œº=0.0850962962962963

=== Iteration 672/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.21s
EPOCH 1 took 19.42s
update_step :  672
reward/intrinsic_batch_mean :  5.556604136119724e-05
reward/extrinsic_batch_mean :  0.08035555555555556
loss/policy :  0.0010693231288865773
loss/rnd :  1.1468883268538443e-06
loss/value :  3.7431779810876558
loss/value_i :  1.964954192730643e-06
loss/value_e :  3.743176008715774
loss/entropy :  2.2488585529905376
reward/intrinsic_running :  0.0009812964025455904
reward/extrinsic_running :  0.08035555555555556
reward/intrinsic_std_running :  0.020736433484954447
reward/extrinsic_std_running :  1.6049329117935194
reward/intrinsic_batch_std :  5.6891701982694454e-05
reward/intrinsic_batch_max :  0.0011499850079417229
reward/intrinsic_batch_min :  4.225914381095208e-06
reward/total_batch :  0.04020556079845838
time/iteration_time :  110.66972708702087
time/fps :  2439.6915679361523
data/episodes_collected :  60
data/frames_collected :  270000
Timer 110.7s | FPS: 2440
Policy Loss: 0.0011, Value Loss: 3.7432, Entropy: 2.2489
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.055, sum=180.9
Extrinsic raw: Œº=0.08035555555555556

=== Iteration 673/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.50s
EPOCH 1 took 19.58s
update_step :  673
reward/intrinsic_batch_mean :  5.456480856841221e-05
reward/extrinsic_batch_mean :  0.0798
loss/policy :  0.00040933611506426877
loss/rnd :  1.1398870004665118e-06
loss/value :  3.0019888877868652
loss/value_i :  1.8822437230924014e-06
loss/value_e :  3.0019870165622597
loss/entropy :  2.2627728418870405
reward/intrinsic_running :  0.0009799910920623147
reward/extrinsic_running :  0.0798
reward/intrinsic_std_running :  0.020721049524237128
reward/extrinsic_std_running :  1.6031076639521817
reward/intrinsic_batch_std :  5.043147426823733e-05
reward/intrinsic_batch_max :  0.0009182382491417229
reward/intrinsic_batch_min :  3.7736876947747078e-06
reward/total_batch :  0.039927282404284205
time/iteration_time :  112.45317149162292
time/fps :  2400.999424192437
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0004, Value Loss: 3.0020, Entropy: 2.2628
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=177.7
Extrinsic raw: Œº=0.0798

=== Iteration 674/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.45s
EPOCH 1 took 18.55s
update_step :  674
reward/intrinsic_batch_mean :  5.233407645011067e-05
reward/extrinsic_batch_mean :  0.08158518518518519
loss/policy :  0.0006560607889145049
loss/rnd :  1.1009586756065828e-06
loss/value :  2.1093020673954124
loss/value_i :  1.5808754104303564e-06
loss/value_e :  2.10930047974442
loss/entropy :  2.2679285930864737
reward/intrinsic_running :  0.0009786849769819884
reward/extrinsic_running :  0.08158518518518519
reward/intrinsic_std_running :  0.02070569989126894
reward/extrinsic_std_running :  1.6359036935575817
reward/intrinsic_batch_std :  4.006431736330973e-05
reward/intrinsic_batch_max :  0.0005470993928611279
reward/intrinsic_batch_min :  5.8161026572634e-06
reward/total_batch :  0.04081875963081765
time/iteration_time :  112.02591800689697
time/fps :  2410.156549517204
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.0s | FPS: 2410
Policy Loss: 0.0007, Value Loss: 2.1093, Entropy: 2.2679
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.026, sum=170.6
Extrinsic raw: Œº=0.08158518518518519

=== Iteration 675/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.88s
EPOCH 1 took 19.45s
update_step :  675
reward/intrinsic_batch_mean :  5.41218292712815e-05
reward/extrinsic_batch_mean :  0.07781481481481481
loss/policy :  0.0004951672321608798
loss/rnd :  1.0818244435761175e-06
loss/value :  4.884086630561135
loss/value_i :  2.2311485005929805e-06
loss/value_e :  4.8840843619722305
loss/entropy :  2.248729752771782
reward/intrinsic_running :  0.0009773872567625905
reward/extrinsic_running :  0.07781481481481481
reward/intrinsic_std_running :  0.020690384153350595
reward/extrinsic_std_running :  1.5596534642892348
reward/intrinsic_batch_std :  4.391409443361979e-05
reward/intrinsic_batch_max :  0.0010866615921258926
reward/intrinsic_batch_min :  6.119673344073817e-06
reward/total_batch :  0.038934468322043045
time/iteration_time :  112.72062516212463
time/fps :  2395.3025421182897
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0005, Value Loss: 4.8841, Entropy: 2.2487
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.053, sum=176.6
Extrinsic raw: Œº=0.07781481481481481

=== Iteration 676/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.50s
EPOCH 1 took 18.37s
update_step :  676
reward/intrinsic_batch_mean :  5.5364360633285727e-05
reward/extrinsic_batch_mean :  0.08405925925925926
loss/policy :  0.0006090882728158524
loss/rnd :  1.1896706837433157e-06
loss/value :  3.463917121742711
loss/value_i :  1.8484644525332525e-06
loss/value_e :  3.4639152523243064
loss/entropy :  2.2437680273345024
reward/intrinsic_running :  0.0009760950624458957
reward/extrinsic_running :  0.08405925925925926
reward/intrinsic_std_running :  0.020675102258971092
reward/extrinsic_std_running :  1.6435104604246906
reward/intrinsic_batch_std :  4.167062238294192e-05
reward/intrinsic_batch_max :  0.000933603965677321
reward/intrinsic_batch_min :  6.177814157126704e-06
reward/total_batch :  0.04205731180994628
time/iteration_time :  111.89186191558838
time/fps :  2413.0441247254334
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.9s | FPS: 2413
Policy Loss: 0.0006, Value Loss: 3.4639, Entropy: 2.2438
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.045, sum=180.8
Extrinsic raw: Œº=0.08405925925925926

=== Iteration 677/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.85s
update_step :  677
reward/intrinsic_batch_mean :  5.816190247845683e-05
reward/extrinsic_batch_mean :  0.08036296296296297
loss/policy :  0.0007995351753296828
loss/rnd :  1.456826771917611e-06
loss/value :  3.63504864952781
loss/value_i :  2.1188435074360643e-06
loss/value_e :  3.635046518210209
loss/entropy :  2.2454806927478677
reward/intrinsic_running :  0.0009748137931439791
reward/extrinsic_running :  0.08036296296296297
reward/intrinsic_std_running :  0.020659853886273442
reward/extrinsic_std_running :  1.6232880263237437
reward/intrinsic_batch_std :  4.304160704515086e-05
reward/intrinsic_batch_max :  0.0006652349256910384
reward/intrinsic_batch_min :  8.488623279845342e-06
reward/total_batch :  0.04021056243272071
time/iteration_time :  113.08578324317932
time/fps :  2387.568023642661
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0008, Value Loss: 3.6350, Entropy: 2.2455
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=190.0
Extrinsic raw: Œº=0.08036296296296297

=== Iteration 678/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.41s
EPOCH 1 took 18.18s
update_step :  678
reward/intrinsic_batch_mean :  7.076697992592084e-05
reward/extrinsic_batch_mean :  0.0811111111111111
loss/policy :  0.0010284578668440438
loss/rnd :  1.2601815755756847e-06
loss/value :  3.2143249042106397
loss/value_i :  1.7349743833013537e-05
loss/value_e :  3.214307544809399
loss/entropy :  2.2397185636289194
reward/intrinsic_running :  0.0009735711747358947
reward/extrinsic_running :  0.0811111111111111
reward/intrinsic_std_running :  0.02064463776548492
reward/extrinsic_std_running :  1.6071986978345236
reward/intrinsic_batch_std :  4.401007670652065e-05
reward/intrinsic_batch_max :  0.0008247546502389014
reward/intrinsic_batch_min :  1.2878546840511262e-05
reward/total_batch :  0.04059093904551851
time/iteration_time :  112.40154433250427
time/fps :  2402.10222736167
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2402
Policy Loss: 0.0010, Value Loss: 3.2143, Entropy: 2.2397
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=231.4
Extrinsic raw: Œº=0.0811111111111111

=== Iteration 679/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.37s
EPOCH 1 took 19.36s
update_step :  679
reward/intrinsic_batch_mean :  5.146209362553943e-05
reward/extrinsic_batch_mean :  0.08331851851851851
loss/policy :  0.000913890612234051
loss/rnd :  1.0684858218403612e-06
loss/value :  3.2288962801297507
loss/value_i :  1.4412275480467404e-05
loss/value_e :  3.2288818738677283
loss/entropy :  2.237621206225771
reward/intrinsic_running :  0.0009722797410256192
reward/extrinsic_running :  0.08331851851851851
reward/intrinsic_std_running :  0.020629457377790403
reward/extrinsic_std_running :  1.6412931516511806
reward/intrinsic_batch_std :  3.844968273878256e-05
reward/intrinsic_batch_max :  0.0006083259359002113
reward/intrinsic_batch_min :  4.609641109709628e-06
reward/total_batch :  0.04168499030607203
time/iteration_time :  111.38645792007446
time/fps :  2423.9930512355368
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0009, Value Loss: 3.2289, Entropy: 2.2376
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.029, sum=168.4
Extrinsic raw: Œº=0.08331851851851851

=== Iteration 680/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.61s
EPOCH 1 took 19.70s
update_step :  680
reward/intrinsic_batch_mean :  5.160048243586196e-05
reward/extrinsic_batch_mean :  0.07977777777777778
loss/policy :  0.0009570774430661307
loss/rnd :  1.0542429573902292e-06
loss/value :  3.4088054750904893
loss/value_i :  3.451230454767497e-06
loss/value_e :  3.408802012602488
loss/entropy :  2.243297880346125
reward/intrinsic_running :  0.0009709913920646679
reward/extrinsic_running :  0.07977777777777778
reward/intrinsic_std_running :  0.020614310456967377
reward/extrinsic_std_running :  1.6031122354676772
reward/intrinsic_batch_std :  3.915368273744494e-05
reward/intrinsic_batch_max :  0.0006483534816652536
reward/intrinsic_batch_min :  5.429683369584382e-06
reward/total_batch :  0.039914689130106824
time/iteration_time :  119.65730929374695
time/fps :  2256.44385281284
data/episodes_collected :  60
data/frames_collected :  270000
Timer 119.7s | FPS: 2256
Policy Loss: 0.0010, Value Loss: 3.4088, Entropy: 2.2433
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=169.0
Extrinsic raw: Œº=0.07977777777777778

=== Iteration 681/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.66s
EPOCH 1 took 19.73s
update_step :  681
reward/intrinsic_batch_mean :  5.1537906877752836e-05
reward/extrinsic_batch_mean :  0.08007407407407408
loss/policy :  0.0011658168377008142
loss/rnd :  1.062038381171464e-06
loss/value :  3.573586617455338
loss/value_i :  2.2013315832268607e-06
loss/value_e :  3.5735844283392937
loss/entropy :  2.243569822022409
reward/intrinsic_running :  0.0009697049355390726
reward/extrinsic_running :  0.08007407407407408
reward/intrinsic_std_running :  0.020599196968918775
reward/extrinsic_std_running :  1.5947585426414386
reward/intrinsic_batch_std :  4.430340334362156e-05
reward/intrinsic_batch_max :  0.0006480701849795878
reward/intrinsic_batch_min :  4.342995907791192e-06
reward/total_batch :  0.040062805990475917
time/iteration_time :  115.81415128707886
time/fps :  2331.3213195400185
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.8s | FPS: 2331
Policy Loss: 0.0012, Value Loss: 3.5736, Entropy: 2.2436
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=168.9
Extrinsic raw: Œº=0.08007407407407408

=== Iteration 682/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.77s
EPOCH 1 took 19.42s
update_step :  682
reward/intrinsic_batch_mean :  5.37528749279604e-05
reward/extrinsic_batch_mean :  0.0848962962962963
loss/policy :  0.00023377251019348589
loss/rnd :  1.1044194820897246e-06
loss/value :  4.830335743499525
loss/value_i :  2.18563569419392e-06
loss/value_e :  4.830333543546272
loss/entropy :  2.205091115200158
reward/intrinsic_running :  0.0009684308074658244
reward/extrinsic_running :  0.0848962962962963
reward/intrinsic_std_running :  0.020584116290567042
reward/extrinsic_std_running :  1.6371531378136102
reward/intrinsic_batch_std :  4.305701278581972e-05
reward/intrinsic_batch_max :  0.0010436495067551732
reward/intrinsic_batch_min :  4.2001988731499296e-06
reward/total_batch :  0.04247502458561213
time/iteration_time :  113.87100291252136
time/fps :  2371.1040835165118
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2371
Policy Loss: 0.0002, Value Loss: 4.8303, Entropy: 2.2051
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.051, sum=176.3
Extrinsic raw: Œº=0.0848962962962963

=== Iteration 683/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.63s
EPOCH 1 took 18.58s
update_step :  683
reward/intrinsic_batch_mean :  5.0472983616762375e-05
reward/extrinsic_batch_mean :  0.07885185185185185
loss/policy :  0.0010950491132186444
loss/rnd :  1.0380532299595044e-06
loss/value :  4.548616167270776
loss/value_i :  1.898630500818399e-06
loss/value_e :  4.548614263534546
loss/entropy :  2.233385609857964
reward/intrinsic_running :  0.0009671514182810545
reward/extrinsic_running :  0.07885185185185185
reward/intrinsic_std_running :  0.02056906905259754
reward/extrinsic_std_running :  1.60038912406405
reward/intrinsic_batch_std :  3.8818446779032255e-05
reward/intrinsic_batch_max :  0.0006207666010595858
reward/intrinsic_batch_min :  4.578644166031154e-06
reward/total_batch :  0.03945116241773431
time/iteration_time :  112.09661793708801
time/fps :  2408.636451025954
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2409
Policy Loss: 0.0011, Value Loss: 4.5486, Entropy: 2.2334
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=165.6
Extrinsic raw: Œº=0.07885185185185185

=== Iteration 684/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.13s
EPOCH 1 took 19.28s
update_step :  684
reward/intrinsic_batch_mean :  5.0027020110526255e-05
reward/extrinsic_batch_mean :  0.08341481481481482
loss/policy :  0.0010576836884314562
loss/rnd :  1.0283816874162408e-06
loss/value :  5.420862551891442
loss/value_i :  1.9445375421651767e-06
loss/value_e :  5.42086056506995
loss/entropy :  2.240193814942331
reward/intrinsic_running :  0.0009658737430985807
reward/extrinsic_running :  0.08341481481481482
reward/intrinsic_std_running :  0.02055405485215965
reward/extrinsic_std_running :  1.6235994894070223
reward/intrinsic_batch_std :  3.978326933437951e-05
reward/intrinsic_batch_max :  0.0006166864186525345
reward/intrinsic_batch_min :  3.7385646010079654e-06
reward/total_batch :  0.041732420917462675
time/iteration_time :  115.33165216445923
time/fps :  2341.074587356025
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2341
Policy Loss: 0.0011, Value Loss: 5.4209, Entropy: 2.2402
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=164.3
Extrinsic raw: Œº=0.08341481481481482

=== Iteration 685/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.45s
EPOCH 1 took 19.16s
update_step :  685
reward/intrinsic_batch_mean :  5.007460493397957e-05
reward/extrinsic_batch_mean :  0.08458518518518518
loss/policy :  0.0005959015772642681
loss/rnd :  1.0305345716171195e-06
loss/value :  5.299235632925322
loss/value_i :  2.2468846020384454e-06
loss/value_e :  5.299233378786029
loss/entropy :  2.231122703263254
reward/intrinsic_running :  0.0009645999033970667
reward/extrinsic_running :  0.08458518518518518
reward/intrinsic_std_running :  0.020539073474026465
reward/extrinsic_std_running :  1.645295474466225
reward/intrinsic_batch_std :  3.939792753307242e-05
reward/intrinsic_batch_max :  0.0006808430189266801
reward/intrinsic_batch_min :  4.047491074743448e-06
reward/total_batch :  0.04231762989505958
time/iteration_time :  113.02534914016724
time/fps :  2388.8446446218204
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0006, Value Loss: 5.2992, Entropy: 2.2311
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.033, sum=164.6
Extrinsic raw: Œº=0.08458518518518518

=== Iteration 686/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.19s
EPOCH 1 took 18.54s
update_step :  686
reward/intrinsic_batch_mean :  5.1375027068779335e-05
reward/extrinsic_batch_mean :  0.0852
loss/policy :  0.000806855773341588
loss/rnd :  1.0648158729164798e-06
loss/value :  4.44460023171974
loss/value_i :  2.0359967290019223e-06
loss/value_e :  4.444598165425387
loss/entropy :  2.2322335568341343
reward/intrinsic_running :  0.0009633330455888424
reward/extrinsic_running :  0.0852
reward/intrinsic_std_running :  0.020524124677171067
reward/extrinsic_std_running :  1.647060298430712
reward/intrinsic_batch_std :  4.2130565662612635e-05
reward/intrinsic_batch_max :  0.0006978408782742918
reward/intrinsic_batch_min :  4.6214254325605e-06
reward/total_batch :  0.04262568751353439
time/iteration_time :  113.52674961090088
time/fps :  2378.294110642577
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2378
Policy Loss: 0.0008, Value Loss: 4.4446, Entropy: 2.2322
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=169.0
Extrinsic raw: Œº=0.0852

=== Iteration 687/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.72s
EPOCH 1 took 18.89s
update_step :  687
reward/intrinsic_batch_mean :  5.1529269421182644e-05
reward/extrinsic_batch_mean :  0.08445925925925926
loss/policy :  0.0007616989649691139
loss/rnd :  1.0845819591657235e-06
loss/value :  5.029955137859691
loss/value_i :  2.6902195600086998e-06
loss/value_e :  5.0299524574568775
loss/entropy :  2.2397744330492886
reward/intrinsic_running :  0.0009620700036733502
reward/extrinsic_running :  0.08445925925925926
reward/intrinsic_std_running :  0.020509208476184138
reward/extrinsic_std_running :  1.6358166960741678
reward/intrinsic_batch_std :  4.282721560866888e-05
reward/intrinsic_batch_max :  0.0008953866781666875
reward/intrinsic_batch_min :  4.6222512537497096e-06
reward/total_batch :  0.042255394264340225
time/iteration_time :  112.93005442619324
time/fps :  2390.860443412446
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: 0.0008, Value Loss: 5.0300, Entropy: 2.2398
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=169.6
Extrinsic raw: Œº=0.08445925925925926

=== Iteration 688/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.97s
EPOCH 1 took 19.03s
update_step :  688
reward/intrinsic_batch_mean :  5.1928105675088534e-05
reward/extrinsic_batch_mean :  0.09034814814814815
loss/policy :  0.0005298611720332481
loss/rnd :  1.0436756952003634e-06
loss/value :  4.631058703769337
loss/value_i :  2.7052324977568896e-06
loss/value_e :  4.631055983630094
loss/entropy :  2.2058879787271675
reward/intrinsic_running :  0.0009608135517696387
reward/extrinsic_running :  0.09034814814814815
reward/intrinsic_std_running :  0.020494324654899525
reward/extrinsic_std_running :  1.6977316536136555
reward/intrinsic_batch_std :  4.5375907314606474e-05
reward/intrinsic_batch_max :  0.0009122937335632741
reward/intrinsic_batch_min :  4.911309133603936e-06
reward/total_batch :  0.04520003812691162
time/iteration_time :  113.870858669281
time/fps :  2371.1070870570156
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2371
Policy Loss: 0.0005, Value Loss: 4.6311, Entropy: 2.2059
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.045, sum=171.0
Extrinsic raw: Œº=0.09034814814814815

=== Iteration 689/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.52s
EPOCH 1 took 19.08s
update_step :  689
reward/intrinsic_batch_mean :  5.0266182745717406e-05
reward/extrinsic_batch_mean :  0.08662962962962963
loss/policy :  0.0008542731317874948
loss/rnd :  1.0308933448841069e-06
loss/value :  5.926859740054969
loss/value_i :  1.9434041136760656e-06
loss/value_e :  5.926857782132698
loss/entropy :  2.225507295492924
reward/intrinsic_running :  0.0009595548859347594
reward/extrinsic_running :  0.08662962962962963
reward/intrinsic_std_running :  0.020479473392049516
reward/extrinsic_std_running :  1.6604313729592295
reward/intrinsic_batch_std :  3.926925097656067e-05
reward/intrinsic_batch_max :  0.0005488136084750295
reward/intrinsic_batch_min :  4.029729552712524e-06
reward/total_batch :  0.04333994790618767
time/iteration_time :  112.47603297233582
time/fps :  2400.5114055401314
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2401
Policy Loss: 0.0009, Value Loss: 5.9269, Entropy: 2.2255
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.027, sum=165.7
Extrinsic raw: Œº=0.08662962962962963

=== Iteration 690/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.43s
EPOCH 1 took 20.05s
update_step :  690
reward/intrinsic_batch_mean :  5.122430232699521e-05
reward/extrinsic_batch_mean :  0.08388148148148149
loss/policy :  0.001340012519380473
loss/rnd :  1.0481076663271587e-06
loss/value :  4.268567786072239
loss/value_i :  1.7078969373566604e-06
loss/value_e :  4.268566081018159
loss/entropy :  2.228297497286941
reward/intrinsic_running :  0.0009583022232955588
reward/extrinsic_running :  0.08388148148148149
reward/intrinsic_std_running :  0.020464654287709796
reward/extrinsic_std_running :  1.6430732859463084
reward/intrinsic_batch_std :  4.191614461286086e-05
reward/intrinsic_batch_max :  0.0005785954417660832
reward/intrinsic_batch_min :  4.230336344335228e-06
reward/total_batch :  0.04196635289190424
time/iteration_time :  114.17380046844482
time/fps :  2364.815736116467
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.2s | FPS: 2365
Policy Loss: 0.0013, Value Loss: 4.2686, Entropy: 2.2283
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=169.0
Extrinsic raw: Œº=0.08388148148148149

=== Iteration 691/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.11s
EPOCH 1 took 20.13s
update_step :  691
reward/intrinsic_batch_mean :  4.991211152465877e-05
reward/extrinsic_batch_mean :  0.08064444444444445
loss/policy :  0.001397000309997097
loss/rnd :  1.020829458728699e-06
loss/value :  4.378022504575325
loss/value_i :  1.6467344556241932e-06
loss/value_e :  4.3780208789941035
loss/entropy :  2.239932591264898
reward/intrinsic_running :  0.0009570493565960869
reward/extrinsic_running :  0.08064444444444445
reward/intrinsic_std_running :  0.020449867452549196
reward/extrinsic_std_running :  1.615041620684498
reward/intrinsic_batch_std :  3.854222478044163e-05
reward/intrinsic_batch_max :  0.0005109392805024981
reward/intrinsic_batch_min :  4.466211976250634e-06
reward/total_batch :  0.040347178277984556
time/iteration_time :  114.9601514339447
time/fps :  2348.6399124581885
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.0s | FPS: 2349
Policy Loss: 0.0014, Value Loss: 4.3780, Entropy: 2.2399
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=164.7
Extrinsic raw: Œº=0.08064444444444445

=== Iteration 692/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 20.26s
update_step :  692
reward/intrinsic_batch_mean :  5.2927825463774317e-05
reward/extrinsic_batch_mean :  0.08383703703703704
loss/policy :  0.0011290898246718853
loss/rnd :  1.0793498962481285e-06
loss/value :  5.806530009616505
loss/value_i :  1.787127146282287e-06
loss/value_e :  5.806528199802745
loss/entropy :  2.2200276851654053
reward/intrinsic_running :  0.0009558088029818836
reward/extrinsic_running :  0.08383703703703704
reward/intrinsic_std_running :  0.020435112267105975
reward/extrinsic_std_running :  1.6249493038583505
reward/intrinsic_batch_std :  4.089277888850764e-05
reward/intrinsic_batch_max :  0.0005805599503219128
reward/intrinsic_batch_min :  4.53974234915222e-06
reward/total_batch :  0.04194498243125041
time/iteration_time :  114.29359269142151
time/fps :  2362.33714980827
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0011, Value Loss: 5.8065, Entropy: 2.2200
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=174.8
Extrinsic raw: Œº=0.08383703703703704

=== Iteration 693/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.72s
EPOCH 1 took 19.08s
update_step :  693
reward/intrinsic_batch_mean :  5.2822651805069686e-05
reward/extrinsic_batch_mean :  0.09008148148148148
loss/policy :  0.001497084854759812
loss/rnd :  1.0805296796840567e-06
loss/value :  4.509152773654822
loss/value_i :  2.0806854453522563e-06
loss/value_e :  4.509150656786832
loss/entropy :  2.206706903197549
reward/intrinsic_running :  0.0009545702774760202
reward/extrinsic_running :  0.09008148148148148
reward/intrinsic_std_running :  0.02042038906521084
reward/extrinsic_std_running :  1.6881153618287612
reward/intrinsic_batch_std :  4.59472050490614e-05
reward/intrinsic_batch_max :  0.0009119276073761284
reward/intrinsic_batch_min :  4.361598257673904e-06
reward/total_batch :  0.04506715206664328
time/iteration_time :  113.80309677124023
time/fps :  2372.5189178527967
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.8s | FPS: 2373
Policy Loss: 0.0015, Value Loss: 4.5092, Entropy: 2.2067
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.045, sum=174.6
Extrinsic raw: Œº=0.09008148148148148

=== Iteration 694/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.17s
EPOCH 1 took 19.71s
update_step :  694
reward/intrinsic_batch_mean :  5.105439489762594e-05
reward/extrinsic_batch_mean :  0.08707407407407407
loss/policy :  0.0016467033300696958
loss/rnd :  1.1942205360631333e-06
loss/value :  6.187082792773391
loss/value_i :  1.8900386731784788e-06
loss/value_e :  6.187080867362745
loss/entropy :  2.2186824986428926
reward/intrinsic_running :  0.0009533300505029704
reward/extrinsic_running :  0.08707407407407407
reward/intrinsic_std_running :  0.020405697838237365
reward/extrinsic_std_running :  1.6715239094007055
reward/intrinsic_batch_std :  4.2452988276900534e-05
reward/intrinsic_batch_max :  0.0006382112042047083
reward/intrinsic_batch_min :  4.762327989737969e-06
reward/total_batch :  0.043562564234485845
time/iteration_time :  112.90428328514099
time/fps :  2391.406172944848
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: 0.0016, Value Loss: 6.1871, Entropy: 2.2187
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=168.9
Extrinsic raw: Œº=0.08707407407407407

=== Iteration 695/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 18.54s
update_step :  695
reward/intrinsic_batch_mean :  8.153441287571763e-05
reward/extrinsic_batch_mean :  0.08417037037037037
loss/policy :  0.0007290927354585041
loss/rnd :  1.2321372702734317e-06
loss/value :  4.52362445267764
loss/value_i :  1.7101175289595134e-06
loss/value_e :  4.523622736786351
loss/entropy :  2.2336121653065537
reward/intrinsic_running :  0.0009521767261843096
reward/extrinsic_running :  0.08417037037037037
reward/intrinsic_std_running :  0.020391034886970947
reward/extrinsic_std_running :  1.6439610522589354
reward/intrinsic_batch_std :  3.88240960473908e-05
reward/intrinsic_batch_max :  0.0006651022122241557
reward/intrinsic_batch_min :  3.2158364774659276e-05
reward/total_batch :  0.04212595239162304
time/iteration_time :  111.84849643707275
time/fps :  2413.9797011210167
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: 0.0007, Value Loss: 4.5236, Entropy: 2.2336
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.033, sum=269.9
Extrinsic raw: Œº=0.08417037037037037

=== Iteration 696/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 19.40s
update_step :  696
reward/intrinsic_batch_mean :  5.3996719891404575e-05
reward/extrinsic_batch_mean :  0.08477037037037037
loss/policy :  0.0012898812410915552
loss/rnd :  1.1413000830736675e-06
loss/value :  4.42815950422576
loss/value_i :  1.748033432911391e-06
loss/value_e :  4.428157719698819
loss/entropy :  2.230923558726455
reward/intrinsic_running :  0.0009509518966847489
reward/extrinsic_running :  0.08477037037037037
reward/intrinsic_std_running :  0.020376406533759578
reward/extrinsic_std_running :  1.6457304758441111
reward/intrinsic_batch_std :  4.375131466365113e-05
reward/intrinsic_batch_max :  0.0007903158548288047
reward/intrinsic_batch_min :  5.806371518701781e-06
reward/total_batch :  0.04241218354513089
time/iteration_time :  114.30444812774658
time/fps :  2362.1127998295233
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0013, Value Loss: 4.4282, Entropy: 2.2309
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=178.9
Extrinsic raw: Œº=0.08477037037037037

=== Iteration 697/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 18.76s
update_step :  697
reward/intrinsic_batch_mean :  5.772902868212205e-05
reward/extrinsic_batch_mean :  0.09478518518518518
loss/policy :  0.0016602097453097954
loss/rnd :  1.104409632675511e-06
loss/value :  5.544835683071252
loss/value_i :  1.8681055383818934e-06
loss/value_e :  5.544833772110216
loss/entropy :  2.1946961915854253
reward/intrinsic_running :  0.0009497398867083606
reward/extrinsic_running :  0.09478518518518518
reward/intrinsic_std_running :  0.020361809236696244
reward/extrinsic_std_running :  1.7659309343702274
reward/intrinsic_batch_std :  4.5442555336372634e-05
reward/intrinsic_batch_max :  0.0006496639107353985
reward/intrinsic_batch_min :  6.802069037803449e-06
reward/total_batch :  0.04742145710693365
time/iteration_time :  112.35225486755371
time/fps :  2403.1560409560902
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2403
Policy Loss: 0.0017, Value Loss: 5.5448, Entropy: 2.1947
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=191.4
Extrinsic raw: Œº=0.09478518518518518

=== Iteration 698/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.18s
EPOCH 1 took 19.27s
update_step :  698
reward/intrinsic_batch_mean :  5.126338207590851e-05
reward/extrinsic_batch_mean :  0.08520740740740741
loss/policy :  0.0013920715883807243
loss/rnd :  1.0421238009643496e-06
loss/value :  4.789259841947844
loss/value_i :  1.8178822418838425e-06
loss/value_e :  4.78925798517285
loss/entropy :  2.201103521115852
reward/intrinsic_running :  0.000948515646060853
reward/extrinsic_running :  0.08520740740740741
reward/intrinsic_std_running :  0.020347243919001532
reward/extrinsic_std_running :  1.638039386295776
reward/intrinsic_batch_std :  4.3587303868646535e-05
reward/intrinsic_batch_max :  0.0009430961799807847
reward/intrinsic_batch_min :  4.772256033902522e-06
reward/total_batch :  0.04262933539474166
time/iteration_time :  113.00965118408203
time/fps :  2389.176474495931
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0014, Value Loss: 4.7893, Entropy: 2.2011
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=170.1
Extrinsic raw: Œº=0.08520740740740741

=== Iteration 699/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.76s
EPOCH 1 took 19.14s
update_step :  699
reward/intrinsic_batch_mean :  5.370477745107362e-05
reward/extrinsic_batch_mean :  0.0858
loss/policy :  0.0011858529293077122
loss/rnd :  1.0845671505938463e-06
loss/value :  4.493315353538051
loss/value_i :  1.8183348136820616e-06
loss/value_e :  4.493313471476237
loss/entropy :  2.2010486089822017
reward/intrinsic_running :  0.0009472986941708837
reward/extrinsic_running :  0.0858
reward/intrinsic_std_running :  0.02033270965849346
reward/extrinsic_std_running :  1.6398163370509695
reward/intrinsic_batch_std :  4.591543651982685e-05
reward/intrinsic_batch_max :  0.0008974170195870101
reward/intrinsic_batch_min :  4.3006407395296264e-06
reward/total_batch :  0.04292685238872554
time/iteration_time :  114.1269760131836
time/fps :  2365.785981824406
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0012, Value Loss: 4.4933, Entropy: 2.2010
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=178.3
Extrinsic raw: Œº=0.0858

=== Iteration 700/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.51s
EPOCH 1 took 19.76s
update_step :  700
reward/intrinsic_batch_mean :  4.903969472924709e-05
reward/extrinsic_batch_mean :  0.08506666666666667
loss/policy :  0.000977106556423347
loss/rnd :  9.97786513022275e-07
loss/value :  4.196765791286122
loss/value_i :  1.6772306552907552e-06
loss/value_e :  4.196764093456847
loss/entropy :  2.22489045605515
reward/intrinsic_running :  0.0009460747689097655
reward/extrinsic_running :  0.08506666666666667
reward/intrinsic_std_running :  0.020318206913056584
reward/extrinsic_std_running :  1.6466151462925387
reward/intrinsic_batch_std :  3.89843993596648e-05
reward/intrinsic_batch_max :  0.0007621559780091047
reward/intrinsic_batch_min :  4.2446658881090116e-06
reward/total_batch :  0.042557853180697956
time/iteration_time :  114.1405417919159
time/fps :  2365.504804526195
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0010, Value Loss: 4.1968, Entropy: 2.2249
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.038, sum=162.9
Extrinsic raw: Œº=0.08506666666666667

=== Iteration 701/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.11s
EPOCH 1 took 19.26s
update_step :  701
reward/intrinsic_batch_mean :  5.1347710668374526e-05
reward/extrinsic_batch_mean :  0.08487407407407407
loss/policy :  0.0006408561206295748
loss/rnd :  1.0495277148369164e-06
loss/value :  6.409527193416249
loss/value_i :  1.828973369576874e-06
loss/value_e :  6.409525296904824
loss/entropy :  2.215112176808444
reward/intrinsic_running :  0.0009448588969560447
reward/extrinsic_running :  0.08487407407407407
reward/intrinsic_std_running :  0.020303734975350183
reward/extrinsic_std_running :  1.6280834287005463
reward/intrinsic_batch_std :  4.229998804403269e-05
reward/intrinsic_batch_max :  0.0008901841938495636
reward/intrinsic_batch_min :  4.8285137381753884e-06
reward/total_batch :  0.042462710892371226
time/iteration_time :  114.73679256439209
time/fps :  2353.2120252400446
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.7s | FPS: 2353
Policy Loss: 0.0006, Value Loss: 6.4095, Entropy: 2.2151
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=170.7
Extrinsic raw: Œº=0.08487407407407407

=== Iteration 702/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 17.99s
update_step :  702
reward/intrinsic_batch_mean :  5.376872052476958e-05
reward/extrinsic_batch_mean :  0.08611111111111111
loss/policy :  0.00132192042479856
loss/rnd :  1.084303633116647e-06
loss/value :  4.0706380316705415
loss/value_i :  2.0260448209366144e-06
loss/value_e :  4.0706359798258
loss/entropy :  2.2250135667396314
reward/intrinsic_running :  0.0009436551378977237
reward/extrinsic_running :  0.08611111111111111
reward/intrinsic_std_running :  0.020289293639524853
reward/extrinsic_std_running :  1.6586617951280131
reward/intrinsic_batch_std :  5.19968963416169e-05
reward/intrinsic_batch_max :  0.0009453181992284954
reward/intrinsic_batch_min :  4.941139650327386e-06
reward/total_batch :  0.04308243991581794
time/iteration_time :  111.04587507247925
time/fps :  2431.427550314426
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.0s | FPS: 2431
Policy Loss: 0.0013, Value Loss: 4.0706, Entropy: 2.2250
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.047, sum=178.9
Extrinsic raw: Œº=0.08611111111111111

=== Iteration 703/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.34s
EPOCH 1 took 18.91s
update_step :  703
reward/intrinsic_batch_mean :  5.41202868717341e-05
reward/extrinsic_batch_mean :  0.0804962962962963
loss/policy :  0.0007791079168038613
loss/rnd :  1.0881948200717901e-06
loss/value :  4.651865991679105
loss/value_i :  2.2963806145526178e-06
loss/value_e :  4.651863697803382
loss/entropy :  2.234793756947373
reward/intrinsic_running :  0.0009424547732671935
reward/extrinsic_running :  0.0804962962962963
reward/intrinsic_std_running :  0.020274882995819532
reward/extrinsic_std_running :  1.6053884882278284
reward/intrinsic_batch_std :  4.224684869671696e-05
reward/intrinsic_batch_max :  0.0007385152857750654
reward/intrinsic_batch_min :  4.22949597123079e-06
reward/total_batch :  0.04027520829158402
time/iteration_time :  112.63156509399414
time/fps :  2397.196556530823
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2397
Policy Loss: 0.0008, Value Loss: 4.6519, Entropy: 2.2348
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=180.2
Extrinsic raw: Œº=0.0804962962962963

=== Iteration 704/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.46s
update_step :  704
reward/intrinsic_batch_mean :  5.2875392402071426e-05
reward/extrinsic_batch_mean :  0.08505185185185185
loss/policy :  0.0008701456875617927
loss/rnd :  1.1961499102185233e-06
loss/value :  4.734636808886672
loss/value_i :  2.292993318667758e-06
loss/value_e :  4.734634547522574
loss/entropy :  2.230106826984521
reward/intrinsic_running :  0.0009412550114388932
reward/extrinsic_running :  0.08505185185185185
reward/intrinsic_std_running :  0.020260503124146505
reward/extrinsic_std_running :  1.655546087900677
reward/intrinsic_batch_std :  4.0980321541764484e-05
reward/intrinsic_batch_max :  0.0006674669566564262
reward/intrinsic_batch_min :  5.236630840954604e-06
reward/total_batch :  0.042552363622126964
time/iteration_time :  112.5635724067688
time/fps :  2398.64455460161
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.6s | FPS: 2399
Policy Loss: 0.0009, Value Loss: 4.7346, Entropy: 2.2301
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=176.2
Extrinsic raw: Œº=0.08505185185185185

=== Iteration 705/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.37s
EPOCH 1 took 18.91s
update_step :  705
reward/intrinsic_batch_mean :  7.70505892128481e-05
reward/extrinsic_batch_mean :  0.08005185185185185
loss/policy :  0.0011697586923026283
loss/rnd :  1.108867896467321e-06
loss/value :  4.628223516724327
loss/value_i :  1.671519807146207e-06
loss/value_e :  4.6282218839183
loss/entropy :  2.233215487364567
reward/intrinsic_running :  0.0009401218843418503
reward/extrinsic_running :  0.08005185185185185
reward/intrinsic_std_running :  0.020246151259231567
reward/extrinsic_std_running :  1.5947631419094392
reward/intrinsic_batch_std :  4.1504307359366184e-05
reward/intrinsic_batch_max :  0.0006382862920872867
reward/intrinsic_batch_min :  2.1667065084329806e-05
reward/total_batch :  0.04006445122053235
time/iteration_time :  114.81580710411072
time/fps :  2351.5925795406724
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.8s | FPS: 2352
Policy Loss: 0.0012, Value Loss: 4.6282, Entropy: 2.2332
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.032, sum=256.9
Extrinsic raw: Œº=0.08005185185185185

=== Iteration 706/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 18.58s
update_step :  706
reward/intrinsic_batch_mean :  5.095615016562752e-05
reward/extrinsic_batch_mean :  0.082
loss/policy :  0.00033540176104217994
loss/rnd :  1.0341575799347167e-06
loss/value :  3.4053706219702056
loss/value_i :  6.097338781053237e-06
loss/value_e :  3.4053645278468276
loss/entropy :  2.240637927344351
reward/intrinsic_running :  0.0009389243495677572
reward/extrinsic_running :  0.082
reward/intrinsic_std_running :  0.02023183257083983
reward/extrinsic_std_running :  1.6190927043209058
reward/intrinsic_batch_std :  3.6621503056414424e-05
reward/intrinsic_batch_max :  0.0005419592489488423
reward/intrinsic_batch_min :  4.523678853729507e-06
reward/total_batch :  0.04102547807508281
time/iteration_time :  114.02661967277527
time/fps :  2367.8681414464886
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.0s | FPS: 2368
Policy Loss: 0.0003, Value Loss: 3.4054, Entropy: 2.2406
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=170.0
Extrinsic raw: Œº=0.082

=== Iteration 707/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.51s
EPOCH 1 took 19.15s
update_step :  707
reward/intrinsic_batch_mean :  5.471697514502146e-05
reward/extrinsic_batch_mean :  0.08109629629629629
loss/policy :  0.002271914784972923
loss/rnd :  1.108324957413336e-06
loss/value :  4.071260284293782
loss/value_i :  1.7634816344980209e-06
loss/value_e :  4.071258516022653
loss/entropy :  2.2257890737417974
reward/intrinsic_running :  0.0009377386734335092
reward/extrinsic_running :  0.08109629629629629
reward/intrinsic_std_running :  0.02021754387562443
reward/extrinsic_std_running :  1.607201749874949
reward/intrinsic_batch_std :  4.1899232382788996e-05
reward/intrinsic_batch_max :  0.0007954995380714536
reward/intrinsic_batch_min :  3.89581646231818e-06
reward/total_batch :  0.040575506635720654
time/iteration_time :  113.60799169540405
time/fps :  2376.593371387998
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2377
Policy Loss: 0.0023, Value Loss: 4.0713, Entropy: 2.2258
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=182.7
Extrinsic raw: Œº=0.08109629629629629

=== Iteration 708/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.75s
EPOCH 1 took 18.69s
update_step :  708
reward/intrinsic_batch_mean :  5.077994243654218e-05
reward/extrinsic_batch_mean :  0.07874074074074074
loss/policy :  0.0009877098914743824
loss/rnd :  1.0223722907457242e-06
loss/value :  3.240971489386125
loss/value_i :  1.5487774441791053e-06
loss/value_e :  3.2409699721769853
loss/entropy :  2.226730845191262
reward/intrinsic_running :  0.0009365479975165185
reward/extrinsic_running :  0.07874074074074074
reward/intrinsic_std_running :  0.02020328574971269
reward/extrinsic_std_running :  1.5906392517101207
reward/intrinsic_batch_std :  3.7836549170356036e-05
reward/intrinsic_batch_max :  0.0005531664937734604
reward/intrinsic_batch_min :  3.8045388919272227e-06
reward/total_batch :  0.03939576034158864
time/iteration_time :  111.75980472564697
time/fps :  2415.895416628619
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2416
Policy Loss: 0.0010, Value Loss: 3.2410, Entropy: 2.2267
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=169.7
Extrinsic raw: Œº=0.07874074074074074

=== Iteration 709/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.41s
EPOCH 1 took 20.46s
update_step :  709
reward/intrinsic_batch_mean :  5.102723287172584e-05
reward/extrinsic_batch_mean :  0.07993333333333333
loss/policy :  0.0006342995276843959
loss/rnd :  1.0341008484801657e-06
loss/value :  2.8184188477920764
loss/value_i :  1.637838257314191e-06
loss/value_e :  2.8184172276294595
loss/entropy :  2.2342565095785893
reward/intrinsic_running :  0.0009353615890538839
reward/extrinsic_running :  0.07993333333333333
reward/intrinsic_std_running :  0.02018905771335134
reward/extrinsic_std_running :  1.6127775429249265
reward/intrinsic_batch_std :  3.6501147458910325e-05
reward/intrinsic_batch_max :  0.0005741377244703472
reward/intrinsic_batch_min :  3.852644567814423e-06
reward/total_batch :  0.03999218028310253
time/iteration_time :  114.46254348754883
time/fps :  2358.850255929971
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2359
Policy Loss: 0.0006, Value Loss: 2.8184, Entropy: 2.2343
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=170.6
Extrinsic raw: Œº=0.07993333333333333

=== Iteration 710/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.79s
EPOCH 1 took 18.63s
update_step :  710
reward/intrinsic_batch_mean :  6.493237388520491e-05
reward/extrinsic_batch_mean :  0.07961481481481482
loss/policy :  0.0011675917987965724
loss/rnd :  1.1167498996655922e-06
loss/value :  3.9425273230581572
loss/value_i :  1.5715270709540963e-06
loss/value_e :  3.9425257408257686
loss/entropy :  2.2342564951289785
reward/intrinsic_running :  0.0009342145240637247
reward/extrinsic_running :  0.07961481481481482
reward/intrinsic_std_running :  0.020174858219368083
reward/extrinsic_std_running :  1.6026605194242676
reward/intrinsic_batch_std :  3.696964990081207e-05
reward/intrinsic_batch_max :  0.0006449415814131498
reward/intrinsic_batch_min :  1.4546859347319696e-05
reward/total_batch :  0.03983987359435001
time/iteration_time :  111.65943360328674
time/fps :  2418.0670749171027
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.7s | FPS: 2418
Policy Loss: 0.0012, Value Loss: 3.9425, Entropy: 2.2343
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=217.2
Extrinsic raw: Œº=0.07961481481481482

=== Iteration 711/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 19.52s
update_step :  711
reward/intrinsic_batch_mean :  5.857202640746874e-05
reward/extrinsic_batch_mean :  0.08151851851851852
loss/policy :  0.0007213876872838503
loss/rnd :  1.1551378227550506e-06
loss/value :  4.359613761757359
loss/value_i :  1.5299781042895946e-06
loss/value_e :  4.359612284284649
loss/entropy :  2.239741462649721
reward/intrinsic_running :  0.0009330542561902163
reward/extrinsic_running :  0.08151851851851852
reward/intrinsic_std_running :  0.020160689353820368
reward/extrinsic_std_running :  1.62688156299942
reward/intrinsic_batch_std :  4.676460558209958e-05
reward/intrinsic_batch_max :  0.0010862782364711165
reward/intrinsic_batch_min :  5.9987955864926334e-06
reward/total_batch :  0.04078854527246299
time/iteration_time :  115.13102912902832
time/fps :  2345.1540565785153
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2345
Policy Loss: 0.0007, Value Loss: 4.3596, Entropy: 2.2397
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.054, sum=196.1
Extrinsic raw: Œº=0.08151851851851852

=== Iteration 712/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.96s
EPOCH 1 took 18.79s
update_step :  712
reward/intrinsic_batch_mean :  5.236374725349446e-05
reward/extrinsic_batch_mean :  0.08481481481481482
loss/policy :  0.0007463555913559641
loss/rnd :  1.0564318234752468e-06
loss/value :  2.720227640686613
loss/value_i :  1.607007999210151e-06
loss/value_e :  2.7202260440046135
loss/entropy :  2.2289333921490293
reward/intrinsic_running :  0.0009318802475334201
reward/extrinsic_running :  0.08481481481481482
reward/intrinsic_std_running :  0.020146550971446374
reward/extrinsic_std_running :  1.6546541999046218
reward/intrinsic_batch_std :  4.043905102115021e-05
reward/intrinsic_batch_max :  0.0007468066760338843
reward/intrinsic_batch_min :  4.260960849933326e-06
reward/total_batch :  0.042433589281034155
time/iteration_time :  112.65190625190735
time/fps :  2396.7637031923596
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2397
Policy Loss: 0.0007, Value Loss: 2.7202, Entropy: 2.2289
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=175.4
Extrinsic raw: Œº=0.08481481481481482

=== Iteration 713/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 18.61s
update_step :  713
reward/intrinsic_batch_mean :  5.2128755367414634e-05
reward/extrinsic_batch_mean :  0.0845925925925926
loss/policy :  0.0010553480110088872
loss/rnd :  1.0467958494094394e-06
loss/value :  5.381455356424505
loss/value_i :  1.5687565692270724e-06
loss/value_e :  5.381453817540949
loss/entropy :  2.233935991923014
reward/intrinsic_running :  0.0009307079318465496
reward/extrinsic_running :  0.0845925925925926
reward/intrinsic_std_running :  0.020132442347118803
reward/extrinsic_std_running :  1.6271856016347221
reward/intrinsic_batch_std :  4.016498408777207e-05
reward/intrinsic_batch_max :  0.0006311057950370014
reward/intrinsic_batch_min :  4.513673047767952e-06
reward/total_batch :  0.04232236067398001
time/iteration_time :  113.20393657684326
time/fps :  2385.076068593454
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0011, Value Loss: 5.3815, Entropy: 2.2339
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=174.8
Extrinsic raw: Œº=0.0845925925925926

=== Iteration 714/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.12s
EPOCH 1 took 18.60s
update_step :  714
reward/intrinsic_batch_mean :  5.2161900574753454e-05
reward/extrinsic_batch_mean :  0.08448888888888889
loss/policy :  0.0018364546642370635
loss/rnd :  1.051791474710075e-06
loss/value :  3.8857752337600244
loss/value_i :  2.6445147778813958e-06
loss/value_e :  3.885772614768057
loss/entropy :  2.221006028579943
reward/intrinsic_running :  0.0009295382663336181
reward/extrinsic_running :  0.08448888888888889
reward/intrinsic_std_running :  0.020118363348823616
reward/extrinsic_std_running :  1.6358106377173172
reward/intrinsic_batch_std :  4.110176040005727e-05
reward/intrinsic_batch_max :  0.0006661557126790285
reward/intrinsic_batch_min :  3.816046046267729e-06
reward/total_batch :  0.04227052539473182
time/iteration_time :  114.88307905197144
time/fps :  2350.215560272857
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2350
Policy Loss: 0.0018, Value Loss: 3.8858, Entropy: 2.2210
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=175.0
Extrinsic raw: Œº=0.08448888888888889

=== Iteration 715/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 19.02s
update_step :  715
reward/intrinsic_batch_mean :  5.221231910758501e-05
reward/extrinsic_batch_mean :  0.08582222222222222
loss/policy :  0.0011108229651158167
loss/rnd :  1.0494767796885616e-06
loss/value :  3.398154027534254
loss/value_i :  1.9508627517414865e-05
loss/value_e :  3.398134500691385
loss/entropy :  2.2132224783752905
reward/intrinsic_running :  0.0009283744678336602
reward/extrinsic_running :  0.08582222222222222
reward/intrinsic_std_running :  0.020104313733884733
reward/extrinsic_std_running :  1.6577822394935493
reward/intrinsic_batch_std :  3.8467186877656175e-05
reward/intrinsic_batch_max :  0.000565698544960469
reward/intrinsic_batch_min :  4.613867986336118e-06
reward/total_batch :  0.0429372172706649
time/iteration_time :  112.70790195465088
time/fps :  2395.5729395853464
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0011, Value Loss: 3.3982, Entropy: 2.2132
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=175.3
Extrinsic raw: Œº=0.08582222222222222

=== Iteration 716/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.57s
EPOCH 1 took 18.38s
update_step :  716
reward/intrinsic_batch_mean :  5.207298986690013e-05
reward/extrinsic_batch_mean :  0.08462962962962962
loss/policy :  0.0015079185373686028
loss/rnd :  1.044050503479053e-06
loss/value :  3.9960982980150166
loss/value_i :  1.9812132536296274e-06
loss/value_e :  3.9960963256431348
loss/entropy :  2.2265119046875923
reward/intrinsic_running :  0.0009272120207223255
reward/extrinsic_running :  0.08462962962962962
reward/intrinsic_std_running :  0.020090293594489002
reward/extrinsic_std_running :  1.6452864356756796
reward/intrinsic_batch_std :  3.966153186457619e-05
reward/intrinsic_batch_max :  0.0005209593800827861
reward/intrinsic_batch_min :  3.964171355619328e-06
reward/total_batch :  0.04234085130974826
time/iteration_time :  115.01146531105042
time/fps :  2347.592035887731
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.0s | FPS: 2348
Policy Loss: 0.0015, Value Loss: 3.9961, Entropy: 2.2265
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.026, sum=175.0
Extrinsic raw: Œº=0.08462962962962962

=== Iteration 717/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.45s
EPOCH 1 took 18.90s
update_step :  717
reward/intrinsic_batch_mean :  5.140331047298753e-05
reward/extrinsic_batch_mean :  0.08270370370370371
loss/policy :  0.0004147281536213334
loss/rnd :  1.081675582719816e-06
loss/value :  4.245088259379069
loss/value_i :  1.639818268620619e-06
loss/value_e :  4.245086619348237
loss/entropy :  2.234746463371046
reward/intrinsic_running :  0.0009260507702517093
reward/extrinsic_running :  0.08270370370370371
reward/intrinsic_std_running :  0.020076302848518857
reward/extrinsic_std_running :  1.6213485771125227
reward/intrinsic_batch_std :  4.412791737036073e-05
reward/intrinsic_batch_max :  0.000933345640078187
reward/intrinsic_batch_min :  4.712052486866014e-06
reward/total_batch :  0.04137755350708835
time/iteration_time :  112.15240740776062
time/fps :  2407.438290810303
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.2s | FPS: 2407
Policy Loss: 0.0004, Value Loss: 4.2451, Entropy: 2.2347
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=172.8
Extrinsic raw: Œº=0.08270370370370371

=== Iteration 718/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 19.74s
update_step :  718
reward/intrinsic_batch_mean :  5.199475415886775e-05
reward/extrinsic_batch_mean :  0.08445925925925926
loss/policy :  0.0008497383449029064
loss/rnd :  1.0570422373899473e-06
loss/value :  5.16692435018944
loss/value_i :  1.8292434240472424e-06
loss/value_e :  5.1669225439880835
loss/entropy :  2.22844905203039
reward/intrinsic_running :  0.0009248927688839173
reward/extrinsic_running :  0.08445925925925926
reward/intrinsic_std_running :  0.02006234127611374
reward/extrinsic_std_running :  1.6358166960741678
reward/intrinsic_batch_std :  4.159311812588909e-05
reward/intrinsic_batch_max :  0.0006242426461540163
reward/intrinsic_batch_min :  4.290745437174337e-06
reward/total_batch :  0.04225562700670907
time/iteration_time :  114.71697759628296
time/fps :  2353.618493595568
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.7s | FPS: 2354
Policy Loss: 0.0008, Value Loss: 5.1669, Entropy: 2.2284
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=174.9
Extrinsic raw: Œº=0.08445925925925926

=== Iteration 719/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.46s
EPOCH 1 took 18.97s
update_step :  719
reward/intrinsic_batch_mean :  6.0832751173088415e-05
reward/extrinsic_batch_mean :  0.07973333333333334
loss/policy :  0.0012242856116217533
loss/rnd :  1.0842836586837648e-06
loss/value :  5.135592204151732
loss/value_i :  1.5328695360839255e-06
loss/value_e :  5.135590715841814
loss/entropy :  2.242410117929632
reward/intrinsic_running :  0.000923759916089203
reward/extrinsic_running :  0.07973333333333334
reward/intrinsic_std_running :  0.02004840790753697
reward/extrinsic_std_running :  1.603121377535435
reward/intrinsic_batch_std :  4.461458593690703e-05
reward/intrinsic_batch_max :  0.0006739155505783856
reward/intrinsic_batch_min :  1.1375256690371316e-05
reward/total_batch :  0.039897083042253215
time/iteration_time :  112.74856948852539
time/fps :  2394.708875020169
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0012, Value Loss: 5.1356, Entropy: 2.2424
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=204.8
Extrinsic raw: Œº=0.07973333333333334

=== Iteration 720/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.07s
EPOCH 1 took 19.56s
update_step :  720
reward/intrinsic_batch_mean :  5.1295034207463755e-05
reward/extrinsic_batch_mean :  0.08418518518518518
loss/policy :  0.0014791336346234223
loss/rnd :  1.027704778759168e-06
loss/value :  3.5946848103494355
loss/value_i :  1.6941414811078699e-06
loss/value_e :  3.594683101682952
loss/entropy :  2.212522055163528
reward/intrinsic_running :  0.0009226085432550763
reward/extrinsic_running :  0.08418518518518518
reward/intrinsic_std_running :  0.02003450440524093
reward/extrinsic_std_running :  1.6439580407603234
reward/intrinsic_batch_std :  4.107037496724126e-05
reward/intrinsic_batch_max :  0.0006174678565002978
reward/intrinsic_batch_min :  4.089966751052998e-06
reward/total_batch :  0.04211824010969632
time/iteration_time :  115.107346534729
time/fps :  2345.6365569033283
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2346
Policy Loss: 0.0015, Value Loss: 3.5947, Entropy: 2.2125
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=172.8
Extrinsic raw: Œº=0.08418518518518518

=== Iteration 721/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.53s
EPOCH 1 took 18.61s
update_step :  721
reward/intrinsic_batch_mean :  5.182949469717978e-05
reward/extrinsic_batch_mean :  0.08643703703703703
loss/policy :  0.0013847741391862546
loss/rnd :  1.0345377091019172e-06
loss/value :  2.6897758877638616
loss/value_i :  1.5928463571154596e-06
loss/value_e :  2.6897742983066673
loss/entropy :  2.2285396510904487
reward/intrinsic_running :  0.0009214598146458883
reward/extrinsic_running :  0.08643703703703703
reward/intrinsic_std_running :  0.02002062981364874
reward/extrinsic_std_running :  1.6772924968859009
reward/intrinsic_batch_std :  4.249252839927671e-05
reward/intrinsic_batch_max :  0.0007261697901412845
reward/intrinsic_batch_min :  4.79143545817351e-06
reward/total_batch :  0.043244433265867105
time/iteration_time :  112.89482879638672
time/fps :  2391.606443612779
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0014, Value Loss: 2.6898, Entropy: 2.2285
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=174.7
Extrinsic raw: Œº=0.08643703703703703

=== Iteration 722/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 18.69s
update_step :  722
reward/intrinsic_batch_mean :  5.0891903714909856e-05
reward/extrinsic_batch_mean :  0.08708888888888888
loss/policy :  0.0005753105047695113
loss/rnd :  1.0153602502352002e-06
loss/value :  5.666531107642434
loss/value_i :  1.9778032531052525e-06
loss/value_e :  5.666529120820941
loss/entropy :  2.228324882911913
reward/intrinsic_running :  0.0009203115598678233
reward/extrinsic_running :  0.08708888888888888
reward/intrinsic_std_running :  0.020006784106950126
reward/extrinsic_std_running :  1.653654977524441
reward/intrinsic_batch_std :  3.965564496517144e-05
reward/intrinsic_batch_max :  0.0005708571989089251
reward/intrinsic_batch_min :  4.2535780266916845e-06
reward/total_batch :  0.043569890396301894
time/iteration_time :  113.5493152141571
time/fps :  2377.8214733463838
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2378
Policy Loss: 0.0006, Value Loss: 5.6665, Entropy: 2.2283
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=171.7
Extrinsic raw: Œº=0.08708888888888888

=== Iteration 723/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.38s
EPOCH 1 took 18.81s
update_step :  723
reward/intrinsic_batch_mean :  4.9912139693744256e-05
reward/extrinsic_batch_mean :  0.08512592592592592
loss/policy :  0.0011910331518403395
loss/rnd :  1.0037861429599146e-06
loss/value :  2.2925729227788523
loss/value_i :  1.4340157973134464e-06
loss/value_e :  2.2925714778177664
loss/entropy :  2.2411155447815405
reward/intrinsic_running :  0.0009191644429314537
reward/extrinsic_running :  0.08512592592592592
reward/intrinsic_std_running :  0.0199929671677446
reward/extrinsic_std_running :  1.646603086625129
reward/intrinsic_batch_std :  3.957124037088828e-05
reward/intrinsic_batch_max :  0.0005031918408349156
reward/intrinsic_batch_min :  4.320608695707051e-06
reward/total_batch :  0.04258791903280983
time/iteration_time :  112.69913721084595
time/fps :  2395.759246096657
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0012, Value Loss: 2.2926, Entropy: 2.2411
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.025, sum=168.5
Extrinsic raw: Œº=0.08512592592592592

=== Iteration 724/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.59s
EPOCH 1 took 19.41s
update_step :  724
reward/intrinsic_batch_mean :  5.417711031119931e-05
reward/extrinsic_batch_mean :  0.0850888888888889
loss/policy :  0.0009833513733720986
loss/rnd :  1.1198756693154406e-06
loss/value :  3.4636927951465952
loss/value_i :  1.7306053939936454e-06
loss/value_e :  3.4636910846739104
loss/entropy :  2.234810308976607
reward/intrinsic_running :  0.0009180313556937662
reward/extrinsic_running :  0.0850888888888889
reward/intrinsic_std_running :  0.019979178384472555
reward/extrinsic_std_running :  1.6375887511902039
reward/intrinsic_batch_std :  4.236075453337162e-05
reward/intrinsic_batch_max :  0.0009224623790942132
reward/intrinsic_batch_min :  4.343144610174932e-06
reward/total_batch :  0.042571532999600044
time/iteration_time :  114.47860026359558
time/fps :  2358.519403437015
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2359
Policy Loss: 0.0010, Value Loss: 3.4637, Entropy: 2.2348
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=183.0
Extrinsic raw: Œº=0.0850888888888889

=== Iteration 725/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.82s
EPOCH 1 took 17.83s
update_step :  725
reward/intrinsic_batch_mean :  4.898910755936312e-05
reward/extrinsic_batch_mean :  0.08314814814814815
loss/policy :  0.0010332202112873677
loss/rnd :  9.76859734974465e-07
loss/value :  4.153362277782325
loss/value_i :  1.3906362538005905e-06
loss/value_e :  4.1533608617204605
loss/entropy :  2.258882244427999
reward/intrinsic_running :  0.0009168886828496934
reward/extrinsic_running :  0.08314814814814815
reward/intrinsic_std_running :  0.019965418599762773
reward/extrinsic_std_running :  1.6327077306142947
reward/intrinsic_batch_std :  3.87201394264895e-05
reward/intrinsic_batch_max :  0.0005569196073338389
reward/intrinsic_batch_min :  5.169632913748501e-06
reward/total_batch :  0.04159856862785376
time/iteration_time :  113.64508962631226
time/fps :  2375.8175640303853
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.6s | FPS: 2376
Policy Loss: 0.0010, Value Loss: 4.1534, Entropy: 2.2589
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.028, sum=165.6
Extrinsic raw: Œº=0.08314814814814815

=== Iteration 726/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 20.14s
update_step :  726
reward/intrinsic_batch_mean :  4.9021536894273327e-05
reward/extrinsic_batch_mean :  0.0867037037037037
loss/policy :  0.0009240616548622986
loss/rnd :  9.884206649117417e-07
loss/value :  3.7824971423004614
loss/value_i :  1.4816672667235031e-06
loss/value_e :  3.782495643153335
loss/entropy :  2.2323720021681352
reward/intrinsic_running :  0.0009157484731964052
reward/extrinsic_running :  0.0867037037037037
reward/intrinsic_std_running :  0.019951687234189726
reward/extrinsic_std_running :  1.660416353739043
reward/intrinsic_batch_std :  3.843460161487063e-05
reward/intrinsic_batch_max :  0.0006158218602649868
reward/intrinsic_batch_min :  3.956536147597944e-06
reward/total_batch :  0.04337636262029899
time/iteration_time :  114.13538455963135
time/fps :  2365.611690377539
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0009, Value Loss: 3.7825, Entropy: 2.2324
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=165.8
Extrinsic raw: Œº=0.0867037037037037

=== Iteration 727/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.81s
EPOCH 1 took 19.60s
update_step :  727
reward/intrinsic_batch_mean :  5.1638536423962686e-05
reward/extrinsic_batch_mean :  0.08388888888888889
loss/policy :  0.0012778281697220254
loss/rnd :  1.0212731905140213e-06
loss/value :  3.99183866110715
loss/value_i :  1.5874803332074159e-06
loss/value_e :  3.9918371149987886
loss/entropy :  2.2293297774863965
reward/intrinsic_running :  0.0009146173028048623
reward/extrinsic_running :  0.08388888888888889
reward/intrinsic_std_running :  0.019937983928079314
reward/extrinsic_std_running :  1.6340303690303868
reward/intrinsic_batch_std :  4.1685744007165906e-05
reward/intrinsic_batch_max :  0.0006686364067718387
reward/intrinsic_batch_min :  4.954743417329155e-06
reward/total_batch :  0.04197026371265643
time/iteration_time :  114.50453901290894
time/fps :  2357.9851272931714
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2358
Policy Loss: 0.0013, Value Loss: 3.9918, Entropy: 2.2293
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=174.8
Extrinsic raw: Œº=0.08388888888888889

=== Iteration 728/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.04s
EPOCH 1 took 19.88s
update_step :  728
reward/intrinsic_batch_mean :  5.232546873698151e-05
reward/extrinsic_batch_mean :  0.0816888888888889
loss/policy :  0.0008309025883632289
loss/rnd :  1.138523059856225e-06
loss/value :  3.3423868977662288
loss/value_i :  3.074120505089289e-06
loss/value_e :  3.3423838398673316
loss/entropy :  2.25169368946191
reward/intrinsic_running :  0.0009134892747171071
reward/extrinsic_running :  0.0816888888888889
reward/intrinsic_std_running :  0.019924308828945008
reward/extrinsic_std_running :  1.6181954625636943
reward/intrinsic_batch_std :  4.387104386798755e-05
reward/intrinsic_batch_max :  0.000576174701564014
reward/intrinsic_batch_min :  4.043897206429392e-06
reward/total_batch :  0.04087060717881294
time/iteration_time :  114.40081524848938
time/fps :  2360.1230411997894
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2360
Policy Loss: 0.0008, Value Loss: 3.3424, Entropy: 2.2517
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=177.3
Extrinsic raw: Œº=0.0816888888888889

=== Iteration 729/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.20s
EPOCH 1 took 19.11s
update_step :  729
reward/intrinsic_batch_mean :  9.978338827861956e-05
reward/extrinsic_batch_mean :  0.08828888888888889
loss/policy :  0.0011907550885525504
loss/rnd :  1.5220258219552776e-06
loss/value :  5.14251832889788
loss/value_i :  3.0049874667246046e-06
loss/value_e :  5.142515290867198
loss/entropy :  2.2443944360270645
reward/intrinsic_running :  0.0009124835459009911
reward/extrinsic_running :  0.08828888888888889
reward/intrinsic_std_running :  0.019910657218664796
reward/extrinsic_std_running :  1.6829387540479726
reward/intrinsic_batch_std :  4.813930161700469e-05
reward/intrinsic_batch_max :  0.0009757850202731788
reward/intrinsic_batch_min :  3.7296355003491044e-05
reward/total_batch :  0.044194336138583756
time/iteration_time :  112.69168329238892
time/fps :  2395.917712041449
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2396
Policy Loss: 0.0012, Value Loss: 5.1425, Entropy: 2.2444
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.049, sum=338.3
Extrinsic raw: Œº=0.08828888888888889

=== Iteration 730/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.45s
EPOCH 1 took 19.25s
update_step :  730
reward/intrinsic_batch_mean :  5.009374112669994e-05
reward/extrinsic_batch_mean :  0.08111851851851852
loss/policy :  0.0006025676372122358
loss/rnd :  1.0034029942014031e-06
loss/value :  3.236770994735487
loss/value_i :  1.4720424925337394e-06
loss/value_e :  3.23676953532479
loss/entropy :  2.242681550257134
reward/intrinsic_running :  0.0009113576187076935
reward/extrinsic_running :  0.08111851851851852
reward/intrinsic_std_running :  0.019897038370015014
reward/extrinsic_std_running :  1.6163886842421142
reward/intrinsic_batch_std :  3.886179616597908e-05
reward/intrinsic_batch_max :  0.0006534713320434093
reward/intrinsic_batch_min :  4.411064310261281e-06
reward/total_batch :  0.04058430612982261
time/iteration_time :  112.95396256446838
time/fps :  2390.3543874868287
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0006, Value Loss: 3.2368, Entropy: 2.2427
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=169.9
Extrinsic raw: Œº=0.08111851851851852

=== Iteration 731/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.62s
EPOCH 1 took 17.94s
update_step :  731
reward/intrinsic_batch_mean :  5.068987942407451e-05
reward/extrinsic_batch_mean :  0.09334074074074074
loss/policy :  0.0010983332088499358
loss/rnd :  1.0005818587683968e-06
loss/value :  3.4341007579456675
loss/value_i :  1.5104813438814413e-06
loss/value_e :  3.434099251573736
loss/entropy :  2.2215002450076016
reward/intrinsic_running :  0.0009102364129884991
reward/extrinsic_running :  0.09334074074074074
reward/intrinsic_std_running :  0.019883447366764003
reward/extrinsic_std_running :  1.7235478339018033
reward/intrinsic_batch_std :  4.0162706195471295e-05
reward/intrinsic_batch_max :  0.0006126496009528637
reward/intrinsic_batch_min :  4.186130354355555e-06
reward/total_batch :  0.0466957153100824
time/iteration_time :  112.90059781074524
time/fps :  2391.4842368912855
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2391
Policy Loss: 0.0011, Value Loss: 3.4341, Entropy: 2.2215
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=172.1
Extrinsic raw: Œº=0.09334074074074074

=== Iteration 732/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 18.15s
update_step :  732
reward/intrinsic_batch_mean :  5.011833813376951e-05
reward/extrinsic_batch_mean :  0.08343703703703703
loss/policy :  0.0009080948216389074
loss/rnd :  9.979405759126663e-07
loss/value :  4.685286803679033
loss/value_i :  1.445284130058457e-06
loss/value_e :  4.685285358717947
loss/entropy :  2.209454641197667
reward/intrinsic_running :  0.0009091167146687527
reward/extrinsic_running :  0.08343703703703703
reward/intrinsic_std_running :  0.01986988423612199
reward/extrinsic_std_running :  1.614444441113745
reward/intrinsic_batch_std :  3.7908188262149804e-05
reward/intrinsic_batch_max :  0.0005676937289535999
reward/intrinsic_batch_min :  3.9698570617474616e-06
reward/total_batch :  0.0417435776875854
time/iteration_time :  111.40370726585388
time/fps :  2423.617728947492
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.4s | FPS: 2424
Policy Loss: 0.0009, Value Loss: 4.6853, Entropy: 2.2095
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=170.3
Extrinsic raw: Œº=0.08343703703703703

=== Iteration 733/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.98s
EPOCH 1 took 18.96s
update_step :  733
reward/intrinsic_batch_mean :  5.236146050868195e-05
reward/extrinsic_batch_mean :  0.08654814814814815
loss/policy :  0.00219401276527523
loss/rnd :  1.009495023977665e-06
loss/value :  4.5898886955145635
loss/value_i :  1.9567053858405745e-06
loss/value_e :  4.589886752041903
loss/entropy :  2.212555285656091
reward/intrinsic_running :  0.0009080059010328899
reward/extrinsic_running :  0.08654814814814815
reward/intrinsic_std_running :  0.01985634859681498
reward/extrinsic_std_running :  1.6599794095934892
reward/intrinsic_batch_std :  4.1911815243701755e-05
reward/intrinsic_batch_max :  0.0007078362395986915
reward/intrinsic_batch_min :  4.870098109677201e-06
reward/total_batch :  0.04330025480432842
time/iteration_time :  114.90817832946777
time/fps :  2349.7022050584496
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2350
Policy Loss: 0.0022, Value Loss: 4.5899, Entropy: 2.2126
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=178.0
Extrinsic raw: Œº=0.08654814814814815

=== Iteration 734/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 18.05s
update_step :  734
reward/intrinsic_batch_mean :  5.427822723412208e-05
reward/extrinsic_batch_mean :  0.0886
loss/policy :  0.001947935162620111
loss/rnd :  1.0689510886687927e-06
loss/value :  4.813617717136037
loss/value_i :  1.6893259529834639e-06
loss/value_e :  4.813616040981177
loss/entropy :  2.1835419842691133
reward/intrinsic_running :  0.0009069016237297363
reward/extrinsic_running :  0.0886
reward/intrinsic_std_running :  0.019842840465675013
reward/extrinsic_std_running :  1.6758629737143387
reward/intrinsic_batch_std :  4.8248417998435496e-05
reward/intrinsic_batch_max :  0.0011724926298484206
reward/intrinsic_batch_min :  3.97261101170443e-06
reward/total_batch :  0.04432713911361706
time/iteration_time :  112.53644108772278
time/fps :  2399.2228418662494
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2399
Policy Loss: 0.0019, Value Loss: 4.8136, Entropy: 2.1835
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.059, sum=184.6
Extrinsic raw: Œº=0.0886

=== Iteration 735/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.33s
EPOCH 1 took 18.19s
update_step :  735
reward/intrinsic_batch_mean :  5.219361068443336e-05
reward/extrinsic_batch_mean :  0.0848962962962963
loss/policy :  0.0012079124166065771
loss/rnd :  1.037301367225816e-06
loss/value :  4.63846928061861
loss/value_i :  1.7060530935988496e-06
loss/value_e :  4.638467615300959
loss/entropy :  2.199915773940809
reward/intrinsic_running :  0.0009057942776817525
reward/extrinsic_running :  0.0848962962962963
reward/intrinsic_std_running :  0.01982936008599947
reward/extrinsic_std_running :  1.6280788577410246
reward/intrinsic_batch_std :  4.434569081065734e-05
reward/intrinsic_batch_max :  0.0008173037203960121
reward/intrinsic_batch_min :  3.906873189407634e-06
reward/total_batch :  0.04247424495349037
time/iteration_time :  113.67609667778015
time/fps :  2375.1695201615407
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: 0.0012, Value Loss: 4.6385, Entropy: 2.1999
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.041, sum=177.7
Extrinsic raw: Œº=0.0848962962962963

=== Iteration 736/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.33s
EPOCH 1 took 19.38s
update_step :  736
reward/intrinsic_batch_mean :  5.124375903852288e-05
reward/extrinsic_batch_mean :  0.08373333333333334
loss/policy :  0.0014000975070027353
loss/rnd :  1.0202962467894505e-06
loss/value :  4.610380053520203
loss/value_i :  1.5316673511733825e-06
loss/value_e :  4.610378554373076
loss/entropy :  2.2252030661611846
reward/intrinsic_running :  0.0009046881165503699
reward/extrinsic_running :  0.08373333333333334
reward/intrinsic_std_running :  0.01981590722254948
reward/extrinsic_std_running :  1.6425848608778737
reward/intrinsic_batch_std :  4.26050312144572e-05
reward/intrinsic_batch_max :  0.0006774692446924746
reward/intrinsic_batch_min :  4.410247584019089e-06
reward/total_batch :  0.04189228854618593
time/iteration_time :  113.513099193573
time/fps :  2378.580110296972
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: 0.0014, Value Loss: 4.6104, Entropy: 2.2252
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=174.6
Extrinsic raw: Œº=0.08373333333333334

=== Iteration 737/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.42s
EPOCH 1 took 19.71s
update_step :  737
reward/intrinsic_batch_mean :  5.191695708105086e-05
reward/extrinsic_batch_mean :  0.08745185185185185
loss/policy :  0.0010427214288166865
loss/rnd :  1.1106360712994612e-06
loss/value :  3.433962254813223
loss/value_i :  1.4446747152099058e-06
loss/value_e :  3.4339607990149297
loss/entropy :  2.2191654190872656
reward/intrinsic_running :  0.0009035864068067683
reward/extrinsic_running :  0.08745185185185185
reward/intrinsic_std_running :  0.019802481640943535
reward/extrinsic_std_running :  1.6714920002623448
reward/intrinsic_batch_std :  4.281775091328966e-05
reward/intrinsic_batch_max :  0.0008596028783358634
reward/intrinsic_batch_min :  4.554363385977922e-06
reward/total_batch :  0.04375188440446645
time/iteration_time :  114.31434631347656
time/fps :  2361.908270547225
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0010, Value Loss: 3.4340, Entropy: 2.2192
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.043, sum=177.0
Extrinsic raw: Œº=0.08745185185185185

=== Iteration 738/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.42s
EPOCH 1 took 18.68s
update_step :  738
reward/intrinsic_batch_mean :  5.237713678346794e-05
reward/extrinsic_batch_mean :  0.0863037037037037
loss/policy :  0.000781128636321448
loss/rnd :  1.0591603299734274e-06
loss/value :  2.398156084797599
loss/value_i :  7.240724359593459e-06
loss/value_e :  2.398148845542561
loss/entropy :  2.219971779621009
reward/intrinsic_running :  0.00090248968554387
reward/extrinsic_running :  0.0863037037037037
reward/intrinsic_std_running :  0.01978908322090489
reward/extrinsic_std_running :  1.6590916201525325
reward/intrinsic_batch_std :  4.183093806109331e-05
reward/intrinsic_batch_max :  0.0006905361078679562
reward/intrinsic_batch_min :  5.1399151743680704e-06
reward/total_batch :  0.043178040420243584
time/iteration_time :  112.51271152496338
time/fps :  2399.7288514382185
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.5s | FPS: 2400
Policy Loss: 0.0008, Value Loss: 2.3982, Entropy: 2.2200
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=178.7
Extrinsic raw: Œº=0.0863037037037037

=== Iteration 739/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.67s
update_step :  739
reward/intrinsic_batch_mean :  5.322618806042522e-05
reward/extrinsic_batch_mean :  0.08231111111111111
loss/policy :  0.0006235048693435436
loss/rnd :  1.066717462697742e-06
loss/value :  2.5505623546513645
loss/value_i :  1.741063940561148e-06
loss/value_e :  2.5505606243104646
loss/entropy :  2.2231336362434155
reward/intrinsic_running :  0.0009013961112661373
reward/extrinsic_running :  0.08231111111111111
reward/intrinsic_std_running :  0.019775711955173816
reward/extrinsic_std_running :  1.6199893893875956
reward/intrinsic_batch_std :  4.228905339077262e-05
reward/intrinsic_batch_max :  0.0005557822296395898
reward/intrinsic_batch_min :  4.90605316372239e-06
reward/total_batch :  0.04118216864958577
time/iteration_time :  113.21681547164917
time/fps :  2384.8047560356545
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0006, Value Loss: 2.5506, Entropy: 2.2231
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=181.7
Extrinsic raw: Œº=0.08231111111111111

=== Iteration 740/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.52s
EPOCH 1 took 18.06s
update_step :  740
reward/intrinsic_batch_mean :  5.4570234147791374e-05
reward/extrinsic_batch_mean :  0.08554074074074074
loss/policy :  0.0010861774384410996
loss/rnd :  1.0081450513456676e-06
loss/value :  3.2102130687598027
loss/value_i :  1.4576326944651639e-06
loss/value_e :  3.210211584062287
loss/entropy :  2.2146092653274536
reward/intrinsic_running :  0.0009003107504366353
reward/extrinsic_running :  0.08554074074074074
reward/intrinsic_std_running :  0.01976236753553617
reward/extrinsic_std_running :  1.6569006665188362
reward/intrinsic_batch_std :  3.928861365281875e-05
reward/intrinsic_batch_max :  0.0005507511086761951
reward/intrinsic_batch_min :  8.091131348919589e-06
reward/total_batch :  0.04279765548744426
time/iteration_time :  111.84149169921875
time/fps :  2414.1308909409518
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2414
Policy Loss: 0.0011, Value Loss: 3.2102, Entropy: 2.2146
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=186.4
Extrinsic raw: Œº=0.08554074074074074

=== Iteration 741/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 19.52s
update_step :  741
reward/intrinsic_batch_mean :  5.111078396928658e-05
reward/extrinsic_batch_mean :  0.08156296296296296
loss/policy :  0.0012208244390256534
loss/rnd :  1.0092256326805165e-06
loss/value :  3.191889388994737
loss/value_i :  1.7184268499752788e-06
loss/value_e :  3.1918876532352334
loss/entropy :  2.2297339909004443
reward/intrinsic_running :  0.0008992172021143076
reward/extrinsic_running :  0.08156296296296296
reward/intrinsic_std_running :  0.019749050564019106
reward/extrinsic_std_running :  1.6085567725386973
reward/intrinsic_batch_std :  4.470465267067095e-05
reward/intrinsic_batch_max :  0.000668079883325845
reward/intrinsic_batch_min :  4.5175002014730126e-06
reward/total_batch :  0.040807036873466124
time/iteration_time :  113.98768281936646
time/fps :  2368.676977387658
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.0s | FPS: 2369
Policy Loss: 0.0012, Value Loss: 3.1919, Entropy: 2.2297
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=174.7
Extrinsic raw: Œº=0.08156296296296296

=== Iteration 742/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.09s
EPOCH 1 took 18.78s
update_step :  742
reward/intrinsic_batch_mean :  5.229489397544832e-05
reward/extrinsic_batch_mean :  0.08758518518518518
loss/policy :  0.0008212853931719578
loss/rnd :  1.0330697588153381e-06
loss/value :  3.945943153265751
loss/value_i :  1.526097030295425e-06
loss/value_e :  3.9459416595372288
loss/entropy :  2.2081181605656943
reward/intrinsic_running :  0.0008981313312731938
reward/extrinsic_running :  0.08758518518518518
reward/intrinsic_std_running :  0.019735760298878417
reward/extrinsic_std_running :  1.6630458285713803
reward/intrinsic_batch_std :  4.466489174760403e-05
reward/intrinsic_batch_max :  0.0006469758809544146
reward/intrinsic_batch_min :  3.977342203143053e-06
reward/total_batch :  0.04381874003958031
time/iteration_time :  112.74041390419006
time/fps :  2394.88210704507
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0008, Value Loss: 3.9459, Entropy: 2.2081
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=178.9
Extrinsic raw: Œº=0.08758518518518518

=== Iteration 743/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.39s
EPOCH 1 took 20.15s
update_step :  743
reward/intrinsic_batch_mean :  5.274834959087726e-05
reward/extrinsic_batch_mean :  0.0932962962962963
loss/policy :  0.0011163608984189164
loss/rnd :  1.0419716121842528e-06
loss/value :  5.390351714509906
loss/value_i :  1.8152447106937568e-06
loss/value_e :  5.390349901083744
loss/entropy :  2.202585310646982
reward/intrinsic_running :  0.0008970482011577401
reward/extrinsic_running :  0.0932962962962963
reward/intrinsic_std_running :  0.019722496816406473
reward/extrinsic_std_running :  1.7235566868975465
reward/intrinsic_batch_std :  4.33872584187941e-05
reward/intrinsic_batch_max :  0.0007523754029534757
reward/intrinsic_batch_min :  3.980855581176002e-06
reward/total_batch :  0.046674522322943585
time/iteration_time :  114.323326587677
time/fps :  2361.7227389979003
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0011, Value Loss: 5.3904, Entropy: 2.2026
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.038, sum=180.5
Extrinsic raw: Œº=0.0932962962962963

=== Iteration 744/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.84s
EPOCH 1 took 18.09s
update_step :  744
reward/intrinsic_batch_mean :  5.132685371439341e-05
reward/extrinsic_batch_mean :  0.0866962962962963
loss/policy :  0.0005547726592119558
loss/rnd :  1.0135562485464271e-06
loss/value :  3.9528514778975286
loss/value_i :  1.4303877213189315e-06
loss/value_e :  3.9528500509984568
loss/entropy :  2.208419944300796
reward/intrinsic_running :  0.0008959662504681916
reward/extrinsic_running :  0.0866962962962963
reward/intrinsic_std_running :  0.01970926013014359
reward/extrinsic_std_running :  1.6604178558158813
reward/intrinsic_batch_std :  4.472227292585041e-05
reward/intrinsic_batch_max :  0.0006930027157068253
reward/intrinsic_batch_min :  3.899585408362327e-06
reward/total_batch :  0.04337381157500535
time/iteration_time :  112.7218017578125
time/fps :  2395.277539833033
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.7s | FPS: 2395
Policy Loss: 0.0006, Value Loss: 3.9529, Entropy: 2.2084
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=175.8
Extrinsic raw: Œº=0.0866962962962963

=== Iteration 745/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.80s
EPOCH 1 took 19.78s
update_step :  745
reward/intrinsic_batch_mean :  5.066859051390498e-05
reward/extrinsic_batch_mean :  0.08768148148148149
loss/policy :  0.0014999462662010708
loss/rnd :  9.956055817617722e-07
loss/value :  5.828219551028627
loss/value_i :  1.422633707107073e-06
loss/value_e :  5.828218120517152
loss/entropy :  2.2035911083221436
reward/intrinsic_running :  0.0008948847079253735
reward/extrinsic_running :  0.08768148148148149
reward/intrinsic_std_running :  0.01969605012865187
reward/extrinsic_std_running :  1.6723760305131266
reward/intrinsic_batch_std :  4.0666867369469e-05
reward/intrinsic_batch_max :  0.0005695772706530988
reward/intrinsic_batch_min :  4.2229653445247095e-06
reward/total_batch :  0.043866075035997695
time/iteration_time :  113.18911981582642
time/fps :  2385.3882814825797
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0015, Value Loss: 5.8282, Entropy: 2.2036
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=173.6
Extrinsic raw: Œº=0.08768148148148149

=== Iteration 746/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 19.45s
update_step :  746
reward/intrinsic_batch_mean :  5.100148428731093e-05
reward/extrinsic_batch_mean :  0.08416296296296297
loss/policy :  0.0007507733023499675
loss/rnd :  1.0039548628397328e-06
loss/value :  5.060816923777263
loss/value_i :  1.3929574238042706e-06
loss/value_e :  5.0608155077153985
loss/entropy :  2.23302744735371
reward/intrinsic_running :  0.000893807111366489
reward/extrinsic_running :  0.08416296296296297
reward/intrinsic_std_running :  0.019682866625383707
reward/extrinsic_std_running :  1.6349260724362924
reward/intrinsic_batch_std :  4.198558412123833e-05
reward/intrinsic_batch_max :  0.0006792301428504288
reward/intrinsic_batch_min :  4.205567620374495e-06
reward/total_batch :  0.04210698222362514
time/iteration_time :  113.94976496696472
time/fps :  2369.465176854695
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2369
Policy Loss: 0.0008, Value Loss: 5.0608, Entropy: 2.2330
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=174.9
Extrinsic raw: Œº=0.08416296296296297

=== Iteration 747/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 19.22s
update_step :  747
reward/intrinsic_batch_mean :  5.1772476394920953e-05
reward/extrinsic_batch_mean :  0.0882
loss/policy :  0.0006053625891747123
loss/rnd :  1.0180375063624303e-06
loss/value :  3.876720867373727
loss/value_i :  1.4155008192105787e-06
loss/value_e :  3.8767194495056616
loss/entropy :  2.233952446417375
reward/intrinsic_running :  0.0008927346879125295
reward/extrinsic_running :  0.0882
reward/intrinsic_std_running :  0.01966970946676864
reward/extrinsic_std_running :  1.7130356477231792
reward/intrinsic_batch_std :  4.2942968824946344e-05
reward/intrinsic_batch_max :  0.0008587241754867136
reward/intrinsic_batch_min :  3.7447614431584952e-06
reward/total_batch :  0.04412588623819746
time/iteration_time :  112.85674905776978
time/fps :  2392.413411286469
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.9s | FPS: 2392
Policy Loss: 0.0006, Value Loss: 3.8767, Entropy: 2.2340
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=177.7
Extrinsic raw: Œº=0.0882

=== Iteration 748/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.63s
EPOCH 1 took 18.92s
update_step :  748
reward/intrinsic_batch_mean :  5.2465811365760196e-05
reward/extrinsic_batch_mean :  0.08386666666666667
loss/policy :  0.0010329421228644524
loss/rnd :  1.0334214886659703e-06
loss/value :  4.811782515410221
loss/value_i :  5.884595108193135e-06
loss/value_e :  4.811776594682173
loss/entropy :  2.234196005445538
reward/intrinsic_running :  0.0008916649964474156
reward/extrinsic_running :  0.08386666666666667
reward/intrinsic_std_running :  0.019656578706847762
reward/extrinsic_std_running :  1.634034909641139
reward/intrinsic_batch_std :  4.700320901208179e-05
reward/intrinsic_batch_max :  0.0008566626347601414
reward/intrinsic_batch_min :  3.865186954499222e-06
reward/total_batch :  0.04195956623901621
time/iteration_time :  113.65004754066467
time/fps :  2375.7139204309824
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2376
Policy Loss: 0.0010, Value Loss: 4.8118, Entropy: 2.2342
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.044, sum=180.2
Extrinsic raw: Œº=0.08386666666666667

=== Iteration 749/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.63s
EPOCH 1 took 18.97s
update_step :  749
reward/intrinsic_batch_mean :  5.01443712135841e-05
reward/extrinsic_batch_mean :  0.08728148148148149
loss/policy :  0.0017168491771868007
loss/rnd :  9.871542254062882e-07
loss/value :  4.305160585677985
loss/value_i :  3.051439629568146e-06
loss/value_e :  4.305157535003893
loss/entropy :  2.2323873693292793
reward/intrinsic_running :  0.0008905945521150749
reward/extrinsic_running :  0.08728148148148149
reward/intrinsic_std_running :  0.019643474302600494
reward/extrinsic_std_running :  1.6710610120379688
reward/intrinsic_batch_std :  4.014769425684694e-05
reward/intrinsic_batch_max :  0.0006560381734743714
reward/intrinsic_batch_min :  4.175465164735215e-06
reward/total_batch :  0.04366581292634754
time/iteration_time :  112.77800178527832
time/fps :  2394.083914645533
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0017, Value Loss: 4.3052, Entropy: 2.2324
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=172.3
Extrinsic raw: Œº=0.08728148148148149

=== Iteration 750/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.25s
EPOCH 1 took 19.30s
update_step :  750
reward/intrinsic_batch_mean :  5.0058779774213625e-05
reward/extrinsic_batch_mean :  0.08091851851851851
loss/policy :  0.0006923253064142597
loss/rnd :  1.0040443895019107e-06
loss/value :  5.073069084774364
loss/value_i :  1.5417247141158441e-06
loss/value_e :  5.073067582014835
loss/entropy :  2.2189694823640767
reward/intrinsic_running :  0.0008895256118204345
reward/extrinsic_running :  0.08091851851851851
reward/intrinsic_std_running :  0.019630396123506054
reward/extrinsic_std_running :  1.5882066432013555
reward/intrinsic_batch_std :  3.942411579592193e-05
reward/intrinsic_batch_max :  0.0006295841303654015
reward/intrinsic_batch_min :  3.5454393128020456e-06
reward/total_batch :  0.04048428864914636
time/iteration_time :  114.93399548530579
time/fps :  2349.1744010110506
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2349
Policy Loss: 0.0007, Value Loss: 5.0731, Entropy: 2.2190
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=172.1
Extrinsic raw: Œº=0.08091851851851851

=== Iteration 751/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.97s
EPOCH 1 took 19.20s
update_step :  751
reward/intrinsic_batch_mean :  5.192733493103905e-05
reward/extrinsic_batch_mean :  0.08773333333333333
loss/policy :  0.0012590322682323556
loss/rnd :  1.2136638223168892e-06
loss/value :  4.13941617084272
loss/value_i :  1.6699984292134822e-06
loss/value_e :  4.139414476625847
loss/entropy :  2.2181520425912105
reward/intrinsic_running :  0.0008884632268030227
reward/extrinsic_running :  0.08773333333333333
reward/intrinsic_std_running :  0.01961734388427519
reward/extrinsic_std_running :  1.681200819520249
reward/intrinsic_batch_std :  4.089742440506898e-05
reward/intrinsic_batch_max :  0.0007600104436278343
reward/intrinsic_batch_min :  5.246270120551344e-06
reward/total_batch :  0.04389263033413218
time/iteration_time :  114.17891311645508
time/fps :  2364.70984554405
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.2s | FPS: 2365
Policy Loss: 0.0013, Value Loss: 4.1394, Entropy: 2.2182
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=178.7
Extrinsic raw: Œº=0.08773333333333333

=== Iteration 752/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.02s
EPOCH 1 took 19.28s
update_step :  752
reward/intrinsic_batch_mean :  9.963209160357817e-05
reward/extrinsic_batch_mean :  0.08801481481481481
loss/policy :  0.0012593023429596515
loss/rnd :  1.6663769039923588e-06
loss/value :  4.66699856339079
loss/value_i :  3.5807603663587626e-06
loss/value_e :  4.666994994336909
loss/entropy :  2.221781094868978
reward/intrinsic_running :  0.0008875168413525796
reward/extrinsic_running :  0.08801481481481481
reward/intrinsic_std_running :  0.0196043133252407
reward/extrinsic_std_running :  1.6732386161116377
reward/intrinsic_batch_std :  4.4858536117421504e-05
reward/intrinsic_batch_max :  0.0007342928438447416
reward/intrinsic_batch_min :  3.2795498555060476e-05
reward/total_batch :  0.04405722345320919
time/iteration_time :  114.30358815193176
time/fps :  2362.130571449055
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0013, Value Loss: 4.6670, Entropy: 2.2218
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.037, sum=343.0
Extrinsic raw: Œº=0.08801481481481481

=== Iteration 753/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.67s
EPOCH 1 took 18.19s
update_step :  753
reward/intrinsic_batch_mean :  6.366521138691125e-05
reward/extrinsic_batch_mean :  0.08668148148148148
loss/policy :  0.0009240143987026937
loss/rnd :  1.019504698736758e-06
loss/value :  4.464792959617846
loss/value_i :  1.927552180845713e-06
loss/value_e :  4.464791052269213
loss/entropy :  2.2158311388709326
reward/intrinsic_running :  0.000886488820659771
reward/extrinsic_running :  0.08668148148148148
reward/intrinsic_std_running :  0.019591311857240473
reward/extrinsic_std_running :  1.6604208598663435
reward/intrinsic_batch_std :  4.262362096308105e-05
reward/intrinsic_batch_max :  0.0011988362530246377
reward/intrinsic_batch_min :  1.3887701243220363e-05
reward/total_batch :  0.0433725733464342
time/iteration_time :  112.98857831954956
time/fps :  2389.62206636849
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0009, Value Loss: 4.4648, Entropy: 2.2158
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.061, sum=219.4
Extrinsic raw: Œº=0.08668148148148148

=== Iteration 754/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.08s
EPOCH 1 took 20.04s
update_step :  754
reward/intrinsic_batch_mean :  5.1050567764435036e-05
reward/extrinsic_batch_mean :  0.08242962962962963
loss/policy :  0.0007456178903918375
loss/rnd :  9.849974250383555e-07
loss/value :  3.347585542635484
loss/value_i :  1.418211612954937e-06
loss/value_e :  3.3475840994806
loss/entropy :  2.2280597108783144
reward/intrinsic_running :  0.0008854332326929507
reward/extrinsic_running :  0.08242962962962963
reward/intrinsic_std_running :  0.019578337429547656
reward/extrinsic_std_running :  1.6386279786624594
reward/intrinsic_batch_std :  3.9181366432216536e-05
reward/intrinsic_batch_max :  0.0006749779568053782
reward/intrinsic_batch_min :  4.298978637962136e-06
reward/total_batch :  0.04124034009869703
time/iteration_time :  114.64090871810913
time/fps :  2355.1802146291757
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.6s | FPS: 2355
Policy Loss: 0.0007, Value Loss: 3.3476, Entropy: 2.2281
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=176.0
Extrinsic raw: Œº=0.08242962962962963

=== Iteration 755/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.20s
EPOCH 1 took 19.05s
update_step :  755
reward/intrinsic_batch_mean :  4.8733822142801526e-05
reward/extrinsic_batch_mean :  0.08331111111111111
loss/policy :  0.0009033627698734177
loss/rnd :  9.535410358142998e-07
loss/value :  3.344080589034341
loss/value_i :  1.302644863464979e-06
loss/value_e :  3.3440792921817666
loss/entropy :  2.2370751445943657
reward/intrinsic_running :  0.0008843753629096175
reward/extrinsic_running :  0.08331111111111111
reward/intrinsic_std_running :  0.019565388944628195
reward/extrinsic_std_running :  1.6322434003618127
reward/intrinsic_batch_std :  3.8327105240257e-05
reward/intrinsic_batch_max :  0.0005988666089251637
reward/intrinsic_batch_min :  4.2734404814837035e-06
reward/total_batch :  0.04167992246662696
time/iteration_time :  112.96157097816467
time/fps :  2390.1933875564696
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2390
Policy Loss: 0.0009, Value Loss: 3.3441, Entropy: 2.2371
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.031, sum=168.1
Extrinsic raw: Œº=0.08331111111111111

=== Iteration 756/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.43s
EPOCH 1 took 20.39s
update_step :  756
reward/intrinsic_batch_mean :  4.8253460029243594e-05
reward/extrinsic_batch_mean :  0.08578518518518519
loss/policy :  0.0008945078403815966
loss/rnd :  9.467189126112454e-07
loss/value :  5.069967414393569
loss/value_i :  1.5057329960654897e-06
loss/value_e :  5.0699658791224165
loss/entropy :  2.231015089786414
reward/intrinsic_running :  0.000883318947214027
reward/extrinsic_running :  0.08578518518518519
reward/intrinsic_std_running :  0.019552466169869435
reward/extrinsic_std_running :  1.6488290385297806
reward/intrinsic_batch_std :  3.8117649010828635e-05
reward/intrinsic_batch_max :  0.0005903506535105407
reward/intrinsic_batch_min :  4.245385753165465e-06
reward/total_batch :  0.04291671932260722
time/iteration_time :  114.71510004997253
time/fps :  2353.6570153570174
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.7s | FPS: 2354
Policy Loss: 0.0009, Value Loss: 5.0700, Entropy: 2.2310
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=166.6
Extrinsic raw: Œº=0.08578518518518519

=== Iteration 757/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.68s
EPOCH 1 took 19.06s
update_step :  757
reward/intrinsic_batch_mean :  4.974375244771552e-05
reward/extrinsic_batch_mean :  0.08962222222222223
loss/policy :  0.0007676069984551181
loss/rnd :  9.768464689262724e-07
loss/value :  4.361246643644391
loss/value_i :  1.7784427379383212e-06
loss/value_e :  4.361244873567061
loss/entropy :  2.233567902536103
reward/intrinsic_running :  0.0008822687096140562
reward/extrinsic_running :  0.08962222222222223
reward/intrinsic_std_running :  0.01953956883651806
reward/extrinsic_std_running :  1.695585031198581
reward/intrinsic_batch_std :  4.0015025734614135e-05
reward/intrinsic_batch_max :  0.0007102595409378409
reward/intrinsic_batch_min :  4.233975687384373e-06
reward/total_batch :  0.044835982987334974
time/iteration_time :  114.77975535392761
time/fps :  2352.331203071875
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.8s | FPS: 2352
Policy Loss: 0.0008, Value Loss: 4.3612, Entropy: 2.2336
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=171.8
Extrinsic raw: Œº=0.08962222222222223

=== Iteration 758/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.82s
EPOCH 1 took 19.21s
update_step :  758
reward/intrinsic_batch_mean :  4.778472308615299e-05
reward/extrinsic_batch_mean :  0.08714074074074074
loss/policy :  0.0007987701194934109
loss/rnd :  9.39947160428677e-07
loss/value :  3.5790335463755056
loss/value_i :  1.5440828633472847e-06
loss/value_e :  3.5790319822051306
loss/entropy :  2.2398955171758477
reward/intrinsic_running :  0.0008812174840109
reward/extrinsic_running :  0.08714074074074074
reward/intrinsic_std_running :  0.019526697138333965
reward/extrinsic_std_running :  1.6706239161106649
reward/intrinsic_batch_std :  3.768547488912792e-05
reward/intrinsic_batch_max :  0.0005807935958728194
reward/intrinsic_batch_min :  3.351193754497217e-06
reward/total_batch :  0.04359426273191345
time/iteration_time :  114.29245209693909
time/fps :  2362.360725019662
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0008, Value Loss: 3.5790, Entropy: 2.2399
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.030, sum=165.2
Extrinsic raw: Œº=0.08714074074074074

=== Iteration 759/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.69s
EPOCH 1 took 18.75s
update_step :  759
reward/intrinsic_batch_mean :  5.110067305606073e-05
reward/extrinsic_batch_mean :  0.08905925925925925
loss/policy :  0.0012395443865733052
loss/rnd :  1.1171511297988852e-06
loss/value :  3.7185889554746225
loss/value_i :  5.619690765260285e-06
loss/value_e :  3.7185833291573958
loss/entropy :  2.2145248181892163
reward/intrinsic_running :  0.0008801753092702534
reward/extrinsic_running :  0.08905925925925925
reward/intrinsic_std_running :  0.01951385060051866
reward/extrinsic_std_running :  1.6762783745789165
reward/intrinsic_batch_std :  4.212642486913981e-05
reward/intrinsic_batch_max :  0.0005775904282927513
reward/intrinsic_batch_min :  4.5552023948403075e-06
reward/total_batch :  0.04455517996615766
time/iteration_time :  114.71680474281311
time/fps :  2353.622039990747
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.7s | FPS: 2354
Policy Loss: 0.0012, Value Loss: 3.7186, Entropy: 2.2145
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=176.8
Extrinsic raw: Œº=0.08905925925925925

=== Iteration 760/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.52s
EPOCH 1 took 19.19s
update_step :  760
reward/intrinsic_batch_mean :  5.923069793041375e-05
reward/extrinsic_batch_mean :  0.0830074074074074
loss/policy :  0.0014936325641236071
loss/rnd :  1.2399839220327549e-06
loss/value :  4.37924642273874
loss/value_i :  1.891286803074212e-06
loss/value_e :  4.379244544289329
loss/entropy :  2.233215306744431
reward/intrinsic_running :  0.0008791530473211766
reward/extrinsic_running :  0.0830074074074074
reward/intrinsic_std_running :  0.019501028702439794
reward/extrinsic_std_running :  1.6130872608313045
reward/intrinsic_batch_std :  4.465275610001945e-05
reward/intrinsic_batch_max :  0.0006597447209060192
reward/intrinsic_batch_min :  8.804068784229457e-06
reward/total_batch :  0.04153331905266891
time/iteration_time :  112.12373089790344
time/fps :  2408.054011740423
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.1s | FPS: 2408
Policy Loss: 0.0015, Value Loss: 4.3792, Entropy: 2.2332
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=205.0
Extrinsic raw: Œº=0.0830074074074074

=== Iteration 761/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.48s
EPOCH 1 took 18.56s
update_step :  761
reward/intrinsic_batch_mean :  5.086960315832214e-05
reward/extrinsic_batch_mean :  0.08728148148148149
loss/policy :  0.0010950975719782891
loss/rnd :  9.916830094880424e-07
loss/value :  4.1911526701667094
loss/value_i :  1.3397593992329238e-06
loss/value_e :  4.19115129925988
loss/entropy :  2.2331063747406006
reward/intrinsic_running :  0.0008781156966226552
reward/extrinsic_running :  0.08728148148148149
reward/intrinsic_std_running :  0.019488232744106524
reward/extrinsic_std_running :  1.6541307716311502
reward/intrinsic_batch_std :  3.9701684256425234e-05
reward/intrinsic_batch_max :  0.0005732144345529377
reward/intrinsic_batch_min :  3.8400648918468505e-06
reward/total_batch :  0.043666175542319906
time/iteration_time :  114.40228271484375
time/fps :  2360.092767318247
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2360
Policy Loss: 0.0011, Value Loss: 4.1912, Entropy: 2.2331
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=176.2
Extrinsic raw: Œº=0.08728148148148149

=== Iteration 762/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.90s
EPOCH 1 took 18.51s
update_step :  762
reward/intrinsic_batch_mean :  5.1707111460267765e-05
reward/extrinsic_batch_mean :  0.0836
loss/policy :  0.0014353160107875187
loss/rnd :  1.0063457332101031e-06
loss/value :  4.477425074938572
loss/value_i :  1.7975582293825994e-05
loss/value_e :  4.4774071032350715
loss/entropy :  2.2344958818320073
reward/intrinsic_running :  0.0008770815139942244
reward/extrinsic_running :  0.0836
reward/intrinsic_std_running :  0.019475461937486865
reward/extrinsic_std_running :  1.6331371546584585
reward/intrinsic_batch_std :  4.5218084947731906e-05
reward/intrinsic_batch_max :  0.0007161861285567284
reward/intrinsic_batch_min :  4.217155037622433e-06
reward/total_batch :  0.04182585355573013
time/iteration_time :  113.98210835456848
time/fps :  2368.792821063642
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.0s | FPS: 2369
Policy Loss: 0.0014, Value Loss: 4.4774, Entropy: 2.2345
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=179.2
Extrinsic raw: Œº=0.0836

=== Iteration 763/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.28s
EPOCH 1 took 18.94s
update_step :  763
reward/intrinsic_batch_mean :  4.9546849975888985e-05
reward/extrinsic_batch_mean :  0.08477037037037037
loss/policy :  0.0012064323095590667
loss/rnd :  9.6657971291527e-07
loss/value :  4.5882356058467515
loss/value_i :  3.892788463348772e-06
loss/value_e :  4.588231736963445
loss/entropy :  2.223347555507313
reward/intrinsic_running :  0.000876045912047208
reward/extrinsic_running :  0.08477037037037037
reward/intrinsic_std_running :  0.019462716366630033
reward/extrinsic_std_running :  1.6276269658195102
reward/intrinsic_batch_std :  4.115474466413001e-05
reward/intrinsic_batch_max :  0.0005956727545708418
reward/intrinsic_batch_min :  4.416785486682784e-06
reward/total_batch :  0.04240995861017313
time/iteration_time :  115.71682167053223
time/fps :  2333.282197887713
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.7s | FPS: 2333
Policy Loss: 0.0012, Value Loss: 4.5882, Entropy: 2.2233
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=171.8
Extrinsic raw: Œº=0.08477037037037037

=== Iteration 764/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.54s
EPOCH 1 took 18.65s
update_step :  764
reward/intrinsic_batch_mean :  5.1966390058091576e-05
reward/extrinsic_batch_mean :  0.08684444444444445
loss/policy :  0.0010494626979131929
loss/rnd :  9.993882864970753e-07
loss/value :  4.205417624025634
loss/value_i :  1.4230053855526696e-06
loss/value_e :  4.205416177258347
loss/entropy :  2.238678495089213
reward/intrinsic_running :  0.0008750183810880204
reward/extrinsic_running :  0.08684444444444445
reward/intrinsic_std_running :  0.019449995574811564
reward/extrinsic_std_running :  1.6697523341154377
reward/intrinsic_batch_std :  4.3980196697631045e-05
reward/intrinsic_batch_max :  0.0007275707321241498
reward/intrinsic_batch_min :  5.0435228331480175e-06
reward/total_batch :  0.04344820541725127
time/iteration_time :  113.23008608818054
time/fps :  2384.5252558558623
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2385
Policy Loss: 0.0010, Value Loss: 4.2054, Entropy: 2.2387
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=180.3
Extrinsic raw: Œº=0.08684444444444445

=== Iteration 765/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 19.60s
update_step :  765
reward/intrinsic_batch_mean :  5.186120052363145e-05
reward/extrinsic_batch_mean :  0.08582962962962963
loss/policy :  0.0009955256440055866
loss/rnd :  1.0040046809287808e-06
loss/value :  3.5651493776928294
loss/value_i :  1.3709929837866432e-06
loss/value_e :  3.565147983305382
loss/entropy :  2.2239228559262827
reward/intrinsic_running :  0.0008739941200363005
reward/extrinsic_running :  0.08582962962962963
reward/intrinsic_std_running :  0.019437299684299587
reward/extrinsic_std_running :  1.6577807389342365
reward/intrinsic_batch_std :  4.489528683623723e-05
reward/intrinsic_batch_max :  0.0007024219376035035
reward/intrinsic_batch_min :  3.884926627506502e-06
reward/total_batch :  0.04294074541507663
time/iteration_time :  115.66761231422424
time/fps :  2334.2748639655
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.7s | FPS: 2334
Policy Loss: 0.0010, Value Loss: 3.5651, Entropy: 2.2239
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=180.1
Extrinsic raw: Œº=0.08582962962962963

=== Iteration 766/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.37s
EPOCH 1 took 19.72s
update_step :  766
reward/intrinsic_batch_mean :  4.97523177206353e-05
reward/extrinsic_batch_mean :  0.08331111111111111
loss/policy :  0.0005858951869110266
loss/rnd :  9.668964237748283e-07
loss/value :  3.976373889229514
loss/value_i :  1.2951232475422854e-06
loss/value_e :  3.9763725526405103
loss/entropy :  2.204473441297358
reward/intrinsic_running :  0.000872967666455681
reward/extrinsic_running :  0.08331111111111111
reward/intrinsic_std_running :  0.019424628813122635
reward/extrinsic_std_running :  1.6139427222232159
reward/intrinsic_batch_std :  4.3481189315617794e-05
reward/intrinsic_batch_max :  0.0009585963562130928
reward/intrinsic_batch_min :  4.1499565668345895e-06
reward/total_batch :  0.04168043171441588
time/iteration_time :  113.51046180725098
time/fps :  2378.63537599274
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.5s | FPS: 2379
Policy Loss: 0.0006, Value Loss: 3.9764, Entropy: 2.2045
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.049, sum=172.9
Extrinsic raw: Œº=0.08331111111111111

=== Iteration 767/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.89s
EPOCH 1 took 19.62s
update_step :  767
reward/intrinsic_batch_mean :  4.8382264783106585e-05
reward/extrinsic_batch_mean :  0.08231111111111111
loss/policy :  0.001017129768363454
loss/rnd :  9.546777861983586e-07
loss/value :  2.905517578125
loss/value_i :  1.265881852566853e-06
loss/value_e :  2.9055162993344394
loss/entropy :  2.226954358996767
reward/intrinsic_running :  0.0008719403689461192
reward/extrinsic_running :  0.08231111111111111
reward/intrinsic_std_running :  0.019411982810671018
reward/extrinsic_std_running :  1.6199893893875956
reward/intrinsic_batch_std :  3.864462874437824e-05
reward/intrinsic_batch_max :  0.0006716636125929654
reward/intrinsic_batch_min :  4.46808235210483e-06
reward/total_batch :  0.04117974668794711
time/iteration_time :  113.91926455497742
time/fps :  2370.099570557691
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2370
Policy Loss: 0.0010, Value Loss: 2.9055, Entropy: 2.2270
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.002, max=0.035, sum=168.2
Extrinsic raw: Œº=0.08231111111111111

=== Iteration 768/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.54s
EPOCH 1 took 19.29s
update_step :  768
reward/intrinsic_batch_mean :  5.100960114665483e-05
reward/extrinsic_batch_mean :  0.0833037037037037
loss/policy :  0.0015899251209868287
loss/rnd :  9.695047038583267e-07
loss/value :  4.508904749696905
loss/value_i :  1.2703672633974885e-06
loss/value_e :  4.508903463681539
loss/entropy :  2.2196044849626944
reward/intrinsic_running :  0.0008709215280686612
reward/extrinsic_running :  0.0833037037037037
reward/intrinsic_std_running :  0.019399361239593196
reward/extrinsic_std_running :  1.6139901476319336
reward/intrinsic_batch_std :  3.840465774706094e-05
reward/intrinsic_batch_max :  0.0005734589649364352
reward/intrinsic_batch_min :  4.34602179666399e-06
reward/total_batch :  0.041677356652425175
time/iteration_time :  112.44368433952332
time/fps :  2401.2020024596127
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.4s | FPS: 2401
Policy Loss: 0.0016, Value Loss: 4.5089, Entropy: 2.2196
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=177.5
Extrinsic raw: Œº=0.0833037037037037

=== Iteration 769/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 19.67s
update_step :  769
reward/intrinsic_batch_mean :  5.0380951625875576e-05
reward/extrinsic_batch_mean :  0.08815555555555556
loss/policy :  0.0012389792598586416
loss/rnd :  9.771237089215432e-07
loss/value :  5.119879924889767
loss/value_i :  1.2423544631295071e-06
loss/value_e :  5.119878653324012
loss/entropy :  2.2046609611222237
reward/intrinsic_running :  0.0008699027609004208
reward/extrinsic_running :  0.08815555555555556
reward/intrinsic_std_running :  0.019386764358606045
reward/extrinsic_std_running :  1.6567714268986096
reward/intrinsic_batch_std :  3.995488954675454e-05
reward/intrinsic_batch_max :  0.0006372809875756502
reward/intrinsic_batch_min :  3.7618722217303002e-06
reward/total_batch :  0.04410296825359072
time/iteration_time :  114.47876334190369
time/fps :  2358.516043657937
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2359
Policy Loss: 0.0012, Value Loss: 5.1199, Entropy: 2.2047
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=175.4
Extrinsic raw: Œº=0.08815555555555556

=== Iteration 770/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.86s
EPOCH 1 took 17.90s
update_step :  770
reward/intrinsic_batch_mean :  5.124033956034745e-05
reward/extrinsic_batch_mean :  0.08168148148148148
loss/policy :  0.001801921132331093
loss/rnd :  9.887891101725748e-07
loss/value :  4.499558347644228
loss/value_i :  1.3449438256429858e-06
loss/value_e :  4.499556989380808
loss/entropy :  2.224654678142432
reward/intrinsic_running :  0.0008688888309319569
reward/extrinsic_running :  0.08168148148148148
reward/intrinsic_std_running :  0.019374191904932003
reward/extrinsic_std_running :  1.6090157983334703
reward/intrinsic_batch_std :  4.1246609424402704e-05
reward/intrinsic_batch_max :  0.0009661207441240549
reward/intrinsic_batch_min :  4.597775387082947e-06
reward/total_batch :  0.04086636091052091
time/iteration_time :  111.79088497161865
time/fps :  2415.2237462700764
data/episodes_collected :  60
data/frames_collected :  270000
Timer 111.8s | FPS: 2415
Policy Loss: 0.0018, Value Loss: 4.4996, Entropy: 2.2247
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.050, sum=178.5
Extrinsic raw: Œº=0.08168148148148148

=== Iteration 771/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.66s
EPOCH 1 took 20.47s
update_step :  771
reward/intrinsic_batch_mean :  5.037815987536844e-05
reward/extrinsic_batch_mean :  0.08521481481481481
loss/policy :  0.0013911760615883395
loss/rnd :  9.76069597672077e-07
loss/value :  4.658305410182837
loss/value_i :  1.2780849701674455e-06
loss/value_e :  4.658304084431041
loss/entropy :  2.200300390070135
reward/intrinsic_running :  0.0008678760063380611
reward/extrinsic_running :  0.08521481481481481
reward/intrinsic_std_running :  0.01936164394809761
reward/extrinsic_std_running :  1.6380378704308725
reward/intrinsic_batch_std :  4.222551545834179e-05
reward/intrinsic_batch_max :  0.0007339072180911899
reward/intrinsic_batch_min :  4.358718797448091e-06
reward/total_batch :  0.04263259648734509
time/iteration_time :  115.35375118255615
time/fps :  2340.6260934913535
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2341
Policy Loss: 0.0014, Value Loss: 4.6583, Entropy: 2.2003
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.038, sum=175.6
Extrinsic raw: Œº=0.08521481481481481

=== Iteration 772/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.56s
EPOCH 1 took 18.67s
update_step :  772
reward/intrinsic_batch_mean :  5.0537011601139694e-05
reward/extrinsic_batch_mean :  0.08834814814814815
loss/policy :  0.0009283686037330577
loss/rnd :  9.768486677330657e-07
loss/value :  2.747602753566973
loss/value_i :  2.0918612662943348e-06
loss/value_e :  2.7476006439237883
loss/entropy :  2.198907935258114
reward/intrinsic_running :  0.000866867327262595
reward/extrinsic_running :  0.08834814814814815
reward/intrinsic_std_running :  0.019349120263099418
reward/extrinsic_std_running :  1.674100690889682
reward/intrinsic_batch_std :  3.804095360901574e-05
reward/intrinsic_batch_max :  0.0005787781556136906
reward/intrinsic_batch_min :  5.1470842663547955e-06
reward/total_batch :  0.044199342579874644
time/iteration_time :  113.05410194396973
time/fps :  2388.237094960195
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0009, Value Loss: 2.7476, Entropy: 2.1989
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=176.3
Extrinsic raw: Œº=0.08834814814814815

=== Iteration 773/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.90s
EPOCH 1 took 19.91s
update_step :  773
reward/intrinsic_batch_mean :  5.147392583713992e-05
reward/extrinsic_batch_mean :  0.08288888888888889
loss/policy :  0.0012523222804619845
loss/rnd :  1.4437539724013098e-06
loss/value :  3.5473971059828093
loss/value_i :  1.3247209353446097e-06
loss/value_e :  3.547395758556597
loss/entropy :  2.2068053411714956
reward/intrinsic_running :  0.000865862099827429
reward/extrinsic_running :  0.08288888888888889
reward/intrinsic_std_running :  0.019336620826712975
reward/extrinsic_std_running :  1.6217902164499702
reward/intrinsic_batch_std :  4.064791212966517e-05
reward/intrinsic_batch_max :  0.0006359369726851583
reward/intrinsic_batch_min :  4.62287198388367e-06
reward/total_batch :  0.04147018140736301
time/iteration_time :  115.40638446807861
time/fps :  2339.5586062630873
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2340
Policy Loss: 0.0013, Value Loss: 3.5474, Entropy: 2.2068
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=179.7
Extrinsic raw: Œº=0.08288888888888889

=== Iteration 774/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 19.47s
update_step :  774
reward/intrinsic_batch_mean :  0.0001451037326536607
reward/extrinsic_batch_mean :  0.07981481481481481
loss/policy :  0.0007247530632991005
loss/rnd :  1.5929565162161563e-06
loss/value :  2.2585005055774343
loss/value_i :  6.753693272995323e-06
loss/value_e :  2.258493755802964
loss/entropy :  2.2129730275183013
reward/intrinsic_running :  0.0008650739852018606
reward/extrinsic_running :  0.07981481481481481
reward/intrinsic_std_running :  0.01932413797099548
reward/extrinsic_std_running :  1.603104616096807
reward/intrinsic_batch_std :  5.186286813251793e-05
reward/intrinsic_batch_max :  0.000884088221937418
reward/intrinsic_batch_min :  6.152079004095867e-05
reward/total_batch :  0.03997995927373424
time/iteration_time :  113.08258771896362
time/fps :  2387.6354923095005
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.1s | FPS: 2388
Policy Loss: 0.0007, Value Loss: 2.2585, Entropy: 2.2130
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.008, max=0.046, sum=506.9
Extrinsic raw: Œº=0.07981481481481481

=== Iteration 775/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.63s
EPOCH 1 took 20.39s
update_step :  775
reward/intrinsic_batch_mean :  5.332477367709443e-05
reward/extrinsic_batch_mean :  0.08121481481481481
loss/policy :  0.001288223178672717
loss/rnd :  9.849623259497369e-07
loss/value :  5.278957832943309
loss/value_i :  1.3899953907611868e-06
loss/value_e :  5.278956406044237
loss/entropy :  2.1953652519168276
reward/intrinsic_running :  0.0008640772676108089
reward/extrinsic_running :  0.08121481481481481
reward/intrinsic_std_running :  0.019311686709561935
reward/extrinsic_std_running :  1.6076611969643873
reward/intrinsic_batch_std :  4.016530375525803e-05
reward/intrinsic_batch_max :  0.0005435678758658469
reward/intrinsic_batch_min :  6.321711225609761e-06
reward/total_batch :  0.04063406979424595
time/iteration_time :  114.63270616531372
time/fps :  2355.3487397447334
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.6s | FPS: 2355
Policy Loss: 0.0013, Value Loss: 5.2790, Entropy: 2.1954
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=186.4
Extrinsic raw: Œº=0.08121481481481481

=== Iteration 776/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.87s
EPOCH 1 took 18.88s
update_step :  776
reward/intrinsic_batch_mean :  4.909805672876381e-05
reward/extrinsic_batch_mean :  0.0839037037037037
loss/policy :  0.0008656077922999182
loss/rnd :  9.474899066004362e-07
loss/value :  4.007588520194545
loss/value_i :  1.46091238575812e-06
loss/value_e :  4.007587046334238
loss/entropy :  2.196484674106945
reward/intrinsic_running :  0.00086307449498448
reward/extrinsic_running :  0.0839037037037037
reward/intrinsic_std_running :  0.019299259825749086
reward/extrinsic_std_running :  1.6340273417816442
reward/intrinsic_batch_std :  3.860654251758904e-05
reward/intrinsic_batch_max :  0.0006366413435898721
reward/intrinsic_batch_min :  3.916639343515271e-06
reward/total_batch :  0.04197640088021623
time/iteration_time :  113.43865823745728
time/fps :  2380.1409871652236
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.4s | FPS: 2380
Policy Loss: 0.0009, Value Loss: 4.0076, Entropy: 2.1965
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=171.7
Extrinsic raw: Œº=0.0839037037037037

=== Iteration 777/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 19.54s
update_step :  777
reward/intrinsic_batch_mean :  4.999204463395775e-05
reward/extrinsic_batch_mean :  0.08157037037037038
loss/policy :  0.0007498952228078534
loss/rnd :  9.680758859593135e-07
loss/value :  2.5356906110590156
loss/value_i :  1.3151483192979703e-06
loss/value_e :  2.5356892853072197
loss/entropy :  2.2115746014045947
reward/intrinsic_running :  0.000862076972914485
reward/extrinsic_running :  0.08157037037037038
reward/intrinsic_std_running :  0.01928685679655031
reward/extrinsic_std_running :  1.6268709960044785
reward/intrinsic_batch_std :  3.8340819873154673e-05
reward/intrinsic_batch_max :  0.0005930967163294554
reward/intrinsic_batch_min :  4.100721525901463e-06
reward/total_batch :  0.04081018120750217
time/iteration_time :  113.24017429351807
time/fps :  2384.312826119122
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.2s | FPS: 2384
Policy Loss: 0.0007, Value Loss: 2.5357, Entropy: 2.2116
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=175.0
Extrinsic raw: Œº=0.08157037037037038

=== Iteration 778/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.26s
EPOCH 1 took 19.07s
update_step :  778
reward/intrinsic_batch_mean :  5.177673195850932e-05
reward/extrinsic_batch_mean :  0.08534074074074074
loss/policy :  0.0010889486415125607
loss/rnd :  1.056919876763266e-06
loss/value :  5.408409082528316
loss/value_i :  1.310330825769294e-06
loss/value_e :  5.408407709815285
loss/entropy :  2.185941374663151
reward/intrinsic_running :  0.0008610847928179566
reward/extrinsic_running :  0.08534074074074074
reward/intrinsic_std_running :  0.01927447754586408
reward/extrinsic_std_running :  1.647458849766369
reward/intrinsic_batch_std :  4.068439292807541e-05
reward/intrinsic_batch_max :  0.0006295716157183051
reward/intrinsic_batch_min :  5.404147941590054e-06
reward/total_batch :  0.04269625873634963
time/iteration_time :  113.30760431289673
time/fps :  2382.893907582763
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2383
Policy Loss: 0.0011, Value Loss: 5.4084, Entropy: 2.1859
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=181.3
Extrinsic raw: Œº=0.08534074074074074

=== Iteration 779/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.20s
EPOCH 1 took 18.17s
update_step :  779
reward/intrinsic_batch_mean :  8.875868290401909e-05
reward/extrinsic_batch_mean :  0.0816962962962963
loss/policy :  0.0007432111870553908
loss/rnd :  1.0602986228811708e-06
loss/value :  3.7309054786508735
loss/value_i :  1.569265102509896e-06
loss/value_e :  3.730903896418485
loss/entropy :  2.1977256500359736
reward/intrinsic_running :  0.0008601798183218268
reward/extrinsic_running :  0.0816962962962963
reward/intrinsic_std_running :  0.01926211886378633
reward/extrinsic_std_running :  1.6181481677983773
reward/intrinsic_batch_std :  3.831090382427543e-05
reward/intrinsic_batch_max :  0.0005932626663707197
reward/intrinsic_batch_min :  3.654837200883776e-05
reward/total_batch :  0.04089252748960016
time/iteration_time :  112.76089096069336
time/fps :  2394.4472032782865
data/episodes_collected :  60
data/frames_collected :  270000
Timer 112.8s | FPS: 2394
Policy Loss: 0.0007, Value Loss: 3.7309, Entropy: 2.1977
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.031, sum=311.0
Extrinsic raw: Œº=0.0816962962962963

=== Iteration 780/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.83s
EPOCH 1 took 19.78s
update_step :  780
reward/intrinsic_batch_mean :  4.848813924378461e-05
reward/extrinsic_batch_mean :  0.08686666666666666
loss/policy :  0.0016474590898503789
loss/rnd :  9.341527068114154e-07
loss/value :  3.3320725415692185
loss/value_i :  1.4287886332650404e-06
loss/value_e :  3.3320711128639453
loss/entropy :  2.1871697902679443
reward/intrinsic_running :  0.0008591867272321348
reward/extrinsic_running :  0.08686666666666666
reward/intrinsic_std_running :  0.019249787377258694
reward/extrinsic_std_running :  1.669747851002038
reward/intrinsic_batch_std :  3.539986436272262e-05
reward/intrinsic_batch_max :  0.0004631409829016775
reward/intrinsic_batch_min :  4.36795698988135e-06
reward/total_batch :  0.04345757740295522
time/iteration_time :  114.12093138694763
time/fps :  2365.9112900552504
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2366
Policy Loss: 0.0016, Value Loss: 3.3321, Entropy: 2.1872
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.024, sum=170.0
Extrinsic raw: Œº=0.08686666666666666

=== Iteration 781/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.22s
EPOCH 1 took 19.08s
update_step :  781
reward/intrinsic_batch_mean :  5.2129856061509164e-05
reward/extrinsic_batch_mean :  0.08347407407407408
loss/policy :  0.0011322985365316554
loss/rnd :  9.89803094274645e-07
loss/value :  3.3494429714751965
loss/value_i :  1.3825766907096047e-06
loss/value_e :  3.3494415843125545
loss/entropy :  2.1769755536859687
reward/intrinsic_running :  0.0008582046576146262
reward/extrinsic_running :  0.08347407407407408
reward/intrinsic_std_running :  0.019237479218782112
reward/extrinsic_std_running :  1.6335936995635636
reward/intrinsic_batch_std :  3.928940003643096e-05
reward/intrinsic_batch_max :  0.0008690057438798249
reward/intrinsic_batch_min :  4.386237378639635e-06
reward/total_batch :  0.04176310196506779
time/iteration_time :  113.70904564857483
time/fps :  2374.481277720442
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2374
Policy Loss: 0.0011, Value Loss: 3.3494, Entropy: 2.1770
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.045, sum=182.9
Extrinsic raw: Œº=0.08347407407407408

=== Iteration 782/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.89s
EPOCH 1 took 19.54s
update_step :  782
reward/intrinsic_batch_mean :  4.998075153147915e-05
reward/extrinsic_batch_mean :  0.08685925925925926
loss/policy :  0.0006722300838164026
loss/rnd :  9.70236083152155e-07
loss/value :  3.6503637595610186
loss/value_i :  1.2881000123233015e-06
loss/value_e :  3.650362491607666
loss/entropy :  2.1881427259156196
reward/intrinsic_running :  0.0008572193966634052
reward/extrinsic_running :  0.08685925925925926
reward/intrinsic_std_running :  0.019225194854489817
reward/extrinsic_std_running :  1.6608531683621854
reward/intrinsic_batch_std :  3.630276821628301e-05
reward/intrinsic_batch_max :  0.0004373178817331791
reward/intrinsic_batch_min :  4.373499450593954e-06
reward/total_batch :  0.04345462000539537
time/iteration_time :  114.44785690307617
time/fps :  2359.1529566923928
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2359
Policy Loss: 0.0007, Value Loss: 3.6504, Entropy: 2.1881
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.023, sum=175.5
Extrinsic raw: Œº=0.08685925925925926

=== Iteration 783/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 19.97s
update_step :  783
reward/intrinsic_batch_mean :  4.870906018596644e-05
reward/extrinsic_batch_mean :  0.0816962962962963
loss/policy :  0.0014965246385999667
loss/rnd :  9.430378731918388e-07
loss/value :  3.507372388333985
loss/value_i :  6.631757173464035e-05
loss/value_e :  3.5073060664263638
loss/entropy :  2.203818841414018
reward/intrinsic_running :  0.0008562331989245201
reward/extrinsic_running :  0.0816962962962963
reward/intrinsic_std_running :  0.019212934129211406
reward/extrinsic_std_running :  1.618193944216018
reward/intrinsic_batch_std :  3.5853511723885715e-05
reward/intrinsic_batch_max :  0.0007524064858444035
reward/intrinsic_batch_min :  4.191746938886354e-06
reward/total_batch :  0.04087250267824113
time/iteration_time :  122.03788638114929
time/fps :  2212.4276977129443
data/episodes_collected :  60
data/frames_collected :  270000
Timer 122.0s | FPS: 2212
Policy Loss: 0.0015, Value Loss: 3.5074, Entropy: 2.2038
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=171.1
Extrinsic raw: Œº=0.0816962962962963

=== Iteration 784/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.51s
EPOCH 1 took 19.39s
update_step :  784
reward/intrinsic_batch_mean :  5.1331178004962834e-05
reward/extrinsic_batch_mean :  0.08170370370370371
loss/policy :  0.0006072552685950403
loss/rnd :  1.1322234973414942e-06
loss/value :  3.290272212389744
loss/value_i :  3.007919914318446e-05
loss/value_e :  3.2902421499743606
loss/entropy :  2.2082565011400166
reward/intrinsic_running :  0.0008552555363035457
reward/extrinsic_running :  0.08170370370370371
reward/intrinsic_std_running :  0.019200696596760013
reward/extrinsic_std_running :  1.6181466493724148
reward/intrinsic_batch_std :  3.757633636624249e-05
reward/intrinsic_batch_max :  0.0006005519535392523
reward/intrinsic_batch_min :  5.4653714869346e-06
reward/total_batch :  0.040877517440854334
time/iteration_time :  117.333811044693
time/fps :  2301.126994819556
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.3s | FPS: 2301
Policy Loss: 0.0006, Value Loss: 3.2903, Entropy: 2.2083
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=180.5
Extrinsic raw: Œº=0.08170370370370371

=== Iteration 785/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.96s
EPOCH 1 took 18.76s
update_step :  785
reward/intrinsic_batch_mean :  5.369095969007402e-05
reward/extrinsic_batch_mean :  0.08714814814814814
loss/policy :  -8.848381747322327e-05
loss/rnd :  9.821352848300167e-07
loss/value :  3.750926704117746
loss/value_i :  2.3001560307558535e-05
loss/value_e :  3.7509037220116817
loss/entropy :  2.2031321344953594
reward/intrinsic_running :  0.000854285927535595
reward/extrinsic_running :  0.08714814814814814
reward/intrinsic_std_running :  0.01918848219561584
reward/extrinsic_std_running :  1.670622421239588
reward/intrinsic_batch_std :  3.7606401277609386e-05
reward/intrinsic_batch_max :  0.0005948883481323719
reward/intrinsic_batch_min :  8.881684152584057e-06
reward/total_batch :  0.04360091955391911
time/iteration_time :  115.25811529159546
time/fps :  2342.5682375329297
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2343
Policy Loss: -0.0001, Value Loss: 3.7509, Entropy: 2.2031
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=188.9
Extrinsic raw: Œº=0.08714814814814814

=== Iteration 786/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.62s
EPOCH 1 took 19.60s
update_step :  786
reward/intrinsic_batch_mean :  5.035679311144526e-05
reward/extrinsic_batch_mean :  0.07680740740740741
loss/policy :  0.0008347622298804873
loss/rnd :  9.711227491924077e-07
loss/value :  4.456855521057591
loss/value_i :  2.6010662243910094e-05
loss/value_e :  4.456829529820067
loss/entropy :  2.2036543687184653
reward/intrinsic_running :  0.0008533112356982983
reward/extrinsic_running :  0.07680740740740741
reward/intrinsic_std_running :  0.0191762913776697
reward/extrinsic_std_running :  1.556370621367623
reward/intrinsic_batch_std :  3.8339620286347365e-05
reward/intrinsic_batch_max :  0.0005928002065047622
reward/intrinsic_batch_min :  3.4427396258251974e-06
reward/total_batch :  0.03842888210025942
time/iteration_time :  116.62526035308838
time/fps :  2315.1073719583774
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.6s | FPS: 2315
Policy Loss: 0.0008, Value Loss: 4.4569, Entropy: 2.2037
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=177.3
Extrinsic raw: Œº=0.07680740740740741

=== Iteration 787/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.57s
EPOCH 1 took 19.27s
update_step :  787
reward/intrinsic_batch_mean :  4.9215173183067776e-05
reward/extrinsic_batch_mean :  0.08156296296296296
loss/policy :  0.0010718729067086701
loss/rnd :  9.410155497114443e-07
loss/value :  2.7927963354370813
loss/value_i :  7.2354018605189845e-06
loss/value_e :  2.79278910521305
loss/entropy :  2.2179516662250864
reward/intrinsic_running :  0.0008523373365464435
reward/extrinsic_running :  0.08156296296296296
reward/intrinsic_std_running :  0.01916412382922988
reward/extrinsic_std_running :  1.6268725056805677
reward/intrinsic_batch_std :  3.669753373785422e-05
reward/intrinsic_batch_max :  0.0006311809993349016
reward/intrinsic_batch_min :  4.270168574294075e-06
reward/total_batch :  0.040806089068073016
time/iteration_time :  114.75630307197571
time/fps :  2352.811939494554
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.8s | FPS: 2353
Policy Loss: 0.0011, Value Loss: 2.7928, Entropy: 2.2180
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=173.3
Extrinsic raw: Œº=0.08156296296296296

=== Iteration 788/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.33s
EPOCH 1 took 20.27s
update_step :  788
reward/intrinsic_batch_mean :  4.983400732962764e-05
reward/extrinsic_batch_mean :  0.08201481481481482
loss/policy :  0.0010229993080649751
loss/rnd :  9.79694566226361e-07
loss/value :  2.8261210665558325
loss/value_i :  4.834826378982777e-06
loss/value_e :  2.826116224129995
loss/entropy :  2.1931038625312573
reward/intrinsic_running :  0.0008513669789162089
reward/extrinsic_running :  0.08201481481481482
reward/intrinsic_std_running :  0.019151979371871804
reward/extrinsic_std_running :  1.6282140453755765
reward/intrinsic_batch_std :  3.7447951818279984e-05
reward/intrinsic_batch_max :  0.0005191297386772931
reward/intrinsic_batch_min :  4.0627328417031094e-06
reward/total_batch :  0.04103232441107222
time/iteration_time :  114.62879037857056
time/fps :  2355.429199839795
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.6s | FPS: 2355
Policy Loss: 0.0010, Value Loss: 2.8261, Entropy: 2.1931
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=175.6
Extrinsic raw: Œº=0.08201481481481482

=== Iteration 789/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.91s
EPOCH 1 took 19.15s
update_step :  789
reward/intrinsic_batch_mean :  4.904712581837548e-05
reward/extrinsic_batch_mean :  0.08346666666666666
loss/policy :  0.0008620662746111383
loss/rnd :  9.45350855159411e-07
loss/value :  3.6028683004957256
loss/value_i :  4.73816880637032e-06
loss/value_e :  3.6028635610233652
loss/entropy :  2.1937509522293555
reward/intrinsic_running :  0.000850397607897897
reward/extrinsic_running :  0.08346666666666666
reward/intrinsic_std_running :  0.01913985802856027
reward/extrinsic_std_running :  1.6417368797167897
reward/intrinsic_batch_std :  3.569964900090839e-05
reward/intrinsic_batch_max :  0.00045809868606738746
reward/intrinsic_batch_min :  3.968971213907935e-06
reward/total_batch :  0.04175785689624252
time/iteration_time :  113.99172401428223
time/fps :  2368.593003876064
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.0s | FPS: 2369
Policy Loss: 0.0009, Value Loss: 3.6029, Entropy: 2.1938
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.024, sum=173.0
Extrinsic raw: Œº=0.08346666666666666

=== Iteration 790/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.30s
EPOCH 1 took 20.14s
update_step :  790
reward/intrinsic_batch_mean :  4.967334525240908e-05
reward/extrinsic_batch_mean :  0.0824
loss/policy :  0.0010383531348038973
loss/rnd :  9.575762760505313e-07
loss/value :  4.663860992951826
loss/value_i :  3.514168656004062e-06
loss/value_e :  4.6638574636343755
loss/entropy :  2.153579751650492
reward/intrinsic_running :  0.0008494321378326825
reward/extrinsic_running :  0.0824
reward/intrinsic_std_running :  0.019127759614438692
reward/extrinsic_std_running :  1.6020158190368925
reward/intrinsic_batch_std :  3.6750352760030936e-05
reward/intrinsic_batch_max :  0.0005820439546369016
reward/intrinsic_batch_min :  4.154942416789709e-06
reward/total_batch :  0.041224836672626206
time/iteration_time :  115.02133679389954
time/fps :  2347.390558360474
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.0s | FPS: 2347
Policy Loss: 0.0010, Value Loss: 4.6639, Entropy: 2.1536
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=175.3
Extrinsic raw: Œº=0.0824

=== Iteration 791/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.49s
EPOCH 1 took 18.51s
update_step :  791
reward/intrinsic_batch_mean :  5.058016587533564e-05
reward/extrinsic_batch_mean :  0.08716296296296297
loss/policy :  0.001680535276439817
loss/rnd :  9.666519290338769e-07
loss/value :  2.9671653545264043
loss/value_i :  2.342724239194164e-06
loss/value_e :  2.9671630082708416
loss/entropy :  2.17069149017334
reward/intrinsic_running :  0.0008484708909275481
reward/extrinsic_running :  0.08716296296296297
reward/intrinsic_std_running :  0.019115684048148444
reward/extrinsic_std_running :  1.6706194313948897
reward/intrinsic_batch_std :  3.8805303019136955e-05
reward/intrinsic_batch_max :  0.0006282596732489765
reward/intrinsic_batch_min :  4.8820047595654614e-06
reward/total_batch :  0.04360677156441915
time/iteration_time :  114.37493753433228
time/fps :  2360.6570269728304
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2361
Policy Loss: 0.0017, Value Loss: 2.9672, Entropy: 2.1707
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=178.6
Extrinsic raw: Œº=0.08716296296296297

=== Iteration 792/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.08s
EPOCH 1 took 19.51s
update_step :  792
reward/intrinsic_batch_mean :  4.8108555974802046e-05
reward/extrinsic_batch_mean :  0.08224444444444444
loss/policy :  0.000953624644987003
loss/rnd :  9.192851426619062e-07
loss/value :  5.094643621733694
loss/value_i :  1.8752976932939254e-06
loss/value_e :  5.094641746896686
loss/entropy :  2.1793923703106968
reward/intrinsic_running :  0.000847506691582058
reward/extrinsic_running :  0.08224444444444444
reward/intrinsic_std_running :  0.019103631530849638
reward/extrinsic_std_running :  1.6108321749339596
reward/intrinsic_batch_std :  3.622505831906622e-05
reward/intrinsic_batch_max :  0.0005200172308832407
reward/intrinsic_batch_min :  4.020405413029948e-06
reward/total_batch :  0.04114627650020962
time/iteration_time :  115.6469099521637
time/fps :  2334.692730758505
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.6s | FPS: 2335
Policy Loss: 0.0010, Value Loss: 5.0946, Entropy: 2.1794
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=170.0
Extrinsic raw: Œº=0.08224444444444444

=== Iteration 793/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 18.59s
update_step :  793
reward/intrinsic_batch_mean :  5.129805057353628e-05
reward/extrinsic_batch_mean :  0.08599259259259259
loss/policy :  0.000892421519948226
loss/rnd :  9.856341505658774e-07
loss/value :  2.8078648935664785
loss/value_i :  2.405385413167647e-06
loss/value_e :  2.807862480481466
loss/entropy :  2.1768414215608076
reward/intrinsic_running :  0.0008465511186216333
reward/extrinsic_running :  0.08599259259259259
reward/intrinsic_std_running :  0.01909160154279432
reward/extrinsic_std_running :  1.6492584461409776
reward/intrinsic_batch_std :  3.987993152389911e-05
reward/intrinsic_batch_max :  0.0006725286948494613
reward/intrinsic_batch_min :  4.412822818267159e-06
reward/total_batch :  0.043021945321583065
time/iteration_time :  114.91113901138306
time/fps :  2349.641665054368
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2350
Policy Loss: 0.0009, Value Loss: 2.8079, Entropy: 2.1768
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=181.4
Extrinsic raw: Œº=0.08599259259259259

=== Iteration 794/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 18.90s
update_step :  794
reward/intrinsic_batch_mean :  5.1401456330825535e-05
reward/extrinsic_batch_mean :  0.08433333333333333
loss/policy :  0.0002717458231596869
loss/rnd :  1.0257542743547123e-06
loss/value :  4.1782071463989485
loss/value_i :  1.0790138036775192e-05
loss/value_e :  4.178196347121037
loss/entropy :  2.1739027789144805
reward/intrinsic_running :  0.000845597666767561
reward/extrinsic_running :  0.08433333333333333
reward/intrinsic_std_running :  0.019079594259961547
reward/extrinsic_std_running :  1.6443559247946917
reward/intrinsic_batch_std :  3.888308097109543e-05
reward/intrinsic_batch_max :  0.0005361201474443078
reward/intrinsic_batch_min :  4.290635843062773e-06
reward/total_batch :  0.04219236739483208
time/iteration_time :  115.24765801429749
time/fps :  2342.780796174653
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.2s | FPS: 2343
Policy Loss: 0.0003, Value Loss: 4.1782, Entropy: 2.1739
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=181.8
Extrinsic raw: Œº=0.08433333333333333

=== Iteration 795/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.99s
EPOCH 1 took 18.98s
update_step :  795
reward/intrinsic_batch_mean :  5.203250120732803e-05
reward/extrinsic_batch_mean :  0.0826
loss/policy :  0.0009799505227640498
loss/rnd :  9.741668382944089e-07
loss/value :  3.0569574020125647
loss/value_i :  1.5583549832103238e-06
loss/value_e :  3.0569558793848213
loss/entropy :  2.167601885217609
reward/intrinsic_running :  0.0008446477285947469
reward/extrinsic_running :  0.0826
reward/intrinsic_std_running :  0.019067609563965856
reward/extrinsic_std_running :  1.6208443784827895
reward/intrinsic_batch_std :  3.94299984958379e-05
reward/intrinsic_batch_max :  0.0005764486850239336
reward/intrinsic_batch_min :  5.249234618531773e-06
reward/total_batch :  0.04132601625060367
time/iteration_time :  116.48588919639587
time/fps :  2317.8773142623177
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.5s | FPS: 2318
Policy Loss: 0.0010, Value Loss: 3.0570, Entropy: 2.1676
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=184.2
Extrinsic raw: Œº=0.0826

=== Iteration 796/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.91s
EPOCH 1 took 19.25s
update_step :  796
reward/intrinsic_batch_mean :  5.254083530052648e-05
reward/extrinsic_batch_mean :  0.0811111111111111
loss/policy :  0.00046703153092301255
loss/rnd :  1.0643901053740454e-06
loss/value :  3.5471596735896487
loss/value_i :  1.908081377209645e-06
loss/value_e :  3.547157757210009
loss/entropy :  2.188798835783294
reward/intrinsic_running :  0.0008437015656500341
reward/extrinsic_running :  0.0811111111111111
reward/intrinsic_std_running :  0.019055647381103734
reward/extrinsic_std_running :  1.6071986978345234
reward/intrinsic_batch_std :  4.355596311693316e-05
reward/intrinsic_batch_max :  0.0009085867204703391
reward/intrinsic_batch_min :  4.798158443009015e-06
reward/total_batch :  0.040581825973205816
time/iteration_time :  116.8307683467865
time/fps :  2311.035045139515
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.8s | FPS: 2311
Policy Loss: 0.0005, Value Loss: 3.5472, Entropy: 2.1888
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.048, sum=186.1
Extrinsic raw: Œº=0.0811111111111111

=== Iteration 797/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.94s
EPOCH 1 took 18.18s
update_step :  797
reward/intrinsic_batch_mean :  5.550637110433551e-05
reward/extrinsic_batch_mean :  0.08271111111111111
loss/policy :  0.0010057013679408665
loss/rnd :  1.0883629594597248e-06
loss/value :  4.375215255852901
loss/value_i :  1.7305060902634233e-06
loss/value_e :  4.375213518287197
loss/entropy :  2.176137909744725
reward/intrinsic_running :  0.0008427623258955295
reward/extrinsic_running :  0.08271111111111111
reward/intrinsic_std_running :  0.01904370754838534
reward/extrinsic_std_running :  1.6213470570812942
reward/intrinsic_batch_std :  5.0849010560406574e-05
reward/intrinsic_batch_max :  0.0010127832647413015
reward/intrinsic_batch_min :  5.372913619794417e-06
reward/total_batch :  0.041383308741107724
time/iteration_time :  115.4783263206482
time/fps :  2338.1010844432585
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.5s | FPS: 2338
Policy Loss: 0.0010, Value Loss: 4.3752, Entropy: 2.1761
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.053, sum=196.7
Extrinsic raw: Œº=0.08271111111111111

=== Iteration 798/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.32s
EPOCH 1 took 19.85s
update_step :  798
reward/intrinsic_batch_mean :  5.368497482287003e-05
reward/extrinsic_batch_mean :  0.08285925925925926
loss/policy :  0.0017245390153027874
loss/rnd :  1.0373780369401644e-06
loss/value :  4.351616285064003
loss/value_i :  2.425482722573537e-06
loss/value_e :  4.351613900878212
loss/entropy :  2.177925792607394
reward/intrinsic_running :  0.0008418223302579608
reward/extrinsic_running :  0.08285925925925926
reward/intrinsic_std_running :  0.019031790227030124
reward/extrinsic_std_running :  1.621796297949868
reward/intrinsic_batch_std :  4.386347038835869e-05
reward/intrinsic_batch_max :  0.0006548347882926464
reward/intrinsic_batch_min :  3.90311606679461e-06
reward/total_batch :  0.041456472117041065
time/iteration_time :  115.9858386516571
time/fps :  2327.87039468583
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.0s | FPS: 2328
Policy Loss: 0.0017, Value Loss: 4.3516, Entropy: 2.1779
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=190.4
Extrinsic raw: Œº=0.08285925925925926

=== Iteration 799/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.49s
EPOCH 1 took 19.00s
update_step :  799
reward/intrinsic_batch_mean :  5.539910773962523e-05
reward/extrinsic_batch_mean :  0.0876962962962963
loss/policy :  0.000585402998805159
loss/rnd :  9.961358697100051e-07
loss/value :  5.56126421509367
loss/value_i :  7.682738633072653e-06
loss/value_e :  5.561256531513099
loss/entropy :  2.158435192975131
reward/intrinsic_running :  0.00084088856244482
reward/extrinsic_running :  0.0876962962962963
reward/intrinsic_std_running :  0.01901989506639485
reward/extrinsic_std_running :  1.64558278216237
reward/intrinsic_batch_std :  3.8317173869891926e-05
reward/intrinsic_batch_max :  0.0007511461153626442
reward/intrinsic_batch_min :  7.440360604960006e-06
reward/total_batch :  0.04387584770201796
time/iteration_time :  115.09240293502808
time/fps :  2345.941114396754
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2346
Policy Loss: 0.0006, Value Loss: 5.5613, Entropy: 2.1584
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=196.6
Extrinsic raw: Œº=0.0876962962962963

=== Iteration 800/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.39s
EPOCH 1 took 20.07s
update_step :  800
reward/intrinsic_batch_mean :  5.4105511196286423e-05
reward/extrinsic_batch_mean :  0.0811111111111111
loss/policy :  0.0007902208264126922
loss/rnd :  1.0391966439425286e-06
loss/value :  3.172202803871848
loss/value_i :  1.440915213785929e-06
loss/value_e :  3.1722013661355684
loss/entropy :  2.1660656531651816
reward/intrinsic_running :  0.0008399545126132693
reward/extrinsic_running :  0.0811111111111111
reward/intrinsic_std_running :  0.01900802228845317
reward/extrinsic_std_running :  1.6163443741364245
reward/intrinsic_batch_std :  3.907740482281525e-05
reward/intrinsic_batch_max :  0.0006569522665813565
reward/intrinsic_batch_min :  4.779213213623734e-06
reward/total_batch :  0.0405826083111537
time/iteration_time :  115.31503081321716
time/fps :  2341.4120266536247
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2341
Policy Loss: 0.0008, Value Loss: 3.1722, Entropy: 2.1661
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=192.1
Extrinsic raw: Œº=0.0811111111111111

=== Iteration 801/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.38s
EPOCH 1 took 19.71s
update_step :  801
reward/intrinsic_batch_mean :  5.4180902759779e-05
reward/extrinsic_batch_mean :  0.08201481481481482
loss/policy :  0.0010104765145418544
loss/rnd :  1.920839264185457e-06
loss/value :  3.0235976847735317
loss/value_i :  4.363057283543722e-06
loss/value_e :  3.0235933300220603
loss/entropy :  2.1528583945650044
reward/intrinsic_running :  0.0008390229970718591
reward/extrinsic_running :  0.08201481481481482
reward/intrinsic_std_running :  0.018996171702188244
reward/extrinsic_std_running :  1.6190896664263748
reward/intrinsic_batch_std :  3.538689253920546e-05
reward/intrinsic_batch_max :  0.0004813750565517694
reward/intrinsic_batch_min :  8.09219363873126e-06
reward/total_batch :  0.0410344978587873
time/iteration_time :  117.08640766143799
time/fps :  2305.9892723049493
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.1s | FPS: 2306
Policy Loss: 0.0010, Value Loss: 3.0236, Entropy: 2.1529
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.025, sum=192.5
Extrinsic raw: Œº=0.08201481481481482

=== Iteration 802/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.46s
EPOCH 1 took 19.01s
update_step :  802
reward/intrinsic_batch_mean :  8.673255757029337e-05
reward/extrinsic_batch_mean :  0.08537037037037037
loss/policy :  0.0006111743912862784
loss/rnd :  1.5114688208637799e-06
loss/value :  4.560004714763526
loss/value_i :  2.4396698821957132e-06
loss/value_e :  4.560002276391694
loss/entropy :  2.150220589204268
reward/intrinsic_running :  0.0008381622187114588
reward/extrinsic_running :  0.08537037037037037
reward/intrinsic_std_running :  0.01898434069519915
reward/extrinsic_std_running :  1.6384807924630156
reward/intrinsic_batch_std :  4.362620679747596e-05
reward/intrinsic_batch_max :  0.0007672245847061276
reward/intrinsic_batch_min :  2.594926809251774e-05
reward/total_batch :  0.04272855146397033
time/iteration_time :  114.47023797035217
time/fps :  2358.6916982729613
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2359
Policy Loss: 0.0006, Value Loss: 4.5600, Entropy: 2.1502
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.005, max=0.040, sum=308.4
Extrinsic raw: Œº=0.08537037037037037

=== Iteration 803/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.70s
EPOCH 1 took 19.18s
update_step :  803
reward/intrinsic_batch_mean :  5.50181709149978e-05
reward/extrinsic_batch_mean :  0.08274074074074074
loss/policy :  0.0006521858528933742
loss/rnd :  1.0169465244044575e-06
loss/value :  3.6688640171831306
loss/value_i :  1.859764913867614e-06
loss/value_e :  3.6688621640205383
loss/entropy :  2.1226607994599775
reward/intrinsic_running :  0.0008372374632315511
reward/extrinsic_running :  0.08274074074074074
reward/intrinsic_std_running :  0.018972534241641605
reward/extrinsic_std_running :  1.6304527567654006
reward/intrinsic_batch_std :  3.92106726688712e-05
reward/intrinsic_batch_max :  0.0005795585457235575
reward/intrinsic_batch_min :  5.256574695522431e-06
reward/total_batch :  0.04139787945582787
time/iteration_time :  116.20920538902283
time/fps :  2323.395974493982
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.2s | FPS: 2323
Policy Loss: 0.0007, Value Loss: 3.6689, Entropy: 2.1227
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=195.7
Extrinsic raw: Œº=0.08274074074074074

=== Iteration 804/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.60s
EPOCH 1 took 18.83s
update_step :  804
reward/intrinsic_batch_mean :  5.2200531097834624e-05
reward/extrinsic_batch_mean :  0.08417777777777778
loss/policy :  0.0009004641793911684
loss/rnd :  9.850440133876956e-07
loss/value :  4.820036638866771
loss/value_i :  1.3328195998176604e-06
loss/value_e :  4.820035258928935
loss/entropy :  2.1340227271571304
reward/intrinsic_running :  0.0008363090620427266
reward/extrinsic_running :  0.08417777777777778
reward/intrinsic_std_running :  0.018960750023942527
reward/extrinsic_std_running :  1.625836317517242
reward/intrinsic_batch_std :  3.9328452442939396e-05
reward/intrinsic_batch_max :  0.0006961913895793259
reward/intrinsic_batch_min :  3.746669563042815e-06
reward/total_batch :  0.04211498915443781
time/iteration_time :  114.0513596534729
time/fps :  2367.354504324652
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.1s | FPS: 2367
Policy Loss: 0.0009, Value Loss: 4.8200, Entropy: 2.1340
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=185.8
Extrinsic raw: Œº=0.08417777777777778

=== Iteration 805/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.59s
EPOCH 1 took 18.66s
update_step :  805
reward/intrinsic_batch_mean :  5.3575993966566146e-05
reward/extrinsic_batch_mean :  0.08481481481481482
loss/policy :  0.0012036830559020127
loss/rnd :  1.0134406238648808e-06
loss/value :  2.76980791128043
loss/value_i :  2.6224649504360005e-06
loss/value_e :  2.7698052868698584
loss/entropy :  2.106088374600266
reward/intrinsic_running :  0.0008353858693890204
reward/extrinsic_running :  0.08481481481481482
reward/intrinsic_std_running :  0.01894898763755171
reward/extrinsic_std_running :  1.6366946600239438
reward/intrinsic_batch_std :  4.2399528360671877e-05
reward/intrinsic_batch_max :  0.000524543400388211
reward/intrinsic_batch_min :  4.009502845292445e-06
reward/total_batch :  0.04243419540439069
time/iteration_time :  115.5832314491272
time/fps :  2335.978987737835
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.6s | FPS: 2336
Policy Loss: 0.0012, Value Loss: 2.7698, Entropy: 2.1061
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.028, sum=190.8
Extrinsic raw: Œº=0.08481481481481482

=== Iteration 806/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 18.72s
update_step :  806
reward/intrinsic_batch_mean :  5.2920263384311074e-05
reward/extrinsic_batch_mean :  0.08342222222222222
loss/policy :  0.0017854810567135273
loss/rnd :  1.000574258975548e-06
loss/value :  5.59878737637491
loss/value_i :  4.819417835154706e-06
loss/value_e :  5.598782550204884
loss/entropy :  2.0915052385041206
reward/intrinsic_running :  0.0008344621996859075
reward/extrinsic_running :  0.08342222222222222
reward/intrinsic_std_running :  0.01893724720233088
reward/extrinsic_std_running :  1.6052448732856548
reward/intrinsic_batch_std :  3.9258595367640824e-05
reward/intrinsic_batch_max :  0.0005839323275722563
reward/intrinsic_batch_min :  3.6369131066749105e-06
reward/total_batch :  0.041737571242803265
time/iteration_time :  113.00737357139587
time/fps :  2389.224627271062
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.0s | FPS: 2389
Policy Loss: 0.0018, Value Loss: 5.5988, Entropy: 2.0915
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=188.6
Extrinsic raw: Œº=0.08342222222222222

=== Iteration 807/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.09s
EPOCH 1 took 19.35s
update_step :  807
reward/intrinsic_batch_mean :  5.0833704913556074e-05
reward/extrinsic_batch_mean :  0.08156296296296296
loss/policy :  0.000881478641090463
loss/rnd :  9.624916823681953e-07
loss/value :  3.0628742051847055
loss/value_i :  1.4180555743251082e-06
loss/value_e :  3.0628727873166404
loss/entropy :  2.1477766867839927
reward/intrinsic_running :  0.0008335371590602546
reward/extrinsic_running :  0.08156296296296296
reward/intrinsic_std_running :  0.01892552871003317
reward/extrinsic_std_running :  1.617740560198
reward/intrinsic_batch_std :  3.995092119501388e-05
reward/intrinsic_batch_max :  0.0005527347675524652
reward/intrinsic_batch_min :  3.8123018839542056e-06
reward/total_batch :  0.04080689833393826
time/iteration_time :  116.03642654418945
time/fps :  2326.855523228109
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.0s | FPS: 2327
Policy Loss: 0.0009, Value Loss: 3.0629, Entropy: 2.1478
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=181.3
Extrinsic raw: Œº=0.08156296296296296

=== Iteration 808/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.47s
EPOCH 1 took 19.24s
update_step :  808
reward/intrinsic_batch_mean :  5.362182476477823e-05
reward/extrinsic_batch_mean :  0.0782
loss/policy :  0.0003338541511876621
loss/rnd :  1.0138062562377441e-06
loss/value :  1.9284275842435432
loss/value_i :  1.4195184087039898e-06
loss/value_e :  1.9284261772126863
loss/entropy :  2.1569299878496113
reward/intrinsic_running :  0.0008326212399055757
reward/extrinsic_running :  0.0782
reward/intrinsic_std_running :  0.018913831703296725
reward/extrinsic_std_running :  1.5887939581586659
reward/intrinsic_batch_std :  4.241670992541147e-05
reward/intrinsic_batch_max :  0.0006403733277693391
reward/intrinsic_batch_min :  3.251779389756848e-06
reward/total_batch :  0.03912681091238239
time/iteration_time :  116.03681993484497
time/fps :  2326.8476346698044
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.0s | FPS: 2327
Policy Loss: 0.0003, Value Loss: 1.9284, Entropy: 2.1569
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=191.4
Extrinsic raw: Œº=0.0782

=== Iteration 809/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.41s
EPOCH 1 took 19.51s
update_step :  809
reward/intrinsic_batch_mean :  5.1813519673986e-05
reward/extrinsic_batch_mean :  0.07978518518518518
loss/policy :  0.0013700120387401319
loss/rnd :  9.80017154350924e-07
loss/value :  3.0444057078072517
loss/value_i :  1.775367879321438e-06
loss/value_e :  3.04440392147411
loss/entropy :  2.1771112861055317
reward/intrinsic_running :  0.0008317036908236198
reward/extrinsic_running :  0.07978518518518518
reward/intrinsic_std_running :  0.01890215648436294
reward/extrinsic_std_running :  1.5947718605455545
reward/intrinsic_batch_std :  3.792126343705268e-05
reward/intrinsic_batch_max :  0.0005055415676906705
reward/intrinsic_batch_min :  4.048066330142319e-06
reward/total_batch :  0.03991849935242958
time/iteration_time :  116.5258162021637
time/fps :  2317.0831048423634
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.5s | FPS: 2317
Policy Loss: 0.0014, Value Loss: 3.0444, Entropy: 2.1771
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=185.0
Extrinsic raw: Œº=0.07978518518518518

=== Iteration 810/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.95s
EPOCH 1 took 18.46s
update_step :  810
reward/intrinsic_batch_mean :  5.260505632934467e-05
reward/extrinsic_batch_mean :  0.08170370370370371
loss/policy :  0.001305206502531126
loss/rnd :  9.967753650623006e-07
loss/value :  3.1634392015861743
loss/value_i :  8.329800207871868e-06
loss/value_e :  3.163430884028926
loss/entropy :  2.1496960827798555
reward/intrinsic_running :  0.0008307893409085943
reward/extrinsic_running :  0.08170370370370371
reward/intrinsic_std_running :  0.018890502825024014
reward/extrinsic_std_running :  1.6181924258330096
reward/intrinsic_batch_std :  4.071938488323123e-05
reward/intrinsic_batch_max :  0.0006857045809738338
reward/intrinsic_batch_min :  4.15099293604726e-06
reward/total_batch :  0.040878154380016525
time/iteration_time :  115.29113411903381
time/fps :  2341.897337233538
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.3s | FPS: 2342
Policy Loss: 0.0013, Value Loss: 3.1634, Entropy: 2.1497
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=188.0
Extrinsic raw: Œº=0.08170370370370371

=== Iteration 811/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.82s
EPOCH 1 took 19.63s
update_step :  811
reward/intrinsic_batch_mean :  5.268637827267176e-05
reward/extrinsic_batch_mean :  0.08288888888888889
loss/policy :  0.0013194301820035573
loss/rnd :  1.0215273012666632e-06
loss/value :  3.304868484988357
loss/value_i :  2.8571447037875536e-05
loss/value_e :  3.3048399271387043
loss/entropy :  2.160967848517678
reward/intrinsic_running :  0.0008298772893985495
reward/extrinsic_running :  0.08288888888888889
reward/intrinsic_std_running :  0.0188788706990288
reward/extrinsic_std_running :  1.6399581596589896
reward/intrinsic_batch_std :  4.1925815011387306e-05
reward/intrinsic_batch_max :  0.0007021537749096751
reward/intrinsic_batch_min :  5.025484369980404e-06
reward/total_batch :  0.04147078763358078
time/iteration_time :  116.79070472717285
time/fps :  2311.8278173826366
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.8s | FPS: 2312
Policy Loss: 0.0013, Value Loss: 3.3049, Entropy: 2.1610
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=188.4
Extrinsic raw: Œº=0.08288888888888889

=== Iteration 812/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.68s
EPOCH 1 took 18.80s
update_step :  812
reward/intrinsic_batch_mean :  5.308951365849579e-05
reward/extrinsic_batch_mean :  0.07992592592592593
loss/policy :  0.000734234938687278
loss/rnd :  9.894651007223068e-07
loss/value :  3.693487306435903
loss/value_i :  2.9079751808432883e-06
loss/value_e :  3.6934844056765237
loss/entropy :  2.1516873547525117
reward/intrinsic_running :  0.0008289680880341083
reward/extrinsic_running :  0.07992592592592593
reward/intrinsic_std_running :  0.018867260000988845
reward/extrinsic_std_running :  1.5943014243078597
reward/intrinsic_batch_std :  3.8432901296946826e-05
reward/intrinsic_batch_max :  0.0006639763596467674
reward/intrinsic_batch_min :  5.616579528577859e-06
reward/total_batch :  0.03998950771979221
time/iteration_time :  115.40999102592468
time/fps :  2339.4854951453
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2339
Policy Loss: 0.0007, Value Loss: 3.6935, Entropy: 2.1517
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=189.9
Extrinsic raw: Œº=0.07992592592592593

=== Iteration 813/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.94s
EPOCH 1 took 20.31s
update_step :  813
reward/intrinsic_batch_mean :  5.332518535962191e-05
reward/extrinsic_batch_mean :  0.08317777777777778
loss/policy :  0.0014427703978126924
loss/rnd :  1.0028244039886252e-06
loss/value :  3.4553493189089224
loss/value_i :  2.3967631622409416e-06
loss/value_e :  3.4553469202735205
loss/entropy :  2.139869530995687
reward/intrinsic_running :  0.0008280605110432391
reward/extrinsic_running :  0.08317777777777778
reward/intrinsic_std_running :  0.018855670728726962
reward/extrinsic_std_running :  1.6043263192896362
reward/intrinsic_batch_std :  4.168282805864039e-05
reward/intrinsic_batch_max :  0.0008167512132786214
reward/intrinsic_batch_min :  4.4405865082808305e-06
reward/total_batch :  0.0416155514815687
time/iteration_time :  116.61195158958435
time/fps :  2315.3715920154114
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.6s | FPS: 2315
Policy Loss: 0.0014, Value Loss: 3.4553, Entropy: 2.1399
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.043, sum=190.9
Extrinsic raw: Œº=0.08317777777777778

=== Iteration 814/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.57s
EPOCH 1 took 19.53s
update_step :  814
reward/intrinsic_batch_mean :  5.343362464518577e-05
reward/extrinsic_batch_mean :  0.08728148148148149
loss/policy :  0.0009891706325685266
loss/rnd :  1.0240936713864468e-06
loss/value :  4.158191428040013
loss/value_i :  3.7744039390776325e-06
loss/value_e :  4.158187653079177
loss/entropy :  2.1364071044054898
reward/intrinsic_running :  0.0008271563904761471
reward/extrinsic_running :  0.08728148148148149
reward/intrinsic_std_running :  0.018844102743934048
reward/extrinsic_std_running :  1.6621718552315012
reward/intrinsic_batch_std :  4.202289685424207e-05
reward/intrinsic_batch_max :  0.0007623443962074816
reward/intrinsic_batch_min :  4.350040853751125e-06
reward/total_batch :  0.04366745755306334
time/iteration_time :  114.23296523094177
time/fps :  2363.590925387852
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.2s | FPS: 2364
Policy Loss: 0.0010, Value Loss: 4.1582, Entropy: 2.1364
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=191.4
Extrinsic raw: Œº=0.08728148148148149

=== Iteration 815/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.76s
EPOCH 1 took 20.37s
update_step :  815
reward/intrinsic_batch_mean :  5.10043026110772e-05
reward/extrinsic_batch_mean :  0.0814
loss/policy :  0.0014301808815534141
loss/rnd :  9.62869566220351e-07
loss/value :  3.7115581649722476
loss/value_i :  1.300872063645577e-06
loss/value_e :  3.7115568301894446
loss/entropy :  2.1733555432521934
reward/intrinsic_running :  0.0008262481749560527
reward/extrinsic_running :  0.0814
reward/intrinsic_std_running :  0.01883255625858737
reward/extrinsic_std_running :  1.608106766770581
reward/intrinsic_batch_std :  3.918388011004602e-05
reward/intrinsic_batch_max :  0.0006689012516289949
reward/intrinsic_batch_min :  3.785280341617181e-06
reward/total_batch :  0.04072550215130554
time/iteration_time :  116.50593996047974
time/fps :  2317.4784057498473
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.5s | FPS: 2317
Policy Loss: 0.0014, Value Loss: 3.7116, Entropy: 2.1734
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=182.8
Extrinsic raw: Œº=0.0814

=== Iteration 816/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.77s
EPOCH 1 took 19.48s
update_step :  816
reward/intrinsic_batch_mean :  5.283219394146322e-05
reward/extrinsic_batch_mean :  0.08525185185185186
loss/policy :  0.0007873936518246245
loss/rnd :  1.0055940513418384e-06
loss/value :  2.696192837122715
loss/value_i :  1.4142342651570234e-06
loss/value_e :  2.6961914120298442
loss/entropy :  2.171335661050045
reward/intrinsic_running :  0.0008253469364330768
reward/extrinsic_running :  0.08525185185185186
reward/intrinsic_std_running :  0.018821030802880476
reward/extrinsic_std_running :  1.6379850685274244
reward/intrinsic_batch_std :  4.2272999824093734e-05
reward/intrinsic_batch_max :  0.0007810732931829989
reward/intrinsic_batch_min :  4.345738034317037e-06
reward/total_batch :  0.04265234202289666
time/iteration_time :  115.39391040802002
time/fps :  2339.8115121093483
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2340
Policy Loss: 0.0008, Value Loss: 2.6962, Entropy: 2.1713
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.042, sum=189.5
Extrinsic raw: Œº=0.08525185185185186

=== Iteration 817/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.72s
EPOCH 1 took 19.60s
update_step :  817
reward/intrinsic_batch_mean :  5.54042606469651e-05
reward/extrinsic_batch_mean :  0.08568148148148148
loss/policy :  0.001618037570909964
loss/rnd :  1.042384443542577e-06
loss/value :  3.8520042860146724
loss/value_i :  1.386059480093095e-06
loss/value_e :  3.85200287175901
loss/entropy :  2.1836961869037514
reward/intrinsic_running :  0.0008244534225848629
reward/extrinsic_running :  0.08568148148148148
reward/intrinsic_std_running :  0.018809526278447404
reward/extrinsic_std_running :  1.6573415175977948
reward/intrinsic_batch_std :  4.657363835080079e-05
reward/intrinsic_batch_max :  0.0008629238582216203
reward/intrinsic_batch_min :  3.598083139877417e-06
reward/total_batch :  0.04286844287106423
time/iteration_time :  114.8516297340393
time/fps :  2350.859109489662
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2351
Policy Loss: 0.0016, Value Loss: 3.8520, Entropy: 2.1837
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=198.8
Extrinsic raw: Œº=0.08568148148148148

=== Iteration 818/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.13s
EPOCH 1 took 18.71s
update_step :  818
reward/intrinsic_batch_mean :  5.130861408160854e-05
reward/extrinsic_batch_mean :  0.0811111111111111
loss/policy :  0.0014922465153645273
loss/rnd :  9.662672911500438e-07
loss/value :  3.2780788468592092
loss/value_i :  1.3351160360440244e-06
loss/value_e :  3.2780775120764067
loss/entropy :  2.1991544925805293
reward/intrinsic_running :  0.0008235530659630009
reward/extrinsic_running :  0.0811111111111111
reward/intrinsic_std_running :  0.018798043154553547
reward/extrinsic_std_running :  1.6163902016377782
reward/intrinsic_batch_std :  3.9161875529301775e-05
reward/intrinsic_batch_max :  0.0006176981842145324
reward/intrinsic_batch_min :  4.390280082589015e-06
reward/total_batch :  0.040581209862596355
time/iteration_time :  114.5053162574768
time/fps :  2357.9691216508904
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2358
Policy Loss: 0.0015, Value Loss: 3.2781, Entropy: 2.1992
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=184.2
Extrinsic raw: Œº=0.0811111111111111

=== Iteration 819/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.85s
EPOCH 1 took 19.39s
update_step :  819
reward/intrinsic_batch_mean :  5.053083990366792e-05
reward/extrinsic_batch_mean :  0.0831925925925926
loss/policy :  0.0009102537914066378
loss/rnd :  9.620729177627116e-07
loss/value :  2.874524819128441
loss/value_i :  1.5079442911855674e-06
loss/value_e :  2.8745233199813147
loss/entropy :  2.2031577428181968
reward/intrinsic_running :  0.0008226535291665417
reward/extrinsic_running :  0.0831925925925926
reward/intrinsic_std_running :  0.018786581085949886
reward/extrinsic_std_running :  1.6317910269089864
reward/intrinsic_batch_std :  3.872157258498721e-05
reward/intrinsic_batch_max :  0.00045617963769473135
reward/intrinsic_batch_min :  4.103052106074756e-06
reward/total_batch :  0.04162156171624813
time/iteration_time :  114.62503147125244
time/fps :  2355.5064416075215
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.6s | FPS: 2356
Policy Loss: 0.0009, Value Loss: 2.8745, Entropy: 2.2032
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.024, sum=181.6
Extrinsic raw: Œº=0.0831925925925926

=== Iteration 820/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.21s
EPOCH 1 took 18.51s
update_step :  820
reward/intrinsic_batch_mean :  5.813738404078187e-05
reward/extrinsic_batch_mean :  0.08566666666666667
loss/policy :  0.0010838668130225305
loss/rnd :  1.0012705159266315e-06
loss/value :  3.6791610519091287
loss/value_i :  1.2661428913264845e-06
loss/value_e :  3.6791597640875615
loss/entropy :  2.1964547634124756
reward/intrinsic_running :  0.000821770827707276
reward/extrinsic_running :  0.08566666666666667
reward/intrinsic_std_running :  0.01877513940725165
reward/extrinsic_std_running :  1.6483813946481631
reward/intrinsic_batch_std :  4.403243556472395e-05
reward/intrinsic_batch_max :  0.0009271181188523769
reward/intrinsic_batch_min :  9.751210200192872e-06
reward/total_batch :  0.04286240202535373
time/iteration_time :  115.0545539855957
time/fps :  2346.712847488008
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2347
Policy Loss: 0.0011, Value Loss: 3.6792, Entropy: 2.1965
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.049, sum=209.0
Extrinsic raw: Œº=0.08566666666666667

=== Iteration 821/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.02s
EPOCH 1 took 19.50s
update_step :  821
reward/intrinsic_batch_mean :  5.057802344476335e-05
reward/extrinsic_batch_mean :  0.08327407407407407
loss/policy :  0.0012856599977098856
loss/rnd :  9.900061854750675e-07
loss/value :  4.564801389520818
loss/value_i :  1.135699631738658e-06
loss/value_e :  4.564800316637212
loss/entropy :  2.216658263495474
reward/intrinsic_running :  0.0008208760290884199
reward/extrinsic_running :  0.08327407407407407
reward/intrinsic_std_running :  0.018763719136983464
reward/extrinsic_std_running :  1.6413021769298035
reward/intrinsic_batch_std :  3.671165257789338e-05
reward/intrinsic_batch_max :  0.00046123628271743655
reward/intrinsic_batch_min :  4.166236067248974e-06
reward/total_batch :  0.04166232604875942
time/iteration_time :  115.71107578277588
time/fps :  2333.3980621429046
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.7s | FPS: 2333
Policy Loss: 0.0013, Value Loss: 4.5648, Entropy: 2.2167
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.025, sum=181.9
Extrinsic raw: Œº=0.08327407407407407

=== Iteration 822/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.33s
EPOCH 1 took 18.35s
update_step :  822
reward/intrinsic_batch_mean :  5.392256364044712e-05
reward/extrinsic_batch_mean :  0.08547407407407408
loss/policy :  0.0015321460995244597
loss/rnd :  9.94236371077546e-07
loss/value :  5.476267345023878
loss/value_i :  1.1781567547007976e-06
loss/value_e :  5.476266160155788
loss/entropy :  2.2015852025060942
reward/intrinsic_running :  0.0008199884148455192
reward/extrinsic_running :  0.08547407407407408
reward/intrinsic_std_running :  0.01875231949487687
reward/extrinsic_std_running :  1.638934194460623
reward/intrinsic_batch_std :  4.005071372521082e-05
reward/intrinsic_batch_max :  0.0005879076779820025
reward/intrinsic_batch_min :  5.605736532743322e-06
reward/total_batch :  0.042763998318857264
time/iteration_time :  114.8765161037445
time/fps :  2350.349829169298
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2350
Policy Loss: 0.0015, Value Loss: 5.4763, Entropy: 2.2016
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.031, sum=194.1
Extrinsic raw: Œº=0.08547407407407408

=== Iteration 823/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.21s
EPOCH 1 took 18.59s
update_step :  823
reward/intrinsic_batch_mean :  5.116269985653532e-05
reward/extrinsic_batch_mean :  0.07991111111111111
loss/policy :  0.0011579797346988044
loss/rnd :  9.759357546747858e-07
loss/value :  3.892444144595753
loss/value_i :  1.3415115958967803e-06
loss/value_e :  3.8924427791075273
loss/entropy :  2.203910535032099
reward/intrinsic_running :  0.0008190982956049245
reward/extrinsic_running :  0.07991111111111111
reward/intrinsic_std_running :  0.01874094077974064
reward/extrinsic_std_running :  1.6035699038530282
reward/intrinsic_batch_std :  3.8250167973413344e-05
reward/intrinsic_batch_max :  0.000596173107624054
reward/intrinsic_batch_min :  3.939565431210212e-06
reward/total_batch :  0.03998113690548383
time/iteration_time :  115.59878325462341
time/fps :  2335.664722398376
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.6s | FPS: 2336
Policy Loss: 0.0012, Value Loss: 3.8924, Entropy: 2.2039
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=184.3
Extrinsic raw: Œº=0.07991111111111111

=== Iteration 824/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.49s
EPOCH 1 took 18.97s
update_step :  824
reward/intrinsic_batch_mean :  6.028366505337612e-05
reward/extrinsic_batch_mean :  0.08008148148148148
loss/policy :  0.0014710607656249495
loss/rnd :  1.0155398694099527e-06
loss/value :  3.049430119268822
loss/value_i :  1.2471107828043222e-06
loss/value_e :  3.0494288711836846
loss/entropy :  2.2118774110620674
reward/intrinsic_running :  0.000818229934483173
reward/extrinsic_running :  0.08008148148148148
reward/intrinsic_std_running :  0.018729581997907568
reward/extrinsic_std_running :  1.604943149111297
reward/intrinsic_batch_std :  3.695139437742701e-05
reward/intrinsic_batch_max :  0.0005050625186413527
reward/intrinsic_batch_min :  1.1072074812545907e-05
reward/total_batch :  0.04007088257326743
time/iteration_time :  116.42951011657715
time/fps :  2318.999708318429
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.4s | FPS: 2319
Policy Loss: 0.0015, Value Loss: 3.0494, Entropy: 2.2119
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=217.3
Extrinsic raw: Œº=0.08008148148148148

=== Iteration 825/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.12s
EPOCH 1 took 19.03s
update_step :  825
reward/intrinsic_batch_mean :  5.352006888207581e-05
reward/extrinsic_batch_mean :  0.08565185185185185
loss/policy :  0.0012974770101154168
loss/rnd :  9.890604660127296e-07
loss/value :  4.323603304949674
loss/value_i :  1.3973790115332205e-06
loss/value_e :  4.323601894306414
loss/entropy :  2.203794959819678
reward/intrinsic_running :  0.000817349206416248
reward/extrinsic_running :  0.08565185185185185
reward/intrinsic_std_running :  0.018718244411906775
reward/extrinsic_std_running :  1.6573028236152973
reward/intrinsic_batch_std :  4.323555133823322e-05
reward/intrinsic_batch_max :  0.0008723821374587715
reward/intrinsic_batch_min :  4.632590844266815e-06
reward/total_batch :  0.04285268596036697
time/iteration_time :  114.77451205253601
time/fps :  2352.4386657937807
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.8s | FPS: 2352
Policy Loss: 0.0013, Value Loss: 4.3236, Entropy: 2.2038
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.047, sum=193.0
Extrinsic raw: Œº=0.08565185185185185

=== Iteration 826/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.92s
EPOCH 1 took 19.19s
update_step :  826
reward/intrinsic_batch_mean :  5.377820243127105e-05
reward/extrinsic_batch_mean :  0.08523703703703704
loss/policy :  0.0006212975051973692
loss/rnd :  1.0079390800786892e-06
loss/value :  3.427415618390748
loss/value_i :  1.2258302776348446e-06
loss/value_e :  3.427414363080805
loss/entropy :  2.2097537842663852
reward/intrinsic_running :  0.0008164719267273514
reward/extrinsic_running :  0.08523703703703704
reward/intrinsic_std_running :  0.018706927340300133
reward/extrinsic_std_running :  1.6470527604376537
reward/intrinsic_batch_std :  4.1477967119842675e-05
reward/intrinsic_batch_max :  0.0007522330852225423
reward/intrinsic_batch_min :  4.285481281840475e-06
reward/total_batch :  0.042645407619734156
time/iteration_time :  115.99212980270386
time/fps :  2327.744136255235
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.0s | FPS: 2328
Policy Loss: 0.0006, Value Loss: 3.4274, Entropy: 2.2098
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.040, sum=194.0
Extrinsic raw: Œº=0.08523703703703704

=== Iteration 827/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.73s
EPOCH 1 took 19.22s
update_step :  827
reward/intrinsic_batch_mean :  5.3363050711326384e-05
reward/extrinsic_batch_mean :  0.0833037037037037
loss/policy :  0.001501611201533568
loss/rnd :  1.015442742093662e-06
loss/value :  4.197102532242283
loss/value_i :  1.2291366405489415e-06
loss/value_e :  4.197101271513737
loss/entropy :  2.2090542569304956
reward/intrinsic_running :  0.0008155938889464633
reward/extrinsic_running :  0.0833037037037037
reward/intrinsic_std_running :  0.018695630879361897
reward/extrinsic_std_running :  1.632244912968703
reward/intrinsic_batch_std :  4.081841181731016e-05
reward/intrinsic_batch_max :  0.0004984684055671096
reward/intrinsic_batch_min :  4.136483767069876e-06
reward/total_batch :  0.04167853337720751
time/iteration_time :  114.86476922035217
time/fps :  2350.59019255976
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.9s | FPS: 2351
Policy Loss: 0.0015, Value Loss: 4.1971, Entropy: 2.2091
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=192.7
Extrinsic raw: Œº=0.0833037037037037

=== Iteration 828/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.93s
EPOCH 1 took 20.17s
update_step :  828
reward/intrinsic_batch_mean :  5.4706388909464834e-05
reward/extrinsic_batch_mean :  0.08434074074074074
loss/policy :  0.0018832893754623717
loss/rnd :  1.0248650107424702e-06
loss/value :  3.6904299349495857
loss/value_i :  1.2703878579403947e-06
loss/value_e :  3.6904286507404214
loss/entropy :  2.2075578516179863
reward/intrinsic_running :  0.0008147200605815733
reward/extrinsic_running :  0.08434074074074074
reward/intrinsic_std_running :  0.01868435477595887
reward/extrinsic_std_running :  1.644399465584402
reward/intrinsic_batch_std :  4.351416796161451e-05
reward/intrinsic_batch_max :  0.0010510216234251857
reward/intrinsic_batch_min :  5.046419119025813e-06
reward/total_batch :  0.0421977235648251
time/iteration_time :  117.81017804145813
time/fps :  2291.822357699734
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.8s | FPS: 2292
Policy Loss: 0.0019, Value Loss: 3.6904, Entropy: 2.2076
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.056, sum=197.6
Extrinsic raw: Œº=0.08434074074074074

=== Iteration 829/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.05s
EPOCH 1 took 19.45s
update_step :  829
reward/intrinsic_batch_mean :  5.0380409305412116e-05
reward/extrinsic_batch_mean :  0.0816962962962963
loss/policy :  0.0006705856349347441
loss/rnd :  9.398353459787221e-07
loss/value :  3.5949803012790102
loss/value_i :  1.2088752396955511e-06
loss/value_e :  3.5949790875116983
loss/entropy :  2.2163012822469077
reward/intrinsic_running :  0.000813841299809748
reward/extrinsic_running :  0.0816962962962963
reward/intrinsic_std_running :  0.018673099324424
reward/extrinsic_std_running :  1.618193944216018
reward/intrinsic_batch_std :  4.011806089916216e-05
reward/intrinsic_batch_max :  0.0005111738573759794
reward/intrinsic_batch_min :  3.888076207658742e-06
reward/total_batch :  0.04087333835280085
time/iteration_time :  115.76150274276733
time/fps :  2332.381608763016
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.8s | FPS: 2332
Policy Loss: 0.0007, Value Loss: 3.5950, Entropy: 2.2163
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.027, sum=182.1
Extrinsic raw: Œº=0.0816962962962963

=== Iteration 830/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.87s
EPOCH 1 took 20.16s
update_step :  830
reward/intrinsic_batch_mean :  5.4003451461600584e-05
reward/extrinsic_batch_mean :  0.08432592592592593
loss/policy :  0.0013418862751374643
loss/rnd :  1.015432002132553e-06
loss/value :  4.671689557306694
loss/value_i :  1.4487598811931754e-06
loss/value_e :  4.671688097895998
loss/entropy :  2.2056825124856196
reward/intrinsic_running :  0.0008129705541703662
reward/extrinsic_running :  0.08432592592592593
reward/intrinsic_std_running :  0.018661863974828833
reward/extrinsic_std_running :  1.6444024776760415
reward/intrinsic_batch_std :  4.414737761751269e-05
reward/intrinsic_batch_max :  0.0006643416127189994
reward/intrinsic_batch_min :  4.298557087167865e-06
reward/total_batch :  0.042189964688693765
time/iteration_time :  116.91862440109253
time/fps :  2309.298466202935
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.9s | FPS: 2309
Policy Loss: 0.0013, Value Loss: 4.6717, Entropy: 2.2057
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=195.3
Extrinsic raw: Œº=0.08432592592592593

=== Iteration 831/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.50s
EPOCH 1 took 18.81s
update_step :  831
reward/intrinsic_batch_mean :  5.488886147557895e-05
reward/extrinsic_batch_mean :  0.08252592592592592
loss/policy :  0.0013465175685599786
loss/rnd :  1.0178847629283678e-06
loss/value :  5.522095673012011
loss/value_i :  1.3992322137848092e-06
loss/value_e :  5.522094242500536
loss/entropy :  2.2140104590040264
reward/intrinsic_running :  0.0008121039400142251
reward/extrinsic_running :  0.08252592592592592
reward/intrinsic_std_running :  0.0186506487972194
reward/extrinsic_std_running :  1.6209052766878491
reward/intrinsic_batch_std :  4.336241316073623e-05
reward/intrinsic_batch_max :  0.0005993157392367721
reward/intrinsic_batch_min :  4.009380518255057e-06
reward/total_batch :  0.04129040739370075
time/iteration_time :  114.3264832496643
time/fps :  2361.6575296064902
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.3s | FPS: 2362
Policy Loss: 0.0013, Value Loss: 5.5221, Entropy: 2.2140
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=198.7
Extrinsic raw: Œº=0.08252592592592592

=== Iteration 832/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.31s
EPOCH 1 took 19.72s
update_step :  832
reward/intrinsic_batch_mean :  5.4061769197660735e-05
reward/extrinsic_batch_mean :  0.08723703703703704
loss/policy :  0.0014643439587389091
loss/rnd :  1.0090046203004022e-06
loss/value :  5.714384440219764
loss/value_i :  1.3948467905279496e-06
loss/value_e :  5.714383009708289
loss/entropy :  2.21225520697507
reward/intrinsic_running :  0.0008112377903949699
reward/extrinsic_running :  0.08723703703703704
reward/intrinsic_std_running :  0.01863945387722837
reward/extrinsic_std_running :  1.6719562935427306
reward/intrinsic_batch_std :  4.505411244685749e-05
reward/intrinsic_batch_max :  0.0006795289227738976
reward/intrinsic_batch_min :  4.2131800910283346e-06
reward/total_batch :  0.04364554940311735
time/iteration_time :  116.02640581130981
time/fps :  2327.0564843583343
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.0s | FPS: 2327
Policy Loss: 0.0015, Value Loss: 5.7144, Entropy: 2.2123
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=195.8
Extrinsic raw: Œº=0.08723703703703704

=== Iteration 833/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.96s
EPOCH 1 took 18.88s
update_step :  833
reward/intrinsic_batch_mean :  5.429479522039468e-05
reward/extrinsic_batch_mean :  0.08682962962962963
loss/policy :  0.0012142310557520073
loss/rnd :  1.0415082332463388e-06
loss/value :  4.263410810268287
loss/value_i :  1.6638614311253177e-06
loss/value_e :  4.263409144950636
loss/entropy :  2.203095125429558
reward/intrinsic_running :  0.0008103729382894138
reward/extrinsic_running :  0.08682962962962963
reward/intrinsic_std_running :  0.018628279119133475
reward/extrinsic_std_running :  1.6697553226867121
reward/intrinsic_batch_std :  4.5868469951600776e-05
reward/intrinsic_batch_max :  0.000673546630423516
reward/intrinsic_batch_min :  4.786516910826322e-06
reward/total_batch :  0.043441962212425016
time/iteration_time :  115.00085210800171
time/fps :  2347.8086905515506
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.0s | FPS: 2348
Policy Loss: 0.0012, Value Loss: 4.2634, Entropy: 2.2031
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=196.7
Extrinsic raw: Œº=0.08682962962962963

=== Iteration 834/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.36s
EPOCH 1 took 19.86s
update_step :  834
reward/intrinsic_batch_mean :  5.5166692236094537e-05
reward/extrinsic_batch_mean :  0.08265925925925927
loss/policy :  0.002428741480054503
loss/rnd :  1.0152022169181278e-06
loss/value :  6.179036288550406
loss/value_i :  1.4536696005851617e-06
loss/value_e :  6.179034807465293
loss/entropy :  2.2051428484194204
reward/intrinsic_running :  0.0008095125524265735
reward/extrinsic_running :  0.08265925925925927
reward/intrinsic_std_running :  0.01861712433618825
reward/extrinsic_std_running :  1.6121945138730664
reward/intrinsic_batch_std :  4.138655253125827e-05
reward/intrinsic_batch_max :  0.0006238564965315163
reward/intrinsic_batch_min :  4.293621259421343e-06
reward/total_batch :  0.04135721297574768
time/iteration_time :  114.23211646080017
time/fps :  2363.6084873963887
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.2s | FPS: 2364
Policy Loss: 0.0024, Value Loss: 6.1790, Entropy: 2.2051
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=200.0
Extrinsic raw: Œº=0.08265925925925927

=== Iteration 835/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.58s
EPOCH 1 took 18.30s
update_step :  835
reward/intrinsic_batch_mean :  5.275565662580414e-05
reward/extrinsic_batch_mean :  0.08402222222222222
loss/policy :  0.001216923858561186
loss/rnd :  9.7672633036051e-07
loss/value :  4.8323400670831855
loss/value_i :  1.315447527552103e-06
loss/value_e :  4.8323386907577515
loss/entropy :  2.2212824496355923
reward/intrinsic_running :  0.0008086499488805528
reward/extrinsic_running :  0.08402222222222222
reward/intrinsic_std_running :  0.018605989733605433
reward/extrinsic_std_running :  1.635385187231829
reward/intrinsic_batch_std :  4.101325117732674e-05
reward/intrinsic_batch_max :  0.0006411931244656444
reward/intrinsic_batch_min :  4.693803930422291e-06
reward/total_batch :  0.042037488939424016
time/iteration_time :  113.66241979598999
time/fps :  2375.455321861145
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.7s | FPS: 2375
Policy Loss: 0.0012, Value Loss: 4.8323, Entropy: 2.2213
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=191.4
Extrinsic raw: Œº=0.08402222222222222

=== Iteration 836/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.37s
EPOCH 1 took 19.93s
update_step :  836
reward/intrinsic_batch_mean :  5.365144003954575e-05
reward/extrinsic_batch_mean :  0.08611111111111111
loss/policy :  0.0021904674341027257
loss/rnd :  1.0005449639445005e-06
loss/value :  4.267101667144082
loss/value_i :  1.3723324042130667e-06
loss/value_e :  4.267100265531829
loss/entropy :  2.2035516500473022
reward/intrinsic_running :  0.0008077907500870172
reward/extrinsic_running :  0.08611111111111111
reward/intrinsic_std_running :  0.018594875061286657
reward/extrinsic_std_running :  1.6497058286214707
reward/intrinsic_batch_std :  4.7939540462715634e-05
reward/intrinsic_batch_max :  0.0009886337211355567
reward/intrinsic_batch_min :  3.801059847319266e-06
reward/total_batch :  0.04308238127557533
time/iteration_time :  116.74482083320618
time/fps :  2312.736428674212
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.7s | FPS: 2313
Policy Loss: 0.0022, Value Loss: 4.2671, Entropy: 2.2036
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.053, sum=194.8
Extrinsic raw: Œº=0.08611111111111111

=== Iteration 837/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.40s
EPOCH 1 took 18.33s
update_step :  837
reward/intrinsic_batch_mean :  5.0408395978943356e-05
reward/extrinsic_batch_mean :  0.08151111111111112
loss/policy :  0.0018299415153733482
loss/rnd :  9.617647187744958e-07
loss/value :  5.395406809720126
loss/value_i :  1.5118769273282273e-06
loss/value_e :  5.395405343084624
loss/entropy :  2.2360498182701343
reward/intrinsic_running :  0.000806928209481473
reward/extrinsic_running :  0.08151111111111112
reward/intrinsic_std_running :  0.018583780468383423
reward/extrinsic_std_running :  1.6085674596045902
reward/intrinsic_batch_std :  4.103340162166477e-05
reward/intrinsic_batch_max :  0.0006063474575057626
reward/intrinsic_batch_min :  3.624428700277349e-06
reward/total_batch :  0.04078075975354503
time/iteration_time :  115.5053198337555
time/fps :  2337.5546718420037
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.5s | FPS: 2338
Policy Loss: 0.0018, Value Loss: 5.3954, Entropy: 2.2360
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=183.1
Extrinsic raw: Œº=0.08151111111111112

=== Iteration 838/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.63s
EPOCH 1 took 19.60s
update_step :  838
reward/intrinsic_batch_mean :  5.2295678101775896e-05
reward/extrinsic_batch_mean :  0.08668148148148148
loss/policy :  0.0003462700000399667
loss/rnd :  1.0884616163807412e-06
loss/value :  4.600309314149799
loss/value_i :  1.2021604609826957e-06
loss/value_e :  4.600308107607292
loss/entropy :  2.2154127395514287
reward/intrinsic_running :  0.0008060698076718695
reward/extrinsic_running :  0.08668148148148148
reward/intrinsic_std_running :  0.018572705631999472
reward/extrinsic_std_running :  1.6604208598663437
reward/intrinsic_batch_std :  4.389527001082292e-05
reward/intrinsic_batch_max :  0.0007155388593673706
reward/intrinsic_batch_min :  4.196263944322709e-06
reward/total_batch :  0.04336688857979163
time/iteration_time :  115.64515924453735
time/fps :  2334.7280747745936
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.6s | FPS: 2335
Policy Loss: 0.0003, Value Loss: 4.6003, Entropy: 2.2154
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.039, sum=190.1
Extrinsic raw: Œº=0.08668148148148148

=== Iteration 839/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.67s
EPOCH 1 took 19.48s
update_step :  839
reward/intrinsic_batch_mean :  5.3067514704236126e-05
reward/extrinsic_batch_mean :  0.08642962962962963
loss/policy :  0.0009636806410553893
loss/rnd :  1.111947572133321e-06
loss/value :  3.0847765135042593
loss/value_i :  1.2562979436276664e-06
loss/value_e :  3.084775254581914
loss/entropy :  2.2266655762990317
reward/intrinsic_running :  0.0008052149387297693
reward/extrinsic_running :  0.08642962962962963
reward/intrinsic_std_running :  0.01856165052062247
reward/extrinsic_std_running :  1.6595348279105233
reward/intrinsic_batch_std :  4.612889325987477e-05
reward/intrinsic_batch_max :  0.0009028547792695463
reward/intrinsic_batch_min :  4.895258825854398e-06
reward/total_batch :  0.04324134857216694
time/iteration_time :  115.63839769363403
time/fps :  2334.8645898339328
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.6s | FPS: 2335
Policy Loss: 0.0010, Value Loss: 3.0848, Entropy: 2.2267
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.049, sum=193.0
Extrinsic raw: Œº=0.08642962962962963

=== Iteration 840/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.33s
EPOCH 1 took 19.68s
update_step :  840
reward/intrinsic_batch_mean :  5.5365086235906344e-05
reward/extrinsic_batch_mean :  0.08858518518518518
loss/policy :  0.0007621007389388978
loss/rnd :  9.858554781685873e-07
loss/value :  5.303446654117469
loss/value_i :  1.2023971156381639e-06
loss/value_e :  5.303445454799768
loss/entropy :  2.210699312614672
reward/intrinsic_running :  0.000804367574298795
reward/extrinsic_running :  0.08858518518518518
reward/intrinsic_std_running :  0.018550614913038176
reward/extrinsic_std_running :  1.6661134854646575
reward/intrinsic_batch_std :  4.2717575434131894e-05
reward/intrinsic_batch_max :  0.0006427119951695204
reward/intrinsic_batch_min :  5.412121936387848e-06
reward/total_batch :  0.044320275135710546
time/iteration_time :  116.56716060638428
time/fps :  2316.261274577296
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.6s | FPS: 2316
Policy Loss: 0.0008, Value Loss: 5.3034, Entropy: 2.2107
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=201.5
Extrinsic raw: Œº=0.08858518518518518

=== Iteration 841/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.61s
EPOCH 1 took 20.31s
update_step :  841
reward/intrinsic_batch_mean :  5.092377393054145e-05
reward/extrinsic_batch_mean :  0.08536296296296296
loss/policy :  0.0017827925631453663
loss/rnd :  9.436721467009743e-07
loss/value :  3.9486657959042173
loss/value_i :  1.2490492467391463e-06
loss/value_e :  3.948664569493496
loss/entropy :  2.213717316136216
reward/intrinsic_running :  0.0008035137728518579
reward/extrinsic_running :  0.08536296296296296
reward/intrinsic_std_running :  0.01853959928855641
reward/extrinsic_std_running :  1.6564671849827135
reward/intrinsic_batch_std :  4.270370071612048e-05
reward/intrinsic_batch_max :  0.0007801535539329052
reward/intrinsic_batch_min :  4.1076041270571295e-06
reward/total_batch :  0.04270694336844675
time/iteration_time :  117.10072350502014
time/fps :  2305.7073595999177
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.1s | FPS: 2306
Policy Loss: 0.0018, Value Loss: 3.9487, Entropy: 2.2137
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.042, sum=185.4
Extrinsic raw: Œº=0.08536296296296296

=== Iteration 842/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.32s
EPOCH 1 took 19.42s
update_step :  842
reward/intrinsic_batch_mean :  5.023609263770831e-05
reward/extrinsic_batch_mean :  0.08756296296296297
loss/policy :  0.0010119035627708813
loss/rnd :  9.329423080268471e-07
loss/value :  4.864325454740813
loss/value_i :  1.131152526850752e-06
loss/value_e :  4.864324405337825
loss/entropy :  2.207075501933242
reward/intrinsic_running :  0.000802660714626843
reward/extrinsic_running :  0.08756296296296297
reward/intrinsic_std_running :  0.018528603302111656
reward/extrinsic_std_running :  1.6728206789173312
reward/intrinsic_batch_std :  3.9890099877247666e-05
reward/intrinsic_batch_max :  0.0005553946830332279
reward/intrinsic_batch_min :  4.076788627571659e-06
reward/total_batch :  0.04380659952780034
time/iteration_time :  114.47348499298096
time/fps :  2358.624794349148
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.5s | FPS: 2359
Policy Loss: 0.0010, Value Loss: 4.8643, Entropy: 2.2071
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=183.0
Extrinsic raw: Œº=0.08756296296296297

=== Iteration 843/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.16s
EPOCH 1 took 19.28s
update_step :  843
reward/intrinsic_batch_mean :  5.199858227167877e-05
reward/extrinsic_batch_mean :  0.08138518518518519
loss/policy :  0.0016876522788538061
loss/rnd :  9.654134857734762e-07
loss/value :  4.268156174457435
loss/value_i :  1.1492378737812308e-06
loss/value_e :  4.268155058224996
loss/entropy :  2.2269301703481963
reward/intrinsic_running :  0.0008018129305433909
reward/extrinsic_running :  0.08138518518518519
reward/intrinsic_std_running :  0.018517626735550775
reward/extrinsic_std_running :  1.6264305861709483
reward/intrinsic_batch_std :  3.9908526353596394e-05
reward/intrinsic_batch_max :  0.0005278591415844858
reward/intrinsic_batch_min :  3.847576863336144e-06
reward/total_batch :  0.04071859188372843
time/iteration_time :  117.22999358177185
time/fps :  2303.1648450246307
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.2s | FPS: 2303
Policy Loss: 0.0017, Value Loss: 4.2682, Entropy: 2.2269
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.029, sum=189.5
Extrinsic raw: Œº=0.08138518518518519

=== Iteration 844/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.17s
EPOCH 1 took 19.63s
update_step :  844
reward/intrinsic_batch_mean :  5.444990093010684e-05
reward/extrinsic_batch_mean :  0.08494074074074075
loss/policy :  0.001208173864252978
loss/rnd :  1.0047679028723382e-06
loss/value :  3.5337852763407156
loss/value_i :  1.2377626190259021e-06
loss/value_e :  3.5337840300617795
loss/entropy :  2.221948367176634
reward/intrinsic_running :  0.00080097191860468
reward/extrinsic_running :  0.08494074074074075
reward/intrinsic_std_running :  0.018506669489990375
reward/extrinsic_std_running :  1.66407016528957
reward/intrinsic_batch_std :  4.681411627449097e-05
reward/intrinsic_batch_max :  0.0012890053912997246
reward/intrinsic_batch_min :  3.8076750570326112e-06
reward/total_batch :  0.04249759532083543
time/iteration_time :  114.43958616256714
time/fps :  2359.3234566267265
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2359
Policy Loss: 0.0012, Value Loss: 3.5338, Entropy: 2.2219
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.070, sum=198.6
Extrinsic raw: Œº=0.08494074074074075

=== Iteration 845/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.70s
EPOCH 1 took 19.13s
update_step :  845
reward/intrinsic_batch_mean :  5.333819585126481e-05
reward/extrinsic_batch_mean :  0.08733333333333333
loss/policy :  0.0011584369704271949
loss/rnd :  9.83742709918674e-07
loss/value :  2.534836035786253
loss/value_i :  1.6671534815555567e-06
loss/value_e :  2.534834356018991
loss/entropy :  2.1933283083366626
reward/intrinsic_running :  0.0008001310595647308
reward/extrinsic_running :  0.08733333333333333
reward/intrinsic_std_running :  0.018495731760592087
reward/extrinsic_std_running :  1.7017971764078201
reward/intrinsic_batch_std :  4.653916672698786e-05
reward/intrinsic_batch_max :  0.0010125575354322791
reward/intrinsic_batch_min :  3.96611676478642e-06
reward/total_batch :  0.0436933357645923
time/iteration_time :  115.18354225158691
time/fps :  2344.084881590626
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.2s | FPS: 2344
Policy Loss: 0.0012, Value Loss: 2.5348, Entropy: 2.1933
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.055, sum=194.7
Extrinsic raw: Œº=0.08733333333333333

=== Iteration 846/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.31s
EPOCH 1 took 18.79s
update_step :  846
reward/intrinsic_batch_mean :  5.349959263781717e-05
reward/extrinsic_batch_mean :  0.0794962962962963
loss/policy :  0.0014846349861755064
loss/rnd :  9.812810393475846e-07
loss/value :  3.22627846399943
loss/value_i :  1.2707991441912423e-06
loss/value_e :  3.22627717256546
loss/entropy :  2.212713447484103
reward/intrinsic_running :  0.0007992904896141987
reward/extrinsic_running :  0.0794962962962963
reward/intrinsic_std_running :  0.01848481345821079
reward/extrinsic_std_running :  1.5929261352016626
reward/intrinsic_batch_std :  4.5283930004336684e-05
reward/intrinsic_batch_max :  0.0008019337547011673
reward/intrinsic_batch_min :  3.704873279275489e-06
reward/total_batch :  0.03977489794446706
time/iteration_time :  113.93383932113647
time/fps :  2369.7963801515716
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.9s | FPS: 2370
Policy Loss: 0.0015, Value Loss: 3.2263, Entropy: 2.2127
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.043, sum=195.4
Extrinsic raw: Œº=0.0794962962962963

=== Iteration 847/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.83s
EPOCH 1 took 19.48s
update_step :  847
reward/intrinsic_batch_mean :  5.478814360910662e-05
reward/extrinsic_batch_mean :  0.08128888888888888
loss/policy :  0.0015797550802358962
loss/rnd :  1.0156336136815574e-06
loss/value :  2.970965896591996
loss/value_i :  4.775482101181159e-06
loss/value_e :  2.970961120995608
loss/entropy :  2.185788302710562
reward/intrinsic_running :  0.0007984545706421425
reward/extrinsic_running :  0.08128888888888888
reward/intrinsic_std_running :  0.01847391438181659
reward/extrinsic_std_running :  1.598404147969753
reward/intrinsic_batch_std :  4.921420086023759e-05
reward/intrinsic_batch_max :  0.0006618014303967357
reward/intrinsic_batch_min :  4.438987616595114e-06
reward/total_batch :  0.040671838516249
time/iteration_time :  116.36998462677002
time/fps :  2320.185921360761
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.4s | FPS: 2320
Policy Loss: 0.0016, Value Loss: 2.9710, Entropy: 2.1858
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=200.2
Extrinsic raw: Œº=0.08128888888888888

=== Iteration 848/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.78s
EPOCH 1 took 18.69s
update_step :  848
reward/intrinsic_batch_mean :  5.104182373074932e-05
reward/extrinsic_batch_mean :  0.08364444444444444
loss/policy :  0.0013551872213032436
loss/rnd :  9.444996792215975e-07
loss/value :  2.621164007620378
loss/value_i :  7.493107146370731e-06
loss/value_e :  2.6211565082723443
loss/entropy :  2.1951456756302803
reward/intrinsic_running :  0.0007976138848884347
reward/extrinsic_running :  0.08364444444444444
reward/intrinsic_std_running :  0.018463034775546203
reward/extrinsic_std_running :  1.6240313054210669
reward/intrinsic_batch_std :  4.024249445962617e-05
reward/intrinsic_batch_max :  0.0006069110240787268
reward/intrinsic_batch_min :  4.353552867542021e-06
reward/total_batch :  0.041847743134087595
time/iteration_time :  114.7532377243042
time/fps :  2352.8747890205736
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.8s | FPS: 2353
Policy Loss: 0.0014, Value Loss: 2.6212, Entropy: 2.1951
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=186.6
Extrinsic raw: Œº=0.08364444444444444

=== Iteration 849/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.74s
EPOCH 1 took 19.61s
update_step :  849
reward/intrinsic_batch_mean :  5.213178782442911e-05
reward/extrinsic_batch_mean :  0.0841925925925926
loss/policy :  0.0010686351579903258
loss/rnd :  9.598212483124922e-07
loss/value :  4.380607312375849
loss/value_i :  1.6607622349125228e-06
loss/value_e :  4.380605650670601
loss/entropy :  2.165590499386643
reward/intrinsic_running :  0.0007967776257579609
reward/extrinsic_running :  0.0841925925925926
reward/intrinsic_std_running :  0.018452174282641478
reward/extrinsic_std_running :  1.634920016148921
reward/intrinsic_batch_std :  4.2447886090461234e-05
reward/intrinsic_batch_max :  0.0008664249908179045
reward/intrinsic_batch_min :  4.6444370127574075e-06
reward/total_batch :  0.04212236219020851
time/iteration_time :  116.65297245979309
time/fps :  2314.5573945238402
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.7s | FPS: 2315
Policy Loss: 0.0011, Value Loss: 4.3806, Entropy: 2.1656
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.047, sum=190.7
Extrinsic raw: Œº=0.0841925925925926

=== Iteration 850/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.29s
EPOCH 1 took 18.38s
update_step :  850
reward/intrinsic_batch_mean :  5.718265049506078e-05
reward/extrinsic_batch_mean :  0.08554074074074074
loss/policy :  0.0011948402768184403
loss/rnd :  1.0575680665748555e-06
loss/value :  3.7034462130430974
loss/value_i :  1.6138064032047899e-06
loss/value_e :  3.7034446344231116
loss/entropy :  2.1237592697143555
reward/intrinsic_running :  0.0007959532666872471
reward/extrinsic_running :  0.08554074074074074
reward/intrinsic_std_running :  0.01844133263442148
reward/extrinsic_std_running :  1.6307193948182772
reward/intrinsic_batch_std :  5.554139332730019e-05
reward/intrinsic_batch_max :  0.0009549499372951686
reward/intrinsic_batch_min :  4.783542408404173e-06
reward/total_batch :  0.0427989616956179
time/iteration_time :  114.97417163848877
time/fps :  2348.353514117555
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.0s | FPS: 2348
Policy Loss: 0.0012, Value Loss: 3.7034, Entropy: 2.1238
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.052, sum=209.3
Extrinsic raw: Œº=0.08554074074074074

=== Iteration 851/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.80s
EPOCH 1 took 20.13s
update_step :  851
reward/intrinsic_batch_mean :  5.563979091013472e-05
reward/extrinsic_batch_mean :  0.08334074074074074
loss/policy :  0.001354778349526565
loss/rnd :  1.0258609625618027e-06
loss/value :  3.3650759747534087
loss/value_i :  1.8135035674910769e-06
loss/value_e :  3.365074173970656
loss/entropy :  2.1403060645768135
reward/intrinsic_running :  0.0007951265431565985
reward/extrinsic_running :  0.08334074074074074
reward/intrinsic_std_running :  0.01843051017884828
reward/extrinsic_std_running :  1.6240480592367215
reward/intrinsic_batch_std :  4.67819067082639e-05
reward/intrinsic_batch_max :  0.0006302503170445561
reward/intrinsic_batch_min :  4.629614977602614e-06
reward/total_batch :  0.04169819026582544
time/iteration_time :  117.05195999145508
time/fps :  2306.6679107270847
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.1s | FPS: 2307
Policy Loss: 0.0014, Value Loss: 3.3651, Entropy: 2.1403
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.034, sum=203.8
Extrinsic raw: Œº=0.08334074074074074

=== Iteration 852/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.97s
EPOCH 1 took 18.61s
update_step :  852
reward/intrinsic_batch_mean :  5.6627731634735365e-05
reward/extrinsic_batch_mean :  0.08376296296296297
loss/policy :  0.0011061630458712127
loss/rnd :  1.0426621744582834e-06
loss/value :  3.741673632101579
loss/value_i :  1.772504113046814e-06
loss/value_e :  3.7416718529932425
loss/entropy :  2.175026218096415
reward/intrinsic_running :  0.0007943037025966413
reward/extrinsic_running :  0.08376296296296297
reward/intrinsic_std_running :  0.018419706651360383
reward/extrinsic_std_running :  1.6426239361659427
reward/intrinsic_batch_std :  3.938811652010409e-05
reward/intrinsic_batch_max :  0.0005478893872350454
reward/intrinsic_batch_min :  7.300153356482042e-06
reward/total_batch :  0.04190979534729885
time/iteration_time :  113.8280098438263
time/fps :  2371.999654306914
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.8s | FPS: 2372
Policy Loss: 0.0011, Value Loss: 3.7417, Entropy: 2.1750
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.030, sum=207.5
Extrinsic raw: Œº=0.08376296296296297

=== Iteration 853/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.65s
EPOCH 1 took 20.46s
update_step :  853
reward/intrinsic_batch_mean :  6.55519073068313e-05
reward/extrinsic_batch_mean :  0.08288148148148149
loss/policy :  0.0016880210843572224
loss/rnd :  1.1867114291376448e-06
loss/value :  4.109111659454577
loss/value_i :  2.192988840003333e-06
loss/value_e :  4.109109452276519
loss/entropy :  2.0770554434169424
reward/intrinsic_running :  0.0007935019909486995
reward/extrinsic_running :  0.08288148148148149
reward/intrinsic_std_running :  0.018408921531431997
reward/extrinsic_std_running :  1.5754555816198261
reward/intrinsic_batch_std :  6.014941019218832e-05
reward/intrinsic_batch_max :  0.0009099759627133608
reward/intrinsic_batch_min :  6.848364591860445e-06
reward/total_batch :  0.04147351669439416
time/iteration_time :  116.38348507881165
time/fps :  2319.916780436361
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.4s | FPS: 2320
Policy Loss: 0.0017, Value Loss: 4.1091, Entropy: 2.0771
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.049, sum=240.4
Extrinsic raw: Œº=0.08288148148148149

=== Iteration 854/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.90s
EPOCH 1 took 19.33s
update_step :  854
reward/intrinsic_batch_mean :  5.810755437075083e-05
reward/extrinsic_batch_mean :  0.08258518518518519
loss/policy :  0.0011670744623353874
loss/rnd :  1.5154944959028922e-06
loss/value :  3.892616781321439
loss/value_i :  6.498930903572645e-06
loss/value_e :  3.89261028622136
loss/entropy :  2.149342822306084
reward/intrinsic_running :  0.0007926874826504904
reward/extrinsic_running :  0.08258518518518519
reward/intrinsic_std_running :  0.018398155745341455
reward/extrinsic_std_running :  1.620893118624033
reward/intrinsic_batch_std :  4.348526314264405e-05
reward/intrinsic_batch_max :  0.0010118576465174556
reward/intrinsic_batch_min :  9.079202754946891e-06
reward/total_batch :  0.04132164636977797
time/iteration_time :  115.2293918132782
time/fps :  2343.152174555582
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.2s | FPS: 2343
Policy Loss: 0.0012, Value Loss: 3.8926, Entropy: 2.1493
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.055, sum=213.2
Extrinsic raw: Œº=0.08258518518518519

=== Iteration 855/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.92s
EPOCH 1 took 19.56s
update_step :  855
reward/intrinsic_batch_mean :  7.198834221274377e-05
reward/extrinsic_batch_mean :  0.08565925925925925
loss/policy :  0.0013681627839987138
loss/rnd :  1.204750371167999e-06
loss/value :  4.56546058438041
loss/value_i :  1.3760823611102586e-06
loss/value_e :  4.565459175543352
loss/entropy :  2.1627474987145625
reward/intrinsic_running :  0.0007919007428861691
reward/extrinsic_running :  0.08565925925925925
reward/intrinsic_std_running :  0.018387407870050974
reward/extrinsic_std_running :  1.6393707833730689
reward/intrinsic_batch_std :  4.531032945538237e-05
reward/intrinsic_batch_max :  0.0009929054649546742
reward/intrinsic_batch_min :  1.994892954826355e-05
reward/total_batch :  0.042865623800736
time/iteration_time :  115.66435861587524
time/fps :  2334.3405283271227
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.7s | FPS: 2334
Policy Loss: 0.0014, Value Loss: 4.5655, Entropy: 2.1627
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.004, max=0.054, sum=264.3
Extrinsic raw: Œº=0.08565925925925925

=== Iteration 856/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.40s
EPOCH 1 took 19.51s
update_step :  856
reward/intrinsic_batch_mean :  5.022160465678435e-05
reward/extrinsic_batch_mean :  0.082
loss/policy :  0.0009464059672388954
loss/rnd :  9.143354020579864e-07
loss/value :  3.1454596790400418
loss/value_i :  1.2408421835888559e-06
loss/value_e :  3.1454584309549043
loss/entropy :  2.193045655886332
reward/intrinsic_running :  0.0007910738040072061
reward/extrinsic_running :  0.082
reward/intrinsic_std_running :  0.0183766803607615
reward/extrinsic_std_running :  1.619092704320906
reward/intrinsic_batch_std :  3.914888759367758e-05
reward/intrinsic_batch_max :  0.000592153868637979
reward/intrinsic_batch_min :  4.2501374082348775e-06
reward/total_batch :  0.041025110802328395
time/iteration_time :  116.17472267150879
time/fps :  2324.0855996139685
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.2s | FPS: 2324
Policy Loss: 0.0009, Value Loss: 3.1455, Entropy: 2.1930
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.032, sum=184.5
Extrinsic raw: Œº=0.082

=== Iteration 857/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.27s
EPOCH 1 took 19.46s
update_step :  857
reward/intrinsic_batch_mean :  5.187472610046421e-05
reward/extrinsic_batch_mean :  0.0848074074074074
loss/policy :  0.001561217823164594
loss/rnd :  9.529747823459426e-07
loss/value :  3.3755412661668025
loss/value_i :  1.3770247078630773e-06
loss/value_e :  3.375539877197959
loss/entropy :  2.1788312341227676
reward/intrinsic_running :  0.0007902519489806158
reward/extrinsic_running :  0.0848074074074074
reward/intrinsic_std_running :  0.018365971508993644
reward/extrinsic_std_running :  1.6366961753225615
reward/intrinsic_batch_std :  4.4621733596079986e-05
reward/intrinsic_batch_max :  0.0006346380687318742
reward/intrinsic_batch_min :  4.113494924240513e-06
reward/total_batch :  0.04242964106675393
time/iteration_time :  115.14694881439209
time/fps :  2344.8298264091995
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2345
Policy Loss: 0.0016, Value Loss: 3.3755, Entropy: 2.1788
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.035, sum=190.7
Extrinsic raw: Œº=0.0848074074074074

=== Iteration 858/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.00s
EPOCH 1 took 19.28s
update_step :  858
reward/intrinsic_batch_mean :  5.297282662060954e-05
reward/extrinsic_batch_mean :  0.08114074074074074
loss/policy :  0.0011137289966978697
loss/rnd :  9.71263540005759e-07
loss/value :  2.157514593817971
loss/value_i :  1.450799602204797e-06
loss/value_e :  2.1575131434382815
loss/entropy :  2.183577219645182
reward/intrinsic_running :  0.0007894329836375929
reward/extrinsic_running :  0.08114074074074074
reward/intrinsic_std_running :  0.01835528131220049
reward/extrinsic_std_running :  1.6071925933266042
reward/intrinsic_batch_std :  4.465039929523794e-05
reward/intrinsic_batch_max :  0.0006140978657640517
reward/intrinsic_batch_min :  3.473158585620695e-06
reward/total_batch :  0.04059685678368067
time/iteration_time :  116.31559777259827
time/fps :  2321.270794032809
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.3s | FPS: 2321
Policy Loss: 0.0011, Value Loss: 2.1575, Entropy: 2.1836
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=194.8
Extrinsic raw: Œº=0.08114074074074074

=== Iteration 859/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.40s
EPOCH 1 took 19.04s
update_step :  859
reward/intrinsic_batch_mean :  5.316867287580896e-05
reward/extrinsic_batch_mean :  0.08198518518518519
loss/policy :  0.002205855957458191
loss/rnd :  9.733753436400796e-07
loss/value :  4.138970340743209
loss/value_i :  1.3644457036813644e-06
loss/value_e :  4.138968948161963
loss/entropy :  2.1855598218513257
reward/intrinsic_running :  0.0007886168344354703
reward/extrinsic_running :  0.08198518518518519
reward/intrinsic_std_running :  0.018344609743831165
reward/extrinsic_std_running :  1.6190957420741812
reward/intrinsic_batch_std :  4.6604449046559576e-05
reward/intrinsic_batch_max :  0.0010555238695815206
reward/intrinsic_batch_min :  3.840971658064518e-06
reward/total_batch :  0.041019176929030496
time/iteration_time :  115.12202143669128
time/fps :  2345.3375525418505
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.1s | FPS: 2345
Policy Loss: 0.0022, Value Loss: 4.1390, Entropy: 2.1856
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.058, sum=195.6
Extrinsic raw: Œº=0.08198518518518519

=== Iteration 860/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.80s
EPOCH 1 took 18.46s
update_step :  860
reward/intrinsic_batch_mean :  5.378435342552755e-05
reward/extrinsic_batch_mean :  0.08067407407407408
loss/policy :  0.0013958033858657334
loss/rnd :  9.903260451155251e-07
loss/value :  3.301610148314274
loss/value_i :  1.411077593357649e-06
loss/value_e :  3.30160873225241
loss/entropy :  2.192578662525524
reward/intrinsic_running :  0.0007878029939859617
reward/extrinsic_running :  0.08067407407407408
reward/intrinsic_std_running :  0.01833395674158704
reward/extrinsic_std_running :  1.6150355543827632
reward/intrinsic_batch_std :  4.624193621699038e-05
reward/intrinsic_batch_max :  0.0006700345547869802
reward/intrinsic_batch_min :  3.5568998555390863e-06
reward/total_batch :  0.0403639292137498
time/iteration_time :  115.42144107818604
time/fps :  2339.253413212048
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.4s | FPS: 2339
Policy Loss: 0.0014, Value Loss: 3.3016, Entropy: 2.1926
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.037, sum=198.0
Extrinsic raw: Œº=0.08067407407407408

=== Iteration 861/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.28s
EPOCH 1 took 18.63s
update_step :  861
reward/intrinsic_batch_mean :  5.427270952534147e-05
reward/extrinsic_batch_mean :  0.08245925925925926
loss/policy :  0.0009740855558916475
loss/rnd :  9.962356092397717e-07
loss/value :  2.2145859490741384
loss/value_i :  1.4816480415902333e-06
loss/value_e :  2.2145844679890256
loss/entropy :  2.1851924802317764
reward/intrinsic_running :  0.0007869924641155273
reward/extrinsic_running :  0.08245925925925926
reward/intrinsic_std_running :  0.018323322214643688
reward/extrinsic_std_running :  1.6295558666134358
reward/intrinsic_batch_std :  4.379315216653495e-05
reward/intrinsic_batch_max :  0.0006562945782206953
reward/intrinsic_batch_min :  4.560273737297393e-06
reward/total_batch :  0.0412567659843923
time/iteration_time :  113.25685119628906
time/fps :  2383.9617396042063
data/episodes_collected :  60
data/frames_collected :  270000
Timer 113.3s | FPS: 2384
Policy Loss: 0.0010, Value Loss: 2.2146, Entropy: 2.1852
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.036, sum=199.9
Extrinsic raw: Œº=0.08245925925925926

=== Iteration 862/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.27s
EPOCH 1 took 19.20s
update_step :  862
reward/intrinsic_batch_mean :  5.2311172057664036e-05
reward/extrinsic_batch_mean :  0.0850888888888889
loss/policy :  0.000713648150188171
loss/rnd :  9.558806110279958e-07
loss/value :  3.933064988165191
loss/value_i :  1.3491344688962712e-06
loss/value_e :  3.9330635901653404
loss/entropy :  2.191481778115937
reward/intrinsic_running :  0.0007861790626734912
reward/extrinsic_running :  0.0850888888888889
reward/intrinsic_std_running :  0.018312706347791842
reward/extrinsic_std_running :  1.6466106241775318
reward/intrinsic_batch_std :  4.381941700546215e-05
reward/intrinsic_batch_max :  0.0005966668832115829
reward/intrinsic_batch_min :  4.2197252696496435e-06
reward/total_batch :  0.04257060003047328
time/iteration_time :  116.06334066390991
time/fps :  2326.315944858521
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.1s | FPS: 2326
Policy Loss: 0.0007, Value Loss: 3.9331, Entropy: 2.1915
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=192.8
Extrinsic raw: Œº=0.0850888888888889

=== Iteration 863/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.91s
EPOCH 1 took 18.62s
update_step :  863
reward/intrinsic_batch_mean :  5.364355607447646e-05
reward/extrinsic_batch_mean :  0.08555555555555555
loss/policy :  0.0016802695873510938
loss/rnd :  9.808006926491406e-07
loss/value :  2.987931901758367
loss/value_i :  1.4170655617817829e-06
loss/value_e :  2.987930482084101
loss/entropy :  2.184397589076649
reward/intrinsic_running :  0.0007853701256423341
reward/extrinsic_running :  0.08555555555555555
reward/intrinsic_std_running :  0.018302108820871545
reward/extrinsic_std_running :  1.6479321123497717
reward/intrinsic_batch_std :  4.5690027063647226e-05
reward/intrinsic_batch_max :  0.0005962765426374972
reward/intrinsic_batch_min :  4.446658749657217e-06
reward/total_batch :  0.04280459955581501
time/iteration_time :  114.41013193130493
time/fps :  2359.930850898027
data/episodes_collected :  60
data/frames_collected :  270000
Timer 114.4s | FPS: 2360
Policy Loss: 0.0017, Value Loss: 2.9879, Entropy: 2.1844
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=197.8
Extrinsic raw: Œº=0.08555555555555555

=== Iteration 864/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 20.31s
EPOCH 1 took 19.80s
update_step :  864
reward/intrinsic_batch_mean :  5.338011276995126e-05
reward/extrinsic_batch_mean :  0.08466666666666667
loss/policy :  0.0011902028698276615
loss/rnd :  9.865757239036943e-07
loss/value :  2.9352037184166186
loss/value_i :  1.3471195815685806e-06
loss/value_e :  2.935202367378004
loss/entropy :  2.188085509069038
reward/intrinsic_running :  0.0007845641111871854
reward/extrinsic_running :  0.08466666666666667
reward/intrinsic_std_running :  0.01829152963263316
reward/extrinsic_std_running :  1.6452789023951733
reward/intrinsic_batch_std :  4.4944207190769846e-05
reward/intrinsic_batch_max :  0.0008466139552183449
reward/intrinsic_batch_min :  4.052783879160415e-06
reward/total_batch :  0.04236002338971831
time/iteration_time :  117.26146459579468
time/fps :  2302.5467141375184
data/episodes_collected :  60
data/frames_collected :  270000
Timer 117.3s | FPS: 2303
Policy Loss: 0.0012, Value Loss: 2.9352, Entropy: 2.1881
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=197.0
Extrinsic raw: Œº=0.08466666666666667

=== Iteration 865/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.75s
EPOCH 1 took 18.71s
update_step :  865
reward/intrinsic_batch_mean :  5.7246231111161316e-05
reward/extrinsic_batch_mean :  0.08834814814814815
loss/policy :  0.0011856813430450998
loss/rnd :  1.0390490508667205e-06
loss/value :  3.561151865756873
loss/value_i :  1.6212339949451042e-06
loss/value_e :  3.561150267268672
loss/entropy :  2.1608011975432886
reward/intrinsic_running :  0.0007837668986899321
reward/extrinsic_running :  0.08834814814814815
reward/intrinsic_std_running :  0.01828096853690629
reward/extrinsic_std_running :  1.6741006908896818
reward/intrinsic_batch_std :  5.080779028978243e-05
reward/intrinsic_batch_max :  0.0007852364215068519
reward/intrinsic_batch_min :  4.273478225513827e-06
reward/total_batch :  0.04420269718962965
time/iteration_time :  115.16842794418335
time/fps :  2344.392511208507
data/episodes_collected :  60
data/frames_collected :  270000
Timer 115.2s | FPS: 2344
Policy Loss: 0.0012, Value Loss: 3.5612, Entropy: 2.1608
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.043, sum=211.4
Extrinsic raw: Œº=0.08834814814814815

=== Iteration 866/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.11s
EPOCH 1 took 20.37s
update_step :  866
reward/intrinsic_batch_mean :  5.317267398356678e-05
reward/extrinsic_batch_mean :  0.08593333333333333
loss/policy :  0.0013321172322541702
loss/rnd :  9.666143159158695e-07
loss/value :  5.4696495677485615
loss/value_i :  1.35196376049862e-06
loss/value_e :  5.469648151686697
loss/entropy :  2.174914757410685
reward/intrinsic_running :  0.000782963478524352
reward/extrinsic_running :  0.08593333333333333
reward/intrinsic_std_running :  0.018270425979758656
reward/extrinsic_std_running :  1.6492705175319178
reward/intrinsic_batch_std :  4.395588935671796e-05
reward/intrinsic_batch_max :  0.0007545059197582304
reward/intrinsic_batch_min :  4.394615189085016e-06
reward/total_batch :  0.04299325300365845
time/iteration_time :  116.06995964050293
time/fps :  2326.183284945184
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.1s | FPS: 2326
Policy Loss: 0.0013, Value Loss: 5.4696, Entropy: 2.1749
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.041, sum=196.4
Extrinsic raw: Œº=0.08593333333333333

=== Iteration 867/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.30s
EPOCH 1 took 19.32s
update_step :  867
reward/intrinsic_batch_mean :  5.315071361232926e-05
reward/extrinsic_batch_mean :  0.0850888888888889
loss/policy :  0.0013284012975142987
loss/rnd :  9.7032867246884e-07
loss/value :  3.1922837098439536
loss/value_i :  1.3657269922380995e-06
loss/value_e :  3.19228232087511
loss/entropy :  2.1920333631110913
reward/intrinsic_running :  0.0007821622979182872
reward/extrinsic_running :  0.0850888888888889
reward/intrinsic_std_running :  0.018259901628075614
reward/extrinsic_std_running :  1.6466106241775318
reward/intrinsic_batch_std :  4.3024353367878104e-05
reward/intrinsic_batch_max :  0.000611617520917207
reward/intrinsic_batch_min :  4.1489229261060245e-06
reward/total_batch :  0.04257101980125061
time/iteration_time :  116.55743479728699
time/fps :  2316.4545485200106
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.6s | FPS: 2316
Policy Loss: 0.0013, Value Loss: 3.1923, Entropy: 2.1920
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.033, sum=196.5
Extrinsic raw: Œº=0.0850888888888889

=== Iteration 868/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 19.00s
EPOCH 1 took 20.12s
update_step :  868
reward/intrinsic_batch_mean :  5.268225124130334e-05
reward/extrinsic_batch_mean :  0.08771111111111111
loss/policy :  0.0011288903223237758
loss/rnd :  9.580615870742226e-07
loss/value :  4.931051312070904
loss/value_i :  1.2483595603705246e-06
loss/value_e :  4.931049993543914
loss/entropy :  2.183302398883935
reward/intrinsic_running :  0.0007813614210386109
reward/extrinsic_running :  0.08771111111111111
reward/intrinsic_std_running :  0.018249395501145856
reward/extrinsic_std_running :  1.6634878857908284
reward/intrinsic_batch_std :  4.410985777209358e-05
reward/intrinsic_batch_max :  0.0008414943586103618
reward/intrinsic_batch_min :  4.693099981523119e-06
reward/total_batch :  0.04388189668117621
time/iteration_time :  116.87315917015076
time/fps :  2310.1968143679446
data/episodes_collected :  60
data/frames_collected :  270000
Timer 116.9s | FPS: 2310
Policy Loss: 0.0011, Value Loss: 4.9311, Entropy: 2.1833
RND Loss: 0.0000
--------------------------------
Iteration Rollout Rewards:
Intrinsic scaled: Œº=0.003, max=0.046, sum=194.9
Extrinsic raw: Œº=0.08771111111111111

=== Iteration 869/1000 ===
Collected 60 episodes, 270000 frames
EPOCH 0 took 18.71s
EPOCH 1 took 19.93s
update_step :  869
reward/intrinsic_batch_mean :  5.240140344674189e-05
reward/extrinsic_batch_mean :  0.08549629629629629
loss/policy :  0.0013033429042314476
loss/rnd :  9.56994172742215e-07
loss/value :  5.253729495135221
loss/value_i :  1.3539789819967127e-06
loss/value_e :  5.253728100747773
loss/entropy :  2.1700153423078135
reward/intrinsic_running :  0.0007805624777204579
reward/extrinsic_running